{
  "CWE-022": {
    "tempfile.TemporaryDirectory": {
      "transformers/tests/models/roberta/test_modeling_roberta.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          516,
          628,
          565,
          18,
          565,
          46,
          565,
          18,
          572,
          60
        ]
      ],
      "transformers/tests/models/roberta_prelayernorm/test_modeling_roberta_prelayernorm.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          526,
          638,
          575,
          18,
          575,
          46,
          575,
          18,
          582,
          60
        ]
      ],
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUpClass",
          1066,
          1077,
          1067,
          24,
          1067,
          52,
          1066,
          20,
          1077,
          38
        ],
        [
          "test_rag_sequence_from_pretrained",
          1116,
          1172,
          1136,
          14,
          1136,
          42,
          1116,
          43,
          1172,
          82
        ],
        [
          "test_rag_token_from_pretrained",
          1175,
          1236,
          1195,
          14,
          1195,
          42,
          1175,
          40,
          1236,
          82
        ],
        [
          "setUpClass",
          685,
          696,
          686,
          24,
          686,
          52,
          685,
          20,
          696,
          38
        ]
      ],
      "transformers/tests/models/roc_bert/test_modeling_roc_bert.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          701,
          813,
          750,
          18,
          750,
          46,
          750,
          18,
          757,
          60
        ]
      ],
      "transformers/tests/models/rt_detr/test_modeling_rt_detr.py": [
        [
          "test_inference_equivalence_for_static_and_dynamic_anchors",
          616,
          653,
          632,
          18,
          632,
          46,
          631,
          13,
          653,
          13
        ]
      ],
      "transformers/tests/models/rt_detr_v2/test_modeling_rt_detr_v2.py": [
        [
          "test_inference_equivalence_for_static_and_dynamic_anchors",
          620,
          657,
          636,
          18,
          636,
          46,
          635,
          13,
          657,
          13
        ]
      ],
      "transformers/tests/models/sam/test_modeling_sam.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          663,
          718,
          684,
          18,
          684,
          46,
          680,
          13,
          693,
          58
        ]
      ],
      "transformers/tests/models/sam2/test_modeling_sam2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          559,
          605,
          580,
          18,
          580,
          46,
          576,
          13,
          598,
          66
        ],
        [
          "flash_attn_inference_equivalence",
          608,
          696,
          627,
          18,
          627,
          46,
          624,
          35,
          638,
          70
        ]
      ],
      "transformers/tests/models/sam_hq/test_modeling_sam_hq.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          711,
          765,
          732,
          18,
          732,
          46,
          728,
          13,
          741,
          58
        ]
      ],
      "transformers/tests/models/siglip/test_modeling_siglip.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          62,
          88,
          67,
          18,
          67,
          46,
          63,
          13,
          79,
          50
        ],
        [
          "_create_and_check_torchscript",
          491,
          560,
          510,
          18,
          510,
          46,
          510,
          18,
          514,
          25
        ],
        [
          "test_load_vision_text_config",
          563,
          576,
          567,
          14,
          567,
          42,
          563,
          38,
          576,
          85
        ],
        [
          "test_load_vision_text_config",
          563,
          576,
          573,
          14,
          573,
          42,
          563,
          38,
          576,
          85
        ]
      ],
      "transformers/tests/models/speech_encoder_decoder/test_modeling_speech_encoder_decoder.py": [
        [
          "check_save_and_load",
          198,
          239,
          224,
          18,
          224,
          46,
          199,
          9,
          239,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          241,
          288,
          268,
          17,
          268,
          45,
          242,
          9,
          288,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          241,
          288,
          269,
          17,
          269,
          45,
          242,
          9,
          288,
          52
        ],
        [
          "test_real_model_save_load_from_pretrained",
          437,
          455,
          446,
          18,
          446,
          46,
          437,
          51,
          455,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          458,
          506,
          466,
          14,
          466,
          42,
          458,
          49,
          473,
          65
        ]
      ],
      "transformers/tests/models/siglip2/test_modeling_siglip2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          64,
          90,
          69,
          18,
          69,
          46,
          65,
          13,
          81,
          50
        ],
        [
          "test_flash_attn_2_inference_equivalence",
          96,
          159,
          118,
          18,
          118,
          46,
          118,
          18,
          148,
          41
        ],
        [
          "test_load_vision_text_config",
          583,
          596,
          587,
          14,
          587,
          42,
          583,
          38,
          596,
          85
        ],
        [
          "test_load_vision_text_config",
          583,
          596,
          593,
          14,
          593,
          42,
          583,
          38,
          596,
          85
        ]
      ],
      "transformers/tests/models/speech_to_text/test_modeling_speech_to_text.py": [
        [
          "check_encoder_decoder_model_standalone",
          222,
          256,
          229,
          14,
          229,
          42,
          222,
          48,
          256,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          222,
          256,
          240,
          14,
          240,
          42,
          222,
          48,
          256,
          99
        ],
        [
          "test_save_load_strict",
          280,
          288,
          285,
          18,
          285,
          46,
          282,
          13,
          288,
          54
        ],
        [
          "_create_and_check_torchscript",
          606,
          680,
          630,
          18,
          630,
          46,
          630,
          18,
          634,
          25
        ]
      ],
      "transformers/tests/models/speecht5/test_modeling_speecht5.py": [
        [
          "test_save_load_strict",
          365,
          373,
          370,
          18,
          370,
          46,
          367,
          13,
          373,
          54
        ],
        [
          "test_save_load_strict",
          871,
          879,
          876,
          18,
          876,
          46,
          873,
          13,
          879,
          54
        ],
        [
          "test_save_load_strict",
          1387,
          1395,
          1392,
          18,
          1392,
          46,
          1389,
          13,
          1395,
          54
        ]
      ],
      "transformers/tests/models/switch_transformers/test_modeling_switch_transformers.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          447,
          521,
          495,
          18,
          495,
          46,
          456,
          13,
          521,
          17
        ]
      ],
      "transformers/tests/models/time_series_transformer/test_modeling_time_series_transformer.py": [
        [
          "check_encoder_decoder_model_standalone",
          144,
          174,
          151,
          14,
          151,
          42,
          144,
          48,
          174,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          144,
          174,
          164,
          14,
          164,
          42,
          144,
          48,
          174,
          99
        ],
        [
          "test_save_load_strict",
          201,
          209,
          206,
          18,
          206,
          46,
          203,
          13,
          209,
          54
        ]
      ],
      "transformers/tests/models/t5/test_modeling_t5.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          443,
          517,
          491,
          18,
          491,
          46,
          452,
          13,
          517,
          17
        ],
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          693,
          18,
          693,
          46,
          693,
          18,
          696,
          50
        ]
      ],
      "transformers/tests/models/umt5/test_modeling_umt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          381,
          18,
          381,
          46,
          381,
          18,
          384,
          50
        ]
      ],
      "transformers/tests/models/timm_wrapper/test_modeling_timm_wrapper.py": [
        [
          "test_timm_config_labels",
          198,
          244,
          238,
          14,
          238,
          42,
          198,
          33,
          244,
          67
        ],
        [
          "test_model_init_args",
          246,
          262,
          259,
          14,
          259,
          42,
          246,
          30,
          262,
          70
        ],
        [
          "test_save_load_to_timm",
          428,
          452,
          435,
          14,
          435,
          42,
          428,
          32,
          447,
          9
        ]
      ],
      "transformers/tests/models/videomae/test_modeling_videomae.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          357,
          399,
          371,
          18,
          371,
          46,
          365,
          35,
          386,
          58
        ]
      ],
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_offline",
          276,
          322,
          290,
          22,
          290,
          50,
          290,
          22,
          290,
          50
        ],
        [
          "test_local_files_only",
          324,
          364,
          335,
          22,
          335,
          50,
          335,
          22,
          335,
          50
        ],
        [
          "test_model_from_pretrained_subfolder",
          454,
          467,
          459,
          14,
          459,
          42,
          454,
          46,
          467,
          64
        ],
        [
          "test_model_manually_shared_disjointed_tensors_optimum",
          469,
          487,
          483,
          14,
          483,
          42,
          469,
          63,
          487,
          64
        ],
        [
          "test_model_from_pretrained_subfolder_sharded",
          489,
          502,
          494,
          14,
          494,
          42,
          489,
          54,
          502,
          64
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          787,
          14,
          787,
          42,
          784,
          44,
          789,
          54
        ],
        [
          "test_checkpoint_variant_local_bin",
          834,
          852,
          837,
          14,
          837,
          42,
          834,
          43,
          851,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          857,
          14,
          857,
          42,
          854,
          51,
          865,
          32
        ],
        [
          "test_checkpoint_variant_local_safe",
          878,
          896,
          881,
          14,
          881,
          42,
          878,
          44,
          895,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          901,
          14,
          901,
          42,
          898,
          52,
          909,
          32
        ],
        [
          "test_checkpoint_loading_only_safetensors_available",
          922,
          953,
          930,
          14,
          930,
          42,
          922,
          60,
          937,
          32
        ],
        [
          "test_checkpoint_loading_only_pytorch_bin_available",
          955,
          986,
          963,
          14,
          963,
          42,
          955,
          60,
          970,
          32
        ],
        [
          "test_checkpoint_variant_hub",
          988,
          995,
          989,
          14,
          989,
          42,
          988,
          37,
          995,
          35
        ],
        [
          "test_checkpoint_variant_hub_sharded",
          997,
          1006,
          998,
          14,
          998,
          42,
          997,
          45,
          1006,
          35
        ],
        [
          "test_checkpoint_variant_hub_safe",
          1008,
          1015,
          1009,
          14,
          1009,
          42,
          1008,
          42,
          1015,
          35
        ],
        [
          "test_checkpoint_variant_hub_sharded_safe",
          1017,
          1026,
          1018,
          14,
          1018,
          42,
          1017,
          50,
          1026,
          35
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1029,
          14,
          1029,
          42,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_from_pretrained_disk_offload_task_model",
          1071,
          1107,
          1084,
          14,
          1084,
          42,
          1071,
          54,
          1107,
          84
        ],
        [
          "test_from_pretrained_disk_offload_derived_to_base_model",
          1112,
          1147,
          1125,
          14,
          1125,
          42,
          1112,
          65,
          1147,
          76
        ],
        [
          "test_from_pretrained_non_contiguous_checkpoint",
          1151,
          1164,
          1162,
          14,
          1162,
          42,
          1151,
          56,
          1164,
          67
        ],
        [
          "test_save_model_with_device_map_cpu",
          1187,
          1200,
          1191,
          14,
          1191,
          42,
          1187,
          45,
          1200,
          62
        ],
        [
          "test_save_offloaded_model",
          1205,
          1237,
          1224,
          14,
          1224,
          42,
          1205,
          35,
          1237,
          69
        ],
        [
          "test_save_offloaded_model_with_direct_params",
          1242,
          1250,
          1249,
          14,
          1249,
          42,
          1242,
          54,
          1250,
          42
        ],
        [
          "test_save_offloaded_model_dynamic_tied_weights_keys",
          1255,
          1273,
          1272,
          14,
          1272,
          42,
          1255,
          61,
          1273,
          42
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1286,
          14,
          1286,
          42,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1299,
          14,
          1299,
          42,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1321,
          18,
          1321,
          46,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_safetensors_save_and_load",
          1331,
          1343,
          1333,
          14,
          1333,
          42,
          1331,
          40,
          1342,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1355,
          14,
          1355,
          42,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_base_model_to_head_model_load",
          1378,
          1398,
          1380,
          14,
          1380,
          42,
          1378,
          44,
          1385,
          79
        ],
        [
          "test_tied_weights_reload",
          1400,
          1422,
          1403,
          14,
          1403,
          42,
          1400,
          34,
          1422,
          77
        ],
        [
          "test_unexpected_keys_warnings",
          1424,
          1448,
          1427,
          14,
          1427,
          42,
          1424,
          39,
          1448,
          76
        ],
        [
          "test_safetensors_torch_from_torch",
          1583,
          1591,
          1586,
          14,
          1586,
          42,
          1583,
          43,
          1590,
          69
        ],
        [
          "test_safetensors_torch_from_torch_sharded",
          1593,
          1601,
          1596,
          14,
          1596,
          42,
          1593,
          51,
          1600,
          69
        ],
        [
          "test_modifying_model_config_gets_moved_to_generation_config",
          1603,
          1626,
          1616,
          18,
          1616,
          46,
          1603,
          69,
          1626,
          77
        ],
        [
          "test_model_from_pretrained_from_mlx",
          1628,
          1645,
          1634,
          14,
          1634,
          42,
          1628,
          45,
          1645,
          87
        ],
        [
          "test_warning_for_beta_gamma_parameters",
          1647,
          1670,
          1654,
          14,
          1654,
          42,
          1647,
          48,
          1670,
          56
        ],
        [
          "test_save_and_load_config_with_custom_generation",
          1747,
          1777,
          1763,
          14,
          1763,
          42,
          1747,
          58,
          1777,
          40
        ],
        [
          "test_unknown_quantization_config",
          1887,
          1898,
          1888,
          14,
          1888,
          42,
          1887,
          42,
          1898,
          95
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          1994,
          14,
          1994,
          42,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2020,
          14,
          2020,
          42,
          2006,
          66,
          2030,
          85
        ],
        [
          "test_ignore_missing_key_works",
          2063,
          2084,
          2066,
          16,
          2066,
          44,
          2063,
          39,
          2083,
          46
        ],
        [
          "test_device_map_works_with_unexpected_keys",
          2086,
          2107,
          2090,
          16,
          2090,
          44,
          2086,
          52,
          2107,
          112
        ],
        [
          "test_device_map_works_with_unexpected_keys_sharded",
          2109,
          2147,
          2113,
          16,
          2113,
          44,
          2109,
          60,
          2139,
          54
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          2409,
          2421,
          2416,
          18,
          2416,
          46,
          2409,
          46,
          2420,
          73
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          2455,
          2467,
          2462,
          18,
          2462,
          46,
          2455,
          62,
          2466,
          73
        ],
        [
          "test_save_and_load_model_with_tensor_extra_state",
          2968,
          3002,
          2999,
          14,
          2999,
          42,
          2968,
          58,
          3002,
          61
        ],
        [
          "test_save_and_load_model_with_dict_extra_state",
          3005,
          3039,
          3036,
          14,
          3036,
          42,
          3005,
          56,
          3039,
          61
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_modeling_vision_text_dual_encoder.py": [
        [
          "check_save_load",
          114,
          132,
          124,
          18,
          124,
          46,
          114,
          25,
          132,
          52
        ],
        [
          "test_real_model_save_load_from_pretrained",
          188,
          204,
          196,
          18,
          196,
          46,
          188,
          51,
          204,
          52
        ]
      ],
      "transformers/tests/models/vit_mae/test_modeling_vit_mae.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          271,
          317,
          285,
          18,
          285,
          46,
          279,
          35,
          304,
          58
        ],
        [
          "test_save_load",
          215,
          243,
          230,
          18,
          230,
          46,
          218,
          13,
          243,
          52
        ]
      ],
      "transformers/tests/models/vision_encoder_decoder/test_modeling_vision_encoder_decoder.py": [
        [
          "check_save_and_load",
          170,
          199,
          186,
          18,
          186,
          46,
          171,
          9,
          199,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          201,
          236,
          218,
          17,
          218,
          45,
          202,
          9,
          236,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          201,
          236,
          219,
          17,
          219,
          45,
          202,
          9,
          236,
          52
        ],
        [
          "test_real_model_save_load_from_pretrained",
          375,
          393,
          384,
          18,
          384,
          46,
          375,
          51,
          393,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          396,
          447,
          407,
          14,
          407,
          42,
          400,
          23,
          414,
          65
        ]
      ],
      "transformers/tests/models/vits/test_modeling_vits.py": [
        [
          "test_save_load",
          309,
          349,
          330,
          18,
          330,
          46,
          322,
          13,
          345,
          39
        ]
      ],
      "transformers/tests/models/voxtral/test_modeling_voxtral.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          191,
          226,
          203,
          18,
          203,
          46,
          199,
          13,
          208,
          73
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_modeling_wav2vec2_bert.py": [
        [
          "create_and_check_model_float16",
          231,
          246,
          234,
          14,
          234,
          42,
          231,
          40,
          246,
          9
        ]
      ],
      "transformers/tests/models/wav2vec2_conformer/test_modeling_wav2vec2_conformer.py": [
        [
          "create_and_check_model_float16",
          224,
          239,
          227,
          14,
          227,
          42,
          224,
          40,
          239,
          9
        ]
      ],
      "transformers/tests/models/x_clip/test_modeling_x_clip.py": [
        [
          "_create_and_check_torchscript",
          564,
          633,
          583,
          18,
          583,
          46,
          583,
          18,
          587,
          25
        ],
        [
          "test_load_vision_text_config",
          635,
          648,
          639,
          14,
          639,
          42,
          635,
          38,
          648,
          85
        ],
        [
          "test_load_vision_text_config",
          635,
          648,
          645,
          14,
          645,
          42,
          635,
          38,
          648,
          85
        ]
      ],
      "transformers/tests/models/wav2vec2/test_modeling_wav2vec2.py": [
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          759,
          18,
          759,
          46,
          759,
          18,
          762,
          50
        ],
        [
          "test_load_attn_adapter",
          1123,
          1200,
          1148,
          14,
          1148,
          42,
          1123,
          32,
          1200,
          74
        ],
        [
          "test_load_attn_adapter",
          1123,
          1200,
          1170,
          14,
          1170,
          42,
          1123,
          32,
          1200,
          74
        ]
      ],
      "transformers/tests/models/whisper/test_modeling_whisper.py": [
        [
          "check_encoder_decoder_model_standalone",
          321,
          348,
          328,
          14,
          328,
          42,
          321,
          48,
          348,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          321,
          348,
          337,
          14,
          337,
          42,
          321,
          48,
          348,
          99
        ],
        [
          "test_save_load_strict",
          418,
          426,
          423,
          18,
          423,
          46,
          420,
          13,
          426,
          54
        ],
        [
          "_create_and_check_torchscript",
          846,
          928,
          878,
          18,
          878,
          46,
          878,
          18,
          882,
          25
        ]
      ],
      "transformers/tests/models/xcodec/test_modeling_xcodec.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          207,
          18,
          207,
          46,
          207,
          18,
          211,
          25
        ]
      ],
      "transformers/tests/models/xlm_roberta_xl/test_modeling_xlm_roberta_xl.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          517,
          629,
          566,
          18,
          566,
          46,
          566,
          18,
          573,
          60
        ],
        [
          "flash_attn_inference_equivalence",
          631,
          733,
          647,
          18,
          647,
          46,
          642,
          13,
          658,
          70
        ]
      ],
      "transformers/tests/models/xmod/test_modeling_xmod.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          531,
          643,
          580,
          18,
          580,
          46,
          580,
          18,
          587,
          60
        ]
      ],
      "transformers/tests/models/zamba/test_modeling_zamba.py": [
        [
          "test_flash_attn_2_fp32_ln",
          435,
          466,
          444,
          18,
          444,
          46,
          440,
          13,
          459,
          56
        ]
      ],
      "transformers/tests/models/zamba2/test_modeling_zamba2.py": [
        [
          "test_flash_attn_2_fp32_ln",
          465,
          496,
          474,
          18,
          474,
          46,
          470,
          13,
          489,
          56
        ]
      ],
      "transformers/tests/quantization/mxfp4/test_mxfp4.py": [
        [
          "test_save_mxfp4",
          470,
          499,
          479,
          14,
          479,
          42,
          470,
          25,
          499,
          79
        ],
        [
          "test_save_mxfp4_non_quantized",
          501,
          530,
          512,
          14,
          512,
          42,
          501,
          39,
          530,
          79
        ]
      ],
      "transformers/tests/optimization/test_optimization.py": [
        [
          "unwrap_and_save_reload_schedule",
          50,
          62,
          56,
          18,
          56,
          46,
          56,
          18,
          61,
          53
        ]
      ],
      "transformers/tests/peft_integration/test_peft_integration.py": [
        [
          "test_peft_save_pretrained",
          122,
          149,
          131,
          22,
          131,
          50,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_add_adapter_from_pretrained",
          198,
          216,
          213,
          22,
          213,
          50,
          205,
          17,
          216,
          96
        ],
        [
          "test_peft_add_multi_adapter",
          302,
          364,
          363,
          53,
          363,
          81,
          334,
          17,
          364,
          53
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          531,
          22,
          531,
          50,
          521,
          17,
          536,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          550,
          22,
          550,
          50,
          540,
          17,
          556,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          577,
          22,
          577,
          50,
          567,
          17,
          582,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          596,
          22,
          596,
          50,
          586,
          17,
          602,
          86
        ],
        [
          "test_peft_load_adapter_training_inference_mode_true",
          787,
          802,
          796,
          22,
          796,
          50,
          793,
          17,
          800,
          79
        ],
        [
          "test_peft_load_adapter_training_inference_mode_false",
          804,
          828,
          813,
          22,
          813,
          50,
          810,
          17,
          818,
          61
        ],
        [
          "test_prefix_tuning_trainer_load_best_model_at_end_error",
          830,
          901,
          879,
          18,
          879,
          46,
          874,
          13,
          894,
          38
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_common.py": [
        [
          "test_pipeline_pathlike",
          126,
          132,
          128,
          14,
          128,
          42,
          126,
          32,
          132,
          66
        ],
        [
          "test_auto_model_pipeline_registration_from_local_dir",
          210,
          215,
          211,
          14,
          211,
          42,
          210,
          62,
          215,
          63
        ],
        [
          "test_dynamic_pipeline",
          749,
          796,
          761,
          14,
          761,
          42,
          753,
          22,
          769,
          93
        ],
        [
          "test_push_to_hub_dynamic_pipeline",
          886,
          964,
          900,
          14,
          900,
          42,
          886,
          43,
          964,
          9
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_segmentation.py": [
        [
          "test_save_load",
          751,
          763,
          761,
          14,
          761,
          42,
          751,
          24,
          763,
          65
        ]
      ],
      "transformers/tests/models/blip_2/test_processing_blip_2.py": [
        [
          "test_save_load_pretrained_additional_features",
          58,
          74,
          59,
          14,
          59,
          42,
          58,
          55,
          74,
          76
        ]
      ],
      "transformers/tests/models/blip/test_processing_blip.py": [
        [
          "test_save_load_pretrained_additional_features",
          55,
          71,
          56,
          14,
          56,
          42,
          55,
          55,
          71,
          76
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "test_save_load_pretrained_additional_features",
          127,
          145,
          128,
          14,
          128,
          42,
          127,
          55,
          145,
          83
        ],
        [
          "test_save_load_pretrained_default",
          102,
          125,
          107,
          14,
          107,
          42,
          102,
          43,
          125,
          88
        ]
      ],
      "transformers/tests/models/clip/test_processing_clip.py": [
        [
          "test_save_load_pretrained_default",
          66,
          89,
          71,
          14,
          71,
          42,
          66,
          43,
          89,
          81
        ],
        [
          "test_save_load_pretrained_additional_features",
          91,
          109,
          92,
          14,
          92,
          42,
          91,
          55,
          109,
          76
        ]
      ],
      "transformers/tests/test_processing_common.py": [
        [
          "test_processor_from_and_save_pretrained",
          202,
          219,
          205,
          14,
          205,
          42,
          202,
          49,
          207,
          35
        ],
        [
          "test_processor_from_and_save_pretrained_as_nested_dict",
          221,
          249,
          224,
          14,
          224,
          42,
          221,
          64,
          234,
          55
        ],
        [
          "test_args_overlap_kwargs",
          511,
          521,
          518,
          14,
          518,
          42,
          514,
          27,
          521,
          73
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          947,
          14,
          947,
          42,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          957,
          14,
          957,
          42,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          968,
          14,
          968,
          42,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          982,
          18,
          982,
          46,
          945,
          39,
          984,
          77
        ]
      ],
      "transformers/tests/models/git/test_processing_git.py": [
        [
          "test_save_load_pretrained_additional_features",
          57,
          73,
          58,
          14,
          58,
          42,
          57,
          55,
          73,
          76
        ]
      ],
      "transformers/tests/models/idefics/test_processing_idefics.py": [
        [
          "test_save_load_pretrained_additional_features",
          111,
          127,
          112,
          14,
          112,
          42,
          111,
          55,
          127,
          79
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "test_save_load_pretrained_default",
          149,
          172,
          154,
          14,
          154,
          42,
          149,
          43,
          172,
          90
        ],
        [
          "test_save_load_pretrained_additional_features",
          175,
          195,
          176,
          14,
          176,
          42,
          175,
          55,
          195,
          85
        ]
      ],
      "transformers/tests/models/instructblip/test_processing_instructblip.py": [
        [
          "test_save_load_pretrained_additional_features",
          69,
          90,
          75,
          14,
          75,
          42,
          69,
          55,
          90,
          77
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_processing_instructblipvideo.py": [
        [
          "test_save_load_pretrained_additional_features",
          72,
          93,
          78,
          14,
          78,
          42,
          72,
          55,
          93,
          77
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "test_save_load_pretrained_default",
          89,
          103,
          95,
          18,
          95,
          46,
          92,
          13,
          103,
          86
        ],
        [
          "test_save_load_pretrained_additional_features",
          105,
          141,
          106,
          14,
          106,
          42,
          105,
          55,
          141,
          82
        ]
      ],
      "transformers/tests/models/kosmos2/test_processing_kosmos2.py": [
        [
          "test_image_processor_load_save_reload",
          100,
          107,
          103,
          14,
          103,
          33,
          100,
          47,
          106,
          82
        ],
        [
          "test_save_load_pretrained_additional_features",
          109,
          125,
          110,
          14,
          110,
          42,
          109,
          55,
          125,
          76
        ]
      ],
      "transformers/tests/models/omdet_turbo/test_processing_omdet_turbo.py": [
        [
          "test_save_load_pretrained_additional_features",
          116,
          132,
          117,
          14,
          117,
          42,
          116,
          55,
          132,
          76
        ]
      ],
      "transformers/tests/models/oneformer/test_processing_oneformer.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          404,
          414,
          407,
          14,
          407,
          42,
          404,
          52,
          414,
          74
        ]
      ],
      "transformers/tests/models/pix2struct/test_processing_pix2struct.py": [
        [
          "test_save_load_pretrained_additional_features",
          64,
          80,
          65,
          14,
          65,
          42,
          64,
          55,
          80,
          82
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_processing_qwen2_audio.py": [
        [
          "test_save_load_pretrained_default",
          56,
          69,
          63,
          14,
          63,
          42,
          56,
          43,
          69,
          83
        ]
      ],
      "transformers/tests/models/pop2piano/test_processing_pop2piano.py": [
        [
          "test_save_load_pretrained_additional_features",
          85,
          113,
          86,
          14,
          86,
          42,
          85,
          55,
          113,
          85
        ]
      ],
      "transformers/tests/models/sam/test_processing_sam.py": [
        [
          "test_save_load_pretrained_additional_features",
          79,
          89,
          80,
          14,
          80,
          42,
          79,
          55,
          89,
          75
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "test_save_load_pretrained_default",
          54,
          66,
          55,
          14,
          55,
          42,
          54,
          43,
          66,
          102
        ],
        [
          "test_save_load_pretrained_additional_features",
          68,
          83,
          69,
          14,
          69,
          42,
          68,
          55,
          83,
          75
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "test_save_load_pretrained_additional_features",
          92,
          112,
          93,
          14,
          93,
          42,
          92,
          55,
          112,
          84
        ]
      ],
      "transformers/tests/models/speech_to_text/test_processing_speech_to_text.py": [
        [
          "test_save_load_pretrained_additional_features",
          85,
          105,
          86,
          14,
          86,
          42,
          85,
          55,
          105,
          87
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "test_save_load_pretrained_additional_features",
          92,
          110,
          93,
          14,
          93,
          42,
          92,
          55,
          110,
          100
        ],
        [
          "test_save_load_pretrained_default",
          77,
          90,
          82,
          14,
          82,
          42,
          77,
          43,
          90,
          100
        ]
      ],
      "transformers/tests/models/udop/test_processing_udop.py": [
        [
          "test_save_load_pretrained_additional_features",
          111,
          147,
          112,
          14,
          112,
          42,
          111,
          55,
          147,
          82
        ],
        [
          "test_save_load_pretrained_default",
          96,
          109,
          101,
          18,
          101,
          46,
          99,
          13,
          109,
          86
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "test_save_load_pretrained_default",
          78,
          92,
          84,
          14,
          84,
          42,
          78,
          43,
          92,
          84
        ],
        [
          "test_save_load_pretrained_additional_features",
          94,
          116,
          95,
          14,
          95,
          42,
          94,
          55,
          116,
          84
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "test_save_load_pretrained_default",
          79,
          93,
          85,
          14,
          85,
          42,
          79,
          43,
          93,
          87
        ],
        [
          "test_save_load_pretrained_additional_features",
          95,
          117,
          96,
          14,
          96,
          42,
          95,
          55,
          117,
          87
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_processor_kosmos2_5.py": [
        [
          "test_image_procesor_load_save_reload",
          68,
          75,
          71,
          14,
          71,
          33,
          68,
          46,
          74,
          82
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_new_processor_registration",
          234,
          270,
          255,
          18,
          255,
          46,
          255,
          18,
          255,
          46
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          126,
          14,
          126,
          42,
          125,
          55,
          135,
          71
        ],
        [
          "test_processor_from_local_directory_from_repo",
          74,
          85,
          75,
          14,
          75,
          42,
          74,
          55,
          85,
          59
        ],
        [
          "test_processor_from_local_directory_from_extractor_config",
          87,
          95,
          88,
          14,
          88,
          42,
          87,
          67,
          95,
          59
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          98,
          14,
          98,
          42,
          97,
          45,
          107,
          75
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          157,
          14,
          157,
          42,
          156,
          55,
          166,
          71
        ],
        [
          "test_processor_from_local_directory_from_model_config",
          187,
          199,
          188,
          14,
          188,
          42,
          187,
          63,
          199,
          59
        ],
        [
          "test_new_processor_registration",
          234,
          270,
          247,
          18,
          247,
          46,
          247,
          18,
          247,
          46
        ],
        [
          "test_auto_processor_save_load",
          411,
          416,
          413,
          14,
          413,
          42,
          411,
          39,
          416,
          95
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          427,
          437,
          431,
          18,
          431,
          46,
          427,
          46,
          435,
          68
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          439,
          454,
          443,
          18,
          443,
          46,
          439,
          62,
          452,
          68
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          464,
          18,
          464,
          46,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          472,
          18,
          472,
          46,
          456,
          44,
          505,
          85
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "test_canonical_hf_index_retriever_save_and_from_pretrained",
          191,
          203,
          193,
          14,
          193,
          42,
          191,
          68,
          203,
          48
        ],
        [
          "test_custom_hf_index_retriever_save_and_from_pretrained",
          220,
          230,
          222,
          14,
          222,
          42,
          220,
          65,
          230,
          44
        ],
        [
          "test_custom_hf_index_retriever_save_and_from_pretrained_from_disk",
          247,
          257,
          249,
          14,
          249,
          42,
          247,
          75,
          257,
          44
        ]
      ],
      "transformers/tests/quantization/quanto_integration/test_quanto.py": [
        [
          "test_serialization_safetensors",
          235,
          244,
          239,
          14,
          239,
          42,
          235,
          40,
          244,
          13
        ],
        [
          "test_load_from_quanto_saved",
          277,
          303,
          292,
          14,
          292,
          42,
          277,
          37,
          303,
          83
        ],
        [
          "test_serialization_bin",
          219,
          228,
          223,
          14,
          223,
          42,
          219,
          32,
          228,
          13
        ],
        [
          "setUp",
          383,
          407,
          397,
          14,
          397,
          42,
          383,
          15,
          406,
          65
        ]
      ],
      "transformers/tests/quantization/spqr_integration/test_spqr.py": [
        [
          "test_save_pretrained",
          156,
          167,
          160,
          14,
          160,
          42,
          156,
          30,
          167,
          110
        ]
      ],
      "transformers/tests/tensor_parallel/test_tensor_parallel.py": [
        [
          "test_model_save",
          176,
          215,
          179,
          14,
          179,
          42,
          176,
          25,
          180,
          44
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          125,
          14,
          125,
          42,
          118,
          39,
          130,
          63
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          110,
          14,
          110,
          42,
          103,
          34,
          115,
          59
        ],
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          326,
          14,
          326,
          42,
          306,
          48,
          331,
          36
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          104,
          14,
          104,
          42,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          119,
          14,
          119,
          42,
          118,
          39,
          130,
          63
        ],
        [
          "test_auto_tokenizer_from_local_folder",
          205,
          213,
          208,
          14,
          208,
          42,
          205,
          47,
          213,
          51
        ],
        [
          "test_get_tokenizer_config",
          220,
          238,
          233,
          14,
          233,
          42,
          220,
          35,
          238,
          68
        ],
        [
          "test_new_tokenizer_registration",
          240,
          260,
          250,
          18,
          250,
          46,
          250,
          18,
          250,
          46
        ],
        [
          "test_new_tokenizer_fast_registration",
          263,
          304,
          286,
          18,
          286,
          46,
          286,
          18,
          286,
          46
        ],
        [
          "test_new_tokenizer_fast_registration",
          263,
          304,
          291,
          18,
          291,
          46,
          291,
          18,
          291,
          46
        ],
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          342,
          18,
          342,
          46,
          332,
          13,
          354,
          73
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          475,
          14,
          475,
          42,
          456,
          40,
          513,
          18
        ]
      ],
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "test_get_tree_starting_at",
          465,
          493,
          466,
          14,
          466,
          42,
          465,
          35,
          479,
          50
        ],
        [
          "test_init_test_examples_dependencies",
          521,
          541,
          522,
          14,
          522,
          42,
          521,
          46,
          540,
          60
        ],
        [
          "test_create_reverse_dependency_map",
          543,
          601,
          544,
          14,
          544,
          42,
          543,
          44,
          558,
          106
        ],
        [
          "test_extract_imports_relative",
          291,
          330,
          292,
          14,
          292,
          42,
          291,
          39,
          306,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          333,
          14,
          333,
          42,
          332,
          39,
          346,
          83
        ],
        [
          "test_print_tree_deps_of",
          495,
          519,
          496,
          14,
          496,
          42,
          495,
          33,
          519,
          75
        ],
        [
          "test_checkout_commit",
          209,
          224,
          210,
          14,
          210,
          42,
          209,
          30,
          216,
          53
        ],
        [
          "test_get_all_tests",
          235,
          240,
          236,
          14,
          236,
          42,
          235,
          28,
          240,
          96
        ],
        [
          "test_diff_is_docstring_only",
          253,
          264,
          254,
          14,
          254,
          42,
          253,
          37,
          261,
          75
        ],
        [
          "test_get_diff",
          266,
          289,
          267,
          14,
          267,
          42,
          266,
          23,
          274,
          83
        ],
        [
          "test_get_module_dependencies",
          372,
          434,
          373,
          14,
          373,
          42,
          372,
          38,
          383,
          96
        ],
        [
          "test_create_reverse_dependency_tree",
          436,
          463,
          437,
          14,
          437,
          42,
          436,
          45,
          449,
          97
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          605,
          14,
          605,
          42,
          604,
          33,
          623,
          76
        ],
        [
          "test_infer_tests_to_run_with_test_modifs",
          686,
          703,
          687,
          14,
          687,
          42,
          686,
          50,
          703,
          76
        ],
        [
          "test_infer_tests_to_run_with_examples_modifs",
          706,
          739,
          707,
          14,
          707,
          42,
          706,
          54,
          724,
          86
        ]
      ],
      "transformers/tests/models/camembert/test_tokenization_camembert.py": [
        [
          "test_rust_and_python_bpe_tokenizers",
          71,
          92,
          73,
          14,
          73,
          33,
          71,
          45,
          92,
          49
        ],
        [
          "test_added_tokens_serialization",
          137,
          217,
          159,
          22,
          159,
          50,
          150,
          13,
          168,
          60
        ],
        [
          "test_added_tokens_serialization",
          137,
          217,
          175,
          34,
          175,
          62,
          169,
          30,
          189,
          37
        ],
        [
          "test_added_tokens_serialization",
          137,
          217,
          207,
          30,
          207,
          58,
          193,
          42,
          217,
          33
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          209,
          18,
          209,
          46,
          208,
          13,
          255,
          17
        ],
        [
          "test_added_token_serializable",
          185,
          198,
          196,
          22,
          196,
          50,
          187,
          13,
          198,
          59
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_decode_single_bytes",
          277,
          291,
          286,
          18,
          286,
          46,
          285,
          13,
          291,
          62
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          222,
          18,
          222,
          46,
          221,
          13,
          275,
          17
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_conversion",
          375,
          393,
          379,
          14,
          379,
          42,
          375,
          25,
          393,
          60
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template",
          1114,
          1174,
          1146,
          22,
          1146,
          50,
          1123,
          13,
          1174,
          103
        ],
        [
          "test_chat_template",
          1114,
          1174,
          1158,
          22,
          1158,
          50,
          1123,
          13,
          1174,
          103
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1184,
          18,
          1184,
          46,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1195,
          18,
          1195,
          46,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1207,
          18,
          1207,
          46,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1708,
          26,
          1708,
          54,
          1706,
          21,
          1711,
          43
        ],
        [
          "test_chat_template_file_priority",
          1734,
          1747,
          1740,
          22,
          1740,
          50,
          1738,
          13,
          1747,
          78
        ],
        [
          "test_added_token_serializable",
          2837,
          2847,
          2845,
          22,
          2845,
          50,
          2840,
          13,
          2847,
          59
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4230,
          18,
          4230,
          46,
          4229,
          13,
          4272,
          17
        ],
        [
          "test_saving_tokenizer_trainer",
          4452,
          4470,
          4455,
          22,
          4455,
          50,
          4453,
          13,
          4470,
          100
        ],
        [
          "test_save_slow_from_fast_and_reload_fast",
          4481,
          4506,
          4488,
          22,
          4488,
          50,
          4486,
          13,
          4506,
          72
        ],
        [
          "test_save_slow_from_fast_and_reload_fast",
          4481,
          4506,
          4502,
          22,
          4502,
          50,
          4486,
          13,
          4506,
          72
        ],
        [
          "test_added_tokens_serialization",
          4565,
          4643,
          4585,
          22,
          4585,
          50,
          4576,
          13,
          4594,
          60
        ],
        [
          "test_added_tokens_serialization",
          4565,
          4643,
          4601,
          34,
          4601,
          62,
          4595,
          30,
          4615,
          37
        ],
        [
          "test_added_tokens_serialization",
          4565,
          4643,
          4633,
          30,
          4633,
          58,
          4619,
          42,
          4643,
          33
        ],
        [
          "test_special_token_addition",
          4645,
          4668,
          4652,
          22,
          4652,
          50,
          4646,
          13,
          4668,
          110
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_class_after_save_and_reload",
          173,
          206,
          177,
          14,
          177,
          42,
          173,
          42,
          206,
          13
        ],
        [
          "test_local_versioning",
          211,
          236,
          216,
          14,
          216,
          42,
          211,
          31,
          236,
          77
        ]
      ],
      "transformers/tests/models/gemma/test_tokenization_gemma.py": [
        [
          "test_conversion",
          236,
          254,
          240,
          14,
          240,
          42,
          236,
          25,
          254,
          60
        ],
        [
          "test_save_fast_load_slow",
          454,
          476,
          465,
          14,
          465,
          42,
          463,
          9,
          473,
          47
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_load_tokenizer_with_model_file_only",
          337,
          344,
          338,
          14,
          338,
          42,
          337,
          50,
          344,
          95
        ],
        [
          "test_conversion",
          413,
          431,
          417,
          14,
          417,
          42,
          413,
          25,
          431,
          60
        ]
      ],
      "transformers/tests/models/m2m_100/test_tokenization_m2m_100.py": [
        [
          "test_special_tokens_unaffacted_by_save_load",
          177,
          182,
          178,
          14,
          178,
          42,
          177,
          53,
          182,
          83
        ]
      ],
      "transformers/tests/test_tokenization_mistral_common.py": [
        [
          "test_save_pretrained",
          137,
          153,
          152,
          18,
          152,
          46,
          137,
          30,
          153,
          68
        ],
        [
          "test_save_pretrained",
          137,
          153,
          138,
          14,
          138,
          42,
          137,
          30,
          153,
          68
        ]
      ],
      "transformers/tests/models/nllb/test_tokenization_nllb.py": [
        [
          "test_new_language_codes",
          298,
          327,
          312,
          14,
          312,
          42,
          298,
          33,
          327,
          47
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          205,
          18,
          205,
          46,
          204,
          13,
          257,
          17
        ]
      ],
      "transformers/tests/models/rembert/test_tokenization_rembert.py": [
        [
          "test_added_tokens_serialization",
          168,
          248,
          191,
          22,
          191,
          50,
          180,
          13,
          200,
          60
        ],
        [
          "test_added_tokens_serialization",
          168,
          248,
          207,
          34,
          207,
          62,
          201,
          30,
          221,
          37
        ],
        [
          "test_added_tokens_serialization",
          168,
          248,
          238,
          30,
          238,
          58,
          225,
          42,
          248,
          33
        ]
      ],
      "transformers/tests/models/roformer/test_tokenization_roformer.py": [
        [
          "test_save_slow_from_fast_and_reload_fast",
          82,
          90,
          87,
          18,
          87,
          46,
          83,
          13,
          90,
          76
        ]
      ],
      "transformers/tests/models/siglip/test_tokenization_siglip.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          252,
          18,
          252,
          46,
          251,
          13,
          305,
          17
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_push_to_hub",
          122,
          132,
          124,
          18,
          124,
          46,
          122,
          26,
          132,
          70
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          134,
          146,
          136,
          18,
          136,
          46,
          134,
          46,
          146,
          70
        ],
        [
          "test_push_to_hub_in_organization",
          148,
          158,
          150,
          18,
          150,
          46,
          148,
          42,
          158,
          70
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          160,
          172,
          162,
          18,
          162,
          46,
          160,
          62,
          172,
          70
        ],
        [
          "test_push_to_hub_dynamic_tokenizer",
          175,
          189,
          178,
          18,
          178,
          46,
          175,
          44,
          189,
          77
        ],
        [
          "test_push_to_hub_dynamic_tokenizer_with_both_slow_and_fast_classes",
          192,
          215,
          199,
          18,
          199,
          46,
          192,
          76,
          215,
          77
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_utils.py": [
        [
          "test_extra_special_tokens_multimodal",
          227,
          273,
          258,
          14,
          258,
          42,
          227,
          46,
          273,
          102
        ],
        [
          "test_extra_special_tokens_multimodal",
          227,
          273,
          245,
          14,
          245,
          42,
          227,
          46,
          273,
          102
        ],
        [
          "test_instantiation_from_tokenizers_json_file",
          333,
          337,
          335,
          14,
          335,
          42,
          333,
          54,
          337,
          94
        ]
      ],
      "transformers/tests/models/t5/test_tokenization_t5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          303,
          18,
          303,
          46,
          302,
          13,
          356,
          17
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "test_nested_vocab",
          789,
          832,
          817,
          14,
          817,
          42,
          789,
          27,
          832,
          60
        ],
        [
          "test_nested_vocab",
          789,
          832,
          826,
          14,
          826,
          42,
          789,
          27,
          832,
          60
        ]
      ],
      "transformers/tests/quantization/torchao_integration/test_torchao.py": [
        [
          "check_serialization_expected_output",
          454,
          465,
          459,
          14,
          459,
          42,
          458,
          17,
          465,
          105
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "setUp",
          742,
          755,
          747,
          14,
          747,
          42,
          742,
          15,
          755,
          40
        ],
        [
          "setUp",
          742,
          755,
          752,
          14,
          752,
          42,
          742,
          15,
          755,
          40
        ],
        [
          "test_reproducible_training",
          763,
          774,
          765,
          14,
          765,
          42,
          763,
          36,
          774,
          72
        ],
        [
          "test_reproducible_training",
          763,
          774,
          771,
          14,
          771,
          42,
          763,
          36,
          774,
          72
        ],
        [
          "test_trainer_with_datasets",
          776,
          803,
          784,
          14,
          784,
          42,
          776,
          36,
          803,
          51
        ],
        [
          "test_model_init",
          805,
          820,
          807,
          14,
          807,
          42,
          805,
          25,
          820,
          72
        ],
        [
          "test_gradient_accumulation_loss_alignment_with_model_loss",
          823,
          920,
          849,
          14,
          849,
          42,
          823,
          67,
          865,
          52
        ],
        [
          "test_gradient_accumulation_loss_alignment_with_loss_func",
          922,
          1021,
          960,
          14,
          960,
          42,
          922,
          66,
          1021,
          107
        ],
        [
          "test_gradient_accumulation_loss_alignment_with_loss_func",
          922,
          1021,
          976,
          14,
          976,
          42,
          922,
          66,
          1021,
          107
        ],
        [
          "test_gradient_accumulation",
          1023,
          1030,
          1025,
          14,
          1025,
          42,
          1023,
          36,
          1030,
          51
        ],
        [
          "test_gradient_checkpointing",
          1032,
          1050,
          1033,
          14,
          1033,
          42,
          1032,
          37,
          1046,
          56
        ],
        [
          "test_training_loss",
          1052,
          1073,
          1056,
          14,
          1056,
          42,
          1052,
          28,
          1073,
          72
        ],
        [
          "test_training_loss",
          1052,
          1073,
          1066,
          14,
          1066,
          42,
          1052,
          28,
          1073,
          72
        ],
        [
          "test_custom_optimizer",
          1075,
          1088,
          1077,
          14,
          1077,
          42,
          1075,
          31,
          1088,
          90
        ],
        [
          "test_lr_scheduler_kwargs",
          1090,
          1117,
          1096,
          14,
          1096,
          42,
          1090,
          34,
          1117,
          90
        ],
        [
          "test_cosine_with_min_lr_scheduler",
          1119,
          1142,
          1124,
          14,
          1124,
          42,
          1119,
          43,
          1140,
          37
        ],
        [
          "test_reduce_lr_on_plateau_args",
          1172,
          1198,
          1176,
          14,
          1176,
          42,
          1172,
          40,
          1198,
          62
        ],
        [
          "test_reduce_lr_on_plateau",
          1200,
          1246,
          1213,
          14,
          1213,
          42,
          1200,
          35,
          1233,
          46
        ],
        [
          "test_adafactor_lr_none",
          1248,
          1267,
          1254,
          14,
          1254,
          42,
          1248,
          32,
          1267,
          90
        ],
        [
          "test_mixed_fp16",
          1271,
          1279,
          1273,
          14,
          1273,
          42,
          1271,
          25,
          1279,
          60
        ],
        [
          "test_mixed_bf16",
          1283,
          1288,
          1285,
          14,
          1285,
          42,
          1283,
          25,
          1288,
          73
        ],
        [
          "test_tf32",
          1292,
          1297,
          1294,
          14,
          1294,
          42,
          1292,
          19,
          1297,
          51
        ],
        [
          "test_include_num_input_tokens_seen",
          1299,
          1395,
          1323,
          14,
          1323,
          42,
          1299,
          44,
          1395,
          79
        ],
        [
          "test_init_with_offloaded_model",
          1420,
          1436,
          1433,
          14,
          1433,
          42,
          1431,
          31,
          1436,
          13
        ],
        [
          "test_schedulefree_adam",
          2062,
          2080,
          2068,
          14,
          2068,
          42,
          2062,
          32,
          2080,
          13
        ],
        [
          "test_schedulefree_radam",
          2084,
          2102,
          2090,
          14,
          2090,
          42,
          2084,
          33,
          2102,
          9
        ],
        [
          "test_galore_adafactor",
          2294,
          2322,
          2305,
          14,
          2305,
          42,
          2294,
          31,
          2322,
          60
        ],
        [
          "test_galore_adafactor_attention_only",
          2326,
          2353,
          2337,
          14,
          2337,
          42,
          2326,
          46,
          2353,
          60
        ],
        [
          "test_galore_adafactor_all_linear",
          2357,
          2384,
          2368,
          14,
          2368,
          42,
          2357,
          42,
          2384,
          60
        ],
        [
          "test_evaluate",
          2774,
          2814,
          2775,
          14,
          2775,
          42,
          2774,
          23,
          2814,
          74
        ],
        [
          "test_evaluate_with_batch_eval_metrics",
          2816,
          2864,
          2817,
          14,
          2817,
          42,
          2816,
          47,
          2864,
          74
        ],
        [
          "test_evaluate_with_jit",
          2866,
          2914,
          2867,
          14,
          2867,
          42,
          2866,
          32,
          2914,
          74
        ],
        [
          "test_predict",
          2916,
          2949,
          2917,
          14,
          2917,
          42,
          2916,
          22,
          2949,
          82
        ],
        [
          "test_predict_with_batch_eval_metrics",
          2985,
          3047,
          2986,
          14,
          2986,
          42,
          2985,
          46,
          3047,
          82
        ],
        [
          "test_predict_with_jit",
          3049,
          3093,
          3050,
          14,
          3050,
          42,
          3049,
          31,
          3093,
          82
        ],
        [
          "test_dynamic_shapes",
          3095,
          3131,
          3098,
          14,
          3098,
          42,
          3095,
          29,
          3107,
          71
        ],
        [
          "test_dynamic_shapes",
          3095,
          3131,
          3116,
          14,
          3116,
          42,
          3116,
          14,
          3125,
          71
        ],
        [
          "test_log_level",
          3133,
          3162,
          3141,
          14,
          3141,
          42,
          3133,
          24,
          3145,
          22
        ],
        [
          "test_can_resume_training_lm",
          3380,
          3429,
          3384,
          14,
          3384,
          42,
          3380,
          37,
          3429,
          37
        ],
        [
          "test_auto_batch_size_finder",
          3493,
          3524,
          3503,
          14,
          3503,
          42,
          3497,
          19,
          3524,
          27
        ],
        [
          "test_resume_training_with_shard_checkpoint",
          3602,
          3624,
          3607,
          14,
          3607,
          42,
          3602,
          52,
          3624,
          64
        ],
        [
          "test_resume_training_with_safe_checkpoint",
          3627,
          3659,
          3634,
          22,
          3634,
          50,
          3633,
          17,
          3659,
          72
        ],
        [
          "test_resume_training_with_gradient_accumulation",
          3662,
          3697,
          3667,
          14,
          3667,
          42,
          3662,
          57,
          3697,
          64
        ],
        [
          "test_resume_training_with_frozen_params",
          3700,
          3737,
          3705,
          14,
          3705,
          42,
          3700,
          49,
          3737,
          64
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3741,
          14,
          3741,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3757,
          14,
          3757,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3775,
          14,
          3775,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3795,
          14,
          3795,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_from_safetensors",
          3810,
          3831,
          3813,
          18,
          3813,
          46,
          3812,
          13,
          3831,
          17
        ],
        [
          "test_trainer_eval_mrpc",
          3834,
          3847,
          3843,
          14,
          3843,
          42,
          3834,
          32,
          3847,
          53
        ],
        [
          "test_trainer_eval_multiple",
          3850,
          3878,
          3861,
          14,
          3861,
          42,
          3861,
          14,
          3878,
          52
        ],
        [
          "test_training_iterable_dataset",
          3891,
          3905,
          3897,
          14,
          3897,
          42,
          3891,
          40,
          3905,
          103
        ],
        [
          "test_evaluation_iterable_dataset",
          3907,
          3934,
          3913,
          14,
          3913,
          42,
          3907,
          42,
          3934,
          74
        ],
        [
          "test_predict_iterable_dataset",
          3936,
          3954,
          3941,
          14,
          3941,
          42,
          3936,
          39,
          3954,
          62
        ],
        [
          "test_num_train_epochs_in_training",
          3956,
          3976,
          3959,
          14,
          3959,
          42,
          3956,
          43,
          3976,
          74
        ],
        [
          "test_num_batches_in_training_with_gradient_accumulation",
          3979,
          4007,
          3980,
          14,
          3980,
          42,
          3979,
          65,
          3981,
          42
        ],
        [
          "test_early_stopping_callback",
          4009,
          4060,
          4011,
          14,
          4011,
          42,
          4009,
          38,
          4041,
          29
        ],
        [
          "test_early_stopping_callback",
          4009,
          4060,
          4028,
          14,
          4028,
          42,
          4009,
          38,
          4041,
          29
        ],
        [
          "test_early_stopping_callback",
          4009,
          4060,
          4046,
          14,
          4046,
          42,
          4046,
          14,
          4060,
          69
        ],
        [
          "test_flos_extraction",
          4062,
          4079,
          4063,
          14,
          4063,
          42,
          4062,
          30,
          4079,
          72
        ],
        [
          "test_checkpoint_rotation",
          4090,
          4112,
          4091,
          14,
          4091,
          42,
          4090,
          34,
          4112,
          69
        ],
        [
          "test_compare_trainer_and_checkpoint_args_logging",
          4114,
          4150,
          4117,
          14,
          4117,
          42,
          4114,
          58,
          4150,
          9
        ],
        [
          "test_mem_metrics",
          4170,
          4178,
          4171,
          14,
          4171,
          42,
          4170,
          26,
          4178,
          61
        ],
        [
          "test_fp16_full_eval",
          4182,
          4241,
          4188,
          14,
          4188,
          42,
          4182,
          29,
          4241,
          73
        ],
        [
          "test_torchdynamo_full_eval",
          4246,
          4289,
          4259,
          14,
          4259,
          42,
          4246,
          36,
          4289,
          31
        ],
        [
          "test_torchdynamo_memory",
          4293,
          4361,
          4337,
          14,
          4337,
          42,
          4327,
          9,
          4343,
          30
        ],
        [
          "test_bf16_full_eval",
          4365,
          4426,
          4380,
          14,
          4380,
          42,
          4365,
          29,
          4426,
          73
        ],
        [
          "test_no_wd_param_group",
          4428,
          4437,
          4430,
          14,
          4430,
          42,
          4428,
          32,
          4437,
          91
        ],
        [
          "test_end_to_end_example",
          4443,
          4485,
          4451,
          14,
          4451,
          42,
          4443,
          33,
          4485,
          45
        ],
        [
          "test_accelerator_config_empty",
          4488,
          4505,
          4490,
          14,
          4490,
          42,
          4488,
          39,
          4503,
          50
        ],
        [
          "test_accelerator_config_from_dict",
          4507,
          4530,
          4510,
          14,
          4510,
          42,
          4507,
          43,
          4521,
          50
        ],
        [
          "test_accelerator_config_from_yaml",
          4532,
          4555,
          4535,
          14,
          4535,
          42,
          4532,
          43,
          4555,
          77
        ],
        [
          "test_accelerator_config_from_dataclass",
          4557,
          4576,
          4570,
          14,
          4570,
          42,
          4557,
          48,
          4576,
          77
        ],
        [
          "test_accelerate_config_from_dataclass_grad_accum",
          4579,
          4602,
          4599,
          14,
          4599,
          42,
          4579,
          58,
          4602,
          74
        ],
        [
          "test_accelerator_config_from_partial",
          4604,
          4623,
          4607,
          14,
          4607,
          42,
          4604,
          46,
          4623,
          76
        ],
        [
          "test_accelerator_custom_state",
          4625,
          4633,
          4627,
          14,
          4627,
          42,
          4625,
          39,
          4633,
          63
        ],
        [
          "test_accelerator_config_from_dict_grad_accum_num_steps",
          4636,
          4671,
          4637,
          14,
          4637,
          42,
          4636,
          64,
          4671,
          105
        ],
        [
          "test_accelerator_config_not_instantiated",
          4673,
          4700,
          4676,
          14,
          4676,
          42,
          4673,
          50,
          4700,
          108
        ],
        [
          "test_accelerator_config_not_instantiated",
          4673,
          4700,
          4695,
          14,
          4695,
          42,
          4673,
          50,
          4700,
          108
        ],
        [
          "test_dtype_to_json",
          4702,
          4729,
          4724,
          18,
          4724,
          46,
          4709,
          13,
          4729,
          59
        ],
        [
          "test_eval_use_gather_object",
          4732,
          4741,
          4736,
          14,
          4736,
          42,
          4732,
          37,
          4741,
          13
        ],
        [
          "test_trainer_saves_tokenizer",
          4743,
          4764,
          4747,
          14,
          4747,
          42,
          4743,
          38,
          4764,
          9
        ],
        [
          "test_trainer_saves_image_processor",
          4767,
          4781,
          4771,
          14,
          4771,
          42,
          4767,
          44,
          4781,
          91
        ],
        [
          "test_trainer_saves_feature_extractor",
          4783,
          4798,
          4787,
          14,
          4787,
          42,
          4783,
          46,
          4798,
          95
        ],
        [
          "test_trainer_saves_processor",
          4801,
          4835,
          4807,
          14,
          4807,
          42,
          4801,
          38,
          4835,
          9
        ],
        [
          "test_save_best_checkpoint",
          4837,
          4903,
          4842,
          14,
          4842,
          42,
          4837,
          35,
          4903,
          17
        ],
        [
          "test_save_best_checkpoint",
          4837,
          4903,
          4874,
          14,
          4874,
          42,
          4837,
          35,
          4903,
          17
        ],
        [
          "test_metric_for_best_model_behavior",
          4905,
          4933,
          4908,
          14,
          4908,
          42,
          4905,
          45,
          4933,
          73
        ],
        [
          "test_metric_for_best_model_behavior",
          4905,
          4933,
          4923,
          14,
          4923,
          42,
          4905,
          45,
          4933,
          73
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4938,
          14,
          4938,
          42,
          4935,
          45,
          4949,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4956,
          14,
          4956,
          42,
          4951,
          13,
          4970,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4980,
          14,
          4980,
          42,
          4976,
          13,
          5006,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5015,
          14,
          5015,
          42,
          5012,
          13,
          5042,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5052,
          14,
          5052,
          42,
          5048,
          13,
          5078,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5088,
          14,
          5088,
          42,
          5084,
          13,
          5113,
          52
        ],
        [
          "test_special_token_alignment",
          5120,
          5163,
          5142,
          14,
          5142,
          42,
          5120,
          38,
          5163,
          87
        ],
        [
          "test_trainer_works_without_model_config",
          5165,
          5197,
          5187,
          14,
          5187,
          42,
          5187,
          14,
          5197,
          27
        ],
        [
          "test_push_to_hub",
          5315,
          5335,
          5318,
          18,
          5318,
          46,
          5315,
          26,
          5335,
          68
        ],
        [
          "test_push_to_hub_in_organization",
          5337,
          5359,
          5339,
          18,
          5339,
          46,
          5337,
          42,
          5359,
          68
        ],
        [
          "test_push_to_hub_with_saves_each_epoch",
          5374,
          5395,
          5376,
          18,
          5376,
          46,
          5374,
          48,
          5395,
          114
        ],
        [
          "test_push_to_hub_with_saves_each_n_steps",
          5397,
          5433,
          5403,
          18,
          5403,
          46,
          5402,
          14,
          5433,
          93
        ],
        [
          "test_push_to_hub_with_tensorboard_logs",
          5436,
          5457,
          5438,
          18,
          5438,
          46,
          5436,
          48,
          5453,
          26
        ],
        [
          "test_push_to_hub_tags",
          5459,
          5484,
          5464,
          18,
          5464,
          46,
          5459,
          31,
          5484,
          72
        ],
        [
          "test_push_to_hub_with_revision",
          5486,
          5501,
          5489,
          18,
          5489,
          46,
          5486,
          40,
          5501,
          67
        ],
        [
          "test_hyperparameter_search",
          5512,
          5547,
          5533,
          14,
          5533,
          42,
          5512,
          36,
          5547,
          111
        ],
        [
          "test_hyperparameter_search",
          5558,
          5603,
          5582,
          14,
          5582,
          42,
          5558,
          36,
          5603,
          13
        ],
        [
          "test_hyperparameter_search",
          5609,
          5635,
          5624,
          14,
          5624,
          42,
          5609,
          36,
          5635,
          13
        ],
        [
          "ray_hyperparameter_search",
          5646,
          5688,
          5672,
          14,
          5672,
          42,
          5646,
          35,
          5688,
          13
        ],
        [
          "test_hyperparameter_search",
          5711,
          5751,
          5735,
          14,
          5735,
          42,
          5711,
          36,
          5751,
          13
        ],
        [
          "test_optim_supported",
          5940,
          5946,
          5941,
          14,
          5941,
          42,
          5940,
          30,
          5946,
          27
        ],
        [
          "test_fused_adam",
          5948,
          5965,
          5959,
          14,
          5959,
          42,
          5948,
          25,
          5965,
          17
        ],
        [
          "test_fused_adam_no_apex",
          5967,
          5975,
          5968,
          14,
          5968,
          42,
          5967,
          33,
          5975,
          62
        ],
        [
          "test_bnb_adam8bit",
          5977,
          5994,
          5988,
          14,
          5988,
          42,
          5977,
          27,
          5994,
          17
        ],
        [
          "test_bnb_paged_adam8bit_alias",
          5996,
          6009,
          6003,
          14,
          6003,
          42,
          5996,
          39,
          6009,
          17
        ],
        [
          "test_bnb_paged_adam",
          6011,
          6024,
          6018,
          14,
          6018,
          42,
          6011,
          29,
          6024,
          17
        ],
        [
          "test_bnb_paged_adam8bit",
          6026,
          6039,
          6033,
          14,
          6033,
          42,
          6026,
          33,
          6039,
          17
        ],
        [
          "test_bnb_ademamix",
          6041,
          6054,
          6048,
          14,
          6048,
          42,
          6041,
          27,
          6054,
          17
        ],
        [
          "test_bnb_ademamix8bit",
          6056,
          6069,
          6063,
          14,
          6063,
          42,
          6056,
          31,
          6069,
          17
        ],
        [
          "test_bnb_paged_ademamix",
          6071,
          6084,
          6078,
          14,
          6078,
          42,
          6071,
          33,
          6084,
          17
        ],
        [
          "test_bnb_paged_ademamix8bit",
          6086,
          6099,
          6093,
          14,
          6093,
          42,
          6086,
          37,
          6099,
          17
        ],
        [
          "test_bnb_lion",
          6101,
          6114,
          6108,
          14,
          6108,
          42,
          6101,
          23,
          6114,
          17
        ],
        [
          "test_bnb_lion8bit",
          6116,
          6129,
          6123,
          14,
          6123,
          42,
          6116,
          27,
          6129,
          17
        ],
        [
          "test_bnb_paged_lion8bit",
          6131,
          6144,
          6138,
          14,
          6138,
          42,
          6131,
          33,
          6144,
          17
        ],
        [
          "test_bnb_paged_lion",
          6146,
          6159,
          6153,
          14,
          6153,
          42,
          6146,
          29,
          6159,
          17
        ],
        [
          "test_bnb_adam8bit_no_bnb",
          6161,
          6169,
          6162,
          14,
          6162,
          42,
          6161,
          34,
          6169,
          62
        ],
        [
          "test_bnb_paged_adam_no_bnb",
          6171,
          6179,
          6172,
          14,
          6172,
          42,
          6171,
          36,
          6179,
          62
        ],
        [
          "test_bnb_paged_adam8bit_no_bnb",
          6181,
          6189,
          6182,
          14,
          6182,
          42,
          6181,
          40,
          6189,
          62
        ],
        [
          "test_bnb_ademamix_no_bnb",
          6191,
          6199,
          6192,
          14,
          6192,
          42,
          6191,
          34,
          6199,
          62
        ],
        [
          "test_bnb_ademamix8bit_no_bnb",
          6201,
          6209,
          6202,
          14,
          6202,
          42,
          6201,
          38,
          6209,
          62
        ],
        [
          "test_bnb_paged_ademamix_no_bnb",
          6211,
          6219,
          6212,
          14,
          6212,
          42,
          6211,
          40,
          6219,
          62
        ],
        [
          "test_bnb_paged_ademamix8bit_no_bnb",
          6221,
          6229,
          6222,
          14,
          6222,
          42,
          6221,
          44,
          6229,
          62
        ],
        [
          "test_bnb_paged_lion_no_bnb",
          6231,
          6239,
          6232,
          14,
          6232,
          42,
          6231,
          36,
          6239,
          62
        ],
        [
          "test_bnb_paged_lion8bit_no_bnb",
          6241,
          6249,
          6242,
          14,
          6242,
          42,
          6241,
          40,
          6249,
          62
        ],
        [
          "test_anyprecision_adamw",
          6251,
          6268,
          6262,
          14,
          6262,
          42,
          6251,
          33,
          6268,
          17
        ],
        [
          "test_no_torchdistx_anyprecision_adamw",
          6270,
          6278,
          6271,
          14,
          6271,
          42,
          6270,
          47,
          6278,
          62
        ],
        [
          "test_hyperparameter_search",
          6289,
          6349,
          6311,
          14,
          6311,
          42,
          6289,
          36,
          6349,
          85
        ],
        [
          "test_get_num_trainable_parameters",
          6362,
          6373,
          6367,
          14,
          6367,
          42,
          6362,
          43,
          6371,
          47
        ],
        [
          "test_get_learning_rates",
          6375,
          6382,
          6377,
          14,
          6377,
          42,
          6375,
          33,
          6382,
          74
        ],
        [
          "test_get_optimizer_group",
          6384,
          6398,
          6386,
          14,
          6386,
          42,
          6384,
          34,
          6398,
          49
        ],
        [
          "test_bnb_8bit_optimizer_skip_embedding",
          6401,
          6417,
          6403,
          14,
          6403,
          42,
          6401,
          48,
          6404,
          64
        ]
      ],
      "transformers/tests/test_training_args.py": [
        [
          "test_custom_output_dir",
          14,
          18,
          16,
          14,
          16,
          42,
          14,
          32,
          18,
          54
        ],
        [
          "test_output_dir_creation",
          20,
          40,
          22,
          14,
          22,
          42,
          20,
          34,
          40,
          56
        ]
      ],
      "transformers/tests/models/auto/test_video_processing_auto.py": [
        [
          "test_video_processor_from_local_file",
          116,
          128,
          117,
          14,
          117,
          42,
          116,
          46,
          128,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_key",
          49,
          63,
          50,
          14,
          50,
          42,
          49,
          60,
          63,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_preprocessor_key",
          65,
          80,
          67,
          14,
          67,
          42,
          65,
          73,
          80,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          83,
          14,
          83,
          42,
          82,
          63,
          114,
          67
        ],
        [
          "test_from_pretrained_dynamic_video_processor",
          150,
          175,
          172,
          14,
          172,
          42,
          150,
          54,
          175,
          90
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          185,
          18,
          185,
          46,
          185,
          18,
          185,
          46
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          200,
          18,
          200,
          46,
          200,
          18,
          200,
          46
        ]
      ],
      "transformers/tests/test_video_processing_common.py": [
        [
          "test_video_processor_from_and_save_pretrained",
          141,
          150,
          145,
          18,
          145,
          46,
          142,
          13,
          150,
          95
        ],
        [
          "test_video_processor_to_json_file",
          121,
          130,
          125,
          18,
          125,
          46,
          122,
          13,
          130,
          95
        ],
        [
          "test_video_processor_save_load_with_autovideoprocessor",
          152,
          163,
          156,
          18,
          156,
          46,
          153,
          13,
          163,
          95
        ]
      ],
      "transformers/tests/generation/test_utils.py": [
        [
          "test_model_parallel_beam_search",
          540,
          560,
          552,
          18,
          552,
          46,
          549,
          35,
          560,
          17
        ],
        [
          "_test_attention_implementation",
          1858,
          1944,
          1911,
          18,
          1911,
          46,
          1911,
          18,
          1944,
          104
        ],
        [
          "test_flash_attention_2_continue_generate_with_position_ids",
          1971,
          2054,
          2003,
          18,
          2003,
          46,
          2003,
          18,
          2022,
          50
        ],
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          2056,
          2162,
          2106,
          18,
          2106,
          46,
          2106,
          18,
          2113,
          60
        ],
        [
          "test_custom_generate_local_directory",
          4625,
          4644,
          4627,
          14,
          4627,
          42,
          4625,
          46,
          4644,
          37
        ]
      ],
      "transformers/tests/quantization/vptq_integration/test_vptq.py": [
        [
          "test_save_pretrained",
          97,
          108,
          101,
          14,
          101,
          42,
          97,
          30,
          108,
          110
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "__init__",
          1841,
          1847,
          1843,
          14,
          1843,
          42,
          1841,
          18,
          1845,
          36
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_report_to_hp_search",
          1867,
          1889,
          1883,
          18,
          1883,
          46,
          1881,
          20,
          1885,
          43
        ]
      ],
      "transformers/utils/update_metadata.py": [
        [
          "update_metadata",
          232,
          312,
          282,
          10,
          282,
          38,
          232,
          21,
          294,
          27
        ]
      ],
      "transformers/tests/causal_lm_tester.py": [
        [
          "test_causal_lm_can_accept_training_kwargs",
          558,
          572,
          564,
          14,
          564,
          42,
          562,
          31,
          572,
          13
        ],
        [
          "test_flash_attn_2_equivalence",
          531,
          556,
          539,
          18,
          539,
          46,
          536,
          35,
          556,
          83
        ]
      ],
      "transformers/src/transformers/models/esm/convert_esm.py": [
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          310,
          14,
          310,
          33,
          287,
          5,
          319,
          77
        ],
        [
          "get_esmfold_tokenizer",
          77,
          84,
          78,
          10,
          78,
          29,
          78,
          10,
          84,
          23
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_FastSpeech2ConformerModel_checkpoint",
          155,
          188,
          175,
          10,
          175,
          29,
          156,
          5,
          185,
          14
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "write_model",
          184,
          433,
          224,
          10,
          224,
          38,
          221,
          34,
          227,
          26
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "convert_tiktoken_to_hf",
          291,
          327,
          312,
          10,
          312,
          38,
          295,
          43,
          320,
          36
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "write_model",
          195,
          436,
          230,
          10,
          230,
          38,
          227,
          34,
          255,
          38
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "convert_processors",
          509,
          736,
          629,
          18,
          629,
          46,
          629,
          18,
          629,
          46
        ],
        [
          "convert_processors",
          509,
          736,
          671,
          14,
          671,
          42,
          671,
          14,
          673,
          46
        ],
        [
          "convert_processors",
          509,
          736,
          685,
          14,
          685,
          42,
          685,
          14,
          687,
          46
        ],
        [
          "upload_model",
          784,
          831,
          808,
          10,
          808,
          38,
          808,
          10,
          813,
          21
        ],
        [
          "build_composite_models",
          834,
          956,
          896,
          10,
          896,
          38,
          896,
          10,
          900,
          35
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "working_or_temp_dir",
          488,
          493,
          490,
          14,
          490,
          42,
          490,
          14,
          491,
          25
        ]
      ],
      "transformers/utils/get_test_reports.py": [
        [
          "run_pytest",
          48,
          79,
          69,
          19,
          69,
          63,
          69,
          19,
          69,
          63
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "_objective",
          318,
          354,
          351,
          18,
          351,
          46,
          346,
          23,
          354,
          64
        ],
        [
          "setup",
          822,
          946,
          916,
          22,
          916,
          50,
          916,
          22,
          919,
          49
        ],
        [
          "on_train_end",
          959,
          1001,
          971,
          18,
          971,
          46,
          963,
          18,
          979,
          54
        ],
        [
          "on_init_end",
          1797,
          1803,
          1800,
          46,
          1800,
          74,
          1800,
          46,
          1800,
          42
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "setUpClass",
          35,
          76,
          39,
          25,
          39,
          53,
          35,
          20,
          56,
          35
        ]
      ],
      "transformers/tests/quantization/aqlm_integration/test_aqlm.py": [
        [
          "test_save_pretrained",
          167,
          178,
          171,
          14,
          171,
          42,
          167,
          30,
          178,
          110
        ]
      ],
      "transformers/tests/quantization/autoround/test_auto_round.py": [
        [
          "test_mixed_bits",
          196,
          217,
          212,
          14,
          212,
          42,
          196,
          25,
          217,
          75
        ],
        [
          "test_save_pretrained",
          121,
          143,
          127,
          14,
          127,
          42,
          121,
          30,
          143,
          63
        ]
      ],
      "transformers/tests/test_backbone_common.py": [
        [
          "test_config_save_pretrained",
          75,
          83,
          79,
          14,
          79,
          42,
          75,
          37,
          83,
          73
        ]
      ],
      "transformers/tests/quantization/autoawq/test_awq.py": [
        [
          "test_save_pretrained",
          242,
          253,
          246,
          14,
          246,
          42,
          242,
          30,
          253,
          107
        ],
        [
          "test_raise_save_pretrained",
          332,
          347,
          346,
          45,
          346,
          73,
          332,
          36,
          347,
          45
        ]
      ],
      "transformers/tests/quantization/bnb/test_4bit.py": [
        [
          "test_serialization",
          686,
          764,
          706,
          14,
          706,
          42,
          686,
          28,
          728,
          19
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "test_find_code_in_transformers",
          299,
          308,
          300,
          14,
          300,
          42,
          299,
          40,
          308,
          46
        ],
        [
          "test_is_copy_consistent_with_ignored_match",
          334,
          342,
          336,
          14,
          336,
          42,
          334,
          52,
          342,
          43
        ],
        [
          "test_is_copy_consistent",
          310,
          332,
          312,
          14,
          312,
          42,
          310,
          33,
          332,
          67
        ],
        [
          "test_is_copy_consistent_with_ignored_no_match",
          344,
          368,
          352,
          14,
          352,
          42,
          344,
          55,
          368,
          70
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_from_pretrained_dynamic_config",
          106,
          128,
          122,
          14,
          122,
          42,
          106,
          45,
          128,
          78
        ],
        [
          "test_pattern_matching_fallback",
          63,
          71,
          64,
          14,
          64,
          42,
          63,
          40,
          71,
          57
        ],
        [
          "test_new_config_registration",
          73,
          92,
          85,
          18,
          85,
          46,
          85,
          18,
          85,
          46
        ]
      ],
      "transformers/tests/test_configuration_common.py": [
        [
          "create_and_test_config_from_and_save_pretrained_composite",
          118,
          155,
          126,
          14,
          126,
          42,
          118,
          67,
          133,
          64
        ],
        [
          "create_and_test_config_to_json_file",
          85,
          93,
          88,
          14,
          88,
          42,
          85,
          45,
          93,
          80
        ],
        [
          "create_and_test_config_from_and_save_pretrained",
          95,
          105,
          98,
          14,
          98,
          42,
          95,
          57,
          105,
          63
        ],
        [
          "create_and_test_config_from_and_save_pretrained_subfolder",
          107,
          116,
          111,
          14,
          111,
          42,
          107,
          67,
          116,
          80
        ],
        [
          "create_and_test_config_from_and_save_pretrained_composite",
          118,
          155,
          152,
          22,
          152,
          50,
          142,
          42,
          155,
          103
        ],
        [
          "create_and_test_config_from_pretrained_custom_kwargs",
          157,
          190,
          181,
          14,
          181,
          42,
          180,
          27,
          190,
          93
        ]
      ],
      "transformers/tests/models/llava/test_configuration_llava.py": [
        [
          "test_arbitrary_reload",
          57,
          70,
          65,
          14,
          65,
          42,
          57,
          31,
          70,
          70
        ],
        [
          "test_pixtral_reload",
          19,
          55,
          50,
          14,
          50,
          42,
          19,
          29,
          55,
          57
        ],
        [
          "test_llava_reload",
          8,
          17,
          12,
          14,
          12,
          42,
          8,
          27,
          17,
          57
        ]
      ],
      "transformers/tests/utils/test_configuration_utils.py": [
        [
          "test_bc_torch_dtype",
          335,
          358,
          348,
          14,
          348,
          42,
          335,
          29,
          358,
          53
        ],
        [
          "test_local_versioning",
          237,
          257,
          241,
          14,
          241,
          42,
          237,
          31,
          257,
          64
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          134,
          146,
          140,
          18,
          140,
          46,
          134,
          62,
          144,
          48
        ],
        [
          "test_saving_config_with_custom_generation_kwargs_raises_warning",
          280,
          285,
          282,
          14,
          282,
          42,
          280,
          73,
          285,
          56
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          108,
          120,
          114,
          18,
          114,
          46,
          108,
          46,
          118,
          48
        ]
      ],
      "transformers/tests/generation/test_configuration_utils.py": [
        [
          "test_refuse_to_save",
          233,
          273,
          240,
          14,
          240,
          42,
          233,
          29,
          273,
          57
        ],
        [
          "test_save_load_config",
          71,
          91,
          78,
          14,
          78,
          42,
          71,
          31,
          91,
          54
        ],
        [
          "test_refuse_to_save",
          233,
          273,
          251,
          14,
          251,
          42,
          233,
          29,
          273,
          57
        ],
        [
          "test_kwarg_init",
          123,
          146,
          140,
          14,
          140,
          42,
          123,
          25,
          146,
          52
        ],
        [
          "test_refuse_to_save",
          233,
          273,
          263,
          14,
          263,
          42,
          233,
          29,
          273,
          57
        ],
        [
          "test_serialize_generation_sequence_bias",
          301,
          313,
          306,
          14,
          306,
          66,
          301,
          49,
          313,
          89
        ],
        [
          "test_serialize_generation_min_length_eos_token",
          315,
          331,
          321,
          14,
          321,
          66,
          315,
          56,
          331,
          71
        ],
        [
          "test_serialize_generation_min_new_tokens",
          333,
          350,
          340,
          14,
          340,
          66,
          333,
          50,
          350,
          81
        ],
        [
          "test_serialize_generation_temperature",
          352,
          363,
          357,
          14,
          357,
          66,
          352,
          47,
          363,
          76
        ],
        [
          "test_serialize_generation_repetition_penalty",
          365,
          376,
          370,
          14,
          370,
          66,
          365,
          54,
          376,
          59
        ],
        [
          "test_serialize_generation_encoder_repetition_penalty",
          378,
          393,
          384,
          14,
          384,
          66,
          378,
          62,
          393,
          81
        ],
        [
          "test_serialize_generation_top_p",
          395,
          406,
          400,
          14,
          400,
          66,
          395,
          41,
          406,
          55
        ],
        [
          "test_serialize_generation_top_k",
          408,
          419,
          413,
          14,
          413,
          66,
          408,
          41,
          419,
          56
        ],
        [
          "test_serialize_generation_min_p",
          421,
          432,
          426,
          14,
          426,
          66,
          421,
          41,
          432,
          56
        ],
        [
          "test_serialize_generation_typical_p",
          434,
          445,
          439,
          14,
          439,
          66,
          434,
          45,
          445,
          58
        ],
        [
          "test_serialize_generation_epsilon_cutoff",
          447,
          458,
          452,
          14,
          452,
          66,
          447,
          50,
          458,
          62
        ],
        [
          "test_serialize_generation_eta_cutoff",
          460,
          471,
          465,
          14,
          465,
          66,
          460,
          46,
          471,
          58
        ],
        [
          "test_serialize_generation_ngram_size",
          473,
          484,
          478,
          14,
          478,
          66,
          473,
          46,
          484,
          69
        ],
        [
          "test_serialize_generation_encoder_ngram_size",
          486,
          500,
          492,
          14,
          492,
          66,
          486,
          54,
          500,
          77
        ],
        [
          "test_serialize_generation_bad_words_ids",
          502,
          513,
          507,
          14,
          507,
          66,
          502,
          49,
          513,
          86
        ],
        [
          "test_serialize_generation_num_beams",
          515,
          531,
          523,
          14,
          523,
          66,
          515,
          45,
          531,
          78
        ],
        [
          "test_serialize_generation_bos_token_id",
          533,
          544,
          538,
          14,
          538,
          66,
          533,
          48,
          544,
          69
        ],
        [
          "test_serialize_generation_eos_token_id",
          546,
          560,
          552,
          14,
          552,
          66,
          546,
          48,
          560,
          69
        ],
        [
          "test_serialize_generation_exponential_decay_length_penalty",
          562,
          584,
          571,
          14,
          571,
          66,
          562,
          68,
          584,
          108
        ],
        [
          "test_serialize_generation_begin_suppress_tokens",
          586,
          601,
          592,
          14,
          592,
          66,
          586,
          57,
          601,
          69
        ],
        [
          "test_serialize_generation_suppress_tokens",
          603,
          614,
          608,
          14,
          608,
          66,
          603,
          51,
          614,
          85
        ],
        [
          "test_serialize_generation_guidance_scale",
          616,
          626,
          620,
          14,
          620,
          66,
          616,
          50,
          626,
          77
        ],
        [
          "test_serialize_generation_guidance_scale_unbatched",
          628,
          641,
          635,
          14,
          635,
          66,
          628,
          60,
          641,
          60
        ],
        [
          "test_serialize_generation_watermarking_config",
          643,
          683,
          661,
          14,
          661,
          66,
          643,
          55,
          683,
          64
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          706,
          720,
          714,
          18,
          714,
          46,
          706,
          46,
          718,
          48
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          736,
          750,
          744,
          18,
          744,
          46,
          736,
          62,
          748,
          48
        ]
      ],
      "transformers/tests/quantization/eetq_integration/test_eetq.py": [
        [
          "test_save_pretrained",
          143,
          155,
          147,
          14,
          147,
          42,
          143,
          30,
          155,
          110
        ]
      ],
      "transformers/tests/models/auto/test_feature_extraction_auto.py": [
        [
          "test_new_feature_extractor_registration",
          135,
          154,
          145,
          18,
          145,
          46,
          145,
          18,
          145,
          46
        ],
        [
          "test_from_pretrained_dynamic_feature_extractor",
          102,
          133,
          126,
          14,
          126,
          42,
          102,
          56,
          133,
          94
        ],
        [
          "test_feature_extractor_from_local_directory_from_config",
          57,
          77,
          58,
          14,
          58,
          42,
          57,
          65,
          77,
          63
        ]
      ],
      "transformers/tests/models/audio_spectrogram_transformer/test_feature_extraction_audio_spectrogram_transformer.py": [
        [
          "test_feat_extract_to_json_file",
          190,
          200,
          193,
          14,
          193,
          42,
          190,
          40,
          200,
          49
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          178,
          188,
          181,
          14,
          181,
          42,
          178,
          52,
          188,
          53
        ]
      ],
      "transformers/tests/quantization/fbgemm_fp8/test_fbgemm_fp8.py": [
        [
          "test_save_pretrained_offload",
          243,
          254,
          247,
          14,
          247,
          42,
          243,
          38,
          254,
          110
        ],
        [
          "test_change_loading_attributes",
          194,
          212,
          198,
          14,
          198,
          42,
          194,
          40,
          212,
          110
        ],
        [
          "test_save_pretrained",
          180,
          192,
          184,
          14,
          184,
          42,
          180,
          30,
          192,
          110
        ],
        [
          "test_save_pretrained_multi_gpu",
          257,
          270,
          261,
          14,
          261,
          42,
          257,
          40,
          270,
          110
        ]
      ],
      "transformers/tests/models/clvp/test_feature_extraction_clvp.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          126,
          139,
          129,
          14,
          129,
          42,
          126,
          52,
          139,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          142,
          155,
          145,
          14,
          145,
          42,
          142,
          40,
          155,
          49
        ]
      ],
      "transformers/tests/test_feature_extraction_common.py": [
        [
          "test_feat_extract_to_json_file",
          32,
          40,
          35,
          14,
          35,
          42,
          32,
          40,
          40,
          85
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          42,
          50,
          45,
          14,
          45,
          42,
          42,
          52,
          50,
          85
        ]
      ],
      "transformers/tests/models/gemma3n/test_feature_extraction_gemma3n.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          148,
          161,
          151,
          14,
          151,
          42,
          148,
          52,
          161,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          163,
          176,
          166,
          14,
          166,
          42,
          163,
          40,
          176,
          49
        ],
        [
          "test_feat_extract_from_pretrained_kwargs",
          178,
          190,
          181,
          14,
          181,
          42,
          178,
          50,
          190,
          61
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_feature_extraction_musicgen_melody.py": [
        [
          "test_feat_extract_to_json_file",
          142,
          152,
          145,
          14,
          145,
          42,
          142,
          40,
          152,
          49
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          129,
          139,
          132,
          14,
          132,
          42,
          129,
          52,
          139,
          53
        ]
      ],
      "transformers/tests/models/pop2piano/test_feature_extraction_pop2piano.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          95,
          108,
          98,
          14,
          98,
          42,
          95,
          52,
          108,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          110,
          123,
          113,
          14,
          113,
          42,
          110,
          40,
          123,
          49
        ]
      ],
      "transformers/tests/models/phi4_multimodal/test_feature_extraction_phi4_multimodal.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          114,
          127,
          117,
          14,
          117,
          42,
          114,
          52,
          127,
          49
        ],
        [
          "test_feat_extract_from_pretrained_kwargs",
          144,
          156,
          147,
          14,
          147,
          42,
          144,
          50,
          156,
          61
        ],
        [
          "test_feat_extract_to_json_file",
          129,
          142,
          132,
          14,
          132,
          42,
          129,
          40,
          142,
          49
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_feature_extraction_seamless_m4t.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          117,
          127,
          120,
          14,
          120,
          42,
          117,
          52,
          127,
          53
        ],
        [
          "test_feat_extract_to_json_file",
          129,
          139,
          132,
          14,
          132,
          42,
          129,
          40,
          139,
          49
        ]
      ],
      "transformers/tests/models/speech_to_text/test_feature_extraction_speech_to_text.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          316,
          326,
          319,
          14,
          319,
          42,
          316,
          52,
          326,
          53
        ],
        [
          "test_feat_extract_to_json_file",
          328,
          338,
          331,
          14,
          331,
          42,
          328,
          40,
          338,
          49
        ]
      ],
      "transformers/tests/utils/test_feature_extraction_utils.py": [
        [
          "test_push_to_hub_via_save_pretrained",
          71,
          82,
          75,
          18,
          75,
          46,
          71,
          46,
          81,
          58
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          93,
          104,
          97,
          18,
          97,
          46,
          93,
          62,
          103,
          58
        ]
      ],
      "transformers/tests/models/whisper/test_feature_extraction_whisper.py": [
        [
          "test_feat_extract_from_pretrained_kwargs",
          148,
          160,
          151,
          14,
          151,
          42,
          148,
          50,
          160,
          61
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          118,
          131,
          121,
          14,
          121,
          42,
          118,
          52,
          131,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          133,
          146,
          136,
          14,
          136,
          42,
          133,
          40,
          146,
          49
        ]
      ],
      "transformers/tests/quantization/finegrained_fp8/test_fp8.py": [
        [
          "test_save_pretrained",
          160,
          172,
          164,
          14,
          164,
          42,
          160,
          30,
          172,
          110
        ],
        [
          "test_save_pretrained_multi_accelerators",
          213,
          226,
          217,
          14,
          217,
          42,
          213,
          49,
          226,
          110
        ],
        [
          "test_save_pretrained_offload",
          239,
          250,
          243,
          14,
          243,
          42,
          239,
          38,
          250,
          110
        ]
      ],
      "transformers/tests/models/univnet/test_feature_extraction_univnet.py": [
        [
          "test_feat_extract_to_json_file",
          174,
          187,
          177,
          14,
          177,
          42,
          174,
          40,
          187,
          49
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          158,
          171,
          161,
          14,
          161,
          42,
          158,
          52,
          171,
          49
        ]
      ],
      "transformers/tests/quantization/fp_quant_integration/test_fp_quant.py": [
        [
          "test_save_pretrained",
          100,
          112,
          104,
          14,
          104,
          42,
          100,
          30,
          112,
          110
        ],
        [
          "test_save_pretrained_multi_gpu",
          131,
          144,
          135,
          14,
          135,
          42,
          131,
          40,
          144,
          110
        ]
      ],
      "transformers/tests/quantization/hqq/test_hqq.py": [
        [
          "test_save_and_load_quantized_model",
          206,
          237,
          224,
          14,
          224,
          42,
          206,
          44,
          237,
          81
        ]
      ],
      "transformers/tests/quantization/higgs/test_higgs.py": [
        [
          "test_save_pretrained_multi_gpu",
          172,
          185,
          176,
          14,
          176,
          42,
          172,
          40,
          185,
          110
        ],
        [
          "test_save_pretrained",
          141,
          153,
          145,
          14,
          145,
          42,
          141,
          30,
          153,
          110
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_has_file_in_cache",
          103,
          112,
          104,
          14,
          104,
          42,
          103,
          32,
          106,
          106
        ],
        [
          "test_get_file_from_repo_local",
          158,
          181,
          159,
          14,
          159,
          42,
          158,
          39,
          181,
          13
        ]
      ],
      "transformers/tests/quantization/gptq/test_gptq.py": [
        [
          "test_change_loading_attributes",
          289,
          303,
          293,
          14,
          293,
          42,
          289,
          40,
          295,
          39
        ],
        [
          "test_serialization",
          241,
          271,
          245,
          14,
          245,
          42,
          241,
          28,
          247,
          39
        ],
        [
          "test_serialization_big_model_inference",
          274,
          282,
          278,
          14,
          278,
          42,
          274,
          48,
          280,
          40
        ]
      ],
      "transformers/tests/utils/test_hf_argparser.py": [
        [
          "test_11_parse_json",
          378,
          395,
          387,
          14,
          387,
          42,
          378,
          28,
          395,
          43
        ],
        [
          "test_14_valid_dict_input_parsing",
          474,
          481,
          475,
          14,
          475,
          42,
          474,
          42,
          481,
          98
        ],
        [
          "test_12_parse_yaml",
          397,
          413,
          406,
          14,
          406,
          42,
          397,
          28,
          413,
          43
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_image_processor_from_local_file",
          123,
          132,
          124,
          14,
          124,
          42,
          123,
          46,
          132,
          61
        ],
        [
          "test_image_processor_from_new_filename",
          79,
          90,
          80,
          14,
          80,
          42,
          79,
          48,
          90,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          93,
          14,
          93,
          42,
          92,
          63,
          121,
          57
        ],
        [
          "test_from_pretrained_dynamic_image_processor",
          171,
          206,
          193,
          14,
          193,
          42,
          171,
          54,
          206,
          87
        ],
        [
          "test_image_processor_from_local_directory_from_feature_extractor_key",
          63,
          77,
          67,
          14,
          67,
          42,
          63,
          78,
          77,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_key",
          50,
          61,
          51,
          14,
          51,
          42,
          50,
          60,
          61,
          61
        ],
        [
          "test_new_image_processor_registration",
          208,
          237,
          228,
          18,
          228,
          46,
          228,
          18,
          228,
          46
        ],
        [
          "test_new_image_processor_registration",
          208,
          237,
          216,
          18,
          216,
          46,
          216,
          18,
          216,
          46
        ]
      ],
      "transformers/tests/quantization/ggml/test_ggml.py": [
        [
          "test_llama3_q4_0_tokenizer",
          433,
          440,
          435,
          14,
          435,
          42,
          433,
          36,
          440,
          84
        ],
        [
          "test_q2_k_serialization",
          189,
          210,
          200,
          14,
          200,
          42,
          189,
          33,
          210,
          91
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_image_processor_from_and_save_pretrained",
          277,
          286,
          281,
          18,
          281,
          46,
          278,
          13,
          286,
          95
        ],
        [
          "test_save_load_fast_slow",
          301,
          349,
          317,
          14,
          317,
          42,
          306,
          32,
          349,
          50
        ],
        [
          "test_save_load_fast_slow_auto",
          351,
          399,
          360,
          14,
          360,
          42,
          356,
          32,
          399,
          50
        ],
        [
          "test_image_processor_to_json_file",
          266,
          275,
          270,
          18,
          270,
          46,
          267,
          13,
          275,
          95
        ],
        [
          "test_image_processor_save_load_with_autoimageprocessor",
          288,
          299,
          292,
          18,
          292,
          46,
          289,
          13,
          296,
          33
        ],
        [
          "test_save_load_fast_slow",
          301,
          349,
          310,
          14,
          310,
          42,
          306,
          32,
          349,
          50
        ],
        [
          "test_save_load_fast_slow_auto",
          351,
          399,
          367,
          14,
          367,
          42,
          356,
          32,
          399,
          50
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          759,
          22,
          759,
          50,
          754,
          13,
          772,
          57
        ]
      ],
      "transformers/tests/models/imagegpt/test_image_processing_imagegpt.py": [
        [
          "test_image_processor_to_json_file",
          146,
          160,
          150,
          18,
          150,
          46,
          147,
          13,
          156,
          59
        ],
        [
          "test_image_processor_from_and_save_pretrained",
          162,
          175,
          166,
          18,
          166,
          46,
          163,
          13,
          171,
          59
        ],
        [
          "test_image_processor_save_load_with_autoimageprocessor",
          177,
          194,
          181,
          18,
          181,
          46,
          178,
          13,
          190,
          59
        ]
      ],
      "transformers/tests/models/oneformer/test_image_processing_oneformer.py": [
        [
          "test_can_load_with_local_metadata",
          359,
          378,
          368,
          18,
          368,
          46,
          367,
          13,
          378,
          64
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_image_processing_qwen2_vl.py": [
        [
          "test_custom_image_size",
          302,
          314,
          305,
          18,
          305,
          46,
          303,
          13,
          314,
          99
        ]
      ],
      "transformers/tests/utils/test_image_processing_utils.py": [
        [
          "test_push_to_hub_via_save_pretrained_fast",
          105,
          114,
          109,
          18,
          109,
          46,
          105,
          51,
          113,
          56
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          94,
          103,
          98,
          18,
          98,
          46,
          94,
          46,
          102,
          56
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          134,
          143,
          138,
          18,
          138,
          46,
          134,
          62,
          142,
          56
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained_fast",
          145,
          154,
          149,
          18,
          149,
          46,
          145,
          67,
          153,
          56
        ]
      ],
      "transformers/tests/models/timm_wrapper/test_image_processing_timm_wrapper.py": [
        [
          "setUp",
          39,
          43,
          41,
          25,
          41,
          53,
          39,
          15,
          43,
          50
        ]
      ],
      "transformers/tests/utils/test_model_card.py": [
        [
          "test_model_card_to_json_file",
          66,
          74,
          69,
          14,
          69,
          42,
          66,
          38,
          74,
          81
        ],
        [
          "test_model_card_from_and_save_pretrained",
          76,
          83,
          79,
          14,
          79,
          42,
          76,
          50,
          83,
          81
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_layer_pruning_behavior",
          96,
          122,
          113,
          18,
          113,
          46,
          113,
          18,
          122,
          99
        ],
        [
          "test_layer_pruning_behavior",
          96,
          122,
          98,
          18,
          98,
          46,
          96,
          41,
          106,
          43
        ],
        [
          "test_debugger_outputs",
          52,
          63,
          53,
          18,
          53,
          46,
          52,
          35,
          60,
          55
        ]
      ],
      "transformers/tests/quantization/bnb/test_mixed_int8.py": [
        [
          "test_inference_with_keep_in_fp32_serialized",
          542,
          571,
          555,
          14,
          555,
          42,
          542,
          53,
          571,
          13
        ],
        [
          "test_int8_serialization",
          370,
          395,
          376,
          14,
          376,
          42,
          370,
          33,
          395,
          114
        ],
        [
          "test_int8_serialization_regression",
          397,
          422,
          403,
          14,
          403,
          42,
          397,
          44,
          422,
          114
        ],
        [
          "test_int8_serialization_sharded",
          424,
          449,
          430,
          14,
          430,
          42,
          424,
          41,
          449,
          118
        ],
        [
          "test_cpu_accelerator_disk_loading_custom_device_map",
          812,
          837,
          825,
          14,
          825,
          42,
          812,
          61,
          837,
          56
        ],
        [
          "test_cpu_accelerator_disk_loading_custom_device_map_kwargs",
          839,
          864,
          851,
          14,
          851,
          42,
          839,
          68,
          864,
          56
        ]
      ],
      "transformers/tests/models/aimv2/test_modeling_aimv2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          144,
          171,
          149,
          18,
          149,
          46,
          145,
          13,
          162,
          50
        ],
        [
          "test_load_vision_text_config",
          429,
          442,
          433,
          14,
          433,
          42,
          429,
          38,
          442,
          85
        ],
        [
          "test_load_vision_text_config",
          429,
          442,
          439,
          14,
          439,
          42,
          429,
          38,
          442,
          85
        ]
      ],
      "transformers/tests/models/align/test_modeling_align.py": [
        [
          "_create_and_check_torchscript",
          491,
          560,
          510,
          18,
          510,
          46,
          510,
          18,
          514,
          25
        ],
        [
          "test_load_vision_text_config",
          562,
          575,
          572,
          14,
          572,
          42,
          562,
          38,
          575,
          85
        ],
        [
          "test_load_vision_text_config",
          562,
          575,
          566,
          14,
          566,
          42,
          562,
          38,
          575,
          85
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "_create_and_check_torchscript",
          467,
          536,
          486,
          18,
          486,
          46,
          486,
          18,
          490,
          25
        ]
      ],
      "transformers/tests/models/autoformer/test_modeling_autoformer.py": [
        [
          "check_encoder_decoder_model_standalone",
          144,
          202,
          151,
          14,
          151,
          42,
          144,
          48,
          202,
          99
        ],
        [
          "test_save_load_strict",
          228,
          236,
          233,
          18,
          233,
          46,
          230,
          13,
          236,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          144,
          202,
          191,
          14,
          191,
          42,
          144,
          48,
          202,
          99
        ]
      ],
      "transformers/tests/models/auto/test_modeling_auto.py": [
        [
          "test_from_pretrained_dynamic_model_distant",
          310,
          363,
          326,
          14,
          326,
          42,
          310,
          52,
          331,
          74
        ],
        [
          "test_from_pretrained_dynamic_model_distant_with_ref",
          365,
          391,
          385,
          14,
          385,
          42,
          379,
          17,
          390,
          74
        ],
        [
          "test_from_pretrained_with_tuple_values",
          274,
          287,
          284,
          14,
          284,
          42,
          274,
          48,
          287,
          57
        ],
        [
          "test_from_pretrained_dynamic_model_local",
          289,
          308,
          297,
          18,
          297,
          46,
          297,
          18,
          297,
          46
        ],
        [
          "test_from_pretrained_dynamic_model_distant",
          310,
          363,
          351,
          14,
          351,
          42,
          335,
          26,
          356,
          74
        ],
        [
          "test_from_pretrained_dynamic_model_distant_with_ref",
          365,
          391,
          370,
          14,
          370,
          42,
          365,
          61,
          375,
          74
        ],
        [
          "test_from_pretrained_dynamic_model_with_period",
          393,
          412,
          408,
          14,
          408,
          42,
          393,
          56,
          412,
          66
        ],
        [
          "test_new_model_registration",
          414,
          463,
          444,
          26,
          444,
          54,
          444,
          26,
          444,
          54
        ]
      ],
      "transformers/tests/models/bamba/test_modeling_bamba.py": [
        [
          "test_flash_attention_2_padding_matches_padding_free_with_position_ids_seq_idx_and_fa_kwargs",
          434,
          514,
          460,
          18,
          460,
          46,
          460,
          18,
          464,
          60
        ]
      ],
      "transformers/tests/models/bart/test_modeling_bart.py": [
        [
          "check_encoder_decoder_model_standalone",
          187,
          217,
          205,
          14,
          205,
          42,
          187,
          48,
          217,
          99
        ],
        [
          "test_save_load_strict",
          434,
          442,
          439,
          18,
          439,
          46,
          436,
          13,
          442,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          187,
          217,
          194,
          14,
          194,
          42,
          187,
          48,
          217,
          99
        ]
      ],
      "transformers/tests/models/bark/test_modeling_bark.py": [
        [
          "test_save_load_strict",
          536,
          544,
          541,
          18,
          541,
          46,
          538,
          13,
          544,
          54
        ],
        [
          "test_save_load_strict",
          623,
          631,
          628,
          18,
          628,
          46,
          625,
          13,
          631,
          54
        ],
        [
          "test_save_load_strict",
          710,
          718,
          715,
          18,
          715,
          46,
          712,
          13,
          718,
          54
        ]
      ],
      "transformers/tests/models/bert_generation/test_modeling_bert_generation.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          313,
          425,
          362,
          18,
          362,
          46,
          362,
          18,
          369,
          60
        ]
      ],
      "transformers/tests/models/bert/test_modeling_bert.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          614,
          726,
          663,
          18,
          663,
          46,
          663,
          18,
          670,
          60
        ]
      ],
      "transformers/tests/models/blenderbot/test_modeling_blenderbot.py": [
        [
          "check_encoder_decoder_model_standalone",
          179,
          209,
          186,
          14,
          186,
          42,
          179,
          48,
          209,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          179,
          209,
          197,
          14,
          197,
          42,
          179,
          48,
          209,
          99
        ],
        [
          "test_save_load_strict",
          238,
          246,
          243,
          18,
          243,
          46,
          240,
          13,
          246,
          54
        ]
      ],
      "transformers/tests/models/blenderbot_small/test_modeling_blenderbot_small.py": [
        [
          "check_encoder_decoder_model_standalone",
          171,
          201,
          178,
          14,
          178,
          42,
          171,
          48,
          201,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          171,
          201,
          189,
          14,
          189,
          42,
          171,
          48,
          201,
          99
        ],
        [
          "test_save_load_strict",
          243,
          251,
          248,
          18,
          248,
          46,
          245,
          13,
          251,
          54
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip.py": [
        [
          "test_load_vision_text_config",
          530,
          543,
          534,
          14,
          534,
          42,
          530,
          38,
          543,
          85
        ],
        [
          "test_load_vision_text_config",
          1209,
          1222,
          1213,
          14,
          1213,
          42,
          1209,
          38,
          1222,
          85
        ],
        [
          "_create_and_check_torchscript",
          1138,
          1207,
          1157,
          18,
          1157,
          46,
          1157,
          18,
          1161,
          25
        ],
        [
          "_create_and_check_torchscript",
          459,
          528,
          478,
          18,
          478,
          46,
          478,
          18,
          482,
          25
        ],
        [
          "test_load_vision_text_config",
          530,
          543,
          540,
          14,
          540,
          42,
          530,
          38,
          543,
          85
        ],
        [
          "_create_and_check_torchscript",
          949,
          1018,
          968,
          18,
          968,
          46,
          968,
          18,
          972,
          25
        ],
        [
          "test_load_vision_text_config",
          1020,
          1033,
          1024,
          14,
          1024,
          42,
          1020,
          38,
          1033,
          85
        ],
        [
          "test_load_vision_text_config",
          1020,
          1033,
          1030,
          14,
          1030,
          42,
          1020,
          38,
          1033,
          85
        ],
        [
          "test_load_vision_text_config",
          1209,
          1222,
          1219,
          14,
          1219,
          42,
          1209,
          38,
          1222,
          85
        ]
      ],
      "transformers/tests/models/bigbird_pegasus/test_modeling_bigbird_pegasus.py": [
        [
          "check_encoder_decoder_model_standalone",
          200,
          230,
          207,
          14,
          207,
          42,
          200,
          48,
          230,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          200,
          230,
          218,
          14,
          218,
          42,
          200,
          48,
          230,
          99
        ],
        [
          "test_save_load_strict",
          297,
          305,
          302,
          18,
          302,
          46,
          299,
          13,
          305,
          54
        ]
      ],
      "transformers/tests/models/blip_2/test_modeling_blip_2.py": [
        [
          "test_load_vision_qformer_text_config",
          567,
          580,
          571,
          14,
          571,
          42,
          567,
          46,
          580,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          918,
          931,
          922,
          14,
          922,
          42,
          918,
          46,
          931,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          567,
          580,
          577,
          14,
          577,
          42,
          567,
          46,
          580,
          91
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          507,
          553,
          528,
          18,
          528,
          46,
          524,
          13,
          546,
          66
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          859,
          905,
          880,
          18,
          880,
          46,
          876,
          13,
          898,
          66
        ],
        [
          "test_load_vision_qformer_text_config",
          918,
          931,
          928,
          14,
          928,
          42,
          918,
          46,
          931,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          1432,
          1445,
          1436,
          14,
          1436,
          42,
          1432,
          46,
          1445,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          1432,
          1445,
          1442,
          14,
          1442,
          42,
          1432,
          46,
          1445,
          91
        ]
      ],
      "transformers/tests/models/chinese_clip/test_modeling_chinese_clip.py": [
        [
          "_create_and_check_torchscript",
          574,
          643,
          593,
          18,
          593,
          46,
          593,
          18,
          597,
          25
        ]
      ],
      "transformers/tests/models/clap/test_modeling_clap.py": [
        [
          "_create_and_check_torchscript",
          528,
          597,
          547,
          18,
          547,
          46,
          547,
          18,
          551,
          25
        ],
        [
          "test_load_audio_text_config",
          599,
          612,
          603,
          14,
          603,
          42,
          599,
          37,
          612,
          85
        ],
        [
          "test_load_audio_text_config",
          599,
          612,
          609,
          14,
          609,
          42,
          599,
          37,
          612,
          85
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "_create_and_check_torchscript",
          493,
          562,
          512,
          18,
          512,
          46,
          512,
          18,
          516,
          25
        ],
        [
          "test_load_vision_text_config",
          564,
          577,
          568,
          14,
          568,
          42,
          564,
          38,
          577,
          85
        ],
        [
          "test_load_vision_text_config",
          564,
          577,
          574,
          14,
          574,
          42,
          564,
          38,
          577,
          85
        ]
      ],
      "transformers/tests/models/clip/test_modeling_clip.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          174,
          202,
          179,
          18,
          179,
          46,
          175,
          13,
          193,
          50
        ],
        [
          "_create_and_check_torchscript",
          565,
          634,
          584,
          18,
          584,
          46,
          584,
          18,
          588,
          25
        ],
        [
          "test_load_vision_text_config",
          636,
          649,
          640,
          14,
          640,
          42,
          636,
          38,
          649,
          85
        ],
        [
          "test_load_vision_text_config",
          636,
          649,
          646,
          14,
          646,
          42,
          636,
          38,
          649,
          85
        ]
      ],
      "transformers/tests/models/clvp/test_modeling_clvp.py": [
        [
          "test_load_speech_text_decoder_config",
          501,
          514,
          511,
          14,
          511,
          42,
          501,
          46,
          514,
          91
        ],
        [
          "test_load_speech_text_decoder_config",
          501,
          514,
          505,
          14,
          505,
          42,
          501,
          46,
          514,
          91
        ]
      ],
      "transformers/tests/models/data2vec/test_modeling_data2vec_text.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          507,
          619,
          556,
          18,
          556,
          46,
          556,
          18,
          563,
          60
        ]
      ],
      "transformers/tests/models/d_fine/test_modeling_d_fine.py": [
        [
          "test_inference_equivalence_for_static_and_dynamic_anchors",
          656,
          690,
          672,
          18,
          672,
          46,
          671,
          13,
          690,
          13
        ]
      ],
      "transformers/tests/models/dac/test_modeling_dac.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          207,
          18,
          207,
          46,
          207,
          18,
          211,
          25
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "_test_eager_matches_sdpa_inference",
          152,
          504,
          250,
          14,
          250,
          42,
          250,
          14,
          257,
          48
        ],
        [
          "test_save_load",
          710,
          755,
          731,
          18,
          731,
          46,
          723,
          13,
          751,
          39
        ],
        [
          "test_keep_in_fp32_modules",
          769,
          785,
          776,
          18,
          776,
          46,
          775,
          21,
          781,
          59
        ],
        [
          "test_save_load_keys_to_ignore_on_save",
          787,
          817,
          801,
          18,
          801,
          46,
          801,
          18,
          806,
          48
        ],
        [
          "test_torch_save_load",
          975,
          1022,
          1017,
          18,
          1017,
          46,
          991,
          29,
          1022,
          64
        ],
        [
          "_create_and_check_torchscript",
          1385,
          1521,
          1466,
          22,
          1466,
          50,
          1466,
          22,
          1470,
          29
        ],
        [
          "test_head_pruning_save_load_from_pretrained",
          1725,
          1759,
          1748,
          18,
          1748,
          46,
          1729,
          13,
          1759,
          97
        ],
        [
          "test_head_pruning_integration",
          1795,
          1846,
          1824,
          18,
          1824,
          46,
          1799,
          13,
          1846,
          80
        ],
        [
          "test_correct_missing_keys",
          2380,
          2404,
          2401,
          22,
          2401,
          50,
          2401,
          22,
          2404,
          102
        ],
        [
          "test_can_use_safetensors",
          2438,
          2472,
          2442,
          18,
          2442,
          46,
          2439,
          13,
          2444,
          46
        ],
        [
          "test_load_save_without_tied_weights",
          2474,
          2491,
          2479,
          18,
          2479,
          46,
          2475,
          13,
          2485,
          54
        ],
        [
          "test_model_weights_reload_no_missing_tied_weights",
          2530,
          2586,
          2534,
          18,
          2534,
          46,
          2531,
          13,
          2553,
          71
        ],
        [
          "test_disk_offload_bin",
          2783,
          2822,
          2797,
          18,
          2797,
          46,
          2790,
          33,
          2816,
          52
        ],
        [
          "test_disk_offload_safetensors",
          2827,
          2860,
          2841,
          18,
          2841,
          46,
          2834,
          33,
          2854,
          52
        ],
        [
          "test_cpu_offload",
          2865,
          2902,
          2882,
          18,
          2882,
          46,
          2872,
          33,
          2885,
          45
        ],
        [
          "test_model_parallelism",
          2908,
          2944,
          2925,
          18,
          2925,
          46,
          2915,
          33,
          2928,
          45
        ],
        [
          "test_load_with_mismatched_shapes",
          2992,
          3034,
          3002,
          22,
          3002,
          50,
          3001,
          18,
          3031,
          46
        ],
        [
          "test_can_load_ignoring_mismatched_shapes",
          3036,
          3118,
          3057,
          22,
          3057,
          50,
          3056,
          18,
          3076,
          51
        ],
        [
          "flash_attn_inference_equivalence",
          3131,
          3281,
          3166,
          18,
          3166,
          46,
          3165,
          43,
          3173,
          55
        ],
        [
          "test_attn_implementation_composite_models",
          3333,
          3389,
          3379,
          18,
          3379,
          46,
          3372,
          43,
          3383,
          52
        ],
        [
          "test_sdpa_can_dispatch_non_composite_models",
          3391,
          3426,
          3406,
          18,
          3406,
          46,
          3402,
          13,
          3417,
          66
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          3428,
          3481,
          3449,
          18,
          3449,
          46,
          3445,
          13,
          3461,
          72
        ],
        [
          "test_sdpa_can_dispatch_on_flash",
          3493,
          3570,
          3557,
          18,
          3557,
          46,
          3557,
          18,
          3565,
          52
        ],
        [
          "test_sdpa_can_compile_dynamic",
          3575,
          3635,
          3618,
          18,
          3618,
          46,
          3618,
          18,
          3629,
          52
        ],
        [
          "flash_attn_can_dispatch_composite_models",
          3637,
          3697,
          3658,
          18,
          3658,
          46,
          3658,
          18,
          3668,
          86
        ],
        [
          "test_flash_attn_2_fp32_ln",
          3716,
          3765,
          3725,
          18,
          3725,
          46,
          3723,
          35,
          3735,
          35
        ],
        [
          "flash_attn_from_config",
          3806,
          3844,
          3841,
          18,
          3841,
          46,
          3841,
          18,
          3844,
          105
        ],
        [
          "test_can_load_with_device_context_manager",
          4176,
          4196,
          4185,
          18,
          4185,
          46,
          4180,
          13,
          4196,
          13
        ],
        [
          "test_can_load_with_global_device_set",
          4203,
          4229,
          4216,
          18,
          4216,
          46,
          4208,
          13,
          4229,
          13
        ],
        [
          "test_cannot_load_with_meta_device_context_manager",
          4231,
          4244,
          4238,
          18,
          4238,
          46,
          4233,
          13,
          4244,
          25
        ],
        [
          "test_bc_torch_dtype",
          4379,
          4401,
          4389,
          18,
          4389,
          46,
          4388,
          21,
          4393,
          117
        ]
      ],
      "transformers/tests/models/deepseek_vl/test_modeling_deepseek_vl.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          190,
          229,
          195,
          18,
          195,
          46,
          191,
          13,
          210,
          72
        ]
      ],
      "transformers/tests/models/deepseek_vl_hybrid/test_modeling_deepseek_vl_hybrid.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          220,
          272,
          225,
          18,
          225,
          46,
          221,
          13,
          246,
          51
        ]
      ],
      "transformers/tests/models/dia/test_modeling_dia.py": [
        [
          "check_encoder_decoder_model_standalone",
          183,
          212,
          190,
          14,
          190,
          42,
          183,
          48,
          212,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          183,
          212,
          201,
          14,
          201,
          42,
          183,
          48,
          212,
          99
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          412,
          443,
          420,
          18,
          420,
          46,
          416,
          13,
          431,
          58
        ]
      ],
      "transformers/tests/models/diffllama/test_modeling_diffllama.py": [
        [
          "test_use_flash_attention_2_true",
          472,
          494,
          478,
          18,
          478,
          46,
          477,
          13,
          489,
          64
        ]
      ],
      "transformers/tests/models/distilbert/test_modeling_distilbert.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          282,
          327,
          306,
          18,
          306,
          46,
          285,
          13,
          327,
          91
        ],
        [
          "test_flash_attn_2_inference_equivalence_right_padding",
          334,
          382,
          358,
          18,
          358,
          46,
          337,
          13,
          382,
          93
        ]
      ],
      "transformers/tests/models/dpr/test_modeling_dpr.py": [
        [
          "test_init_changed_config",
          211,
          222,
          218,
          14,
          218,
          42,
          211,
          34,
          222,
          35
        ]
      ],
      "transformers/tests/models/edgetam/test_modeling_edgetam.py": [
        [
          "flash_attn_inference_equivalence",
          266,
          352,
          283,
          18,
          283,
          46,
          280,
          35,
          294,
          70
        ]
      ],
      "transformers/tests/models/electra/test_modeling_electra.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          476,
          588,
          525,
          18,
          525,
          46,
          525,
          18,
          532,
          60
        ]
      ],
      "transformers/tests/models/encoder_decoder/test_modeling_encoder_decoder.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          511,
          591,
          567,
          14,
          567,
          42,
          512,
          9,
          591,
          13
        ],
        [
          "test_real_model_save_load_from_pretrained",
          668,
          696,
          683,
          18,
          683,
          46,
          668,
          51,
          696,
          52
        ],
        [
          "check_encoder_decoder_model_from_pretrained_using_model_paths",
          169,
          212,
          183,
          13,
          183,
          41,
          170,
          9,
          190,
          65
        ],
        [
          "check_save_and_load",
          245,
          284,
          270,
          18,
          270,
          46,
          246,
          9,
          284,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          286,
          332,
          313,
          17,
          313,
          45,
          287,
          9,
          332,
          52
        ],
        [
          "check_encoder_decoder_model_from_pretrained_using_model_paths",
          169,
          212,
          182,
          13,
          182,
          41,
          170,
          9,
          190,
          65
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          286,
          332,
          312,
          17,
          312,
          45,
          287,
          9,
          332,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          698,
          747,
          709,
          14,
          709,
          42,
          702,
          23,
          716,
          65
        ]
      ],
      "transformers/tests/models/encodec/test_modeling_encodec.py": [
        [
          "_create_and_check_torchscript",
          212,
          300,
          234,
          18,
          234,
          46,
          234,
          18,
          238,
          25
        ]
      ],
      "transformers/tests/models/ernie4_5_moe/test_modeling_ernie4_5_moe.py": [
        [
          "test_flash_attn_2_equivalence",
          72,
          99,
          80,
          18,
          80,
          46,
          77,
          35,
          99,
          78
        ]
      ],
      "transformers/tests/models/esm/test_modeling_esm.py": [
        [
          "test_flash_attn_2_equivalence",
          313,
          339,
          321,
          18,
          321,
          46,
          318,
          35,
          339,
          83
        ]
      ],
      "transformers/tests/models/ernie/test_modeling_ernie.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          568,
          680,
          617,
          18,
          617,
          46,
          617,
          18,
          624,
          60
        ]
      ],
      "transformers/tests/models/fsmt/test_modeling_fsmt.py": [
        [
          "get_model",
          464,
          478,
          472,
          18,
          472,
          46,
          471,
          21,
          476,
          37
        ],
        [
          "test_save_load_missing_keys",
          242,
          251,
          248,
          18,
          248,
          46,
          245,
          13,
          251,
          54
        ]
      ],
      "transformers/tests/models/fastspeech2_conformer/test_modeling_fastspeech2_conformer.py": [
        [
          "test_save_load_strict",
          197,
          204,
          201,
          14,
          201,
          42,
          197,
          31,
          204,
          50
        ],
        [
          "test_save_load_strict",
          616,
          623,
          620,
          14,
          620,
          42,
          616,
          31,
          623,
          50
        ]
      ],
      "transformers/tests/models/flava/test_modeling_flava.py": [
        [
          "_create_and_check_torchscript",
          920,
          999,
          947,
          18,
          947,
          46,
          947,
          18,
          951,
          25
        ],
        [
          "test_load_image_text_config",
          1001,
          1020,
          1005,
          14,
          1005,
          42,
          1001,
          37,
          1020,
          97
        ],
        [
          "test_load_image_text_config",
          1001,
          1020,
          1011,
          14,
          1011,
          42,
          1001,
          37,
          1020,
          97
        ],
        [
          "test_load_image_text_config",
          1001,
          1020,
          1017,
          14,
          1017,
          42,
          1001,
          37,
          1020,
          97
        ]
      ],
      "transformers/tests/models/gemma3/test_modeling_gemma3.py": [
        [
          "test_automodelforcausallm",
          342,
          352,
          349,
          14,
          349,
          42,
          342,
          35,
          352,
          80
        ]
      ],
      "transformers/tests/models/gemma3n/test_modeling_gemma3n.py": [
        [
          "test_automodelforcausallm",
          716,
          726,
          723,
          14,
          723,
          42,
          716,
          35,
          726,
          68
        ]
      ],
      "transformers/tests/models/granite_speech/test_modeling_granite_speech.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          252,
          287,
          267,
          18,
          267,
          46,
          260,
          13,
          272,
          73
        ]
      ],
      "transformers/tests/models/groupvit/test_modeling_groupvit.py": [
        [
          "_create_and_check_torchscript",
          569,
          638,
          588,
          18,
          588,
          46,
          588,
          18,
          592,
          25
        ],
        [
          "test_load_vision_text_config",
          640,
          653,
          644,
          14,
          644,
          42,
          640,
          38,
          653,
          85
        ],
        [
          "test_load_vision_text_config",
          640,
          653,
          650,
          14,
          650,
          42,
          640,
          38,
          653,
          85
        ]
      ],
      "transformers/tests/models/idefics2/test_modeling_idefics2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          337,
          360,
          342,
          18,
          342,
          46,
          338,
          13,
          357,
          66
        ]
      ],
      "transformers/tests/models/hubert/test_modeling_hubert.py": [
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          505,
          18,
          505,
          46,
          505,
          18,
          508,
          50
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_modeling_instructblipvideo.py": [
        [
          "test_load_vision_qformer_text_config",
          550,
          563,
          560,
          14,
          560,
          42,
          550,
          46,
          563,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          550,
          563,
          554,
          14,
          554,
          42,
          550,
          46,
          563,
          91
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          578,
          624,
          599,
          18,
          599,
          46,
          595,
          13,
          617,
          66
        ]
      ],
      "transformers/tests/models/informer/test_modeling_informer.py": [
        [
          "test_save_load_strict",
          214,
          222,
          219,
          18,
          219,
          46,
          216,
          13,
          222,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          151,
          189,
          179,
          14,
          179,
          42,
          151,
          48,
          189,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          151,
          189,
          158,
          14,
          158,
          42,
          151,
          48,
          189,
          99
        ]
      ],
      "transformers/tests/models/jamba/test_modeling_jamba.py": [
        [
          "test_flash_attn_2_fp32_ln",
          503,
          534,
          512,
          18,
          512,
          46,
          508,
          13,
          527,
          56
        ]
      ],
      "transformers/tests/models/janus/test_modeling_janus.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          204,
          243,
          209,
          18,
          209,
          46,
          205,
          13,
          224,
          72
        ]
      ],
      "transformers/tests/models/instructblip/test_modeling_instructblip.py": [
        [
          "test_load_vision_qformer_text_config",
          538,
          551,
          542,
          14,
          542,
          42,
          538,
          46,
          551,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          538,
          551,
          548,
          14,
          548,
          42,
          538,
          46,
          551,
          91
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          566,
          612,
          587,
          18,
          587,
          46,
          583,
          13,
          605,
          66
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_modeling_kosmos2_5.py": [
        [
          "test_load_save_without_tied_weights",
          396,
          415,
          401,
          18,
          401,
          46,
          399,
          13,
          407,
          54
        ]
      ],
      "transformers/tests/models/kyutai_speech_to_text/test_modeling_kyutai_speech_to_text.py": [
        [
          "_test_attention_implementation",
          443,
          517,
          486,
          18,
          486,
          46,
          484,
          21,
          517,
          104
        ]
      ],
      "transformers/tests/models/kosmos2/test_modeling_kosmos2.py": [
        [
          "test_load_save_without_tied_weights",
          334,
          351,
          339,
          18,
          339,
          46,
          337,
          13,
          345,
          54
        ],
        [
          "_create_and_check_torchscript",
          490,
          568,
          513,
          18,
          513,
          46,
          513,
          18,
          517,
          25
        ]
      ],
      "transformers/tests/models/led/test_modeling_led.py": [
        [
          "check_encoder_decoder_model_standalone",
          205,
          237,
          212,
          14,
          212,
          42,
          205,
          48,
          237,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          205,
          237,
          225,
          14,
          225,
          42,
          205,
          48,
          237,
          99
        ],
        [
          "test_save_load_strict",
          312,
          320,
          317,
          18,
          317,
          46,
          314,
          13,
          320,
          54
        ]
      ],
      "transformers/tests/models/longcat_flash/test_modeling_longcat_flash.py": [
        [
          "test_flash_attn_2_fp32_ln",
          352,
          398,
          361,
          18,
          361,
          46,
          359,
          35,
          371,
          35
        ]
      ],
      "transformers/tests/models/m2m_100/test_modeling_m2m_100.py": [
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          193,
          14,
          193,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          204,
          14,
          204,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "test_save_load_strict",
          269,
          277,
          274,
          18,
          274,
          46,
          271,
          13,
          277,
          54
        ]
      ],
      "transformers/tests/models/longt5/test_modeling_longt5.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          404,
          478,
          452,
          18,
          452,
          46,
          413,
          13,
          478,
          17
        ]
      ],
      "transformers/tests/models/marian/test_modeling_marian.py": [
        [
          "check_encoder_decoder_model_standalone",
          184,
          214,
          202,
          14,
          202,
          42,
          184,
          48,
          214,
          99
        ],
        [
          "test_share_encoder_decoder_embeddings",
          271,
          295,
          291,
          18,
          291,
          46,
          289,
          13,
          295,
          114
        ],
        [
          "check_encoder_decoder_model_standalone",
          184,
          214,
          191,
          14,
          191,
          42,
          184,
          48,
          214,
          99
        ],
        [
          "test_save_load_strict",
          243,
          251,
          248,
          18,
          248,
          46,
          245,
          13,
          251,
          54
        ]
      ],
      "transformers/tests/models/mbart/test_modeling_mbart.py": [
        [
          "test_save_load_strict",
          261,
          269,
          266,
          18,
          266,
          46,
          263,
          13,
          269,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          178,
          208,
          185,
          14,
          185,
          42,
          178,
          48,
          208,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          178,
          208,
          196,
          14,
          196,
          42,
          178,
          48,
          208,
          99
        ]
      ],
      "transformers/tests/models/metaclip_2/test_modeling_metaclip_2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          173,
          201,
          178,
          18,
          178,
          46,
          174,
          13,
          192,
          50
        ],
        [
          "test_load_vision_text_config",
          646,
          659,
          650,
          14,
          650,
          42,
          646,
          38,
          659,
          85
        ],
        [
          "_create_and_check_torchscript",
          575,
          644,
          594,
          18,
          594,
          46,
          594,
          18,
          598,
          25
        ],
        [
          "test_load_vision_text_config",
          646,
          659,
          656,
          14,
          656,
          42,
          646,
          38,
          659,
          85
        ]
      ],
      "transformers/tests/models/mimi/test_modeling_mimi.py": [
        [
          "_create_and_check_torchscript",
          225,
          313,
          247,
          18,
          247,
          46,
          247,
          18,
          251,
          25
        ],
        [
          "test_flash_attn_2_inference_equivalence",
          399,
          424,
          404,
          18,
          404,
          46,
          400,
          13,
          415,
          70
        ]
      ],
      "transformers/tests/models/modernbert/test_modeling_modernbert.py": [
        [
          "test_saved_config_excludes_reference_compile",
          363,
          369,
          365,
          14,
          365,
          42,
          363,
          54,
          369,
          62
        ],
        [
          "flash_attn_inference_equivalence",
          383,
          510,
          418,
          18,
          418,
          46,
          417,
          43,
          425,
          55
        ]
      ],
      "transformers/tests/models/mvp/test_modeling_mvp.py": [
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          193,
          14,
          193,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          204,
          14,
          204,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "test_save_load_strict",
          458,
          466,
          463,
          18,
          463,
          46,
          460,
          13,
          466,
          54
        ]
      ],
      "transformers/tests/models/mt5/test_modeling_mt5.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          434,
          508,
          482,
          18,
          482,
          46,
          443,
          13,
          508,
          17
        ],
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          685,
          18,
          685,
          46,
          685,
          18,
          688,
          50
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_modeling_musicgen_melody.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          302,
          377,
          310,
          18,
          310,
          46,
          307,
          35,
          324,
          70
        ],
        [
          "test_flash_attn_2_inference_equivalence_right_padding",
          384,
          458,
          392,
          18,
          392,
          46,
          389,
          35,
          406,
          70
        ],
        [
          "test_sdpa_can_dispatch_on_flash",
          924,
          973,
          956,
          18,
          956,
          46,
          954,
          21,
          968,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          975,
          1007,
          986,
          18,
          986,
          46,
          982,
          13,
          991,
          81
        ]
      ],
      "transformers/tests/models/moshi/test_modeling_moshi.py": [
        [
          "test_eager_matches_sdpa_generate",
          642,
          713,
          665,
          18,
          665,
          46,
          663,
          21,
          683,
          66
        ]
      ],
      "transformers/tests/models/nllb_moe/test_modeling_nllb_moe.py": [
        [
          "check_encoder_decoder_model_standalone",
          198,
          228,
          205,
          14,
          205,
          42,
          198,
          48,
          228,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          198,
          228,
          216,
          14,
          216,
          42,
          198,
          48,
          228,
          99
        ],
        [
          "test_save_load_strict",
          271,
          279,
          276,
          18,
          276,
          46,
          273,
          13,
          279,
          54
        ]
      ],
      "transformers/tests/models/musicgen/test_modeling_musicgen.py": [
        [
          "test_flash_attn_2_inference_equivalence_right_padding",
          373,
          445,
          381,
          18,
          381,
          46,
          378,
          35,
          393,
          70
        ],
        [
          "test_flash_attn_2_inference_equivalence",
          293,
          366,
          301,
          18,
          301,
          46,
          298,
          35,
          313,
          70
        ],
        [
          "test_sdpa_can_dispatch_on_flash",
          921,
          970,
          953,
          18,
          953,
          46,
          951,
          21,
          965,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          972,
          1004,
          983,
          18,
          983,
          46,
          979,
          13,
          988,
          81
        ]
      ],
      "transformers/tests/models/opt/test_modeling_opt.py": [
        [
          "test_save_load_strict",
          252,
          260,
          257,
          18,
          257,
          46,
          254,
          13,
          260,
          54
        ]
      ],
      "transformers/tests/models/owlv2/test_modeling_owlv2.py": [
        [
          "test_load_vision_text_config",
          529,
          542,
          533,
          14,
          533,
          42,
          529,
          38,
          542,
          85
        ],
        [
          "_create_and_check_torchscript",
          462,
          527,
          480,
          18,
          480,
          46,
          480,
          18,
          484,
          25
        ],
        [
          "test_load_vision_text_config",
          529,
          542,
          539,
          14,
          539,
          42,
          529,
          38,
          542,
          85
        ],
        [
          "_create_and_check_torchscript",
          671,
          736,
          689,
          18,
          689,
          46,
          689,
          18,
          693,
          25
        ]
      ],
      "transformers/tests/models/owlvit/test_modeling_owlvit.py": [
        [
          "test_load_vision_text_config",
          524,
          537,
          534,
          14,
          534,
          42,
          524,
          38,
          537,
          85
        ],
        [
          "test_load_vision_text_config",
          524,
          537,
          528,
          14,
          528,
          42,
          524,
          38,
          537,
          85
        ],
        [
          "_create_and_check_torchscript",
          457,
          522,
          475,
          18,
          475,
          46,
          475,
          18,
          479,
          25
        ],
        [
          "_create_and_check_torchscript",
          664,
          729,
          682,
          18,
          682,
          46,
          682,
          18,
          686,
          25
        ]
      ],
      "transformers/tests/models/parakeet/test_modeling_parakeet.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          275,
          298,
          286,
          18,
          286,
          46,
          282,
          13,
          295,
          66
        ]
      ],
      "transformers/tests/models/patchtst/test_modeling_patchtst.py": [
        [
          "test_save_load_strict",
          204,
          212,
          209,
          18,
          209,
          46,
          206,
          13,
          212,
          54
        ]
      ],
      "transformers/tests/models/pegasus/test_modeling_pegasus.py": [
        [
          "check_encoder_decoder_model_standalone",
          189,
          219,
          207,
          14,
          207,
          42,
          189,
          48,
          219,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          189,
          219,
          196,
          14,
          196,
          42,
          189,
          48,
          219,
          99
        ],
        [
          "test_save_load_strict",
          249,
          257,
          254,
          18,
          254,
          46,
          251,
          13,
          257,
          54
        ]
      ],
      "transformers/tests/models/patchtsmixer/test_modeling_patchtsmixer.py": [
        [
          "test_save_load_strict",
          273,
          281,
          278,
          18,
          278,
          46,
          275,
          13,
          281,
          54
        ]
      ],
      "transformers/tests/models/pegasus_x/test_modeling_pegasus_x.py": [
        [
          "check_encoder_decoder_model_standalone",
          169,
          199,
          176,
          14,
          176,
          42,
          169,
          48,
          199,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          169,
          199,
          187,
          14,
          187,
          42,
          169,
          48,
          199,
          99
        ],
        [
          "test_save_load_strict",
          232,
          240,
          237,
          18,
          237,
          46,
          234,
          13,
          240,
          54
        ]
      ],
      "transformers/tests/models/plbart/test_modeling_plbart.py": [
        [
          "check_encoder_decoder_model_standalone",
          176,
          206,
          194,
          14,
          194,
          42,
          176,
          48,
          206,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          176,
          206,
          183,
          14,
          183,
          42,
          176,
          48,
          206,
          99
        ],
        [
          "test_save_load_strict",
          257,
          265,
          262,
          18,
          262,
          46,
          259,
          13,
          265,
          54
        ]
      ],
      "transformers/tests/models/perceiver/test_modeling_perceiver.py": [
        [
          "test_save_load",
          686,
          729,
          701,
          26,
          701,
          54,
          697,
          21,
          712,
          60
        ],
        [
          "test_save_load",
          686,
          729,
          718,
          22,
          718,
          50,
          715,
          25,
          729,
          56
        ],
        [
          "test_correct_missing_keys",
          731,
          757,
          753,
          22,
          753,
          50,
          753,
          22,
          757,
          80
        ]
      ],
      "transformers/tests/models/pix2struct/test_modeling_pix2struct.py": [
        [
          "test_load_vision_text_config",
          694,
          707,
          698,
          14,
          698,
          42,
          694,
          38,
          707,
          85
        ],
        [
          "_create_and_check_torchscript",
          623,
          692,
          642,
          18,
          642,
          46,
          642,
          18,
          646,
          25
        ],
        [
          "test_load_vision_text_config",
          694,
          707,
          704,
          14,
          704,
          42,
          694,
          38,
          707,
          85
        ]
      ],
      "transformers/tests/models/pop2piano/test_modeling_pop2piano.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          375,
          449,
          423,
          18,
          423,
          46,
          384,
          13,
          449,
          17
        ]
      ],
      "transformers/tests/models/pvt_v2/test_modeling_pvt_v2.py": [
        [
          "test_config_save_pretrained",
          371,
          383,
          375,
          14,
          375,
          42,
          371,
          37,
          380,
          53
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          296,
          333,
          308,
          18,
          308,
          46,
          304,
          13,
          313,
          64
        ],
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          335,
          418,
          352,
          18,
          352,
          46,
          350,
          21,
          355,
          60
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          335,
          415,
          352,
          18,
          352,
          46,
          350,
          21,
          355,
          60
        ]
      ],
      "transformers/tests/models/qwen3_next/test_modeling_qwen3_next.py": [
        [
          "test_can_use_device_map",
          311,
          343,
          324,
          18,
          324,
          46,
          316,
          13,
          343,
          17
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_modeling_qwen2_vl.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          277,
          358,
          294,
          18,
          294,
          46,
          292,
          21,
          297,
          60
        ]
      ],
      "transformers/tests/models/prophetnet/test_modeling_prophetnet.py": [
        [
          "check_causal_lm_from_pretrained",
          489,
          512,
          494,
          14,
          494,
          42,
          490,
          9,
          512,
          9
        ],
        [
          "create_and_check_encoder_decoder_shared_weights",
          336,
          414,
          388,
          18,
          388,
          46,
          355,
          13,
          414,
          17
        ],
        [
          "test_config_save",
          968,
          975,
          971,
          14,
          971,
          42,
          968,
          26,
          975,
          52
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_modeling_qwen2_audio.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          159,
          194,
          171,
          18,
          171,
          46,
          167,
          13,
          176,
          73
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_modeling_qwen3_omni_moe.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          307,
          344,
          319,
          18,
          319,
          46,
          315,
          13,
          324,
          64
        ],
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          346,
          429,
          363,
          18,
          363,
          46,
          361,
          21,
          366,
          60
        ]
      ]
    },
    "os.path.join": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUpClass",
          1066,
          1077,
          1069,
          26,
          1069,
          71,
          1066,
          20,
          1077,
          38
        ],
        [
          "setUp",
          113,
          178,
          177,
          29,
          177,
          73,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          134,
          30,
          134,
          75,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          136,
          27,
          136,
          95,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          169,
          27,
          169,
          97,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          167,
          31,
          167,
          77,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          170,
          28,
          170,
          99,
          113,
          15,
          178,
          55
        ],
        [
          "dpr_tokenizer",
          181,
          182,
          182,
          60,
          182,
          105,
          181,
          23,
          182,
          106
        ],
        [
          "dpr_ctx_encoder_tokenizer",
          185,
          186,
          186,
          59,
          186,
          104,
          185,
          35,
          186,
          105
        ],
        [
          "bart_tokenizer",
          189,
          190,
          190,
          46,
          190,
          92,
          189,
          24,
          190,
          93
        ],
        [
          "t5_tokenizer",
          193,
          194,
          194,
          44,
          194,
          88,
          193,
          22,
          194,
          89
        ],
        [
          "setUpClass",
          685,
          696,
          688,
          26,
          688,
          71,
          685,
          20,
          696,
          38
        ]
      ],
      "transformers/tests/models/siglip/test_modeling_siglip.py": [
        [
          "_create_and_check_torchscript",
          491,
          560,
          511,
          32,
          511,
          76,
          510,
          18,
          514,
          25
        ]
      ],
      "transformers/tests/models/speech_to_text/test_modeling_speech_to_text.py": [
        [
          "_create_and_check_torchscript",
          606,
          680,
          631,
          32,
          631,
          76,
          630,
          18,
          634,
          25
        ]
      ],
      "transformers/tests/models/t5/test_modeling_t5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          694,
          33,
          694,
          71,
          693,
          18,
          696,
          50
        ]
      ],
      "transformers/tests/models/umt5/test_modeling_umt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          382,
          33,
          382,
          71,
          381,
          18,
          384,
          50
        ]
      ],
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_model_from_pretrained_subfolder",
          454,
          467,
          460,
          35,
          460,
          66,
          454,
          46,
          467,
          64
        ],
        [
          "test_model_from_pretrained_subfolder_sharded",
          489,
          502,
          495,
          35,
          495,
          66,
          489,
          54,
          502,
          64
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          796,
          38,
          796,
          65,
          796,
          38,
          797,
          49
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          799,
          30,
          799,
          70,
          799,
          30,
          805,
          61
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          802,
          49,
          802,
          83,
          799,
          30,
          805,
          61
        ],
        [
          "test_checkpoint_variant_local_bin",
          834,
          852,
          842,
          28,
          842,
          62,
          834,
          43,
          851,
          69
        ],
        [
          "test_checkpoint_variant_local_bin",
          834,
          852,
          844,
          45,
          844,
          79,
          834,
          43,
          851,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          861,
          34,
          861,
          74,
          854,
          51,
          865,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          863,
          45,
          863,
          85,
          854,
          51,
          865,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          867,
          37,
          867,
          71,
          865,
          17,
          868,
          66
        ],
        [
          "test_checkpoint_variant_local_safe",
          878,
          896,
          886,
          28,
          886,
          62,
          878,
          44,
          895,
          69
        ],
        [
          "test_checkpoint_variant_local_safe",
          878,
          896,
          888,
          45,
          888,
          84,
          878,
          44,
          895,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          905,
          34,
          905,
          74,
          898,
          52,
          909,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          907,
          45,
          907,
          90,
          898,
          52,
          909,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          911,
          37,
          911,
          71,
          909,
          17,
          912,
          66
        ],
        [
          "test_checkpoint_loading_only_safetensors_available",
          922,
          953,
          934,
          34,
          934,
          74,
          922,
          60,
          937,
          32
        ],
        [
          "test_checkpoint_loading_only_safetensors_available",
          922,
          953,
          939,
          37,
          939,
          71,
          937,
          17,
          940,
          66
        ],
        [
          "test_checkpoint_loading_only_pytorch_bin_available",
          955,
          986,
          967,
          34,
          967,
          74,
          955,
          60,
          970,
          32
        ],
        [
          "test_checkpoint_loading_only_pytorch_bin_available",
          955,
          986,
          972,
          37,
          972,
          71,
          970,
          17,
          973,
          66
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1037,
          44,
          1037,
          78,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1042,
          44,
          1042,
          78,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1045,
          44,
          1045,
          78,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_from_pretrained_disk_offload_task_model",
          1071,
          1107,
          1091,
          30,
          1091,
          61,
          1071,
          54,
          1107,
          84
        ],
        [
          "test_from_pretrained_disk_offload_derived_to_base_model",
          1112,
          1147,
          1132,
          30,
          1132,
          61,
          1112,
          65,
          1147,
          76
        ],
        [
          "test_save_offloaded_model",
          1205,
          1237,
          1225,
          30,
          1225,
          61,
          1205,
          35,
          1237,
          69
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1294,
          46,
          1294,
          99,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1307,
          46,
          1307,
          99,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1322,
          27,
          1322,
          62,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_safetensors_save_and_load",
          1331,
          1343,
          1336,
          44,
          1336,
          83,
          1331,
          40,
          1342,
          73
        ],
        [
          "test_safetensors_save_and_load",
          1331,
          1343,
          1337,
          45,
          1337,
          79,
          1331,
          40,
          1342,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1358,
          45,
          1358,
          85,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1359,
          44,
          1359,
          89,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1361,
          45,
          1361,
          79,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1362,
          45,
          1362,
          84,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_base_model_to_head_model_load",
          1378,
          1398,
          1393,
          45,
          1393,
          84,
          1389,
          31,
          1398,
          17
        ],
        [
          "test_tied_weights_reload",
          1400,
          1422,
          1412,
          36,
          1412,
          70,
          1400,
          34,
          1422,
          77
        ],
        [
          "test_unexpected_keys_warnings",
          1424,
          1448,
          1443,
          40,
          1443,
          79,
          1424,
          39,
          1448,
          76
        ],
        [
          "test_model_from_pretrained_from_mlx",
          1628,
          1645,
          1636,
          28,
          1636,
          69,
          1628,
          45,
          1645,
          87
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          1998,
          23,
          1998,
          61,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2024,
          23,
          2024,
          61,
          2006,
          66,
          2030,
          85
        ]
      ],
      "transformers/tests/models/vits/test_modeling_vits.py": [
        [
          "test_save_load",
          309,
          349,
          334,
          48,
          334,
          84,
          322,
          13,
          345,
          39
        ],
        [
          "test_save_load",
          309,
          349,
          336,
          58,
          336,
          105,
          322,
          13,
          345,
          39
        ]
      ],
      "transformers/tests/models/x_clip/test_modeling_x_clip.py": [
        [
          "_create_and_check_torchscript",
          564,
          633,
          584,
          32,
          584,
          76,
          583,
          18,
          587,
          25
        ]
      ],
      "transformers/tests/models/wav2vec2/test_modeling_wav2vec2.py": [
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          760,
          33,
          760,
          71,
          759,
          18,
          762,
          50
        ],
        [
          "test_load_attn_adapter",
          1123,
          1200,
          1156,
          29,
          1156,
          91,
          1123,
          32,
          1200,
          74
        ],
        [
          "test_load_attn_adapter",
          1123,
          1200,
          1178,
          27,
          1178,
          87,
          1123,
          32,
          1200,
          74
        ]
      ],
      "transformers/tests/models/whisper/test_modeling_whisper.py": [
        [
          "_create_and_check_torchscript",
          846,
          928,
          879,
          32,
          879,
          76,
          878,
          18,
          882,
          25
        ]
      ],
      "transformers/tests/models/xcodec/test_modeling_xcodec.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          208,
          32,
          208,
          76,
          207,
          18,
          211,
          25
        ]
      ],
      "transformers/tests/optimization/test_optimization.py": [
        [
          "unwrap_and_save_reload_schedule",
          50,
          62,
          57,
          29,
          57,
          68,
          56,
          18,
          61,
          53
        ]
      ],
      "transformers/tests/test_pipeline_mixin.py": [
        [
          "run_pipeline_test",
          347,
          489,
          387,
          23,
          387,
          87,
          387,
          23,
          387,
          19
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_common.py": [
        [
          "test_push_to_hub_dynamic_pipeline",
          886,
          964,
          901,
          26,
          901,
          59,
          886,
          43,
          964,
          9
        ]
      ],
      "transformers/tests/models/align/test_processing_align.py": [
        [
          "setUp",
          39,
          72,
          59,
          27,
          59,
          88,
          39,
          15,
          72,
          46
        ],
        [
          "setUp",
          39,
          72,
          70,
          37,
          70,
          87,
          39,
          15,
          72,
          46
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "setUpClass",
          40,
          84,
          63,
          26,
          63,
          86,
          40,
          20,
          84,
          49
        ],
        [
          "setUpClass",
          40,
          84,
          77,
          36,
          77,
          87,
          40,
          20,
          84,
          49
        ]
      ],
      "transformers/tests/models/bark/test_processing_bark.py": [
        [
          "test_speaker_embeddings",
          82,
          115,
          106,
          23,
          106,
          63,
          106,
          23,
          111,
          31
        ]
      ],
      "transformers/tests/models/clipseg/test_processing_clipseg.py": [
        [
          "setUp",
          39,
          65,
          47,
          27,
          47,
          88,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          48,
          28,
          48,
          90,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          63,
          37,
          63,
          87,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/flava/test_processing_flava.py": [
        [
          "setUp",
          46,
          81,
          50,
          27,
          50,
          88,
          46,
          15,
          81,
          46
        ],
        [
          "setUp",
          46,
          81,
          79,
          37,
          79,
          87,
          46,
          15,
          81,
          46
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "setUpClass",
          48,
          80,
          52,
          26,
          52,
          86,
          48,
          20,
          80,
          22
        ],
        [
          "setUpClass",
          48,
          80,
          66,
          36,
          66,
          85,
          48,
          20,
          80,
          22
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "setUpClass",
          49,
          67,
          57,
          39,
          57,
          90,
          49,
          20,
          67,
          49
        ]
      ],
      "transformers/tests/models/kosmos2/test_processing_kosmos2.py": [
        [
          "test_full_processor",
          189,
          471,
          210,
          22,
          210,
          63,
          189,
          29,
          471,
          118
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_processing_layoutlmv2.py": [
        [
          "setUp",
          42,
          73,
          68,
          27,
          68,
          88,
          42,
          15,
          73,
          60
        ],
        [
          "setUp",
          42,
          73,
          71,
          38,
          71,
          90,
          42,
          15,
          73,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_processing_layoutlmv3.py": [
        [
          "setUp",
          42,
          86,
          71,
          27,
          71,
          88,
          42,
          15,
          86,
          60
        ],
        [
          "setUp",
          42,
          86,
          72,
          28,
          72,
          90,
          42,
          15,
          86,
          60
        ],
        [
          "setUp",
          42,
          86,
          84,
          40,
          84,
          92,
          42,
          15,
          86,
          60
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "setUp",
          50,
          70,
          57,
          27,
          57,
          88,
          50,
          15,
          70,
          46
        ],
        [
          "setUp",
          50,
          70,
          68,
          37,
          68,
          87,
          50,
          15,
          70,
          46
        ]
      ],
      "transformers/tests/models/markuplm/test_processing_markuplm.py": [
        [
          "setUp",
          47,
          70,
          56,
          27,
          56,
          88,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          57,
          28,
          57,
          90,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          58,
          38,
          58,
          91,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          68,
          40,
          68,
          92,
          47,
          15,
          70,
          62
        ]
      ],
      "transformers/tests/models/owlvit/test_processing_owlvit.py": [
        [
          "setUp",
          39,
          65,
          47,
          27,
          47,
          88,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          48,
          28,
          48,
          90,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          63,
          37,
          63,
          87,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/oneformer/test_processing_oneformer.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          404,
          414,
          409,
          48,
          409,
          99,
          404,
          52,
          414,
          74
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_processing_shieldgemma2.py": [
        [
          "test_policy_definitions_saved_in_config",
          102,
          110,
          103,
          33,
          103,
          86,
          102,
          49,
          110,
          62
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "setUpClass",
          31,
          42,
          35,
          26,
          35,
          86,
          31,
          20,
          42,
          49
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "setUpClass",
          41,
          65,
          63,
          39,
          63,
          90,
          41,
          20,
          65,
          62
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "setUpClass",
          39,
          61,
          43,
          26,
          43,
          86,
          39,
          20,
          61,
          49
        ],
        [
          "setUpClass",
          39,
          61,
          54,
          36,
          54,
          85,
          39,
          20,
          61,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "setUpClass",
          35,
          63,
          54,
          26,
          54,
          86,
          35,
          20,
          63,
          49
        ],
        [
          "setUpClass",
          35,
          63,
          55,
          39,
          55,
          90,
          35,
          20,
          63,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "setUpClass",
          36,
          64,
          55,
          26,
          55,
          86,
          36,
          20,
          64,
          49
        ],
        [
          "setUpClass",
          36,
          64,
          56,
          39,
          56,
          90,
          36,
          20,
          64,
          49
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_processor_kosmos2_5.py": [
        [
          "test_full_processor",
          301,
          391,
          313,
          22,
          313,
          63,
          301,
          29,
          391,
          9
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_processor_from_local_directory_from_extractor_config",
          87,
          95,
          90,
          47,
          90,
          94,
          87,
          67,
          95,
          59
        ],
        [
          "test_processor_from_local_directory_from_extractor_config",
          87,
          95,
          91,
          36,
          91,
          73,
          87,
          67,
          95,
          59
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          107,
          35,
          107,
          74,
          97,
          45,
          107,
          75
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          110,
          27,
          110,
          66,
          109,
          32,
          111,
          46
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          114,
          23,
          114,
          69,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          118,
          23,
          118,
          69,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          135,
          31,
          135,
          70,
          125,
          55,
          135,
          71
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          137,
          27,
          137,
          66,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          141,
          27,
          141,
          66,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          145,
          23,
          145,
          69,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          149,
          23,
          149,
          69,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          166,
          31,
          166,
          70,
          156,
          55,
          166,
          71
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          168,
          27,
          168,
          66,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          172,
          27,
          172,
          66,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          176,
          23,
          176,
          70,
          176,
          18,
          185,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          180,
          23,
          180,
          70,
          176,
          18,
          185,
          59
        ],
        [
          "test_processor_from_local_directory_from_model_config",
          187,
          199,
          192,
          36,
          192,
          73,
          187,
          63,
          199,
          59
        ],
        [
          "test_processor_from_local_directory_from_model_config",
          187,
          199,
          194,
          23,
          194,
          70,
          187,
          63,
          199,
          59
        ],
        [
          "test_new_processor_registration",
          234,
          270,
          248,
          30,
          248,
          63,
          248,
          43,
          248,
          63
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          465,
          30,
          465,
          63,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          486,
          27,
          486,
          72,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          497,
          48,
          497,
          100,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          498,
          48,
          498,
          94,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          499,
          48,
          499,
          92,
          456,
          44,
          505,
          85
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "setUp",
          50,
          77,
          68,
          27,
          68,
          88,
          50,
          15,
          77,
          25
        ],
        [
          "setUp",
          50,
          77,
          69,
          40,
          69,
          92,
          50,
          15,
          77,
          25
        ]
      ],
      "transformers/examples/pytorch/test_pytorch_examples.py": [
        [
          "listcomp",
          33,
          34,
          34,
          5,
          34,
          52,
          35,
          9,
          34,
          52
        ],
        [
          "get_results",
          85,
          93,
          87,
          12,
          87,
          55,
          85,
          17,
          88,
          27
        ],
        [
          "test_run_speech_recognition_ctc_adapter",
          446,
          476,
          475,
          44,
          475,
          93,
          472,
          14,
          476,
          70
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "setUp",
          43,
          105,
          65,
          30,
          65,
          75,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          67,
          27,
          67,
          95,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          98,
          31,
          98,
          77,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          100,
          27,
          100,
          97,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          101,
          28,
          101,
          99,
          43,
          15,
          105,
          39
        ],
        [
          "get_dpr_tokenizer",
          107,
          108,
          108,
          60,
          108,
          105,
          107,
          27,
          108,
          106
        ],
        [
          "get_dpr_ctx_encoder_tokenizer",
          110,
          111,
          111,
          59,
          111,
          104,
          110,
          39,
          111,
          105
        ],
        [
          "get_bart_tokenizer",
          113,
          114,
          114,
          46,
          114,
          92,
          113,
          28,
          114,
          93
        ],
        [
          "get_dummy_custom_hf_index_retriever",
          147,
          174,
          156,
          36,
          156,
          75,
          156,
          36,
          162,
          21
        ],
        [
          "get_dummy_custom_hf_index_retriever",
          147,
          174,
          157,
          33,
          157,
          76,
          156,
          36,
          162,
          21
        ],
        [
          "get_dummy_custom_hf_index_retriever",
          147,
          174,
          158,
          50,
          158,
          93,
          156,
          36,
          162,
          21
        ],
        [
          "get_dummy_custom_hf_index_retriever",
          147,
          174,
          160,
          34,
          160,
          73,
          156,
          36,
          162,
          21
        ]
      ],
      "transformers/tests/models/bart/test_tokenization_bart.py": [
        [
          "setUpClass",
          36,
          70,
          65,
          26,
          65,
          86,
          36,
          20,
          70,
          39
        ],
        [
          "setUpClass",
          36,
          70,
          66,
          27,
          66,
          88,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/tensor_parallel/test_tensor_parallel.py": [
        [
          "test_model_save",
          176,
          215,
          202,
          33,
          202,
          62,
          202,
          33,
          205,
          57
        ],
        [
          "test_model_save",
          176,
          215,
          203,
          29,
          203,
          55,
          202,
          33,
          205,
          57
        ],
        [
          "test_model_save",
          176,
          215,
          209,
          42,
          209,
          82,
          209,
          32,
          211,
          53
        ],
        [
          "test_model_save",
          176,
          215,
          210,
          38,
          210,
          74,
          209,
          32,
          211,
          53
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_tokenizer_from_type",
          103,
          115,
          105,
          55,
          105,
          88,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          111,
          56,
          111,
          90,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          112,
          56,
          112,
          90,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          120,
          55,
          120,
          88,
          118,
          39,
          130,
          63
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          126,
          56,
          126,
          90,
          118,
          39,
          130,
          63
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          127,
          56,
          127,
          90,
          118,
          39,
          130,
          63
        ],
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          346,
          36,
          346,
          75,
          332,
          13,
          354,
          73
        ],
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          349,
          27,
          349,
          72,
          332,
          13,
          354,
          73
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          477,
          25,
          477,
          60,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          480,
          34,
          480,
          72,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          484,
          37,
          484,
          72,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          493,
          27,
          493,
          64,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          506,
          37,
          506,
          84,
          456,
          40,
          513,
          18
        ]
      ],
      "transformers/tests/models/bartpho/test_tokenization_bartpho.py": [
        [
          "setUpClass",
          34,
          47,
          41,
          38,
          41,
          110,
          34,
          20,
          43,
          37
        ]
      ],
      "transformers/tests/models/bertweet/test_tokenization_bertweet.py": [
        [
          "setUpClass",
          29,
          44,
          38,
          26,
          38,
          86,
          29,
          20,
          41,
          37
        ],
        [
          "setUpClass",
          29,
          44,
          39,
          27,
          39,
          88,
          29,
          20,
          41,
          37
        ]
      ],
      "transformers/tests/models/biogpt/test_tokenization_biogpt.py": [
        [
          "setUpClass",
          33,
          68,
          63,
          26,
          63,
          86,
          33,
          20,
          68,
          39
        ],
        [
          "setUpClass",
          33,
          68,
          64,
          27,
          64,
          88,
          33,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/bert/test_tokenization_bert.py": [
        [
          "setUpClass",
          44,
          66,
          64,
          26,
          64,
          86,
          44,
          20,
          66,
          73
        ]
      ],
      "transformers/tests/models/blenderbot_small/test_tokenization_blenderbot_small.py": [
        [
          "setUpClass",
          35,
          49,
          44,
          26,
          44,
          86,
          35,
          20,
          49,
          39
        ],
        [
          "setUpClass",
          35,
          49,
          45,
          27,
          45,
          88,
          35,
          20,
          49,
          39
        ]
      ],
      "transformers/tests/models/bert_japanese/test_tokenization_bert_japanese.py": [
        [
          "setUpClass",
          44,
          77,
          75,
          26,
          75,
          86,
          44,
          20,
          77,
          73
        ],
        [
          "test_pickle_mecab_tokenizer",
          106,
          124,
          115,
          20,
          115,
          65,
          106,
          37,
          124,
          51
        ],
        [
          "test_pickle_sudachi_tokenizer",
          202,
          220,
          211,
          20,
          211,
          65,
          202,
          39,
          220,
          51
        ],
        [
          "test_pickle_jumanpp_tokenizer",
          297,
          315,
          306,
          20,
          306,
          65,
          297,
          39,
          315,
          51
        ],
        [
          "setUpClass",
          412,
          419,
          417,
          26,
          417,
          86,
          412,
          20,
          419,
          73
        ]
      ],
      "transformers/tests/models/clip/test_tokenization_clip.py": [
        [
          "setUpClass",
          37,
          50,
          45,
          26,
          45,
          86,
          37,
          20,
          50,
          39
        ],
        [
          "setUpClass",
          37,
          50,
          46,
          27,
          46,
          88,
          37,
          20,
          50,
          39
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          212,
          27,
          212,
          74,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          215,
          27,
          215,
          72,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          225,
          27,
          225,
          74,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          227,
          27,
          227,
          72,
          208,
          13,
          255,
          17
        ]
      ],
      "transformers/tests/models/clvp/test_tokenization_clvp.py": [
        [
          "setUpClass",
          34,
          71,
          66,
          26,
          66,
          67,
          34,
          20,
          71,
          39
        ],
        [
          "setUpClass",
          34,
          71,
          67,
          27,
          67,
          68,
          34,
          20,
          71,
          39
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          225,
          27,
          225,
          74,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          228,
          27,
          228,
          72,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          240,
          27,
          240,
          74,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          242,
          27,
          242,
          72,
          221,
          13,
          275,
          17
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_conversion",
          375,
          393,
          382,
          23,
          382,
          61,
          375,
          25,
          393,
          60
        ]
      ],
      "transformers/tests/models/cpmant/test_tokenization_cpmant.py": [
        [
          "setUpClass",
          31,
          54,
          52,
          26,
          52,
          86,
          31,
          20,
          54,
          73
        ]
      ],
      "transformers/tests/models/ctrl/test_tokenization_ctrl.py": [
        [
          "setUpClass",
          31,
          45,
          40,
          26,
          40,
          86,
          31,
          20,
          45,
          39
        ],
        [
          "setUpClass",
          31,
          45,
          41,
          27,
          41,
          88,
          31,
          20,
          45,
          39
        ]
      ],
      "transformers/tests/models/deberta/test_tokenization_deberta.py": [
        [
          "setUpClass",
          34,
          69,
          64,
          26,
          64,
          86,
          34,
          20,
          69,
          39
        ],
        [
          "setUpClass",
          34,
          69,
          65,
          27,
          65,
          88,
          34,
          20,
          69,
          39
        ]
      ],
      "transformers/tests/models/codegen/test_tokenization_codegen.py": [
        [
          "setUpClass",
          38,
          74,
          69,
          26,
          69,
          86,
          38,
          20,
          74,
          39
        ],
        [
          "setUpClass",
          38,
          74,
          70,
          27,
          70,
          88,
          38,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/electra/test_tokenization_electra.py": [
        [
          "setUpClass",
          43,
          65,
          63,
          26,
          63,
          86,
          43,
          20,
          65,
          73
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_pickle_tokenizer",
          830,
          849,
          840,
          28,
          840,
          73,
          833,
          13,
          849,
          63
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1712,
          58,
          1712,
          108,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1714,
          60,
          1714,
          108,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1716,
          48,
          1716,
          118,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1719,
          58,
          1719,
          108,
          1719,
          43,
          1728,
          111
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1728,
          61,
          1728,
          109,
          1719,
          43,
          1728,
          111
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4234,
          27,
          4234,
          63,
          4229,
          13,
          4272,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4239,
          27,
          4239,
          63,
          4229,
          13,
          4272,
          17
        ],
        [
          "test_saving_tokenizer_trainer",
          4452,
          4470,
          4469,
          40,
          4469,
          74,
          4453,
          13,
          4470,
          100
        ],
        [
          "test_saving_tokenizer_trainer",
          4452,
          4470,
          4470,
          64,
          4470,
          98,
          4453,
          13,
          4470,
          100
        ],
        [
          "test_save_slow_from_fast_and_reload_fast",
          4481,
          4506,
          4492,
          38,
          4492,
          78,
          4486,
          13,
          4506,
          72
        ]
      ],
      "transformers/tests/models/esm/test_tokenization_esm.py": [
        [
          "setUpClass",
          31,
          38,
          36,
          26,
          36,
          86,
          31,
          20,
          38,
          73
        ]
      ],
      "transformers/tests/models/flaubert/test_tokenization_flaubert.py": [
        [
          "setUpClass",
          33,
          47,
          42,
          26,
          42,
          86,
          33,
          20,
          47,
          39
        ],
        [
          "setUpClass",
          33,
          47,
          43,
          27,
          43,
          88,
          33,
          20,
          47,
          39
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_local_versioning",
          211,
          236,
          220,
          44,
          220,
          88,
          211,
          31,
          236,
          77
        ],
        [
          "test_local_versioning",
          211,
          236,
          230,
          25,
          230,
          69,
          211,
          31,
          236,
          77
        ],
        [
          "test_local_versioning",
          211,
          236,
          230,
          72,
          230,
          117,
          211,
          31,
          236,
          77
        ]
      ],
      "transformers/tests/models/funnel/test_tokenization_funnel.py": [
        [
          "setUpClass",
          35,
          55,
          53,
          26,
          53,
          86,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/gpt_neox_japanese/test_tokenization_gpt_neox_japanese.py": [
        [
          "setUpClass",
          37,
          72,
          67,
          26,
          67,
          86,
          37,
          20,
          72,
          56
        ],
        [
          "setUpClass",
          37,
          72,
          68,
          26,
          68,
          86,
          37,
          20,
          72,
          56
        ]
      ],
      "transformers/tests/models/gpt2/test_tokenization_gpt2.py": [
        [
          "setUpClass",
          37,
          73,
          68,
          26,
          68,
          86,
          37,
          20,
          73,
          39
        ],
        [
          "setUpClass",
          37,
          73,
          69,
          27,
          69,
          88,
          37,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/layoutlm/test_tokenization_layoutlm.py": [
        [
          "setUpClass",
          35,
          55,
          53,
          26,
          53,
          86,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/herbert/test_tokenization_herbert.py": [
        [
          "setUpClass",
          36,
          77,
          72,
          26,
          72,
          86,
          36,
          20,
          77,
          39
        ],
        [
          "setUpClass",
          36,
          77,
          73,
          27,
          73,
          88,
          36,
          20,
          77,
          39
        ]
      ],
      "transformers/tests/models/fsmt/test_tokenization_fsmt.py": [
        [
          "setUpClass",
          37,
          85,
          74,
          30,
          74,
          94,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          75,
          30,
          75,
          94,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          76,
          23,
          76,
          75,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          77,
          27,
          77,
          88,
          37,
          20,
          85,
          40
        ]
      ],
      "transformers/tests/models/led/test_tokenization_led.py": [
        [
          "setUpClass",
          34,
          68,
          63,
          26,
          63,
          86,
          34,
          20,
          68,
          39
        ],
        [
          "setUpClass",
          34,
          68,
          64,
          27,
          64,
          88,
          34,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py": [
        [
          "setUpClass",
          136,
          158,
          156,
          26,
          156,
          86,
          136,
          20,
          158,
          73
        ]
      ],
      "transformers/tests/models/gemma/test_tokenization_gemma.py": [
        [
          "test_conversion",
          236,
          254,
          243,
          23,
          243,
          61,
          236,
          25,
          254,
          60
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_conversion",
          413,
          431,
          420,
          23,
          420,
          61,
          413,
          25,
          431,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "setUpClass",
          128,
          163,
          158,
          26,
          158,
          86,
          128,
          20,
          163,
          39
        ],
        [
          "setUpClass",
          128,
          163,
          159,
          27,
          159,
          88,
          128,
          20,
          163,
          39
        ]
      ],
      "transformers/tests/models/longformer/test_tokenization_longformer.py": [
        [
          "setUpClass",
          39,
          74,
          69,
          26,
          69,
          86,
          39,
          20,
          74,
          39
        ],
        [
          "setUpClass",
          39,
          74,
          70,
          27,
          70,
          88,
          39,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/lxmert/test_tokenization_lxmert.py": [
        [
          "setUpClass",
          35,
          55,
          53,
          26,
          53,
          86,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/mgp_str/test_tokenization_mgp_str.py": [
        [
          "setUpClass",
          36,
          44,
          42,
          26,
          42,
          86,
          36,
          20,
          44,
          53
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "setUpClass",
          52,
          71,
          62,
          26,
          62,
          86,
          52,
          20,
          71,
          62
        ],
        [
          "setUpClass",
          52,
          71,
          63,
          27,
          63,
          88,
          52,
          20,
          71,
          62
        ],
        [
          "setUpClass",
          52,
          71,
          64,
          37,
          64,
          89,
          52,
          20,
          71,
          62
        ]
      ],
      "transformers/tests/models/mobilebert/test_tokenization_mobilebert.py": [
        [
          "setUpClass",
          44,
          71,
          64,
          26,
          64,
          86,
          44,
          20,
          68,
          27
        ]
      ],
      "transformers/tests/models/mpnet/test_tokenization_mpnet.py": [
        [
          "setUpClass",
          35,
          57,
          55,
          26,
          55,
          86,
          35,
          20,
          57,
          73
        ]
      ],
      "transformers/tests/models/mvp/test_tokenization_mvp.py": [
        [
          "setUpClass",
          36,
          70,
          65,
          26,
          65,
          86,
          36,
          20,
          70,
          39
        ],
        [
          "setUpClass",
          36,
          70,
          66,
          27,
          66,
          88,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/models/openai/test_tokenization_openai.py": [
        [
          "setUpClass",
          38,
          73,
          68,
          26,
          68,
          86,
          38,
          20,
          73,
          39
        ],
        [
          "setUpClass",
          38,
          73,
          69,
          27,
          69,
          88,
          38,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/phobert/test_tokenization_phobert.py": [
        [
          "setUpClass",
          29,
          45,
          38,
          26,
          38,
          86,
          29,
          20,
          42,
          37
        ],
        [
          "setUpClass",
          29,
          45,
          39,
          27,
          39,
          88,
          29,
          20,
          42,
          37
        ]
      ],
      "transformers/tests/models/prophetnet/test_tokenization_prophetnet.py": [
        [
          "setUpClass",
          39,
          61,
          59,
          26,
          59,
          86,
          39,
          20,
          61,
          73
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          208,
          27,
          208,
          74,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          211,
          27,
          211,
          72,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          223,
          27,
          223,
          74,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          225,
          27,
          225,
          72,
          204,
          13,
          257,
          17
        ]
      ],
      "transformers/tests/models/pop2piano/test_tokenization_pop2piano.py": [
        [
          "test_pickle_tokenizer",
          227,
          242,
          233,
          20,
          233,
          60,
          227,
          31,
          242,
          55
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "setUp",
          38,
          100,
          60,
          30,
          60,
          75,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          62,
          27,
          62,
          95,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          93,
          31,
          93,
          77,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          95,
          27,
          95,
          97,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          96,
          28,
          96,
          99,
          38,
          15,
          100,
          39
        ],
        [
          "get_dpr_tokenizer",
          102,
          103,
          103,
          60,
          103,
          105,
          102,
          27,
          103,
          106
        ],
        [
          "get_bart_tokenizer",
          105,
          106,
          106,
          46,
          106,
          92,
          105,
          28,
          106,
          93
        ],
        [
          "test_save_load_pretrained_with_saved_config",
          112,
          122,
          113,
          20,
          113,
          65,
          112,
          53,
          122,
          102
        ]
      ],
      "transformers/tests/models/qwen2/test_tokenization_qwen2.py": [
        [
          "setUpClass",
          40,
          92,
          87,
          26,
          87,
          86,
          40,
          20,
          92,
          39
        ],
        [
          "setUpClass",
          40,
          92,
          88,
          27,
          88,
          88,
          40,
          20,
          92,
          39
        ]
      ],
      "transformers/tests/models/roberta/test_tokenization_roberta.py": [
        [
          "setUpClass",
          37,
          72,
          68,
          27,
          68,
          88,
          37,
          20,
          72,
          39
        ],
        [
          "setUpClass",
          37,
          72,
          67,
          26,
          67,
          86,
          37,
          20,
          72,
          39
        ]
      ],
      "transformers/tests/models/roc_bert/test_tokenization_roc_bert.py": [
        [
          "setUpClass",
          44,
          61,
          53,
          26,
          53,
          86,
          53,
          26,
          61,
          88
        ],
        [
          "setUpClass",
          44,
          61,
          54,
          31,
          54,
          96,
          53,
          26,
          61,
          88
        ],
        [
          "setUpClass",
          44,
          61,
          55,
          39,
          55,
          112,
          53,
          26,
          61,
          88
        ]
      ],
      "transformers/tests/models/siglip/test_tokenization_siglip.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          255,
          27,
          255,
          74,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          258,
          27,
          258,
          72,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          270,
          27,
          270,
          74,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          272,
          27,
          272,
          72,
          251,
          13,
          305,
          17
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_push_to_hub",
          122,
          132,
          125,
          30,
          125,
          63,
          122,
          26,
          132,
          70
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          134,
          146,
          137,
          30,
          137,
          63,
          134,
          46,
          146,
          70
        ],
        [
          "test_push_to_hub_in_organization",
          148,
          158,
          151,
          30,
          151,
          63,
          148,
          42,
          158,
          70
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          160,
          172,
          163,
          30,
          163,
          63,
          160,
          62,
          172,
          70
        ],
        [
          "test_push_to_hub_dynamic_tokenizer",
          175,
          189,
          179,
          30,
          179,
          63,
          175,
          44,
          189,
          77
        ],
        [
          "test_push_to_hub_dynamic_tokenizer_with_both_slow_and_fast_classes",
          192,
          215,
          200,
          30,
          200,
          63,
          192,
          76,
          215,
          77
        ]
      ],
      "transformers/tests/models/tapas/test_tokenization_tapas.py": [
        [
          "setUpClass",
          113,
          135,
          133,
          26,
          133,
          86,
          113,
          20,
          135,
          73
        ]
      ],
      "transformers/tests/models/vits/test_tokenization_vits.py": [
        [
          "setUpClass",
          35,
          52,
          50,
          26,
          50,
          86,
          35,
          20,
          52,
          53
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_utils.py": [
        [
          "test_instantiation_from_tokenizers_json_file",
          333,
          337,
          336,
          33,
          336,
          74,
          333,
          54,
          337,
          94
        ],
        [
          "test_instantiation_from_tokenizers_json_file",
          333,
          337,
          337,
          52,
          337,
          93,
          333,
          54,
          337,
          94
        ]
      ],
      "transformers/tests/models/t5/test_tokenization_t5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          306,
          27,
          306,
          74,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          309,
          27,
          309,
          72,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          321,
          27,
          321,
          74,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          323,
          27,
          323,
          72,
          302,
          13,
          356,
          17
        ]
      ],
      "transformers/tests/models/wav2vec2_phoneme/test_tokenization_wav2vec2_phoneme.py": [
        [
          "setUpClass",
          35,
          59,
          57,
          26,
          57,
          86,
          35,
          20,
          59,
          53
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "setUpClass",
          60,
          71,
          69,
          26,
          69,
          86,
          60,
          20,
          71,
          53
        ],
        [
          "setUpClass",
          379,
          390,
          388,
          26,
          388,
          86,
          379,
          20,
          390,
          53
        ],
        [
          "test_special_characters_in_vocab",
          478,
          496,
          482,
          22,
          482,
          72,
          478,
          42,
          496,
          45
        ],
        [
          "test_special_characters_in_vocab",
          478,
          496,
          492,
          35,
          492,
          84,
          478,
          42,
          496,
          45
        ],
        [
          "test_special_characters_in_vocab",
          478,
          496,
          493,
          58,
          493,
          107,
          478,
          42,
          496,
          45
        ],
        [
          "test_nested_vocab",
          789,
          832,
          818,
          29,
          818,
          63,
          789,
          27,
          832,
          60
        ]
      ],
      "transformers/tests/models/xlm/test_tokenization_xlm.py": [
        [
          "setUpClass",
          32,
          67,
          62,
          26,
          62,
          86,
          32,
          20,
          67,
          39
        ],
        [
          "setUpClass",
          32,
          67,
          63,
          27,
          63,
          88,
          32,
          20,
          67,
          39
        ]
      ],
      "transformers/tests/trainer/test_trainer_callback.py": [
        [
          "test_stateful_callbacks",
          272,
          304,
          298,
          22,
          298,
          66,
          272,
          33,
          303,
          46
        ],
        [
          "test_stateful_mixed_callbacks",
          306,
          347,
          336,
          22,
          336,
          66,
          306,
          39,
          343,
          28
        ],
        [
          "test_stateful_duplicate_callbacks",
          349,
          384,
          375,
          22,
          375,
          66,
          349,
          43,
          382,
          28
        ],
        [
          "test_missing_stateful_callback",
          386,
          413,
          409,
          22,
          409,
          66,
          386,
          40,
          413,
          71
        ],
        [
          "test_stateful_control",
          415,
          427,
          424,
          22,
          424,
          66,
          415,
          31,
          427,
          51
        ],
        [
          "test_stateful_control",
          415,
          427,
          425,
          53,
          425,
          96,
          415,
          31,
          427,
          51
        ]
      ],
      "transformers/tests/extended/test_trainer_ext.py": [
        [
          "run_seq2seq_quick",
          55,
          91,
          78,
          44,
          78,
          89,
          56,
          9,
          80,
          22
        ],
        [
          "test_run_seq2seq",
          139,
          162,
          150,
          44,
          150,
          89,
          139,
          26,
          155,
          75
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "check_saved_checkpoints",
          624,
          637,
          634,
          26,
          634,
          71,
          633,
          13,
          636,
          37
        ],
        [
          "check_saved_checkpoints",
          624,
          637,
          637,
          48,
          637,
          81,
          636,
          17,
          637,
          83
        ],
        [
          "check_best_model_has_been_loaded",
          639,
          665,
          642,
          22,
          642,
          85,
          640,
          9,
          646,
          53
        ],
        [
          "check_best_model_has_been_loaded",
          639,
          665,
          643,
          51,
          643,
          96,
          640,
          9,
          646,
          53
        ],
        [
          "check_best_model_has_been_loaded",
          639,
          665,
          648,
          22,
          648,
          78,
          646,
          22,
          649,
          24
        ],
        [
          "check_best_model_has_been_loaded",
          639,
          665,
          656,
          41,
          656,
          78,
          655,
          17,
          656,
          26
        ],
        [
          "check_best_model_has_been_loaded",
          639,
          665,
          658,
          58,
          658,
          100,
          658,
          30,
          658,
          26
        ],
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          695,
          28,
          695,
          66,
          694,
          22,
          695,
          24
        ],
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          699,
          28,
          699,
          61,
          697,
          13,
          699,
          24
        ],
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          704,
          26,
          704,
          70,
          702,
          25,
          705,
          22
        ],
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          709,
          26,
          709,
          65,
          707,
          25,
          710,
          22
        ],
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          728,
          57,
          728,
          88,
          727,
          13,
          728,
          89
        ],
        [
          "test_multiple_peft_adapters",
          1521,
          1575,
          1569,
          22,
          1569,
          58,
          1548,
          31,
          1575,
          60
        ],
        [
          "test_save_collator_tokenizer_by_default",
          3195,
          3211,
          3210,
          58,
          3210,
          102,
          3195,
          49,
          3211,
          76
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3224,
          31,
          3224,
          92,
          3213,
          40,
          3224,
          93
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3228,
          31,
          3228,
          67,
          3224,
          9,
          3228,
          68
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3247,
          31,
          3247,
          68,
          3228,
          9,
          3247,
          69
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3249,
          31,
          3249,
          68,
          3247,
          9,
          3249,
          69
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3251,
          35,
          3251,
          71,
          3249,
          9,
          3251,
          72
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3257,
          59,
          3257,
          117,
          3251,
          9,
          3258,
          39
        ],
        [
          "test_can_resume_training",
          3275,
          3372,
          3293,
          22,
          3293,
          58,
          3275,
          34,
          3372,
          98
        ],
        [
          "test_can_resume_training",
          3275,
          3372,
          3306,
          22,
          3306,
          59,
          3275,
          34,
          3372,
          98
        ],
        [
          "test_can_resume_training",
          3275,
          3372,
          3333,
          22,
          3333,
          58,
          3275,
          34,
          3372,
          98
        ],
        [
          "test_can_resume_training",
          3275,
          3372,
          3346,
          22,
          3346,
          59,
          3275,
          34,
          3372,
          98
        ],
        [
          "test_can_resume_training_lm",
          3380,
          3429,
          3420,
          26,
          3420,
          83,
          3380,
          37,
          3429,
          37
        ],
        [
          "test_resume_training_with_randomness",
          3434,
          3487,
          3458,
          50,
          3458,
          87,
          3442,
          25,
          3487,
          53
        ],
        [
          "test_resume_training_with_randomness",
          3434,
          3487,
          3483,
          50,
          3483,
          86,
          3442,
          25,
          3487,
          53
        ],
        [
          "test_auto_batch_size_finder",
          3493,
          3524,
          3498,
          13,
          3498,
          109,
          3497,
          19,
          3524,
          27
        ],
        [
          "test_resume_training_with_shard_checkpoint",
          3602,
          3624,
          3613,
          26,
          3613,
          61,
          3602,
          52,
          3624,
          64
        ],
        [
          "test_resume_training_with_safe_checkpoint",
          3627,
          3659,
          3646,
          34,
          3646,
          69,
          3633,
          17,
          3659,
          72
        ],
        [
          "test_resume_training_with_gradient_accumulation",
          3662,
          3697,
          3680,
          26,
          3680,
          61,
          3662,
          57,
          3697,
          64
        ],
        [
          "test_resume_training_with_frozen_params",
          3700,
          3737,
          3718,
          26,
          3718,
          61,
          3700,
          49,
          3737,
          64
        ],
        [
          "check_checkpoint_deletion",
          4081,
          4088,
          4084,
          25,
          4084,
          80,
          4083,
          13,
          4084,
          96
        ],
        [
          "test_checkpoint_rotation",
          4090,
          4112,
          4100,
          51,
          4100,
          87,
          4090,
          34,
          4112,
          69
        ],
        [
          "test_checkpoint_rotation",
          4090,
          4112,
          4108,
          51,
          4108,
          88,
          4090,
          34,
          4112,
          69
        ],
        [
          "test_checkpoint_rotation",
          4090,
          4112,
          4111,
          51,
          4111,
          87,
          4090,
          34,
          4112,
          69
        ],
        [
          "test_compare_trainer_and_checkpoint_args_logging",
          4114,
          4150,
          4129,
          26,
          4129,
          61,
          4114,
          58,
          4150,
          9
        ],
        [
          "test_end_to_end_example",
          4443,
          4485,
          4446,
          13,
          4448,
          13,
          4443,
          33,
          4485,
          45
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4974,
          20,
          4974,
          79,
          4972,
          13,
          4975,
          38
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5009,
          25,
          5009,
          105,
          5007,
          13,
          5010,
          67
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5045,
          25,
          5045,
          105,
          5043,
          13,
          5046,
          67
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5081,
          25,
          5081,
          105,
          5079,
          13,
          5082,
          67
        ],
        [
          "test_resume_from_interrupted_training",
          5199,
          5305,
          5268,
          27,
          5268,
          74,
          5199,
          47,
          5305,
          98
        ],
        [
          "test_resume_from_interrupted_training",
          5199,
          5305,
          5299,
          33,
          5299,
          80,
          5199,
          47,
          5305,
          98
        ],
        [
          "test_resume_from_interrupted_training",
          5199,
          5305,
          5304,
          28,
          5304,
          81,
          5199,
          47,
          5305,
          98
        ],
        [
          "test_push_to_hub",
          5315,
          5335,
          5320,
          32,
          5320,
          69,
          5315,
          26,
          5335,
          68
        ],
        [
          "test_push_to_hub_in_organization",
          5337,
          5359,
          5344,
          32,
          5344,
          69,
          5337,
          42,
          5359,
          68
        ],
        [
          "test_push_to_hub_with_saves_each_epoch",
          5374,
          5395,
          5380,
          36,
          5380,
          73,
          5374,
          48,
          5395,
          114
        ],
        [
          "test_push_to_hub_with_saves_each_n_steps",
          5397,
          5433,
          5407,
          36,
          5407,
          73,
          5402,
          14,
          5433,
          93
        ],
        [
          "test_push_to_hub_with_tensorboard_logs",
          5436,
          5457,
          5441,
          32,
          5441,
          69,
          5436,
          48,
          5453,
          26
        ],
        [
          "test_push_to_hub_tags",
          5459,
          5484,
          5467,
          32,
          5467,
          69,
          5459,
          31,
          5484,
          72
        ],
        [
          "test_push_to_hub_with_revision",
          5486,
          5501,
          5492,
          32,
          5492,
          69,
          5486,
          40,
          5501,
          67
        ]
      ],
      "transformers/tests/test_training_args.py": [
        [
          "test_output_dir_creation",
          20,
          40,
          23,
          26,
          23,
          61,
          20,
          34,
          40,
          56
        ]
      ],
      "transformers/tests/test_video_processing_common.py": [
        [
          "test_video_processor_to_json_file",
          121,
          130,
          126,
          34,
          126,
          81,
          122,
          13,
          130,
          95
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "listcomp",
          704,
          705,
          705,
          29,
          705,
          86,
          705,
          29,
          705,
          86
        ],
        [
          "listcomp",
          1060,
          1060,
          1060,
          23,
          1060,
          46,
          1060,
          23,
          1060,
          46
        ],
        [
          "create_test_list_from_filter",
          1109,
          1121,
          1113,
          21,
          1113,
          71,
          1112,
          9,
          1114,
          34
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "save_vocabulary",
          302,
          317,
          306,
          26,
          308,
          9,
          307,
          30,
          310,
          78
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert_fast.py": [
        [
          "save_vocabulary",
          158,
          175,
          168,
          26,
          170,
          9,
          169,
          30,
          172,
          78
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "save_vocabulary",
          282,
          309,
          286,
          22,
          288,
          9,
          287,
          30,
          290,
          69
        ],
        [
          "save_vocabulary",
          282,
          309,
          289,
          22,
          291,
          9,
          290,
          30,
          299,
          95
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez.py": [
        [
          "save_vocabulary",
          273,
          288,
          277,
          26,
          279,
          9,
          278,
          30,
          281,
          78
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez_fast.py": [
        [
          "save_vocabulary",
          173,
          190,
          183,
          26,
          185,
          9,
          184,
          30,
          187,
          78
        ]
      ],
      "transformers/src/transformers/models/bartpho/tokenization_bartpho.py": [
        [
          "save_vocabulary",
          286,
          315,
          290,
          26,
          292,
          9,
          291,
          30,
          295,
          53
        ],
        [
          "save_vocabulary",
          286,
          315,
          293,
          38,
          296,
          9,
          295,
          14,
          298,
          78
        ]
      ],
      "transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py": [
        [
          "save_vocabulary",
          159,
          174,
          163,
          26,
          165,
          9,
          164,
          30,
          167,
          78
        ]
      ],
      "transformers/src/transformers/models/bert/tokenization_bert.py": [
        [
          "save_vocabulary",
          239,
          257,
          242,
          26,
          244,
          13,
          243,
          34,
          242,
          22
        ]
      ],
      "transformers/src/transformers/models/bert_japanese/tokenization_bert_japanese.py": [
        [
          "save_vocabulary",
          312,
          342,
          315,
          30,
          317,
          17,
          316,
          38,
          315,
          26
        ],
        [
          "save_vocabulary",
          312,
          342,
          319,
          30,
          322,
          17,
          321,
          22,
          319,
          26
        ],
        [
          "__init__",
          348,
          432,
          429,
          23,
          429,
          54,
          429,
          23,
          430,
          24
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "get_tests_dir",
          1522,
          1542,
          1540,
          16,
          1540,
          51,
          1540,
          16,
          1540,
          51
        ],
        [
          "_prepare_debugging_info",
          3522,
          3531,
          3526,
          9,
          3526,
          100,
          3522,
          29,
          3531,
          15
        ],
        [
          "patch_testing_methods_to_collect_info",
          3741,
          3768,
          3748,
          9,
          3748,
          100,
          3742,
          5,
          3751,
          27
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "save_vocabulary",
          233,
          248,
          237,
          26,
          239,
          9,
          238,
          30,
          241,
          78
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "save_vocabulary",
          373,
          394,
          377,
          26,
          379,
          9,
          378,
          30,
          381,
          69
        ],
        [
          "save_vocabulary",
          373,
          394,
          380,
          26,
          382,
          9,
          381,
          30,
          384,
          78
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird_fast.py": [
        [
          "save_vocabulary",
          178,
          195,
          188,
          26,
          190,
          9,
          189,
          30,
          192,
          78
        ]
      ],
      "transformers/src/transformers/models/biogpt/tokenization_biogpt.py": [
        [
          "save_vocabulary",
          284,
          310,
          288,
          22,
          290,
          9,
          289,
          30,
          292,
          69
        ],
        [
          "save_vocabulary",
          284,
          310,
          291,
          22,
          293,
          9,
          292,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "save_vocabulary",
          192,
          219,
          196,
          22,
          198,
          9,
          197,
          30,
          200,
          69
        ],
        [
          "save_vocabulary",
          192,
          219,
          199,
          22,
          201,
          9,
          200,
          30,
          209,
          95
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "save_vocabulary",
          305,
          332,
          309,
          22,
          311,
          9,
          310,
          30,
          313,
          69
        ],
        [
          "save_vocabulary",
          305,
          332,
          312,
          22,
          314,
          9,
          313,
          30,
          322,
          95
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert.py": [
        [
          "save_vocabulary",
          229,
          244,
          233,
          26,
          235,
          9,
          234,
          30,
          237,
          78
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert_fast.py": [
        [
          "save_vocabulary",
          177,
          194,
          187,
          26,
          189,
          9,
          188,
          30,
          191,
          78
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "save_vocabulary",
          489,
          516,
          493,
          22,
          495,
          9,
          494,
          30,
          497,
          69
        ],
        [
          "save_vocabulary",
          489,
          516,
          496,
          22,
          498,
          9,
          497,
          30,
          506,
          95
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "save_vocabulary",
          337,
          364,
          341,
          22,
          343,
          9,
          342,
          30,
          345,
          69
        ],
        [
          "save_vocabulary",
          337,
          364,
          344,
          22,
          346,
          9,
          345,
          30,
          354,
          95
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama.py": [
        [
          "save_vocabulary",
          331,
          356,
          345,
          26,
          347,
          9,
          346,
          30,
          349,
          78
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "save_vocabulary",
          276,
          303,
          280,
          22,
          282,
          9,
          281,
          30,
          284,
          69
        ],
        [
          "save_vocabulary",
          276,
          303,
          283,
          22,
          285,
          9,
          284,
          30,
          293,
          95
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama_fast.py": [
        [
          "save_vocabulary",
          326,
          343,
          336,
          26,
          338,
          9,
          337,
          30,
          340,
          78
        ]
      ],
      "transformers/src/transformers/models/convbert/tokenization_convbert.py": [
        [
          "save_vocabulary",
          242,
          260,
          245,
          26,
          247,
          13,
          246,
          34,
          245,
          22
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "save_vocabulary",
          327,
          342,
          331,
          26,
          333,
          9,
          332,
          30,
          335,
          78
        ]
      ],
      "transformers/src/transformers/models/cpmant/tokenization_cpmant.py": [
        [
          "save_vocabulary",
          198,
          223,
          200,
          26,
          202,
          13,
          201,
          34,
          200,
          22
        ]
      ],
      "transformers/src/transformers/models/ctrl/tokenization_ctrl.py": [
        [
          "save_vocabulary",
          215,
          242,
          219,
          22,
          221,
          9,
          220,
          30,
          223,
          69
        ],
        [
          "save_vocabulary",
          215,
          242,
          222,
          22,
          224,
          9,
          223,
          30,
          232,
          95
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "save_vocabulary",
          330,
          357,
          334,
          22,
          336,
          9,
          335,
          30,
          338,
          69
        ],
        [
          "save_vocabulary",
          330,
          357,
          337,
          22,
          339,
          9,
          338,
          30,
          347,
          95
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm_fast.py": [
        [
          "save_vocabulary",
          205,
          222,
          215,
          26,
          217,
          9,
          216,
          30,
          219,
          78
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          182,
          26,
          184,
          9,
          183,
          30,
          186,
          78
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2.py": [
        [
          "save_pretrained",
          440,
          447,
          444,
          21,
          444,
          48,
          444,
          21,
          447,
          27
        ]
      ],
      "transformers/src/transformers/models/distilbert/tokenization_distilbert.py": [
        [
          "save_vocabulary",
          251,
          269,
          254,
          26,
          256,
          13,
          255,
          34,
          254,
          22
        ]
      ],
      "transformers/src/transformers/models/electra/tokenization_electra.py": [
        [
          "save_vocabulary",
          241,
          259,
          244,
          26,
          246,
          13,
          245,
          34,
          244,
          22
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": [
        [
          "save_vocabulary",
          146,
          167,
          160,
          22,
          162,
          9,
          161,
          30,
          167,
          28
        ]
      ],
      "transformers/src/transformers/models/deprecated/ernie_m/tokenization_ernie_m.py": [
        [
          "save_vocabulary",
          382,
          406,
          385,
          26,
          387,
          13,
          386,
          34,
          385,
          22
        ],
        [
          "save_vocabulary",
          382,
          406,
          401,
          32,
          401,
          86,
          401,
          32,
          406,
          28
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet_fast.py": [
        [
          "save_vocabulary",
          141,
          152,
          145,
          26,
          147,
          9,
          146,
          30,
          149,
          78
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "save_vocabulary",
          489,
          515,
          493,
          22,
          495,
          9,
          494,
          30,
          497,
          69
        ],
        [
          "save_vocabulary",
          489,
          515,
          496,
          22,
          498,
          9,
          497,
          30,
          505,
          95
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "save_vocabulary",
          296,
          311,
          300,
          26,
          302,
          9,
          301,
          30,
          304,
          78
        ]
      ],
      "transformers/src/transformers/models/esm/tokenization_esm.py": [
        [
          "save_vocabulary",
          136,
          140,
          137,
          22,
          137,
          115,
          137,
          52,
          140,
          28
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "save_vocabulary",
          433,
          467,
          438,
          26,
          440,
          9,
          439,
          30,
          442,
          69
        ],
        [
          "save_vocabulary",
          433,
          467,
          441,
          26,
          443,
          9,
          442,
          30,
          445,
          69
        ],
        [
          "save_vocabulary",
          433,
          467,
          444,
          23,
          446,
          9,
          445,
          30,
          457,
          95
        ]
      ],
      "transformers/src/transformers/models/funnel/tokenization_funnel.py": [
        [
          "save_vocabulary",
          301,
          319,
          304,
          26,
          306,
          13,
          305,
          34,
          304,
          22
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma.py": [
        [
          "save_vocabulary",
          197,
          222,
          211,
          26,
          213,
          9,
          212,
          30,
          215,
          78
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "save_vocabulary",
          298,
          325,
          302,
          22,
          304,
          9,
          303,
          30,
          306,
          69
        ],
        [
          "save_vocabulary",
          298,
          325,
          305,
          22,
          307,
          9,
          306,
          30,
          315,
          95
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma_fast.py": [
        [
          "save_vocabulary",
          163,
          180,
          173,
          26,
          175,
          9,
          174,
          30,
          177,
          78
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "save_vocabulary",
          236,
          251,
          240,
          26,
          242,
          9,
          241,
          30,
          244,
          78
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "save_vocabulary",
          165,
          193,
          168,
          26,
          170,
          13,
          169,
          34,
          172,
          73
        ],
        [
          "save_vocabulary",
          165,
          193,
          171,
          26,
          173,
          13,
          172,
          34,
          171,
          22
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "save_vocabulary",
          240,
          268,
          243,
          26,
          245,
          13,
          244,
          34,
          247,
          73
        ],
        [
          "save_vocabulary",
          240,
          268,
          246,
          26,
          248,
          13,
          247,
          34,
          246,
          22
        ]
      ],
      "transformers/src/transformers/models/layoutlm/tokenization_layoutlm.py": [
        [
          "save_vocabulary",
          242,
          260,
          245,
          26,
          247,
          13,
          246,
          34,
          245,
          22
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "save_vocabulary",
          568,
          594,
          572,
          22,
          574,
          9,
          573,
          30,
          576,
          69
        ],
        [
          "save_vocabulary",
          568,
          594,
          575,
          22,
          577,
          9,
          576,
          30,
          584,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "save_vocabulary",
          336,
          370,
          352,
          24,
          354,
          9,
          353,
          30,
          359,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          358,
          23,
          360,
          9,
          359,
          30,
          365,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          364,
          23,
          366,
          9,
          365,
          30,
          370,
          55
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py": [
        [
          "save_vocabulary",
          360,
          378,
          363,
          26,
          365,
          13,
          364,
          34,
          363,
          22
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "save_vocabulary",
          411,
          438,
          415,
          22,
          417,
          9,
          416,
          30,
          419,
          69
        ],
        [
          "save_vocabulary",
          411,
          438,
          418,
          22,
          420,
          9,
          419,
          30,
          428,
          95
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm.py": [
        [
          "save_vocabulary",
          421,
          436,
          425,
          26,
          427,
          9,
          426,
          30,
          429,
          78
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "save_vocabulary",
          295,
          322,
          302,
          22,
          304,
          9,
          303,
          30,
          312,
          95
        ],
        [
          "save_vocabulary",
          295,
          322,
          299,
          22,
          301,
          9,
          300,
          30,
          303,
          69
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama_fast.py": [
        [
          "save_vocabulary",
          218,
          235,
          228,
          26,
          230,
          9,
          229,
          30,
          232,
          78
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "save_vocabulary",
          291,
          318,
          295,
          22,
          297,
          9,
          296,
          30,
          299,
          69
        ],
        [
          "save_vocabulary",
          291,
          318,
          298,
          22,
          300,
          9,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py": [
        [
          "save_vocabulary",
          794,
          811,
          804,
          26,
          806,
          9,
          805,
          30,
          808,
          78
        ]
      ],
      "transformers/src/transformers/models/lxmert/tokenization_lxmert.py": [
        [
          "save_vocabulary",
          241,
          259,
          244,
          26,
          246,
          13,
          245,
          34,
          244,
          22
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama.py": [
        [
          "save_vocabulary",
          306,
          331,
          320,
          26,
          322,
          9,
          321,
          30,
          324,
          78
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "save_vocabulary",
          287,
          330,
          294,
          34,
          297,
          13,
          296,
          18,
          300,
          57
        ],
        [
          "save_vocabulary",
          287,
          330,
          298,
          34,
          301,
          13,
          300,
          18,
          305,
          50
        ],
        [
          "save_vocabulary",
          287,
          330,
          307,
          30,
          309,
          13,
          308,
          34,
          311,
          46
        ],
        [
          "save_vocabulary",
          287,
          330,
          318,
          29,
          320,
          13,
          319,
          34,
          321,
          79
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "save_vocabulary",
          369,
          398,
          373,
          22,
          375,
          9,
          374,
          30,
          377,
          69
        ],
        [
          "save_vocabulary",
          369,
          398,
          376,
          22,
          378,
          9,
          377,
          30,
          388,
          95
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "save_vocabulary",
          1691,
          1725,
          1695,
          22,
          1697,
          9,
          1696,
          30,
          1699,
          69
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1698,
          22,
          1700,
          9,
          1699,
          30,
          1708,
          95
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1718,
          29,
          1720,
          9,
          1719,
          30,
          1725,
          56
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart.py": [
        [
          "save_vocabulary",
          294,
          309,
          298,
          26,
          300,
          9,
          299,
          30,
          302,
          78
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50.py": [
        [
          "save_vocabulary",
          242,
          257,
          246,
          26,
          248,
          9,
          247,
          30,
          250,
          78
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50_fast.py": [
        [
          "save_vocabulary",
          238,
          255,
          248,
          26,
          250,
          9,
          249,
          30,
          252,
          78
        ]
      ],
      "transformers/src/transformers/models/mgp_str/tokenization_mgp_str.py": [
        [
          "save_vocabulary",
          90,
          101,
          94,
          22,
          96,
          9,
          95,
          30,
          101,
          28
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart_fast.py": [
        [
          "save_vocabulary",
          249,
          266,
          259,
          26,
          261,
          9,
          260,
          30,
          263,
          78
        ]
      ],
      "transformers/src/transformers/models/mobilebert/tokenization_mobilebert.py": [
        [
          "save_vocabulary",
          243,
          261,
          246,
          26,
          248,
          13,
          247,
          34,
          246,
          22
        ]
      ],
      "transformers/src/transformers/models/mpnet/tokenization_mpnet.py": [
        [
          "save_vocabulary",
          296,
          314,
          299,
          26,
          301,
          13,
          300,
          34,
          299,
          22
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "save_vocabulary",
          1530,
          1553,
          1535,
          26,
          1537,
          9,
          1536,
          30,
          1539,
          78
        ],
        [
          "save_vocabulary",
          1530,
          1553,
          1546,
          29,
          1548,
          9,
          1547,
          30,
          1553,
          48
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "save_vocabulary",
          283,
          310,
          287,
          22,
          289,
          9,
          288,
          30,
          291,
          69
        ],
        [
          "save_vocabulary",
          283,
          310,
          290,
          22,
          292,
          9,
          291,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/myt5/tokenization_myt5.py": [
        [
          "save_vocabulary",
          368,
          377,
          370,
          26,
          372,
          13,
          371,
          34,
          370,
          22
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb_fast.py": [
        [
          "save_vocabulary",
          307,
          324,
          317,
          26,
          319,
          9,
          318,
          30,
          321,
          78
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb.py": [
        [
          "save_vocabulary",
          332,
          347,
          336,
          26,
          338,
          9,
          337,
          30,
          340,
          78
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "save_vocabulary",
          366,
          393,
          373,
          22,
          375,
          9,
          374,
          30,
          383,
          95
        ],
        [
          "save_vocabulary",
          366,
          393,
          370,
          22,
          372,
          9,
          371,
          30,
          374,
          69
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus_fast.py": [
        [
          "save_vocabulary",
          195,
          212,
          205,
          26,
          207,
          9,
          206,
          30,
          209,
          78
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus.py": [
        [
          "save_vocabulary",
          274,
          289,
          278,
          26,
          280,
          9,
          279,
          30,
          282,
          78
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "save_vocabulary",
          298,
          319,
          302,
          26,
          304,
          9,
          303,
          30,
          306,
          69
        ],
        [
          "save_vocabulary",
          298,
          319,
          305,
          26,
          307,
          9,
          306,
          30,
          309,
          78
        ]
      ],
      "transformers/src/transformers/tokenization_mistral_common.py": [
        [
          "from_pretrained",
          1685,
          1809,
          1799,
          30,
          1799,
          88,
          1799,
          30,
          1799,
          26
        ]
      ],
      "transformers/src/transformers/models/pop2piano/tokenization_pop2piano.py": [
        [
          "save_vocabulary",
          344,
          365,
          359,
          26,
          361,
          9,
          360,
          30,
          365,
          32
        ]
      ],
      "transformers/src/transformers/models/plbart/tokenization_plbart.py": [
        [
          "save_vocabulary",
          370,
          385,
          374,
          26,
          376,
          9,
          375,
          30,
          378,
          78
        ]
      ],
      "transformers/src/transformers/models/rag/tokenization_rag.py": [
        [
          "save_pretrained",
          35,
          42,
          39,
          33,
          39,
          90,
          38,
          9,
          42,
          54
        ],
        [
          "save_pretrained",
          35,
          42,
          40,
          26,
          40,
          76,
          38,
          9,
          42,
          54
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "save_vocabulary",
          308,
          335,
          312,
          22,
          314,
          9,
          313,
          30,
          316,
          69
        ],
        [
          "save_vocabulary",
          308,
          335,
          315,
          22,
          317,
          9,
          316,
          30,
          325,
          95
        ]
      ],
      "transformers/src/transformers/models/prophetnet/tokenization_prophetnet.py": [
        [
          "save_vocabulary",
          435,
          453,
          438,
          26,
          440,
          13,
          439,
          34,
          438,
          22
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/tokenization_realm.py": [
        [
          "save_vocabulary",
          307,
          325,
          310,
          26,
          312,
          13,
          311,
          34,
          310,
          22
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer.py": [
        [
          "save_vocabulary",
          158,
          173,
          162,
          26,
          164,
          9,
          163,
          30,
          166,
          78
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer_fast.py": [
        [
          "save_vocabulary",
          94,
          111,
          104,
          26,
          106,
          9,
          105,
          30,
          108,
          78
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert_fast.py": [
        [
          "save_vocabulary",
          184,
          195,
          188,
          26,
          190,
          9,
          189,
          30,
          192,
          78
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert.py": [
        [
          "save_vocabulary",
          219,
          234,
          223,
          26,
          225,
          9,
          224,
          30,
          227,
          78
        ]
      ],
      "transformers/src/transformers/models/deprecated/retribert/tokenization_retribert.py": [
        [
          "save_vocabulary",
          236,
          254,
          239,
          26,
          241,
          13,
          240,
          34,
          239,
          22
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "save_vocabulary",
          291,
          318,
          295,
          22,
          297,
          9,
          296,
          30,
          299,
          69
        ],
        [
          "save_vocabulary",
          291,
          318,
          298,
          22,
          300,
          9,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/roformer/tokenization_roformer.py": [
        [
          "save_vocabulary",
          490,
          508,
          493,
          26,
          495,
          13,
          494,
          34,
          493,
          22
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "save_vocabulary",
          362,
          377,
          366,
          26,
          368,
          9,
          367,
          30,
          370,
          78
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t_fast.py": [
        [
          "save_vocabulary",
          320,
          337,
          330,
          26,
          332,
          9,
          331,
          30,
          334,
          78
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t.py": [
        [
          "save_vocabulary",
          497,
          512,
          501,
          26,
          503,
          9,
          502,
          30,
          505,
          78
        ]
      ],
      "transformers/src/transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py": [
        [
          "save_vocabulary",
          220,
          249,
          224,
          22,
          226,
          9,
          225,
          30,
          228,
          69
        ],
        [
          "save_vocabulary",
          220,
          249,
          227,
          23,
          229,
          9,
          228,
          30,
          235,
          33
        ]
      ],
      "transformers/src/transformers/models/splinter/tokenization_splinter.py": [
        [
          "save_vocabulary",
          280,
          298,
          283,
          26,
          285,
          13,
          284,
          34,
          283,
          22
        ]
      ],
      "transformers/src/transformers/models/speecht5/tokenization_speecht5.py": [
        [
          "save_vocabulary",
          205,
          220,
          209,
          26,
          211,
          9,
          210,
          30,
          213,
          78
        ]
      ],
      "transformers/src/transformers/models/squeezebert/tokenization_squeezebert.py": [
        [
          "save_vocabulary",
          242,
          260,
          245,
          26,
          247,
          13,
          246,
          34,
          245,
          22
        ]
      ],
      "transformers/src/transformers/models/roc_bert/tokenization_roc_bert.py": [
        [
          "save_vocabulary",
          827,
          869,
          830,
          26,
          833,
          13,
          832,
          18,
          836,
          57
        ],
        [
          "save_vocabulary",
          827,
          869,
          834,
          31,
          837,
          13,
          836,
          18,
          840,
          57
        ],
        [
          "save_vocabulary",
          827,
          869,
          838,
          39,
          841,
          13,
          840,
          18,
          849,
          86
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "save_vocabulary",
          430,
          445,
          434,
          26,
          436,
          9,
          435,
          30,
          438,
          78
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5_fast.py": [
        [
          "save_vocabulary",
          156,
          174,
          166,
          26,
          168,
          9,
          167,
          30,
          170,
          78
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "save_vocabulary",
          465,
          492,
          469,
          22,
          471,
          9,
          470,
          30,
          473,
          69
        ],
        [
          "save_vocabulary",
          465,
          492,
          472,
          22,
          474,
          9,
          473,
          30,
          482,
          95
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "save_vocabulary",
          491,
          506,
          495,
          26,
          497,
          9,
          496,
          30,
          499,
          78
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "save_vocabulary",
          372,
          390,
          375,
          26,
          377,
          13,
          376,
          34,
          375,
          22
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "save_vocabulary",
          317,
          327,
          319,
          26,
          322,
          13,
          321,
          18,
          319,
          22
        ],
        [
          "build_corpus",
          729,
          761,
          733,
          35,
          733,
          65,
          733,
          13,
          735,
          65
        ],
        [
          "build_corpus",
          729,
          761,
          734,
          35,
          734,
          65,
          733,
          13,
          735,
          65
        ],
        [
          "build_corpus",
          729,
          761,
          735,
          35,
          735,
          64,
          733,
          13,
          735,
          65
        ],
        [
          "build_corpus",
          729,
          761,
          737,
          35,
          737,
          65,
          737,
          13,
          737,
          66
        ],
        [
          "build_corpus",
          729,
          761,
          739,
          34,
          744,
          13,
          739,
          34,
          745,
          23
        ],
        [
          "build_corpus",
          729,
          761,
          751,
          49,
          751,
          79,
          751,
          26,
          753,
          21
        ],
        [
          "build_corpus",
          729,
          761,
          752,
          49,
          752,
          79,
          751,
          26,
          753,
          21
        ],
        [
          "build_corpus",
          729,
          761,
          753,
          48,
          753,
          77,
          751,
          26,
          753,
          21
        ],
        [
          "build_corpus",
          729,
          761,
          755,
          49,
          755,
          79,
          755,
          26,
          757,
          21
        ],
        [
          "build_corpus",
          729,
          761,
          756,
          49,
          756,
          79,
          755,
          26,
          757,
          21
        ],
        [
          "build_corpus",
          729,
          761,
          757,
          48,
          757,
          77,
          755,
          26,
          757,
          21
        ],
        [
          "build_corpus",
          729,
          761,
          760,
          49,
          760,
          79,
          759,
          26,
          761,
          21
        ],
        [
          "build_corpus",
          729,
          761,
          761,
          48,
          761,
          77,
          759,
          26,
          761,
          21
        ],
        [
          "get_lm_corpus",
          784,
          821,
          785,
          10,
          785,
          42,
          784,
          19,
          787,
          25
        ],
        [
          "get_lm_corpus",
          784,
          821,
          786,
          17,
          786,
          50,
          784,
          19,
          787,
          25
        ],
        [
          "get_lm_corpus",
          784,
          821,
          814,
          36,
          814,
          77,
          812,
          33,
          814,
          32
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop_fast.py": [
        [
          "save_vocabulary",
          1006,
          1023,
          1016,
          26,
          1018,
          9,
          1017,
          30,
          1020,
          78
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "save_vocabulary",
          231,
          243,
          236,
          22,
          238,
          9,
          237,
          30,
          243,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        [
          "save_vocabulary",
          558,
          569,
          562,
          22,
          564,
          9,
          563,
          30,
          569,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py": [
        [
          "save_vocabulary",
          624,
          635,
          628,
          22,
          630,
          9,
          629,
          30,
          635,
          28
        ],
        [
          "save_vocabulary",
          901,
          912,
          905,
          22,
          907,
          9,
          906,
          30,
          912,
          28
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "save_vocabulary",
          439,
          452,
          442,
          27,
          444,
          9,
          443,
          30,
          446,
          55
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "_save_pretrained",
          695,
          742,
          722,
          33,
          724,
          13,
          723,
          34,
          727,
          26
        ],
        [
          "_save_pretrained",
          695,
          742,
          736,
          30,
          738,
          13,
          737,
          34,
          740,
          22
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "save_chat_templates",
          2416,
          2469,
          2428,
          30,
          2430,
          9,
          2429,
          30,
          2432,
          69
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2431,
          29,
          2433,
          9,
          2432,
          30,
          2436,
          27
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2455,
          41,
          2455,
          97,
          2454,
          21,
          2459,
          75
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2539,
          35,
          2541,
          9,
          2540,
          30,
          2543,
          69
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2542,
          33,
          2544,
          9,
          2543,
          30,
          2553,
          28
        ],
        [
          "_save_pretrained",
          2640,
          2673,
          2660,
          29,
          2662,
          9,
          2661,
          30,
          2665,
          22
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm.py": [
        [
          "save_vocabulary",
          284,
          299,
          288,
          26,
          290,
          9,
          289,
          30,
          292,
          78
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "save_vocabulary",
          801,
          837,
          805,
          22,
          807,
          9,
          806,
          30,
          809,
          69
        ],
        [
          "save_vocabulary",
          801,
          837,
          808,
          22,
          810,
          9,
          809,
          30,
          812,
          69
        ],
        [
          "save_vocabulary",
          801,
          837,
          811,
          27,
          813,
          9,
          812,
          30,
          821,
          95
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          182,
          26,
          184,
          9,
          183,
          30,
          186,
          78
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "save_vocabulary",
          532,
          558,
          536,
          22,
          538,
          9,
          537,
          30,
          540,
          69
        ],
        [
          "save_vocabulary",
          532,
          558,
          539,
          22,
          541,
          9,
          540,
          30,
          548,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        [
          "save_vocabulary",
          279,
          294,
          283,
          26,
          285,
          9,
          284,
          30,
          287,
          78
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py": [
        [
          "save_vocabulary",
          174,
          191,
          184,
          26,
          186,
          9,
          185,
          30,
          188,
          78
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py": [
        [
          "save_vocabulary",
          283,
          298,
          287,
          26,
          289,
          9,
          288,
          30,
          291,
          78
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet_fast.py": [
        [
          "save_vocabulary",
          210,
          227,
          220,
          26,
          222,
          9,
          221,
          30,
          224,
          78
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "save_vocabulary",
          369,
          384,
          373,
          26,
          375,
          9,
          374,
          30,
          377,
          78
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "save_metrics",
          884,
          919,
          905,
          12,
          905,
          70,
          905,
          12,
          909,
          15
        ],
        [
          "save_metrics",
          884,
          919,
          910,
          16,
          910,
          69,
          910,
          16,
          911,
          31
        ],
        [
          "save_state",
          922,
          932,
          931,
          12,
          931,
          67,
          931,
          12,
          932,
          33
        ],
        [
          "remove_dummy_checkpoint",
          996,
          1001,
          999,
          20,
          999,
          53,
          998,
          13,
          1000,
          35
        ]
      ],
      "transformers/src/transformers/trainer_utils.py": [
        [
          "listcomp",
          204,
          205,
          207,
          70,
          207,
          95,
          207,
          56,
          207,
          96
        ],
        [
          "get_last_checkpoint",
          202,
          211,
          211,
          12,
          211,
          106,
          211,
          12,
          211,
          106
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "default_logdir",
          111,
          119,
          119,
          12,
          119,
          74,
          112,
          5,
          119,
          74
        ],
        [
          "__post_init__",
          1467,
          1917,
          1493,
          32,
          1493,
          78,
          1493,
          32,
          1493,
          28
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_tune_save_checkpoint",
          1891,
          1899,
          1892,
          22,
          1892,
          102,
          1891,
          31,
          1894,
          32
        ],
        [
          "_tune_save_checkpoint",
          1891,
          1899,
          1897,
          37,
          1897,
          80,
          1896,
          63,
          1899,
          96
        ],
        [
          "_tune_save_checkpoint",
          1891,
          1899,
          1898,
          53,
          1898,
          92,
          1896,
          63,
          1899,
          96
        ],
        [
          "_tune_save_checkpoint",
          1891,
          1899,
          1899,
          56,
          1899,
          95,
          1896,
          63,
          1899,
          96
        ],
        [
          "train",
          2124,
          2229,
          2198,
          49,
          2198,
          104,
          2198,
          21,
          2199,
          49
        ],
        [
          "_inner_training_loop",
          2252,
          2734,
          2424,
          13,
          2424,
          68,
          2423,
          51,
          2425,
          9
        ],
        [
          "_inner_training_loop",
          2252,
          2734,
          2426,
          54,
          2426,
          109,
          2426,
          26,
          2430,
          40
        ],
        [
          "_get_output_dir",
          2736,
          2754,
          2751,
          23,
          2751,
          66,
          2750,
          24,
          2751,
          19
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2760,
          23,
          2760,
          71,
          2760,
          23,
          2767,
          60
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2761,
          32,
          2761,
          89,
          2760,
          23,
          2767,
          60
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2762,
          37,
          2762,
          99,
          2760,
          23,
          2767,
          60
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2763,
          24,
          2763,
          73,
          2760,
          23,
          2767,
          60
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2764,
          30,
          2764,
          85,
          2760,
          23,
          2767,
          60
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2765,
          29,
          2765,
          83,
          2760,
          23,
          2767,
          60
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2766,
          35,
          2766,
          95,
          2760,
          23,
          2767,
          60
        ],
        [
          "genexpr",
          2770,
          2770,
          2772,
          34,
          2772,
          82,
          2771,
          21,
          2772,
          83
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2775,
          31,
          2775,
          92,
          2775,
          16,
          2775,
          93
        ],
        [
          "listcomp",
          2779,
          2780,
          2782,
          34,
          2782,
          82,
          2781,
          21,
          2782,
          83
        ],
        [
          "listcomp",
          2779,
          2780,
          2784,
          36,
          2784,
          106,
          2784,
          21,
          2784,
          107
        ],
        [
          "listcomp",
          2779,
          2780,
          2785,
          39,
          2785,
          114,
          2785,
          24,
          2785,
          115
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2872,
          39,
          2872,
          87,
          2871,
          29,
          2873,
          114
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2895,
          27,
          2895,
          86,
          2893,
          26,
          2900,
          63
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2896,
          32,
          2896,
          96,
          2893,
          26,
          2900,
          63
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2897,
          35,
          2897,
          102,
          2893,
          26,
          2900,
          63
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2898,
          40,
          2898,
          112,
          2893,
          26,
          2900,
          63
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2989,
          29,
          2989,
          99,
          2989,
          14,
          2989,
          100
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2990,
          13,
          2990,
          78,
          2989,
          105,
          2991,
          9
        ],
        [
          "_load_rng_state",
          3078,
          3119,
          3085,
          24,
          3085,
          81,
          3084,
          29,
          3086,
          43
        ],
        [
          "_load_rng_state",
          3078,
          3119,
          3093,
          24,
          3093,
          64,
          3093,
          24,
          3094,
          43
        ],
        [
          "_save_checkpoint",
          3159,
          3217,
          3171,
          22,
          3171,
          61,
          3170,
          19,
          3174,
          78
        ],
        [
          "_save_checkpoint",
          3159,
          3217,
          3185,
          35,
          3185,
          79,
          3184,
          38,
          3187,
          50
        ],
        [
          "_save_checkpoint",
          3159,
          3217,
          3209,
          37,
          3209,
          80,
          3209,
          13,
          3209,
          81
        ],
        [
          "_save_rng_state",
          3219,
          3267,
          3265,
          36,
          3265,
          76,
          3265,
          13,
          3265,
          77
        ],
        [
          "_save_rng_state",
          3219,
          3267,
          3267,
          36,
          3267,
          103,
          3267,
          13,
          3267,
          104
        ],
        [
          "_save_optimizer_and_scheduler",
          3269,
          3332,
          3279,
          21,
          3281,
          21,
          3274,
          21,
          3283,
          17
        ],
        [
          "_save_optimizer_and_scheduler",
          3269,
          3332,
          3285,
          54,
          3285,
          93,
          3285,
          17,
          3285,
          94
        ],
        [
          "_save_optimizer_and_scheduler",
          3269,
          3332,
          3287,
          57,
          3287,
          96,
          3286,
          18,
          3288,
          52
        ],
        [
          "_save_optimizer_and_scheduler",
          3269,
          3332,
          3295,
          21,
          3295,
          60,
          3293,
          17,
          3298,
          17
        ],
        [
          "_save_optimizer_and_scheduler",
          3269,
          3332,
          3319,
          53,
          3319,
          92,
          3319,
          13,
          3319,
          93
        ],
        [
          "_save_optimizer_and_scheduler",
          3269,
          3332,
          3331,
          60,
          3331,
          99,
          3330,
          18,
          3332,
          48
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3345,
          36,
          3345,
          75,
          3342,
          22,
          3347,
          52
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3351,
          23,
          3351,
          62,
          3351,
          13,
          3351,
          70
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3354,
          32,
          3354,
          71,
          3354,
          17,
          3354,
          72
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3355,
          35,
          3355,
          78,
          3355,
          20,
          3355,
          79
        ],
        [
          "genexpr",
          3359,
          3359,
          3361,
          42,
          3361,
          78,
          3360,
          29,
          3361,
          79
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3367,
          23,
          3367,
          99,
          3367,
          13,
          3367,
          100
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3371,
          54,
          3371,
          93,
          3371,
          39,
          3371,
          94
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3378,
          25,
          3380,
          25,
          3376,
          21,
          3385,
          35
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3389,
          25,
          3389,
          64,
          3387,
          21,
          3388,
          35
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3394,
          25,
          3394,
          64,
          3391,
          22,
          3402,
          69
        ],
        [
          "opt_load_hook",
          3406,
          3407,
          3407,
          54,
          3407,
          93,
          3406,
          39,
          3407,
          109
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3428,
          33,
          3428,
          72,
          3425,
          25,
          3430,
          25
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3434,
          36,
          3434,
          75,
          3431,
          22,
          3436,
          52
        ],
        [
          "_save_scaler",
          3438,
          3456,
          3449,
          63,
          3449,
          99,
          3447,
          13,
          3450,
          52
        ],
        [
          "_save_scaler",
          3438,
          3456,
          3455,
          66,
          3455,
          102,
          3454,
          18,
          3456,
          48
        ],
        [
          "_load_scaler",
          3458,
          3483,
          3463,
          49,
          3463,
          85,
          3463,
          34,
          3465,
          33
        ],
        [
          "_load_scaler",
          3458,
          3483,
          3472,
          25,
          3472,
          61,
          3469,
          22,
          3476,
          69
        ],
        [
          "_load_scaler",
          3458,
          3483,
          3481,
          36,
          3481,
          72,
          3478,
          22,
          3483,
          52
        ],
        [
          "save_model",
          4003,
          4055,
          4021,
          18,
          4021,
          60,
          4021,
          13,
          4021,
          69
        ],
        [
          "_save_tpu",
          4057,
          4127,
          4066,
          35,
          4066,
          78,
          4065,
          13,
          4066,
          79
        ],
        [
          "_save_tpu",
          4057,
          4127,
          4077,
          25,
          4079,
          13,
          4074,
          17,
          4085,
          36
        ],
        [
          "_save_tpu",
          4057,
          4127,
          4089,
          33,
          4089,
          60,
          4086,
          22,
          4095,
          65
        ],
        [
          "_save_tpu",
          4057,
          4127,
          4104,
          46,
          4104,
          83,
          4103,
          21,
          4104,
          84
        ],
        [
          "_save_tpu",
          4057,
          4127,
          4117,
          37,
          4117,
          74,
          4115,
          17,
          4117,
          75
        ],
        [
          "_save",
          4129,
          4170,
          4150,
          37,
          4150,
          79,
          4149,
          21,
          4151,
          21
        ],
        [
          "_save",
          4129,
          4170,
          4153,
          44,
          4153,
          81,
          4153,
          21,
          4153,
          82
        ],
        [
          "_save",
          4129,
          4170,
          4170,
          31,
          4170,
          74,
          4170,
          9,
          4170,
          75
        ],
        [
          "create_model_card",
          4790,
          4862,
          4830,
          31,
          4830,
          77,
          4830,
          31,
          4832,
          46
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4877,
          26,
          4877,
          68,
          4876,
          13,
          4878,
          41
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4887,
          31,
          4887,
          76,
          4886,
          13,
          4887,
          77
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4888,
          29,
          4888,
          74,
          4888,
          17,
          4888,
          116
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4888,
          77,
          4888,
          115,
          4888,
          17,
          4888,
          116
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4893,
          31,
          4893,
          74,
          4893,
          9,
          4895,
          56
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5028,
          27,
          5028,
          73,
          5025,
          21,
          5028,
          74
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5029,
          23,
          5029,
          69,
          5029,
          18,
          5030,
          31
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5045,
          23,
          5045,
          69,
          5045,
          18,
          5047,
          32
        ]
      ],
      "transformers/utils/update_metadata.py": [
        [
          "update_metadata",
          232,
          312,
          283,
          36,
          283,
          75,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          284,
          30,
          284,
          72,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          286,
          19,
          286,
          58,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          288,
          19,
          288,
          61,
          232,
          21,
          294,
          27
        ]
      ],
      "transformers/utils/update_tiny_models.py": [
        [
          "get_tiny_model_summary_from_hub",
          67,
          142,
          141,
          19,
          141,
          74,
          136,
          40,
          142,
          64
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "get_dev_examples",
          169,
          176,
          172,
          16,
          172,
          49,
          169,
          26,
          176,
          58
        ],
        [
          "__init__",
          83,
          128,
          94,
          36,
          102,
          13,
          84,
          13,
          108,
          55
        ],
        [
          "get_train_examples",
          160,
          167,
          163,
          16,
          163,
          51,
          160,
          28,
          167,
          60
        ],
        [
          "get_train_examples",
          160,
          167,
          164,
          18,
          164,
          55,
          160,
          28,
          167,
          60
        ],
        [
          "get_dev_examples",
          169,
          176,
          173,
          18,
          173,
          53,
          169,
          26,
          176,
          58
        ],
        [
          "get_test_examples",
          178,
          185,
          181,
          16,
          181,
          50,
          178,
          27,
          185,
          59
        ],
        [
          "get_test_examples",
          178,
          185,
          182,
          18,
          182,
          54,
          178,
          27,
          185,
          59
        ],
        [
          "get_train_examples",
          227,
          230,
          230,
          53,
          230,
          89,
          227,
          28,
          230,
          100
        ],
        [
          "get_dev_examples",
          232,
          235,
          235,
          53,
          235,
          86,
          232,
          26,
          235,
          95
        ],
        [
          "get_test_examples",
          237,
          241,
          241,
          53,
          241,
          88,
          237,
          27,
          241,
          98
        ],
        [
          "get_train_examples",
          273,
          276,
          276,
          53,
          276,
          87,
          273,
          28,
          276,
          98
        ],
        [
          "get_dev_examples",
          278,
          281,
          281,
          53,
          281,
          85,
          278,
          26,
          281,
          94
        ],
        [
          "get_train_examples",
          324,
          327,
          327,
          54,
          327,
          90,
          324,
          28,
          327,
          101
        ],
        [
          "get_dev_examples",
          329,
          332,
          332,
          54,
          332,
          88,
          329,
          26,
          332,
          97
        ],
        [
          "get_test_examples",
          334,
          336,
          336,
          54,
          336,
          89,
          334,
          27,
          336,
          99
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "save_git_info",
          463,
          466,
          466,
          27,
          466,
          67,
          463,
          19,
          466,
          68
        ]
      ],
      "transformers/examples/legacy/token-classification/utils_ner.py": [
        [
          "__init__",
          216,
          262,
          228,
          36,
          231,
          13,
          217,
          13,
          237,
          55
        ]
      ],
      "transformers/examples/pytorch/question-answering/utils_qa.py": [
        [
          "postprocess_qa_predictions",
          31,
          249,
          227,
          27,
          229,
          9,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          227,
          27,
          229,
          9,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          227,
          27,
          229,
          9,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          227,
          27,
          229,
          9,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          230,
          22,
          232,
          9,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          230,
          22,
          232,
          9,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          230,
          22,
          232,
          9,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          230,
          22,
          232,
          9,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          234,
          30,
          236,
          13,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          234,
          30,
          236,
          13,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          421,
          27,
          423,
          9,
          422,
          25,
          427,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          421,
          27,
          423,
          9,
          422,
          67,
          427,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          424,
          22,
          426,
          9,
          422,
          25,
          427,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          424,
          22,
          426,
          9,
          422,
          67,
          427,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          428,
          30,
          430,
          13,
          428,
          30,
          441,
          75
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "save_pretrained",
          549,
          608,
          594,
          39,
          594,
          88,
          594,
          39,
          608,
          44
        ]
      ],
      "transformers/src/transformers/data/processors/xnli.py": [
        [
          "get_train_examples",
          37,
          56,
          40,
          32,
          40,
          102,
          39,
          14,
          42,
          39
        ],
        [
          "get_test_examples",
          58,
          79,
          60,
          32,
          60,
          79,
          58,
          27,
          62,
          39
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_paper_link",
          54,
          91,
          59,
          25,
          59,
          64,
          59,
          25,
          59,
          64
        ],
        [
          "get_first_commit_date",
          94,
          121,
          103,
          17,
          103,
          72,
          103,
          17,
          106,
          36
        ],
        [
          "get_first_commit_date",
          94,
          121,
          107,
          21,
          107,
          63,
          107,
          21,
          107,
          17
        ],
        [
          "insert_dates",
          180,
          250,
          190,
          21,
          190,
          55,
          190,
          21,
          194,
          25
        ]
      ],
      "transformers/src/transformers/pipelines/__init__.py": [
        [
          "pipeline",
          514,
          1094,
          1012,
          51,
          1014,
          29,
          1013,
          92,
          1014,
          29
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          77,
          25,
          77,
          73,
          60,
          15,
          81,
          33
        ],
        [
          "summarize",
          60,
          146,
          84,
          31,
          84,
          72,
          81,
          9,
          84,
          73
        ],
        [
          "summarize",
          60,
          146,
          86,
          41,
          86,
          82,
          86,
          21,
          95,
          47
        ],
        [
          "summarize",
          60,
          146,
          143,
          19,
          143,
          58,
          133,
          9,
          144,
          44
        ],
        [
          "combine_summaries",
          149,
          195,
          190,
          15,
          190,
          55,
          190,
          10,
          195,
          19
        ]
      ],
      "transformers/benchmark/benchmarks_entrypoint.py": [
        [
          "_export_pandas_data",
          228,
          253,
          233,
          27,
          233,
          81,
          228,
          29,
          253,
          42
        ],
        [
          "_export_pandas_data",
          228,
          253,
          239,
          23,
          239,
          86,
          228,
          29,
          253,
          42
        ],
        [
          "_export_pandas_data",
          228,
          253,
          245,
          22,
          245,
          84,
          228,
          29,
          253,
          42
        ],
        [
          "_export_pandas_data",
          228,
          253,
          251,
          24,
          251,
          85,
          228,
          29,
          253,
          42
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "save_chat",
          395,
          411,
          406,
          24,
          406,
          53,
          404,
          24,
          406,
          20
        ]
      ],
      "transformers/benchmark_v2/benchmark_framework.py": [
        [
          "save_results",
          1171,
          1199,
          1174,
          21,
          1174,
          61,
          1171,
          22,
          1185,
          58
        ],
        [
          "save_results",
          1171,
          1199,
          1180,
          20,
          1180,
          52,
          1171,
          22,
          1185,
          58
        ]
      ],
      "transformers/utils/check_config_attributes.py": [
        [
          "listcomp",
          478,
          478,
          478,
          23,
          478,
          49,
          478,
          23,
          478,
          49
        ]
      ],
      "transformers/utils/check_doctest_list.py": [
        [
          "clean_doctest_list",
          44,
          76,
          59,
          20,
          59,
          48,
          57,
          13,
          60,
          40
        ]
      ],
      "transformers/utils/check_dummies.py": [
        [
          "read_init",
          95,
          137,
          102,
          15,
          102,
          63,
          96,
          5,
          106,
          14
        ],
        [
          "check_dummies",
          186,
          248,
          200,
          12,
          200,
          54,
          186,
          19,
          206,
          54
        ],
        [
          "dictcomp",
          201,
          202,
          202,
          18,
          202,
          92,
          202,
          98,
          202,
          92
        ]
      ],
      "transformers/utils/check_inits.py": [
        [
          "check_submodules",
          320,
          349,
          333,
          15,
          333,
          63,
          321,
          5,
          343,
          37
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "find_code_in_transformers",
          386,
          460,
          424,
          49,
          424,
          87,
          424,
          34,
          424,
          88
        ],
        [
          "find_code_in_transformers",
          386,
          460,
          427,
          22,
          427,
          51,
          427,
          22,
          427,
          18
        ],
        [
          "find_code_in_transformers",
          386,
          460,
          433,
          15,
          433,
          53,
          433,
          10,
          439,
          30
        ],
        [
          "check_copies",
          829,
          859,
          843,
          31,
          843,
          72,
          843,
          21,
          845,
          17
        ],
        [
          "check_copies",
          829,
          859,
          844,
          36,
          844,
          75,
          843,
          21,
          845,
          17
        ],
        [
          "get_model_list",
          862,
          898,
          874,
          15,
          874,
          47,
          862,
          20,
          877,
          15
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "check_model_list",
          442,
          470,
          449,
          18,
          449,
          61,
          443,
          5,
          451,
          39
        ],
        [
          "check_model_list",
          442,
          470,
          454,
          21,
          454,
          51,
          454,
          21,
          455,
          35
        ],
        [
          "get_model_test_files",
          565,
          597,
          581,
          23,
          581,
          59,
          566,
          5,
          583,
          40
        ],
        [
          "get_model_test_files",
          565,
          597,
          584,
          13,
          584,
          44,
          583,
          9,
          585,
          27
        ],
        [
          "get_model_test_files",
          565,
          597,
          590,
          20,
          590,
          56,
          589,
          13,
          591,
          35
        ],
        [
          "get_model_test_files",
          565,
          597,
          594,
          28,
          594,
          64,
          594,
          28,
          595,
          43
        ],
        [
          "find_tested_models",
          602,
          650,
          613,
          15,
          613,
          52,
          602,
          24,
          621,
          26
        ],
        [
          "check_models_are_tested",
          662,
          694,
          689,
          20,
          689,
          57,
          687,
          13,
          693,
          13
        ],
        [
          "check_all_decorator_order",
          898,
          911,
          903,
          24,
          903,
          57,
          903,
          24,
          905,
          18
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1052,
          22,
          1052,
          61,
          1052,
          8,
          1052,
          62
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1053,
          9,
          1053,
          56,
          1052,
          67,
          1054,
          5
        ],
        [
          "check_deprecated_constant_is_up_to_date",
          1170,
          1196,
          1174,
          25,
          1174,
          82,
          1171,
          5,
          1180,
          31
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "find_matching_model_files",
          903,
          940,
          917,
          39,
          917,
          91,
          917,
          17,
          917,
          92
        ],
        [
          "find_matching_model_files",
          903,
          940,
          921,
          39,
          921,
          91,
          921,
          17,
          921,
          92
        ],
        [
          "find_matching_model_files",
          903,
          940,
          926,
          29,
          926,
          87,
          926,
          29,
          931,
          36
        ],
        [
          "find_matching_model_files",
          903,
          940,
          928,
          37,
          928,
          110,
          926,
          29,
          931,
          36
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "merge_transformers_sharded_states",
          268,
          282,
          278,
          27,
          278,
          99,
          277,
          9,
          281,
          40
        ],
        [
          "get_megatron_sharded_states",
          285,
          306,
          300,
          31,
          300,
          89,
          299,
          13,
          301,
          46
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          340,
          48,
          340,
          84,
          340,
          37,
          342,
          17
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          341,
          37,
          341,
          96,
          340,
          37,
          342,
          17
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          591,
          27,
          591,
          66,
          590,
          9,
          591,
          67
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          594,
          41,
          594,
          82,
          594,
          9,
          594,
          85
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          596,
          27,
          596,
          74,
          596,
          27,
          605,
          9
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          620,
          37,
          620,
          91,
          608,
          54,
          621,
          37
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          642,
          33,
          642,
          77,
          640,
          27,
          642,
          18
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          650,
          24,
          650,
          88,
          647,
          14,
          674,
          43
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          655,
          19,
          655,
          57,
          647,
          14,
          674,
          43
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          721,
          38,
          721,
          78,
          721,
          38,
          726,
          21
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          725,
          25,
          725,
          64,
          721,
          38,
          726,
          21
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          900,
          30,
          900,
          70,
          900,
          30,
          903,
          46
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          902,
          31,
          902,
          75,
          900,
          30,
          903,
          46
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "save_pretrained",
          695,
          766,
          754,
          30,
          754,
          75,
          749,
          30,
          766,
          13
        ],
        [
          "save_pretrained",
          695,
          766,
          754,
          30,
          754,
          75,
          754,
          30,
          759,
          22
        ],
        [
          "from_pretrained",
          769,
          945,
          884,
          23,
          884,
          75,
          884,
          23,
          888,
          63
        ],
        [
          "from_pretrained",
          769,
          945,
          888,
          27,
          888,
          62,
          884,
          23,
          888,
          63
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "save_pretrained",
          432,
          494,
          482,
          30,
          482,
          70,
          482,
          30,
          494,
          13
        ],
        [
          "save_pretrained",
          432,
          494,
          482,
          30,
          482,
          70,
          482,
          30,
          487,
          22
        ],
        [
          "_get_config_dict",
          669,
          760,
          699,
          27,
          699,
          80,
          696,
          41,
          699,
          81
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "shard_on_the_fly",
          70,
          149,
          104,
          25,
          106,
          13,
          104,
          25,
          111,
          30
        ],
        [
          "shard_on_the_fly",
          70,
          149,
          118,
          17,
          120,
          5,
          118,
          17,
          125,
          36
        ],
        [
          "shard_on_the_fly",
          70,
          149,
          135,
          25,
          135,
          107,
          131,
          9,
          138,
          24
        ],
        [
          "shard_on_the_fly",
          70,
          149,
          136,
          34,
          136,
          68,
          131,
          9,
          138,
          24
        ],
        [
          "shard_on_the_fly",
          70,
          149,
          145,
          15,
          145,
          57,
          142,
          17,
          149,
          26
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          168,
          23,
          168,
          75,
          163,
          5,
          169,
          42
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          176,
          17,
          176,
          64,
          171,
          13,
          177,
          36
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          182,
          22,
          182,
          92,
          179,
          16,
          189,
          40
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          188,
          21,
          188,
          68,
          179,
          16,
          189,
          40
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          192,
          19,
          192,
          90,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          196,
          32,
          196,
          84,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          228,
          36,
          228,
          96,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          268,
          33,
          268,
          84,
          261,
          14,
          272,
          32
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          107,
          35,
          107,
          77,
          104,
          17,
          111,
          31
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          133,
          17,
          136,
          17,
          131,
          13,
          139,
          30
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          152,
          19,
          152,
          86,
          147,
          18,
          154,
          32
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          167,
          35,
          167,
          77,
          164,
          17,
          171,
          31
        ]
      ],
      "transformers/src/transformers/models/deprecated/bort/convert_bort_original_gluonnlp_checkpoint_to_pytorch.py": [
        [
          "convert_bort_checkpoint_to_pytorch",
          54,
          305,
          103,
          23,
          103,
          60,
          54,
          40,
          207,
          52
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "create_tokenizer_config",
          280,
          296,
          294,
          22,
          294,
          70,
          280,
          29,
          296,
          48
        ],
        [
          "create_tokenizer_json",
          299,
          337,
          337,
          44,
          337,
          85,
          312,
          15,
          337,
          88
        ],
        [
          "convert_hf_blt_to_unified",
          362,
          410,
          387,
          19,
          387,
          55,
          363,
          5,
          391,
          36
        ],
        [
          "convert_hf_blt_to_unified",
          362,
          410,
          394,
          20,
          394,
          57,
          394,
          20,
          403,
          23
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          131,
          29,
          131,
          73,
          130,
          13,
          132,
          44
        ],
        [
          "write_model",
          84,
          436,
          86,
          24,
          86,
          82,
          84,
          17,
          91,
          46
        ],
        [
          "write_model",
          84,
          436,
          87,
          19,
          87,
          63,
          84,
          17,
          91,
          46
        ],
        [
          "write_model",
          84,
          436,
          88,
          31,
          88,
          87,
          84,
          17,
          91,
          46
        ],
        [
          "listcomp",
          138,
          141,
          140,
          17,
          140,
          75,
          142,
          17,
          141,
          13
        ],
        [
          "write_model",
          84,
          436,
          318,
          18,
          318,
          70,
          318,
          18,
          320,
          40
        ],
        [
          "write_model",
          84,
          436,
          329,
          15,
          329,
          76,
          326,
          26,
          337,
          53
        ],
        [
          "write_model",
          84,
          436,
          341,
          15,
          341,
          85,
          341,
          10,
          355,
          42
        ],
        [
          "write_model",
          84,
          436,
          352,
          15,
          352,
          67,
          341,
          10,
          355,
          42
        ],
        [
          "write_model",
          84,
          436,
          384,
          24,
          384,
          94,
          357,
          13,
          436,
          58
        ]
      ],
      "transformers/src/transformers/models/clvp/convert_clvp_to_hf.py": [
        [
          "convert_clvp_weights",
          194,
          217,
          198,
          27,
          198,
          86,
          197,
          9,
          199,
          46
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          194,
          270,
          213,
          26,
          213,
          78,
          207,
          22,
          214,
          46
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "load_model_state_dict",
          203,
          233,
          207,
          18,
          207,
          73,
          203,
          27,
          211,
          33
        ],
        [
          "load_model_state_dict",
          203,
          233,
          208,
          24,
          208,
          68,
          203,
          27,
          211,
          33
        ],
        [
          "load_model_state_dict",
          203,
          233,
          221,
          26,
          221,
          61,
          219,
          13,
          223,
          41
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "load_model_state_dict",
          176,
          206,
          180,
          18,
          180,
          73,
          176,
          27,
          184,
          33
        ],
        [
          "load_model_state_dict",
          176,
          206,
          181,
          24,
          181,
          68,
          176,
          27,
          184,
          33
        ],
        [
          "load_model_state_dict",
          176,
          206,
          194,
          26,
          194,
          61,
          192,
          13,
          196,
          41
        ]
      ],
      "transformers/src/transformers/models/dialogpt/convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_dialogpt_checkpoint",
          29,
          33,
          33,
          19,
          33,
          70,
          29,
          33,
          33,
          71
        ]
      ],
      "transformers/src/transformers/models/dia/convert_dia_to_hf.py": [
        [
          "convert_dia_model_to_hf",
          78,
          155,
          104,
          23,
          104,
          61,
          104,
          23,
          110,
          46
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          200,
          16,
          200,
          54,
          156,
          5,
          206,
          23
        ]
      ],
      "transformers/src/transformers/models/doge/convert_doge_weights_to_hf.py": [
        [
          "listcomp",
          50,
          50,
          50,
          25,
          50,
          50,
          50,
          25,
          50,
          50
        ],
        [
          "convert_doge_model",
          94,
          109,
          96,
          15,
          96,
          52,
          94,
          24,
          106,
          33
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          294,
          16,
          294,
          54,
          253,
          5,
          300,
          23
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "convert_model",
          191,
          286,
          216,
          15,
          216,
          53,
          207,
          8,
          228,
          39
        ],
        [
          "convert_model",
          191,
          286,
          216,
          15,
          216,
          53,
          211,
          5,
          228,
          39
        ],
        [
          "load_model_state_dict",
          158,
          188,
          162,
          18,
          162,
          73,
          158,
          27,
          166,
          33
        ],
        [
          "load_model_state_dict",
          158,
          188,
          163,
          24,
          163,
          68,
          158,
          27,
          166,
          33
        ],
        [
          "load_model_state_dict",
          158,
          188,
          176,
          26,
          176,
          61,
          174,
          13,
          178,
          41
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_tiktoken",
          105,
          210,
          187,
          15,
          187,
          52,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          190,
          15,
          190,
          56,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          193,
          15,
          193,
          63,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          196,
          15,
          196,
          65,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          208,
          15,
          208,
          52,
          105,
          22,
          210,
          35
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          218,
          366,
          240,
          18,
          240,
          98,
          238,
          13,
          252,
          73
        ],
        [
          "load_model",
          218,
          366,
          242,
          16,
          242,
          43,
          238,
          13,
          252,
          73
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t_v2/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          219,
          374,
          238,
          18,
          238,
          98,
          219,
          16,
          250,
          73
        ],
        [
          "load_model",
          219,
          374,
          240,
          16,
          240,
          43,
          219,
          16,
          250,
          73
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          124,
          21,
          124,
          74,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          123,
          21,
          123,
          74,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          129,
          22,
          129,
          77,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          145,
          22,
          145,
          77,
          142,
          16,
          152,
          34
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          151,
          19,
          151,
          90,
          142,
          16,
          152,
          34
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          153,
          28,
          153,
          61,
          152,
          9,
          154,
          43
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          164,
          30,
          164,
          82,
          156,
          10,
          168,
          35
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          214,
          34,
          214,
          94,
          209,
          5,
          243,
          24
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          253,
          33,
          253,
          84,
          246,
          14,
          260,
          45
        ]
      ],
      "transformers/src/transformers/models/gemma2/convert_gemma2_weights_to_hf.py": [
        [
          "write_model",
          84,
          158,
          100,
          44,
          100,
          78,
          98,
          13,
          101,
          54
        ],
        [
          "main",
          172,
          235,
          223,
          20,
          223,
          58,
          223,
          20,
          224,
          68
        ]
      ],
      "transformers/src/transformers/models/fuyu/convert_fuyu_model_weights_to_hf.py": [
        [
          "main",
          93,
          122,
          113,
          16,
          113,
          64,
          94,
          14,
          122,
          46
        ]
      ],
      "transformers/src/transformers/models/gemma/convert_gemma_weights_to_hf.py": [
        [
          "main",
          139,
          202,
          190,
          20,
          190,
          58,
          190,
          20,
          191,
          68
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "listcomp",
          41,
          41,
          41,
          25,
          41,
          50,
          41,
          25,
          41,
          50
        ],
        [
          "listcomp",
          42,
          42,
          42,
          18,
          42,
          43,
          42,
          18,
          42,
          43
        ],
        [
          "convert_glm_model",
          156,
          173,
          158,
          15,
          158,
          52,
          156,
          23,
          173,
          41
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "listcomp",
          46,
          46,
          46,
          25,
          46,
          50,
          46,
          25,
          46,
          50
        ],
        [
          "listcomp",
          47,
          47,
          47,
          18,
          47,
          43,
          47,
          18,
          47,
          43
        ],
        [
          "convert_glm4_model",
          161,
          178,
          163,
          15,
          163,
          52,
          161,
          24,
          178,
          41
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/convert_gptsan_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_gptsan_to_pt",
          28,
          171,
          29,
          22,
          29,
          71,
          28,
          29,
          31,
          17
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "main",
          700,
          805,
          786,
          15,
          786,
          67,
          743,
          28,
          797,
          82
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_model",
          146,
          284,
          181,
          37,
          181,
          71,
          181,
          13,
          181,
          73
        ],
        [
          "save_sharded_model",
          287,
          314,
          313,
          37,
          313,
          117,
          312,
          9,
          313,
          118
        ],
        [
          "create_safetensors_index",
          317,
          322,
          321,
          15,
          321,
          70,
          321,
          10,
          322,
          39
        ],
        [
          "write_tokenizer",
          426,
          772,
          770,
          30,
          770,
          73,
          769,
          9,
          772,
          68
        ]
      ],
      "transformers/src/transformers/models/hubert/convert_hubert_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_hubert_checkpoint",
          183,
          246,
          204,
          26,
          204,
          77,
          196,
          27,
          205,
          58
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "save_sharded_model",
          174,
          247,
          233,
          22,
          233,
          62,
          231,
          9,
          235,
          31
        ],
        [
          "save_sharded_model",
          174,
          247,
          243,
          18,
          243,
          74,
          243,
          18,
          247,
          22
        ],
        [
          "merge_tp_weights",
          250,
          625,
          621,
          19,
          621,
          58,
          621,
          19,
          625,
          63
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "load_model_state_dict",
          209,
          239,
          213,
          18,
          213,
          73,
          209,
          27,
          217,
          33
        ],
        [
          "load_model_state_dict",
          209,
          239,
          214,
          24,
          214,
          68,
          209,
          27,
          217,
          33
        ],
        [
          "load_model_state_dict",
          209,
          239,
          227,
          26,
          227,
          61,
          225,
          13,
          229,
          41
        ],
        [
          "listcomp",
          271,
          271,
          271,
          70,
          271,
          96,
          271,
          28,
          271,
          97
        ],
        [
          "convert_model",
          242,
          447,
          278,
          15,
          278,
          53,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          280,
          15,
          280,
          66,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          282,
          15,
          282,
          65,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          284,
          15,
          284,
          63,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          288,
          27,
          288,
          68,
          278,
          10,
          295,
          42
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "max_context_length",
          199,
          210,
          204,
          15,
          204,
          53,
          204,
          10,
          207,
          37
        ],
        [
          "write_model",
          213,
          554,
          223,
          15,
          223,
          58,
          214,
          5,
          244,
          32
        ],
        [
          "write_model",
          213,
          554,
          341,
          31,
          341,
          82,
          341,
          16,
          341,
          83
        ],
        [
          "write_model",
          213,
          554,
          342,
          24,
          342,
          75,
          342,
          24,
          342,
          20
        ],
        [
          "write_model",
          213,
          554,
          344,
          24,
          344,
          72,
          344,
          24,
          344,
          20
        ],
        [
          "listcomp",
          347,
          348,
          348,
          27,
          348,
          84,
          349,
          21,
          348,
          85
        ],
        [
          "write_tokenizer",
          668,
          692,
          669,
          22,
          669,
          68,
          668,
          21,
          677,
          52
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "write_model",
          184,
          433,
          196,
          24,
          196,
          67,
          185,
          5,
          197,
          61
        ],
        [
          "write_model",
          184,
          433,
          231,
          17,
          231,
          68,
          230,
          22,
          230,
          18
        ],
        [
          "listcomp",
          237,
          238,
          238,
          28,
          238,
          62,
          239,
          21,
          238,
          102
        ],
        [
          "write_model",
          184,
          433,
          335,
          36,
          335,
          73,
          335,
          13,
          335,
          74
        ],
        [
          "write_model",
          184,
          433,
          358,
          32,
          358,
          69,
          358,
          9,
          366,
          36
        ],
        [
          "write_model",
          184,
          433,
          362,
          32,
          362,
          91,
          358,
          9,
          366,
          36
        ],
        [
          "main",
          521,
          601,
          578,
          16,
          578,
          62,
          578,
          16,
          590,
          42
        ]
      ],
      "transformers/src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          28,
          131,
          50,
          15,
          50,
          106,
          28,
          29,
          62,
          54
        ]
      ],
      "transformers/src/transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py": [
        [
          "load_state_dict_from_safetensors",
          30,
          37,
          33,
          20,
          33,
          63,
          30,
          38,
          34,
          25
        ],
        [
          "load_state_dict_from_torch",
          40,
          41,
          41,
          23,
          41,
          66,
          40,
          32,
          41,
          106
        ],
        [
          "convert_mamba2_checkpoint_file_to_huggingface_model_file",
          116,
          142,
          126,
          19,
          126,
          85,
          117,
          5,
          138,
          48
        ],
        [
          "convert_mamba2_checkpoint_file_to_huggingface_model_file",
          116,
          142,
          139,
          36,
          139,
          77,
          138,
          13,
          142,
          114
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "save_single_safetensor",
          131,
          140,
          138,
          9,
          138,
          55,
          132,
          5,
          140,
          5
        ],
        [
          "save_sharded_safetensors",
          143,
          167,
          160,
          15,
          160,
          67,
          144,
          5,
          165,
          50
        ],
        [
          "save_sharded_safetensors",
          143,
          167,
          167,
          26,
          167,
          65,
          165,
          9,
          167,
          85
        ],
        [
          "convert_mamba_ssm_checkpoint_file_to_huggingface_model_file",
          171,
          234,
          203,
          19,
          203,
          69,
          196,
          9,
          225,
          48
        ],
        [
          "convert_mamba_ssm_checkpoint_file_to_huggingface_model_file",
          171,
          234,
          217,
          9,
          217,
          65,
          196,
          9,
          225,
          48
        ]
      ],
      "transformers/src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          125,
          15,
          125,
          72,
          124,
          39,
          191,
          42
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          136,
          17,
          136,
          78,
          124,
          39,
          191,
          42
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          144,
          17,
          144,
          79,
          124,
          39,
          191,
          42
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          242,
          17,
          242,
          79,
          235,
          5,
          263,
          14
        ]
      ],
      "transformers/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py": [
        [
          "main",
          275,
          326,
          324,
          30,
          324,
          72,
          320,
          5,
          326,
          57
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py": [
        [
          "main",
          312,
          422,
          420,
          30,
          420,
          72,
          407,
          17,
          422,
          57
        ]
      ],
      "transformers/src/transformers/models/mistral3/convert_mistral3_weights_to_hf.py": [
        [
          "convert_and_write_model",
          171,
          188,
          173,
          24,
          173,
          61,
          171,
          29,
          179,
          28
        ],
        [
          "convert_and_write_model",
          171,
          188,
          180,
          41,
          180,
          75,
          179,
          9,
          182,
          40
        ],
        [
          "convert_and_write_processor",
          191,
          214,
          193,
          22,
          193,
          59,
          191,
          33,
          214,
          41
        ],
        [
          "convert_and_write_processor",
          191,
          214,
          198,
          24,
          198,
          61,
          191,
          33,
          214,
          41
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/convert_megatron_to_pytorch.py": [
        [
          "main",
          147,
          183,
          181,
          30,
          181,
          73,
          174,
          33,
          183,
          45
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "convert_and_write_model",
          194,
          220,
          196,
          24,
          196,
          61,
          194,
          29,
          201,
          28
        ],
        [
          "convert_and_write_model",
          194,
          220,
          204,
          45,
          204,
          79,
          203,
          13,
          206,
          44
        ],
        [
          "listcomp",
          211,
          212,
          212,
          24,
          212,
          52,
          212,
          98,
          212,
          92
        ],
        [
          "convert_and_write_tokenizer",
          223,
          240,
          227,
          26,
          227,
          63,
          227,
          26,
          228,
          17
        ],
        [
          "convert_and_write_tokenizer",
          223,
          240,
          232,
          40,
          232,
          78,
          231,
          44,
          232,
          17
        ]
      ],
      "transformers/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py": [
        [
          "write_model",
          61,
          217,
          64,
          24,
          64,
          67,
          61,
          17,
          68,
          80
        ],
        [
          "listcomp",
          96,
          97,
          97,
          20,
          97,
          76,
          98,
          13,
          97,
          116
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          29,
          183,
          54,
          15,
          54,
          77,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          57,
          15,
          57,
          77,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          60,
          15,
          60,
          107,
          29,
          29,
          74,
          61
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          245,
          23,
          245,
          57,
          236,
          29,
          246,
          42
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          292,
          19,
          292,
          54,
          292,
          19,
          296,
          48
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_model",
          209,
          471,
          218,
          15,
          218,
          58,
          210,
          5,
          252,
          49
        ],
        [
          "write_model",
          209,
          471,
          341,
          27,
          341,
          78,
          341,
          12,
          341,
          79
        ],
        [
          "write_model",
          209,
          471,
          342,
          20,
          342,
          71,
          342,
          20,
          342,
          16
        ],
        [
          "write_model",
          209,
          471,
          344,
          20,
          344,
          68,
          344,
          20,
          344,
          16
        ],
        [
          "listcomp",
          347,
          353,
          349,
          17,
          349,
          74,
          354,
          17,
          353,
          13
        ],
        [
          "write_tokenizer",
          497,
          565,
          563,
          30,
          563,
          73,
          562,
          9,
          565,
          68
        ],
        [
          "main",
          590,
          640,
          632,
          24,
          632,
          70,
          591,
          14,
          640,
          5
        ],
        [
          "main",
          590,
          640,
          638,
          21,
          638,
          63,
          591,
          14,
          640,
          5
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          83,
          25,
          85,
          13,
          80,
          28,
          88,
          22
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          93,
          17,
          95,
          5,
          93,
          17,
          103,
          36
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          104,
          21,
          104,
          57,
          104,
          21,
          106,
          59
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          113,
          25,
          113,
          107,
          111,
          9,
          115,
          24
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          114,
          34,
          114,
          68,
          111,
          9,
          115,
          24
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          122,
          15,
          122,
          57,
          119,
          17,
          126,
          26
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "extract_nemo_archive",
          57,
          147,
          77,
          25,
          77,
          48,
          76,
          13,
          78,
          39
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          86,
          25,
          86,
          48,
          85,
          13,
          91,
          36
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "write_model",
          68,
          216,
          166,
          28,
          166,
          65,
          166,
          5,
          172,
          60
        ],
        [
          "write_model",
          68,
          216,
          78,
          22,
          78,
          52,
          69,
          5,
          84,
          58
        ],
        [
          "write_model",
          68,
          216,
          110,
          25,
          110,
          65,
          106,
          5,
          114,
          34
        ],
        [
          "write_model",
          68,
          216,
          149,
          32,
          149,
          69,
          149,
          9,
          149,
          70
        ],
        [
          "write_model",
          68,
          216,
          170,
          28,
          170,
          87,
          166,
          5,
          172,
          60
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "write_model",
          65,
          183,
          67,
          22,
          67,
          52,
          65,
          17,
          83,
          54
        ],
        [
          "write_model",
          65,
          183,
          94,
          25,
          94,
          65,
          90,
          5,
          98,
          34
        ],
        [
          "write_model",
          65,
          183,
          125,
          32,
          125,
          69,
          125,
          9,
          125,
          70
        ],
        [
          "write_model",
          65,
          183,
          141,
          28,
          141,
          65,
          141,
          5,
          147,
          59
        ],
        [
          "write_model",
          65,
          183,
          145,
          28,
          145,
          87,
          141,
          5,
          147,
          59
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "write_model",
          91,
          215,
          93,
          22,
          93,
          52,
          91,
          17,
          99,
          23
        ],
        [
          "write_model",
          91,
          215,
          122,
          25,
          122,
          65,
          119,
          5,
          126,
          34
        ],
        [
          "write_model",
          91,
          215,
          164,
          32,
          164,
          69,
          164,
          9,
          164,
          70
        ],
        [
          "write_model",
          91,
          215,
          178,
          28,
          178,
          65,
          178,
          5,
          206,
          33
        ],
        [
          "write_model",
          91,
          215,
          182,
          28,
          182,
          87,
          178,
          5,
          206,
          33
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "read_metadata",
          198,
          216,
          205,
          33,
          205,
          74,
          203,
          13,
          206,
          74
        ],
        [
          "read_metadata",
          198,
          216,
          206,
          25,
          206,
          64,
          203,
          13,
          206,
          74
        ],
        [
          "write_model",
          272,
          398,
          281,
          22,
          281,
          52,
          273,
          5,
          299,
          59
        ],
        [
          "write_model",
          272,
          398,
          308,
          25,
          308,
          72,
          304,
          5,
          314,
          34
        ],
        [
          "write_model",
          272,
          398,
          340,
          32,
          340,
          69,
          340,
          9,
          340,
          70
        ],
        [
          "write_model",
          272,
          398,
          355,
          28,
          355,
          65,
          355,
          5,
          383,
          24
        ],
        [
          "write_model",
          272,
          398,
          359,
          28,
          359,
          87,
          355,
          5,
          383,
          24
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_download",
          147,
          182,
          152,
          23,
          152,
          50,
          147,
          15,
          154,
          38
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "listcomp",
          245,
          250,
          247,
          21,
          247,
          55,
          251,
          21,
          250,
          17
        ],
        [
          "write_model",
          195,
          436,
          237,
          17,
          237,
          65,
          227,
          34,
          255,
          38
        ],
        [
          "write_model",
          195,
          436,
          293,
          36,
          293,
          73,
          293,
          13,
          294,
          38
        ],
        [
          "write_model",
          195,
          436,
          311,
          32,
          311,
          69,
          311,
          9,
          317,
          40
        ],
        [
          "write_model",
          195,
          436,
          348,
          32,
          348,
          69,
          348,
          9,
          361,
          26
        ],
        [
          "write_model",
          195,
          436,
          353,
          32,
          353,
          91,
          348,
          9,
          361,
          26
        ],
        [
          "main",
          553,
          611,
          592,
          24,
          592,
          66,
          592,
          14,
          611,
          5
        ],
        [
          "main",
          553,
          611,
          594,
          16,
          594,
          62,
          592,
          14,
          611,
          5
        ]
      ],
      "transformers/src/transformers/models/persimmon/convert_persimmon_weights_to_hf.py": [
        [
          "main",
          96,
          125,
          116,
          16,
          116,
          64,
          97,
          14,
          125,
          46
        ]
      ],
      "transformers/src/transformers/models/phi/convert_phi_weights_to_hf.py": [
        [
          "convert_phi_weights",
          105,
          164,
          116,
          26,
          116,
          104,
          115,
          13,
          117,
          45
        ],
        [
          "convert_phi_weights",
          105,
          164,
          146,
          33,
          146,
          105,
          146,
          33,
          148,
          65
        ],
        [
          "convert_phi_weights",
          105,
          164,
          153,
          31,
          153,
          80,
          151,
          21,
          158,
          29
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/convert_phi4_multimodal_weights_to_hf.py": [
        [
          "extract_adapters_data",
          216,
          249,
          238,
          40,
          238,
          78,
          231,
          26,
          249,
          96
        ],
        [
          "convert_and_write_model",
          143,
          166,
          145,
          33,
          145,
          70,
          143,
          29,
          150,
          28
        ],
        [
          "convert_and_write_model",
          143,
          166,
          151,
          41,
          151,
          75,
          150,
          9,
          153,
          40
        ],
        [
          "extract_adapters_data",
          216,
          249,
          222,
          41,
          222,
          75,
          221,
          9,
          223,
          47
        ],
        [
          "extract_adapters_data",
          216,
          249,
          246,
          40,
          246,
          78,
          231,
          26,
          249,
          96
        ],
        [
          "extract_adapters_data",
          216,
          249,
          248,
          28,
          248,
          95,
          231,
          26,
          249,
          96
        ],
        [
          "extract_adapters_data",
          216,
          249,
          249,
          28,
          249,
          95,
          231,
          26,
          249,
          96
        ]
      ],
      "transformers/src/transformers/models/recurrent_gemma/convert_recurrent_gemma_to_hf.py": [
        [
          "main",
          155,
          218,
          206,
          20,
          206,
          58,
          206,
          20,
          207,
          68
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          130,
          27,
          130,
          62,
          129,
          9,
          130,
          63
        ],
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          133,
          27,
          133,
          70,
          133,
          27,
          149,
          37
        ],
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          150,
          37,
          150,
          72,
          149,
          13,
          151,
          113
        ],
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          151,
          77,
          151,
          112,
          149,
          13,
          151,
          113
        ]
      ],
      "transformers/src/transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          223,
          290,
          264,
          26,
          264,
          77,
          254,
          27,
          265,
          58
        ]
      ],
      "transformers/src/transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          235,
          302,
          276,
          26,
          276,
          77,
          266,
          27,
          277,
          58
        ]
      ],
      "transformers/src/transformers/models/siglip2/convert_siglip2_to_hf.py": [
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          400,
          19,
          400,
          68,
          400,
          19,
          404,
          42
        ]
      ],
      "transformers/src/transformers/convert_slow_tokenizers_checkpoints_to_fast.py": [
        [
          "convert_slow_checkpoint_to_fast",
          37,
          98,
          71,
          34,
          71,
          78,
          70,
          64,
          71,
          30
        ],
        [
          "convert_slow_checkpoint_to_fast",
          37,
          98,
          85,
          38,
          85,
          89,
          85,
          38,
          86,
          42
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "convert_siglip_checkpoint",
          380,
          506,
          497,
          36,
          497,
          85,
          497,
          36,
          502,
          59
        ]
      ],
      "transformers/src/transformers/models/speech_encoder_decoder/convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          214,
          284,
          268,
          15,
          268,
          66,
          215,
          5,
          284,
          63
        ],
        [
          "convert_wav2vec2_checkpoint",
          214,
          284,
          271,
          39,
          271,
          90,
          215,
          5,
          284,
          63
        ]
      ],
      "transformers/src/transformers/models/bark/convert_suno_to_hf.py": [
        [
          "_get_ckpt_path",
          80,
          84,
          84,
          12,
          84,
          72,
          84,
          12,
          84,
          72
        ],
        [
          "load_whole_bark_model",
          212,
          250,
          220,
          32,
          220,
          69,
          213,
          5,
          250,
          86
        ],
        [
          "load_whole_bark_model",
          212,
          250,
          222,
          57,
          222,
          98,
          213,
          5,
          250,
          86
        ],
        [
          "load_whole_bark_model",
          212,
          250,
          223,
          61,
          223,
          100,
          213,
          5,
          250,
          86
        ],
        [
          "load_whole_bark_model",
          212,
          250,
          224,
          57,
          224,
          94,
          213,
          5,
          250,
          86
        ]
      ],
      "transformers/src/transformers/models/timesfm/convert_timesfm_orignal_to_hf.py": [
        [
          "write_model",
          36,
          147,
          38,
          22,
          38,
          52,
          36,
          17,
          43,
          55
        ],
        [
          "main",
          244,
          273,
          264,
          9,
          264,
          110,
          264,
          39,
          265,
          5
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          203,
          37,
          203,
          88,
          198,
          9,
          209,
          44
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          204,
          36,
          204,
          86,
          198,
          9,
          209,
          44
        ]
      ],
      "transformers/src/transformers/models/unispeech/convert_unispeech_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_unispeech_checkpoint",
          190,
          258,
          211,
          26,
          211,
          77,
          203,
          27,
          212,
          58
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_classifier_to_hf.py": [
        [
          "main",
          142,
          208,
          199,
          18,
          199,
          61,
          199,
          18,
          203,
          23
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_conformer/convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_conformer_checkpoint",
          220,
          294,
          244,
          26,
          244,
          77,
          236,
          27,
          245,
          58
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          274,
          358,
          308,
          26,
          308,
          77,
          300,
          27,
          309,
          58
        ]
      ],
      "transformers/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          220,
          33,
          220,
          84,
          217,
          5,
          226,
          40
        ],
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          221,
          32,
          221,
          82,
          217,
          5,
          226,
          40
        ]
      ],
      "transformers/.circleci/create_circleci_config.py": [
        [
          "__post_init__",
          98,
          129,
          120,
          25,
          120,
          91,
          120,
          25,
          122,
          40
        ],
        [
          "listcomp",
          358,
          358,
          358,
          52,
          358,
          115,
          358,
          19,
          358,
          117
        ],
        [
          "create_circleci_config",
          354,
          393,
          392,
          15,
          392,
          58,
          392,
          10,
          393,
          141
        ]
      ],
      "transformers/utils/custom_init_isort.py": [
        [
          "sort_imports_in_all_inits",
          308,
          322,
          318,
          35,
          318,
          67,
          318,
          22,
          319,
          21
        ],
        [
          "sort_imports_in_all_inits",
          308,
          322,
          320,
          29,
          320,
          61,
          320,
          29,
          320,
          24
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "get_tiny_config",
          354,
          445,
          377,
          21,
          377,
          101,
          377,
          21,
          377,
          101
        ],
        [
          "get_checkpoint_dir",
          739,
          742,
          742,
          12,
          742,
          46,
          739,
          24,
          742,
          46
        ],
        [
          "build_model",
          745,
          768,
          753,
          28,
          753,
          65,
          745,
          17,
          755,
          42
        ],
        [
          "build_composite_models",
          834,
          956,
          900,
          34,
          900,
          64,
          900,
          47,
          900,
          64
        ],
        [
          "build_composite_models",
          834,
          956,
          905,
          34,
          905,
          64,
          905,
          47,
          905,
          64
        ],
        [
          "build_composite_models",
          834,
          956,
          909,
          28,
          909,
          83,
          909,
          28,
          909,
          83
        ],
        [
          "build_composite_models",
          834,
          956,
          910,
          28,
          910,
          83,
          910,
          28,
          910,
          83
        ],
        [
          "build_composite_models",
          834,
          956,
          926,
          26,
          929,
          13,
          926,
          26,
          929,
          13
        ],
        [
          "build_composite_models",
          834,
          956,
          933,
          38,
          933,
          83,
          933,
          51,
          933,
          83
        ],
        [
          "build_composite_models",
          834,
          956,
          934,
          38,
          934,
          83,
          934,
          51,
          934,
          83
        ],
        [
          "build",
          1046,
          1190,
          1116,
          31,
          1116,
          68,
          1106,
          9,
          1118,
          39
        ],
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1295,
          15,
          1295,
          66,
          1294,
          36,
          1299,
          38
        ],
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1317,
          15,
          1317,
          74,
          1317,
          10,
          1318,
          65
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1336,
          19,
          1336,
          54,
          1336,
          19,
          1348,
          14
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1365,
          60,
          1365,
          98,
          1363,
          13,
          1367,
          27
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1371,
          57,
          1371,
          95,
          1370,
          13,
          1371,
          97
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1385,
          36,
          1385,
          72,
          1385,
          25,
          1385,
          73
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1388,
          34,
          1388,
          76,
          1388,
          17,
          1388,
          77
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1401,
          19,
          1401,
          66,
          1401,
          14,
          1402,
          51
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1409,
          15,
          1409,
          66,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1412,
          15,
          1412,
          74,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1418,
          15,
          1418,
          61,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1424,
          15,
          1424,
          60,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1428,
          15,
          1428,
          67,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1431,
          48,
          1431,
          83,
          1408,
          26,
          1431,
          84
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "format_mrpc",
          57,
          106,
          59,
          16,
          59,
          45,
          57,
          17,
          60,
          34
        ],
        [
          "format_mrpc",
          57,
          106,
          63,
          27,
          63,
          80,
          63,
          27,
          64,
          22
        ],
        [
          "format_mrpc",
          57,
          106,
          64,
          26,
          64,
          78,
          63,
          27,
          64,
          22
        ],
        [
          "format_mrpc",
          57,
          106,
          67,
          27,
          67,
          76,
          66,
          9,
          70,
          61
        ],
        [
          "format_mrpc",
          57,
          106,
          68,
          26,
          68,
          74,
          66,
          9,
          70,
          61
        ],
        [
          "format_mrpc",
          57,
          106,
          75,
          51,
          75,
          87,
          75,
          5,
          79,
          25
        ],
        [
          "format_mrpc",
          57,
          106,
          78,
          15,
          78,
          51,
          75,
          5,
          79,
          25
        ],
        [
          "format_mrpc",
          57,
          106,
          84,
          14,
          84,
          48,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          85,
          14,
          85,
          46,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          99,
          14,
          99,
          47,
          98,
          9,
          103,
          42
        ],
        [
          "download_diagnostic",
          109,
          116,
          111,
          26,
          111,
          61,
          109,
          25,
          111,
          62
        ],
        [
          "download_diagnostic",
          109,
          116,
          112,
          18,
          112,
          53,
          112,
          9,
          112,
          54
        ],
        [
          "download_diagnostic",
          109,
          116,
          113,
          17,
          113,
          70,
          113,
          17,
          116,
          10
        ]
      ],
      "transformers/utils/extract_warnings.py": [
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          42,
          25,
          42,
          61,
          41,
          13,
          43,
          43
        ],
        [
          "listcomp",
          72,
          72,
          72,
          14,
          72,
          42,
          72,
          14,
          72,
          42
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_cached_module_file",
          316,
          485,
          439,
          34,
          439,
          91,
          437,
          13,
          440,
          60
        ],
        [
          "get_cached_module_file",
          316,
          485,
          453,
          43,
          453,
          83,
          447,
          23,
          456,
          54
        ],
        [
          "get_cached_module_file",
          316,
          485,
          485,
          12,
          485,
          52,
          485,
          12,
          485,
          52
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "save_pretrained",
          355,
          414,
          400,
          41,
          400,
          92,
          400,
          41,
          414,
          46
        ],
        [
          "get_feature_extractor_dict",
          417,
          529,
          465,
          38,
          465,
          104,
          465,
          38,
          465,
          34
        ]
      ],
      "transformers/examples/legacy/seq2seq/finetune_trainer.py": [
        [
          "handle_metrics",
          141,
          154,
          154,
          24,
          154,
          72,
          154,
          5,
          154,
          73
        ],
        [
          "main",
          157,
          366,
          326,
          40,
          326,
          99,
          322,
          13,
          330,
          63
        ],
        [
          "main",
          157,
          366,
          361,
          44,
          361,
          105,
          357,
          30,
          361,
          106
        ],
        [
          "main",
          157,
          366,
          364,
          32,
          364,
          89,
          364,
          9,
          364,
          90
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "listcomp",
          164,
          164,
          164,
          14,
          164,
          42,
          164,
          14,
          164,
          42
        ],
        [
          "download_artifact",
          93,
          109,
          107,
          17,
          107,
          64,
          104,
          14,
          109,
          34
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_last_daily_ci_reports",
          123,
          159,
          143,
          29,
          143,
          76,
          142,
          9,
          144,
          44
        ],
        [
          "get_last_daily_ci_reports",
          123,
          159,
          145,
          26,
          145,
          64,
          145,
          26,
          151,
          36
        ],
        [
          "get_last_daily_ci_reports",
          123,
          159,
          152,
          29,
          152,
          62,
          151,
          17,
          153,
          47
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          713,
          34,
          713,
          83,
          713,
          19,
          713,
          84
        ],
        [
          "is_timm_local_checkpoint",
          693,
          718,
          714,
          19,
          714,
          68,
          714,
          14,
          716,
          47
        ]
      ],
      "transformers/src/transformers/data/datasets/glue.py": [
        [
          "__init__",
          76,
          149,
          99,
          32,
          102,
          9,
          100,
          13,
          104,
          48
        ]
      ],
      "transformers/src/transformers/data/processors/glue.py": [
        [
          "get_train_examples",
          142,
          145,
          144,
          35,
          144,
          69,
          142,
          28,
          145,
          98
        ],
        [
          "get_train_examples",
          142,
          145,
          145,
          53,
          145,
          87,
          142,
          28,
          145,
          98
        ],
        [
          "get_dev_examples",
          147,
          149,
          149,
          53,
          149,
          85,
          147,
          26,
          149,
          94
        ],
        [
          "get_test_examples",
          151,
          153,
          153,
          53,
          153,
          86,
          151,
          27,
          153,
          96
        ],
        [
          "get_train_examples",
          189,
          191,
          191,
          53,
          191,
          87,
          189,
          28,
          191,
          98
        ],
        [
          "get_dev_examples",
          193,
          195,
          195,
          53,
          195,
          93,
          193,
          26,
          195,
          110
        ],
        [
          "get_test_examples",
          197,
          199,
          199,
          53,
          199,
          94,
          197,
          27,
          199,
          112
        ],
        [
          "get_dev_examples",
          226,
          228,
          228,
          53,
          228,
          96,
          226,
          26,
          228,
          116
        ],
        [
          "get_test_examples",
          230,
          232,
          232,
          53,
          232,
          97,
          230,
          27,
          232,
          118
        ],
        [
          "get_train_examples",
          251,
          253,
          253,
          53,
          253,
          87,
          251,
          28,
          253,
          98
        ],
        [
          "get_dev_examples",
          255,
          257,
          257,
          53,
          257,
          85,
          255,
          26,
          257,
          94
        ],
        [
          "get_test_examples",
          259,
          261,
          261,
          53,
          261,
          86,
          259,
          27,
          261,
          96
        ],
        [
          "get_train_examples",
          298,
          300,
          300,
          53,
          300,
          87,
          298,
          28,
          300,
          98
        ],
        [
          "get_dev_examples",
          302,
          304,
          304,
          53,
          304,
          85,
          302,
          26,
          304,
          94
        ],
        [
          "get_test_examples",
          306,
          308,
          308,
          53,
          308,
          86,
          306,
          27,
          308,
          96
        ],
        [
          "get_train_examples",
          344,
          346,
          346,
          53,
          346,
          87,
          344,
          28,
          346,
          98
        ],
        [
          "get_dev_examples",
          348,
          350,
          350,
          53,
          350,
          85,
          348,
          26,
          350,
          94
        ],
        [
          "get_test_examples",
          352,
          354,
          354,
          53,
          354,
          86,
          352,
          27,
          354,
          96
        ],
        [
          "get_train_examples",
          390,
          392,
          392,
          53,
          392,
          87,
          390,
          28,
          392,
          98
        ],
        [
          "get_dev_examples",
          394,
          396,
          396,
          53,
          396,
          85,
          394,
          26,
          396,
          94
        ],
        [
          "get_test_examples",
          398,
          400,
          400,
          53,
          400,
          86,
          398,
          27,
          400,
          96
        ],
        [
          "get_train_examples",
          442,
          444,
          444,
          53,
          444,
          87,
          442,
          28,
          444,
          98
        ],
        [
          "get_dev_examples",
          446,
          448,
          448,
          53,
          448,
          85,
          446,
          26,
          448,
          94
        ],
        [
          "get_test_examples",
          450,
          452,
          452,
          53,
          452,
          86,
          450,
          27,
          452,
          96
        ],
        [
          "get_train_examples",
          488,
          490,
          490,
          53,
          490,
          87,
          488,
          28,
          490,
          98
        ],
        [
          "get_dev_examples",
          492,
          494,
          494,
          53,
          494,
          85,
          492,
          26,
          494,
          94
        ],
        [
          "get_test_examples",
          496,
          498,
          498,
          53,
          498,
          86,
          496,
          27,
          498,
          96
        ],
        [
          "get_train_examples",
          534,
          536,
          536,
          53,
          536,
          87,
          534,
          28,
          536,
          98
        ],
        [
          "get_dev_examples",
          538,
          540,
          540,
          53,
          540,
          85,
          538,
          26,
          540,
          94
        ],
        [
          "get_test_examples",
          542,
          544,
          544,
          53,
          544,
          86,
          542,
          27,
          544,
          96
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "listcomp",
          415,
          415,
          415,
          23,
          415,
          51,
          415,
          57,
          415,
          51
        ],
        [
          "cached_files",
          319,
          579,
          421,
          29,
          421,
          67,
          421,
          29,
          422,
          48
        ],
        [
          "cached_files",
          319,
          579,
          423,
          74,
          423,
          111,
          423,
          62,
          423,
          111
        ],
        [
          "cached_files",
          319,
          579,
          562,
          63,
          562,
          100,
          562,
          41,
          562,
          100
        ],
        [
          "has_file",
          609,
          701,
          645,
          31,
          645,
          66,
          645,
          16,
          645,
          67
        ],
        [
          "dictcomp",
          748,
          748,
          748,
          37,
          748,
          64,
          748,
          71,
          748,
          65
        ],
        [
          "listcomp",
          777,
          778,
          780,
          62,
          780,
          89,
          780,
          45,
          780,
          112
        ],
        [
          "listcomp",
          784,
          785,
          787,
          31,
          787,
          58,
          786,
          17,
          787,
          59
        ],
        [
          "listcomp",
          784,
          785,
          787,
          78,
          787,
          105,
          787,
          64,
          787,
          106
        ],
        [
          "_upload_modified_files",
          750,
          827,
          793,
          30,
          793,
          60,
          792,
          13,
          793,
          61
        ],
        [
          "_upload_modified_files",
          750,
          827,
          795,
          37,
          795,
          67,
          795,
          26,
          795,
          68
        ],
        [
          "_upload_modified_files",
          750,
          827,
          798,
          45,
          798,
          78,
          795,
          21,
          800,
          21
        ],
        [
          "_upload_modified_files",
          750,
          827,
          798,
          94,
          798,
          114,
          795,
          21,
          800,
          21
        ],
        [
          "_upload_modified_files",
          750,
          827,
          803,
          56,
          803,
          86,
          802,
          17,
          804,
          17
        ],
        [
          "push_to_hub",
          829,
          975,
          964,
          29,
          964,
          63,
          964,
          13,
          975,
          13
        ],
        [
          "listcomp",
          1059,
          1059,
          1059,
          28,
          1059,
          84,
          1059,
          90,
          1059,
          84
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "save_pretrained",
          202,
          261,
          247,
          39,
          247,
          88,
          247,
          39,
          261,
          44
        ],
        [
          "get_image_processor_dict",
          264,
          382,
          318,
          36,
          318,
          104,
          318,
          36,
          318,
          32
        ]
      ],
      "transformers/src/transformers/models/oneformer/image_processing_oneformer.py": [
        [
          "load_metadata",
          382,
          397,
          383,
          13,
          383,
          77,
          383,
          26,
          385,
          32
        ],
        [
          "load_metadata",
          382,
          397,
          383,
          13,
          383,
          77,
          383,
          53,
          385,
          32
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/lightning_base.py": [
        [
          "_feature_file",
          193,
          201,
          194,
          16,
          201,
          9,
          193,
          23,
          201,
          9
        ],
        [
          "on_test_end",
          287,
          296,
          291,
          36,
          291,
          97,
          287,
          21,
          293,
          38
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          41,
          100,
          61,
          32,
          64,
          9,
          62,
          13,
          70,
          51
        ],
        [
          "__init__",
          187,
          226,
          201,
          25,
          201,
          57,
          200,
          13,
          202,
          49
        ],
        [
          "__init__",
          335,
          418,
          357,
          32,
          360,
          9,
          353,
          38,
          382,
          51
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "_objective",
          258,
          284,
          263,
          38,
          263,
          73,
          263,
          38,
          263,
          34
        ],
        [
          "dynamic_modules_import_trainable",
          412,
          429,
          423,
          36,
          423,
          100,
          421,
          20,
          428,
          53
        ],
        [
          "on_train_begin",
          703,
          723,
          712,
          27,
          712,
          68,
          712,
          27,
          712,
          23
        ],
        [
          "on_save",
          1024,
          1045,
          1034,
          29,
          1034,
          67,
          1028,
          29,
          1038,
          41
        ],
        [
          "on_save",
          1511,
          1520,
          1514,
          29,
          1514,
          67,
          1513,
          24,
          1520,
          13
        ],
        [
          "on_train_end",
          1574,
          1579,
          1577,
          59,
          1577,
          101,
          1577,
          17,
          1577,
          102
        ],
        [
          "_log_model_checkpoint",
          1773,
          1795,
          1774,
          39,
          1774,
          80,
          1773,
          31,
          1776,
          53
        ],
        [
          "_log_model_checkpoint",
          1773,
          1795,
          1777,
          42,
          1777,
          97,
          1777,
          42,
          1780,
          49
        ],
        [
          "_log_model_checkpoint",
          1773,
          1795,
          1781,
          29,
          1781,
          79,
          1781,
          42,
          1781,
          79
        ],
        [
          "on_save",
          2111,
          2139,
          2114,
          29,
          2114,
          67,
          2113,
          24,
          2125,
          56
        ],
        [
          "on_save",
          2196,
          2202,
          2199,
          29,
          2199,
          67,
          2198,
          24,
          2202,
          39
        ],
        [
          "on_train_end",
          2301,
          2316,
          2313,
          30,
          2313,
          64,
          2312,
          24,
          2315,
          86
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "direct_transformers_import",
          1953,
          1969,
          1964,
          16,
          1964,
          39,
          1953,
          32,
          1969,
          17
        ],
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2178,
          49,
          2178,
          76,
          2178,
          35,
          2178,
          77
        ],
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2179,
          69,
          2179,
          96,
          2179,
          35,
          2179,
          31
        ],
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2181,
          32,
          2181,
          57,
          2181,
          18,
          2181,
          58
        ],
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2203,
          19,
          2203,
          54,
          2203,
          14,
          2216,
          72
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "save_pretrained",
          114,
          123,
          118,
          38,
          118,
          90,
          118,
          38,
          118,
          34
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "_serialize_tensor_like_io",
          70,
          116,
          96,
          20,
          96,
          58,
          96,
          20,
          96,
          58
        ],
        [
          "log_model_debug_trace",
          228,
          268,
          232,
          20,
          232,
          93,
          232,
          20,
          232,
          93
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/modeling_deta.py": [
        [
          "load_cuda_kernels",
          56,
          83,
          66,
          13,
          66,
          57,
          57,
          10,
          71,
          33
        ],
        [
          "load_cuda_kernels",
          56,
          83,
          67,
          13,
          67,
          58,
          57,
          10,
          71,
          33
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "load_sharded_checkpoint",
          372,
          444,
          396,
          18,
          396,
          57,
          372,
          29,
          402,
          24
        ],
        [
          "load_sharded_checkpoint",
          372,
          444,
          397,
          23,
          397,
          67,
          372,
          29,
          402,
          24
        ],
        [
          "load_sharded_checkpoint",
          372,
          444,
          436,
          29,
          436,
          60,
          435,
          9,
          441,
          20
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          941,
          32,
          941,
          117,
          941,
          32,
          942,
          26
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          944,
          17,
          944,
          112,
          943,
          51,
          945,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          947,
          32,
          949,
          17,
          947,
          32,
          947,
          28
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          951,
          17,
          951,
          118,
          950,
          51,
          952,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          954,
          32,
          956,
          17,
          954,
          32,
          957,
          26
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          959,
          17,
          959,
          107,
          958,
          42,
          960,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          962,
          32,
          964,
          17,
          962,
          32,
          962,
          28
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          966,
          17,
          966,
          113,
          965,
          42,
          967,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          969,
          32,
          971,
          17,
          969,
          32,
          972,
          26
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          983,
          29,
          983,
          82,
          983,
          14,
          983,
          83
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3989,
          29,
          3989,
          66,
          3988,
          13,
          3999,
          54
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4050,
          39,
          4050,
          78,
          4050,
          17,
          4050,
          98
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4052,
          38,
          4052,
          77,
          4052,
          17,
          4052,
          78
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4057,
          31,
          4057,
          72,
          4057,
          31,
          4058,
          68
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4061,
          31,
          4061,
          98,
          4060,
          31,
          4070,
          13
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4079,
          29,
          4079,
          69,
          4072,
          12,
          4088,
          13
        ],
        [
          "dictcomp",
          5225,
          5225,
          5225,
          38,
          5225,
          60,
          5225,
          66,
          5225,
          60
        ]
      ],
      "transformers/utils/models_to_deprecate.py": [
        [
          "get_list_of_repo_model_paths",
          155,
          169,
          157,
          24,
          157,
          66,
          155,
          34,
          162,
          45
        ],
        [
          "get_list_of_repo_model_paths",
          155,
          169,
          160,
          35,
          160,
          77,
          155,
          34,
          162,
          45
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "main",
          691,
          908,
          720,
          25,
          720,
          116,
          720,
          25,
          720,
          21
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "retrieve_artifact",
          276,
          288,
          283,
          27,
          283,
          50,
          283,
          40,
          283,
          50
        ],
        [
          "retrieve_artifact",
          276,
          288,
          286,
          52,
          286,
          75,
          285,
          13,
          286,
          86
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_datasets.py": [
        [
          "make_test_data_dir",
          46,
          50,
          48,
          24,
          48,
          63,
          47,
          9,
          49,
          75
        ],
        [
          "make_test_data_dir",
          46,
          50,
          49,
          24,
          49,
          63,
          47,
          9,
          49,
          75
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "model_failures",
          372,
          528,
          483,
          21,
          483,
          97,
          457,
          17,
          497,
          45
        ],
        [
          "model_failures",
          372,
          528,
          493,
          21,
          493,
          98,
          457,
          17,
          497,
          45
        ],
        [
          "model_failures",
          372,
          528,
          514,
          33,
          514,
          117,
          508,
          35,
          526,
          21
        ],
        [
          "payload",
          556,
          698,
          601,
          29,
          601,
          94,
          596,
          28,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          601,
          29,
          601,
          94,
          600,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          601,
          29,
          601,
          94,
          598,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          606,
          29,
          606,
          94,
          596,
          28,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          606,
          29,
          606,
          94,
          600,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          606,
          29,
          606,
          94,
          598,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          635,
          29,
          635,
          95,
          635,
          29,
          663,
          40
        ],
        [
          "payload",
          556,
          698,
          635,
          29,
          635,
          95,
          635,
          29,
          670,
          156
        ],
        [
          "payload",
          556,
          698,
          640,
          29,
          640,
          95,
          635,
          29,
          663,
          40
        ],
        [
          "payload",
          556,
          698,
          640,
          29,
          640,
          95,
          635,
          29,
          670,
          156
        ],
        [
          "retrieve_artifact",
          944,
          959,
          954,
          27,
          954,
          59,
          954,
          40,
          954,
          59
        ],
        [
          "retrieve_artifact",
          944,
          959,
          957,
          52,
          957,
          84,
          956,
          13,
          957,
          95
        ],
        [
          "listcomp",
          1561,
          1561,
          1561,
          89,
          1561,
          115,
          1561,
          44,
          1561,
          116
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_seq2seq_examples_multi_gpu.py": [
        [
          "test_distributed_eval",
          32,
          55,
          52,
          29,
          52,
          70,
          32,
          31,
          55,
          52
        ]
      ],
      "transformers/examples/pytorch/old_test_xla_examples.py": [
        [
          "get_results",
          31,
          39,
          33,
          12,
          33,
          55,
          31,
          17,
          34,
          27
        ]
      ],
      "transformers/src/transformers/utils/peft_utils.py": [
        [
          "find_adapter_config_file",
          29,
          100,
          82,
          39,
          82,
          81,
          82,
          39,
          82,
          35
        ]
      ],
      "transformers/utils/process_test_artifacts.py": [
        [
          "process_artifacts",
          47,
          69,
          59,
          25,
          59,
          70,
          56,
          19,
          61,
          42
        ]
      ],
      "transformers/src/transformers/models/bark/processing_bark.py": [
        [
          "_load_voice_preset",
          180,
          213,
          206,
          27,
          206,
          113,
          205,
          23,
          209,
          17
        ],
        [
          "from_pretrained",
          67,
          122,
          106,
          27,
          106,
          103,
          105,
          17,
          110,
          34
        ],
        [
          "save_pretrained",
          124,
          178,
          153,
          25,
          153,
          88,
          153,
          13,
          159,
          58
        ],
        [
          "save_pretrained",
          124,
          178,
          165,
          25,
          167,
          25,
          163,
          21,
          171,
          33
        ],
        [
          "save_pretrained",
          124,
          178,
          171,
          37,
          171,
          105,
          163,
          21,
          171,
          33
        ],
        [
          "save_pretrained",
          124,
          178,
          175,
          23,
          175,
          80,
          175,
          18,
          176,
          46
        ]
      ],
      "transformers/src/transformers/models/evolla/processing_evolla.py": [
        [
          "save_pretrained",
          211,
          227,
          213,
          48,
          213,
          108,
          211,
          25,
          218,
          105
        ]
      ],
      "transformers/src/transformers/models/instructblip/processing_instructblip.py": [
        [
          "save_pretrained",
          156,
          172,
          160,
          34,
          160,
          82,
          159,
          9,
          165,
          26
        ]
      ],
      "transformers/src/transformers/models/instructblipvideo/processing_instructblipvideo.py": [
        [
          "save_pretrained",
          184,
          200,
          188,
          34,
          188,
          82,
          187,
          9,
          193,
          26
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py": [
        [
          "from_pretrained",
          121,
          189,
          165,
          40,
          165,
          115,
          160,
          13,
          169,
          19
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "save_pretrained",
          723,
          896,
          806,
          33,
          806,
          76,
          806,
          33,
          815,
          41
        ],
        [
          "save_pretrained",
          723,
          896,
          807,
          43,
          807,
          90,
          806,
          33,
          815,
          41
        ],
        [
          "save_pretrained",
          723,
          896,
          808,
          44,
          810,
          9,
          806,
          33,
          815,
          41
        ],
        [
          "save_pretrained",
          723,
          896,
          811,
          29,
          811,
          75,
          806,
          33,
          815,
          41
        ],
        [
          "save_pretrained",
          723,
          896,
          833,
          45,
          833,
          101,
          832,
          25,
          836,
          82
        ],
        [
          "save_pretrained",
          723,
          896,
          854,
          43,
          854,
          92,
          854,
          43,
          859,
          64
        ],
        [
          "get_processor_dict",
          899,
          1149,
          941,
          30,
          941,
          88,
          941,
          30,
          941,
          26
        ]
      ],
      "transformers/utils/release.py": [
        [
          "update_version_in_examples",
          99,
          119,
          116,
          44,
          116,
          70,
          115,
          43,
          116,
          111
        ],
        [
          "update_version_in_examples",
          99,
          119,
          119,
          44,
          119,
          70,
          119,
          21,
          119,
          102
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/retrieval_realm.py": [
        [
          "from_pretrained",
          101,
          120,
          103,
          34,
          103,
          107,
          103,
          34,
          103,
          30
        ],
        [
          "save_pretrained",
          122,
          126,
          124,
          17,
          124,
          75,
          122,
          25,
          126,
          54
        ]
      ],
      "transformers/src/transformers/models/rag/retrieval_rag.py": [
        [
          "save_pretrained",
          464,
          482,
          467,
          30,
          467,
          83,
          467,
          30,
          469,
          38
        ],
        [
          "save_pretrained",
          464,
          482,
          471,
          33,
          471,
          74,
          471,
          33,
          476,
          41
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "generate_summary_report",
          164,
          190,
          172,
          20,
          172,
          82,
          165,
          5,
          190,
          23
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          733,
          31,
          733,
          91,
          733,
          31,
          734,
          42
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          311,
          23,
          311,
          65,
          308,
          19,
          312,
          44
        ],
        [
          "main",
          268,
          722,
          645,
          38,
          645,
          78,
          645,
          38,
          645,
          34
        ],
        [
          "main",
          268,
          722,
          699,
          30,
          699,
          70,
          699,
          30,
          699,
          26
        ],
        [
          "main",
          268,
          722,
          718,
          23,
          718,
          71,
          718,
          18,
          719,
          56
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/run_glue.py": [
        [
          "main",
          176,
          197,
          184,
          27,
          187,
          9,
          184,
          27,
          188,
          36
        ],
        [
          "main",
          176,
          197,
          195,
          40,
          195,
          95,
          195,
          23,
          197,
          34
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          632,
          35,
          632,
          103,
          630,
          27,
          633,
          46
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "main",
          191,
          445,
          258,
          35,
          258,
          73,
          258,
          35,
          258,
          31
        ],
        [
          "main",
          191,
          445,
          260,
          40,
          260,
          83,
          260,
          40,
          260,
          36
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          273,
          23,
          273,
          65,
          270,
          19,
          274,
          44
        ],
        [
          "main",
          235,
          692,
          588,
          38,
          588,
          78,
          588,
          38,
          588,
          34
        ],
        [
          "main",
          235,
          692,
          646,
          30,
          646,
          70,
          646,
          30,
          646,
          26
        ],
        [
          "main",
          235,
          692,
          688,
          19,
          688,
          67,
          687,
          51,
          689,
          37
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          377,
          23,
          377,
          65,
          373,
          23,
          378,
          44
        ],
        [
          "main",
          328,
          911,
          843,
          38,
          843,
          78,
          843,
          38,
          843,
          34
        ],
        [
          "main",
          328,
          911,
          893,
          30,
          893,
          70,
          893,
          30,
          893,
          26
        ],
        [
          "main",
          328,
          911,
          907,
          23,
          907,
          71,
          907,
          18,
          908,
          56
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          519,
          32,
          519,
          97,
          517,
          27,
          520,
          46
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "main",
          234,
          650,
          278,
          23,
          278,
          65,
          275,
          19,
          279,
          44
        ],
        [
          "main",
          234,
          650,
          298,
          35,
          298,
          68,
          298,
          35,
          298,
          31
        ],
        [
          "main",
          234,
          650,
          300,
          40,
          300,
          78,
          300,
          40,
          300,
          36
        ],
        [
          "main",
          234,
          650,
          558,
          38,
          558,
          78,
          558,
          38,
          558,
          34
        ],
        [
          "main",
          234,
          650,
          626,
          30,
          626,
          70,
          626,
          30,
          626,
          26
        ],
        [
          "main",
          234,
          650,
          646,
          23,
          646,
          71,
          645,
          55,
          647,
          41
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "main",
          197,
          364,
          354,
          28,
          354,
          88,
          347,
          9,
          355,
          36
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "handle_repository_creation",
          387,
          410,
          401,
          23,
          401,
          65,
          398,
          19,
          402,
          44
        ],
        [
          "main",
          413,
          747,
          652,
          38,
          652,
          78,
          652,
          38,
          652,
          34
        ],
        [
          "main",
          413,
          747,
          711,
          30,
          711,
          70,
          711,
          30,
          711,
          26
        ],
        [
          "main",
          413,
          747,
          731,
          23,
          731,
          71,
          731,
          18,
          736,
          31
        ]
      ],
      "transformers/examples/legacy/multiple_choice/run_multiple_choice.py": [
        [
          "main",
          90,
          234,
          224,
          28,
          224,
          85,
          220,
          9,
          225,
          36
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          430,
          23,
          430,
          65,
          427,
          19,
          431,
          44
        ],
        [
          "main",
          384,
          804,
          733,
          38,
          733,
          78,
          733,
          38,
          733,
          34
        ],
        [
          "main",
          384,
          804,
          783,
          30,
          783,
          70,
          783,
          30,
          783,
          26
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          318,
          23,
          318,
          65,
          315,
          19,
          319,
          44
        ],
        [
          "main",
          275,
          760,
          682,
          38,
          682,
          78,
          682,
          38,
          682,
          34
        ],
        [
          "main",
          275,
          760,
          737,
          30,
          737,
          70,
          737,
          30,
          737,
          26
        ],
        [
          "main",
          275,
          760,
          756,
          23,
          756,
          71,
          756,
          18,
          757,
          56
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          275,
          28,
          275,
          85,
          271,
          9,
          276,
          42
        ],
        [
          "main",
          101,
          315,
          301,
          36,
          301,
          93,
          287,
          24,
          302,
          42
        ],
        [
          "main",
          101,
          315,
          309,
          40,
          309,
          101,
          309,
          40,
          310,
          42
        ],
        [
          "main",
          101,
          315,
          312,
          27,
          312,
          70,
          311,
          18,
          313,
          94
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          634,
          35,
          634,
          91,
          619,
          9,
          635,
          42
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          322,
          23,
          322,
          65,
          319,
          19,
          323,
          44
        ],
        [
          "main",
          284,
          835,
          740,
          38,
          740,
          78,
          740,
          38,
          740,
          34
        ],
        [
          "main",
          284,
          835,
          802,
          30,
          802,
          70,
          802,
          30,
          802,
          26
        ],
        [
          "main",
          284,
          835,
          825,
          23,
          825,
          71,
          825,
          18,
          827,
          53
        ]
      ],
      "transformers/examples/legacy/run_openai_gpt.py": [
        [
          "main",
          104,
          315,
          271,
          29,
          271,
          71,
          268,
          25,
          281,
          24
        ],
        [
          "main",
          104,
          315,
          272,
          30,
          272,
          71,
          268,
          25,
          281,
          24
        ],
        [
          "main",
          104,
          315,
          310,
          28,
          310,
          76,
          307,
          22,
          313,
          44
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection_no_trainer.py": [
        [
          "main",
          411,
          796,
          449,
          23,
          449,
          65,
          446,
          19,
          450,
          44
        ],
        [
          "main",
          411,
          796,
          701,
          38,
          701,
          78,
          701,
          38,
          701,
          34
        ],
        [
          "main",
          411,
          796,
          760,
          30,
          760,
          70,
          760,
          30,
          760,
          26
        ],
        [
          "main",
          411,
          796,
          780,
          23,
          780,
          71,
          780,
          18,
          785,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "save_prefixed_metrics",
          64,
          84,
          83,
          15,
          83,
          49,
          83,
          10,
          84,
          39
        ],
        [
          "main",
          299,
          1057,
          342,
          23,
          342,
          65,
          339,
          19,
          343,
          44
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "main",
          253,
          637,
          291,
          23,
          291,
          65,
          288,
          19,
          292,
          44
        ],
        [
          "main",
          253,
          637,
          529,
          38,
          529,
          78,
          529,
          38,
          529,
          34
        ],
        [
          "main",
          253,
          637,
          610,
          30,
          610,
          70,
          610,
          30,
          610,
          26
        ],
        [
          "main",
          253,
          637,
          633,
          23,
          633,
          71,
          631,
          89,
          634,
          51
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "main",
          338,
          1035,
          902,
          38,
          902,
          78,
          902,
          38,
          902,
          34
        ],
        [
          "save_prefixed_metrics",
          69,
          89,
          88,
          15,
          88,
          49,
          88,
          10,
          89,
          39
        ],
        [
          "main",
          338,
          1035,
          381,
          23,
          381,
          65,
          378,
          19,
          382,
          44
        ],
        [
          "main",
          338,
          1035,
          911,
          30,
          911,
          70,
          911,
          30,
          911,
          26
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          558,
          22,
          558,
          71,
          556,
          34,
          561,
          49
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          557,
          22,
          557,
          71,
          555,
          34,
          560,
          49
        ],
        [
          "main",
          396,
          837,
          828,
          20,
          828,
          71,
          827,
          20,
          832,
          32
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "train",
          73,
          263,
          104,
          9,
          104,
          61,
          103,
          82,
          105,
          5
        ],
        [
          "train",
          73,
          263,
          103,
          23,
          103,
          75,
          89,
          17,
          103,
          76
        ],
        [
          "train",
          73,
          263,
          107,
          46,
          107,
          98,
          107,
          9,
          108,
          119
        ],
        [
          "train",
          73,
          263,
          108,
          46,
          108,
          98,
          107,
          9,
          108,
          119
        ],
        [
          "train",
          73,
          263,
          240,
          34,
          240,
          91,
          240,
          34,
          242,
          76
        ],
        [
          "train",
          73,
          263,
          246,
          38,
          246,
          82,
          242,
          37,
          251,
          90
        ],
        [
          "train",
          73,
          263,
          249,
          56,
          249,
          95,
          242,
          37,
          251,
          90
        ],
        [
          "train",
          73,
          263,
          250,
          56,
          250,
          95,
          242,
          37,
          251,
          90
        ],
        [
          "evaluate",
          266,
          397,
          350,
          30,
          350,
          88,
          346,
          16,
          353,
          35
        ],
        [
          "evaluate",
          266,
          397,
          351,
          25,
          351,
          89,
          346,
          16,
          353,
          35
        ],
        [
          "evaluate",
          266,
          397,
          354,
          37,
          354,
          93,
          354,
          37,
          354,
          33
        ],
        [
          "load_and_cache_examples",
          400,
          467,
          407,
          28,
          414,
          5,
          410,
          13,
          417,
          43
        ],
        [
          "main",
          470,
          835,
          793,
          26,
          793,
          75,
          788,
          25,
          801,
          29
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "load_and_cache_examples",
          230,
          272,
          236,
          28,
          243,
          5,
          239,
          13,
          244,
          43
        ],
        [
          "train",
          275,
          410,
          391,
          34,
          391,
          91,
          391,
          34,
          393,
          64
        ],
        [
          "train",
          275,
          410,
          397,
          38,
          397,
          82,
          393,
          25,
          398,
          76
        ],
        [
          "evaluate",
          413,
          470,
          463,
          24,
          463,
          72,
          459,
          17,
          466,
          40
        ],
        [
          "main",
          473,
          717,
          679,
          26,
          679,
          75,
          673,
          13,
          684,
          29
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          281,
          23,
          281,
          65,
          278,
          19,
          282,
          44
        ],
        [
          "main",
          238,
          654,
          580,
          38,
          580,
          78,
          580,
          38,
          580,
          34
        ],
        [
          "main",
          238,
          654,
          630,
          30,
          630,
          70,
          630,
          30,
          630,
          26
        ],
        [
          "main",
          238,
          654,
          650,
          23,
          650,
          71,
          649,
          55,
          651,
          41
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          392,
          23,
          392,
          65,
          389,
          19,
          393,
          44
        ],
        [
          "main",
          339,
          809,
          712,
          38,
          712,
          78,
          712,
          38,
          712,
          34
        ],
        [
          "main",
          339,
          809,
          787,
          30,
          787,
          70,
          787,
          30,
          787,
          26
        ],
        [
          "main",
          339,
          809,
          808,
          23,
          808,
          71,
          807,
          55,
          809,
          41
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          754,
          42,
          754,
          108,
          748,
          31,
          756,
          56
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          676,
          42,
          676,
          108,
          670,
          31,
          678,
          56
        ]
      ],
      "transformers/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py": [
        [
          "main",
          406,
          804,
          443,
          23,
          443,
          65,
          440,
          19,
          444,
          44
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          369,
          23,
          369,
          65,
          366,
          19,
          370,
          44
        ],
        [
          "main",
          329,
          796,
          687,
          38,
          687,
          78,
          687,
          38,
          687,
          34
        ],
        [
          "main",
          329,
          796,
          773,
          30,
          773,
          70,
          773,
          30,
          773,
          26
        ],
        [
          "main",
          329,
          796,
          792,
          19,
          792,
          67,
          792,
          14,
          793,
          61
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_xnli.py": [
        [
          "main",
          194,
          461,
          455,
          31,
          455,
          87,
          447,
          13,
          456,
          42
        ]
      ],
      "transformers/utils/sort_auto_mappings.py": [
        [
          "listcomp",
          109,
          109,
          109,
          15,
          109,
          50,
          109,
          15,
          109,
          50
        ]
      ],
      "transformers/src/transformers/data/datasets/squad.py": [
        [
          "__init__",
          115,
          189,
          136,
          32,
          139,
          9,
          137,
          13,
          145,
          51
        ]
      ],
      "transformers/examples/legacy/token-classification/tasks.py": [
        [
          "read_examples_from_file",
          17,
          43,
          20,
          21,
          20,
          57,
          20,
          21,
          26,
          25
        ],
        [
          "read_examples_from_file",
          108,
          126,
          111,
          21,
          111,
          57,
          111,
          21,
          116,
          41
        ]
      ],
      "transformers/src/transformers/data/processors/squad.py": [
        [
          "get_train_examples",
          500,
          520,
          517,
          13,
          517,
          85,
          517,
          36,
          520,
          57
        ],
        [
          "get_dev_examples",
          522,
          541,
          538,
          13,
          538,
          83,
          538,
          36,
          541,
          55
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "test_run_clm_no_trainer",
          103,
          127,
          126,
          40,
          126,
          71,
          123,
          9,
          127,
          80
        ],
        [
          "get_results",
          49,
          57,
          51,
          12,
          51,
          55,
          49,
          17,
          52,
          27
        ],
        [
          "setUpClass",
          66,
          71,
          69,
          26,
          69,
          71,
          66,
          20,
          71,
          24
        ],
        [
          "test_run_glue_no_trainer",
          78,
          99,
          98,
          40,
          98,
          71,
          78,
          34,
          99,
          81
        ],
        [
          "test_run_glue_no_trainer",
          78,
          99,
          99,
          40,
          99,
          79,
          78,
          34,
          99,
          81
        ],
        [
          "test_run_clm_no_trainer",
          103,
          127,
          127,
          40,
          127,
          78,
          123,
          9,
          127,
          80
        ],
        [
          "test_run_mlm_no_trainer",
          131,
          148,
          147,
          40,
          147,
          71,
          131,
          33,
          148,
          80
        ],
        [
          "test_run_mlm_no_trainer",
          131,
          148,
          148,
          40,
          148,
          78,
          131,
          33,
          148,
          80
        ],
        [
          "test_run_ner_no_trainer",
          151,
          176,
          175,
          40,
          175,
          71,
          153,
          18,
          176,
          80
        ],
        [
          "test_run_ner_no_trainer",
          151,
          176,
          176,
          40,
          176,
          78,
          153,
          18,
          176,
          80
        ],
        [
          "test_run_squad_no_trainer",
          179,
          204,
          203,
          40,
          203,
          71,
          179,
          35,
          204,
          79
        ],
        [
          "test_run_squad_no_trainer",
          179,
          204,
          204,
          40,
          204,
          77,
          179,
          35,
          204,
          79
        ],
        [
          "test_run_swag_no_trainer",
          207,
          226,
          226,
          40,
          226,
          79,
          207,
          34,
          226,
          81
        ],
        [
          "test_run_summarization_no_trainer",
          230,
          254,
          253,
          40,
          253,
          71,
          230,
          43,
          254,
          90
        ],
        [
          "test_run_summarization_no_trainer",
          230,
          254,
          254,
          40,
          254,
          88,
          230,
          43,
          254,
          90
        ],
        [
          "test_run_translation_no_trainer",
          258,
          284,
          283,
          40,
          283,
          71,
          258,
          41,
          284,
          88
        ],
        [
          "test_run_translation_no_trainer",
          258,
          284,
          284,
          40,
          284,
          86,
          258,
          41,
          284,
          88
        ],
        [
          "test_run_image_classification_no_trainer",
          309,
          332,
          331,
          40,
          331,
          70,
          309,
          50,
          332,
          97
        ],
        [
          "test_run_image_classification_no_trainer",
          309,
          332,
          332,
          40,
          332,
          95,
          309,
          50,
          332,
          97
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "test_phi4_with_all_processors",
          374,
          826,
          431,
          13,
          431,
          69,
          374,
          39,
          826,
          101
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          138,
          13,
          138,
          74,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          134,
          13,
          134,
          74,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          150,
          13,
          150,
          69,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          146,
          13,
          146,
          69,
          94,
          39,
          372,
          100
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          423,
          13,
          423,
          74,
          374,
          39,
          826,
          101
        ],
        [
          "setUpClass",
          35,
          76,
          40,
          21,
          40,
          80,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          41,
          21,
          41,
          66,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          42,
          21,
          42,
          84,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          45,
          21,
          45,
          52,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          48,
          22,
          48,
          92,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          50,
          19,
          50,
          81,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          53,
          21,
          53,
          61,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          57,
          25,
          57,
          87,
          56,
          13,
          63,
          30
        ],
        [
          "setUpClass",
          35,
          76,
          60,
          24,
          60,
          72,
          56,
          13,
          63,
          30
        ],
        [
          "setUpClass",
          35,
          76,
          64,
          27,
          64,
          101,
          64,
          27,
          65,
          79
        ],
        [
          "setUpClass",
          35,
          76,
          74,
          26,
          74,
          85,
          68,
          29,
          76,
          20
        ],
        [
          "setUpClass",
          35,
          76,
          75,
          32,
          75,
          77,
          68,
          29,
          76,
          20
        ],
        [
          "setUpClass",
          35,
          76,
          76,
          24,
          76,
          74,
          68,
          29,
          76,
          20
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          117,
          22,
          117,
          61,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          118,
          22,
          118,
          67,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          119,
          40,
          119,
          85,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          120,
          40,
          120,
          86,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          121,
          40,
          121,
          91,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          122,
          40,
          122,
          78,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          123,
          40,
          123,
          93,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          124,
          40,
          124,
          78,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          125,
          40,
          125,
          91,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          130,
          13,
          130,
          56,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          142,
          13,
          142,
          69,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          154,
          13,
          154,
          69,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          158,
          13,
          158,
          69,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          162,
          13,
          162,
          55,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          259,
          50,
          259,
          95,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          295,
          47,
          295,
          85,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          372,
          46,
          372,
          99,
          94,
          39,
          372,
          100
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          397,
          22,
          397,
          62,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          398,
          22,
          398,
          68,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          399,
          40,
          399,
          86,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          400,
          40,
          400,
          87,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          401,
          40,
          401,
          92,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          402,
          40,
          402,
          100,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          403,
          40,
          403,
          97,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          404,
          40,
          404,
          89,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          405,
          40,
          405,
          78,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          406,
          40,
          406,
          94,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          407,
          40,
          407,
          78,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          408,
          40,
          408,
          92,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          409,
          40,
          409,
          102,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          410,
          40,
          410,
          100,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          415,
          13,
          415,
          56,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          419,
          13,
          419,
          74,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          427,
          13,
          427,
          69,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          435,
          13,
          435,
          77,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          439,
          13,
          439,
          79,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          443,
          13,
          443,
          71,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          447,
          13,
          447,
          55,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          683,
          50,
          683,
          96,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          721,
          47,
          721,
          85,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          826,
          46,
          826,
          100,
          374,
          39,
          826,
          101
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "test_is_copy_consistent",
          310,
          332,
          316,
          33,
          316,
          72,
          310,
          33,
          332,
          67
        ],
        [
          "test_is_copy_consistent",
          310,
          332,
          323,
          33,
          323,
          72,
          310,
          33,
          332,
          67
        ],
        [
          "test_is_copy_consistent_with_ignored_match",
          334,
          342,
          340,
          33,
          340,
          72,
          334,
          52,
          342,
          43
        ],
        [
          "test_is_copy_consistent_with_ignored_no_match",
          344,
          368,
          356,
          33,
          356,
          72,
          344,
          55,
          368,
          70
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_pattern_matching_fallback",
          63,
          71,
          66,
          22,
          66,
          58,
          63,
          40,
          71,
          57
        ],
        [
          "test_pattern_matching_fallback",
          63,
          71,
          68,
          23,
          68,
          57,
          63,
          40,
          71,
          57
        ],
        [
          "test_from_pretrained_dynamic_config",
          106,
          128,
          125,
          44,
          125,
          84,
          106,
          45,
          128,
          78
        ]
      ],
      "transformers/tests/test_configuration_common.py": [
        [
          "create_and_test_config_to_json_file",
          85,
          93,
          89,
          30,
          89,
          68,
          85,
          45,
          93,
          80
        ],
        [
          "create_and_test_config_from_and_save_pretrained_subfolder",
          107,
          116,
          112,
          30,
          112,
          64,
          107,
          67,
          116,
          80
        ]
      ],
      "transformers/tests/utils/test_configuration_utils.py": [
        [
          "test_local_versioning",
          237,
          257,
          244,
          53,
          244,
          94,
          237,
          31,
          257,
          64
        ],
        [
          "test_local_versioning",
          237,
          257,
          255,
          25,
          255,
          66,
          237,
          31,
          257,
          64
        ],
        [
          "test_local_versioning",
          237,
          257,
          255,
          69,
          255,
          111,
          237,
          31,
          257,
          64
        ]
      ],
      "transformers/tests/deepspeed/test_deepspeed.py": [
        [
          "check_saved_checkpoints_deepspeed",
          805,
          833,
          824,
          24,
          824,
          57,
          823,
          17,
          825,
          87
        ],
        [
          "check_saved_checkpoints_deepspeed",
          805,
          833,
          820,
          26,
          820,
          71,
          819,
          13,
          823,
          37
        ],
        [
          "check_saved_checkpoints_deepspeed",
          805,
          833,
          828,
          23,
          828,
          68,
          828,
          23,
          829,
          40
        ],
        [
          "check_saved_checkpoints_deepspeed",
          805,
          833,
          832,
          24,
          832,
          54,
          829,
          17,
          833,
          87
        ],
        [
          "test_can_resume_training_errors",
          863,
          882,
          881,
          30,
          881,
          69,
          863,
          41,
          882,
          75
        ],
        [
          "test_can_resume_training_normal",
          885,
          946,
          923,
          26,
          923,
          65,
          909,
          13,
          946,
          64
        ],
        [
          "test_can_resume_training_normal",
          885,
          946,
          936,
          26,
          936,
          66,
          909,
          13,
          946,
          64
        ],
        [
          "do_checks",
          1237,
          1248,
          1239,
          39,
          1239,
          84,
          1239,
          29,
          1241,
          29
        ],
        [
          "do_checks",
          1237,
          1248,
          1245,
          38,
          1245,
          82,
          1245,
          28,
          1247,
          29
        ]
      ],
      "transformers/tests/trainer/test_data_collator.py": [
        [
          "setUp",
          46,
          52,
          50,
          27,
          50,
          68,
          46,
          15,
          52,
          73
        ],
        [
          "setUp",
          721,
          727,
          725,
          27,
          725,
          68,
          721,
          15,
          727,
          73
        ],
        [
          "setUp",
          1043,
          1049,
          1047,
          27,
          1047,
          68,
          1043,
          15,
          1049,
          73
        ],
        [
          "setUp",
          1548,
          1554,
          1552,
          27,
          1552,
          68,
          1548,
          15,
          1554,
          73
        ]
      ],
      "transformers/tests/utils/test_doc_samples.py": [
        [
          "listcomp",
          51,
          51,
          51,
          75,
          51,
          103,
          51,
          27,
          51,
          104
        ]
      ],
      "transformers/tests/utils/test_dynamic_module_utils.py": [
        [
          "test_import_parsing",
          123,
          129,
          124,
          21,
          124,
          58,
          123,
          25,
          129,
          35
        ]
      ],
      "transformers/tests/models/auto/test_feature_extraction_auto.py": [
        [
          "test_from_pretrained_dynamic_feature_extractor",
          102,
          133,
          129,
          44,
          129,
          88,
          102,
          56,
          133,
          94
        ]
      ],
      "transformers/tests/models/audio_spectrogram_transformer/test_feature_extraction_audio_spectrogram_transformer.py": [
        [
          "test_feat_extract_to_json_file",
          190,
          200,
          194,
          30,
          194,
          74,
          190,
          40,
          200,
          49
        ]
      ],
      "transformers/tests/models/clvp/test_feature_extraction_clvp.py": [
        [
          "test_feat_extract_to_json_file",
          142,
          155,
          146,
          30,
          146,
          74,
          142,
          40,
          155,
          49
        ]
      ],
      "transformers/tests/test_feature_extraction_common.py": [
        [
          "test_feat_extract_to_json_file",
          32,
          40,
          36,
          30,
          36,
          74,
          32,
          40,
          40,
          85
        ]
      ],
      "transformers/tests/models/gemma3n/test_feature_extraction_gemma3n.py": [
        [
          "test_feat_extract_to_json_file",
          163,
          176,
          167,
          30,
          167,
          74,
          163,
          40,
          176,
          49
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_feature_extraction_musicgen_melody.py": [
        [
          "test_feat_extract_to_json_file",
          142,
          152,
          146,
          30,
          146,
          74,
          142,
          40,
          152,
          49
        ]
      ],
      "transformers/tests/models/pop2piano/test_feature_extraction_pop2piano.py": [
        [
          "test_feat_extract_to_json_file",
          110,
          123,
          114,
          30,
          114,
          74,
          110,
          40,
          123,
          49
        ]
      ],
      "transformers/tests/models/phi4_multimodal/test_feature_extraction_phi4_multimodal.py": [
        [
          "test_feat_extract_to_json_file",
          129,
          142,
          133,
          30,
          133,
          74,
          129,
          40,
          142,
          49
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_feature_extraction_seamless_m4t.py": [
        [
          "test_feat_extract_to_json_file",
          129,
          139,
          133,
          30,
          133,
          74,
          129,
          40,
          139,
          49
        ]
      ],
      "transformers/tests/models/speech_to_text/test_feature_extraction_speech_to_text.py": [
        [
          "test_feat_extract_to_json_file",
          328,
          338,
          332,
          30,
          332,
          74,
          328,
          40,
          338,
          49
        ]
      ],
      "transformers/tests/models/whisper/test_feature_extraction_whisper.py": [
        [
          "test_feat_extract_to_json_file",
          133,
          146,
          137,
          30,
          137,
          74,
          133,
          40,
          146,
          49
        ]
      ],
      "transformers/tests/models/univnet/test_feature_extraction_univnet.py": [
        [
          "test_feat_extract_to_json_file",
          174,
          187,
          178,
          30,
          178,
          74,
          174,
          40,
          187,
          49
        ]
      ],
      "transformers/tests/fsdp/test_fsdp.py": [
        [
          "test_training_and_can_resume_normally",
          297,
          329,
          308,
          22,
          308,
          63,
          297,
          47,
          311,
          48
        ],
        [
          "genexpr",
          314,
          314,
          316,
          34,
          316,
          70,
          315,
          21,
          316,
          71
        ],
        [
          "test_training_and_can_resume_normally",
          297,
          329,
          319,
          31,
          319,
          80,
          319,
          16,
          319,
          81
        ],
        [
          "test_accelerate_fsdp2_integration",
          353,
          394,
          373,
          22,
          373,
          63,
          353,
          43,
          376,
          48
        ],
        [
          "genexpr",
          379,
          379,
          381,
          34,
          381,
          70,
          380,
          21,
          381,
          71
        ],
        [
          "test_accelerate_fsdp2_integration",
          353,
          394,
          384,
          31,
          384,
          80,
          384,
          16,
          384,
          81
        ],
        [
          "run_cmd_and_get_logs",
          416,
          435,
          434,
          44,
          434,
          89,
          433,
          9,
          435,
          19
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_cached_file",
          44,
          62,
          50,
          43,
          50,
          76,
          49,
          13,
          50,
          78
        ],
        [
          "test_cached_file",
          44,
          62,
          51,
          19,
          51,
          57,
          51,
          14,
          62,
          107
        ],
        [
          "test_cached_file",
          44,
          62,
          53,
          40,
          53,
          101,
          51,
          14,
          62,
          107
        ],
        [
          "test_cached_file",
          44,
          62,
          62,
          40,
          62,
          106,
          51,
          14,
          62,
          107
        ],
        [
          "test_non_existence_is_cached",
          74,
          96,
          78,
          19,
          78,
          57,
          74,
          38,
          96,
          37
        ],
        [
          "test_non_existence_is_cached",
          74,
          96,
          80,
          40,
          80,
          96,
          74,
          38,
          96,
          37
        ]
      ],
      "transformers/tests/utils/test_hf_argparser.py": [
        [
          "test_11_parse_json",
          378,
          395,
          388,
          31,
          388,
          64,
          378,
          28,
          395,
          43
        ],
        [
          "test_12_parse_yaml",
          397,
          413,
          407,
          31,
          407,
          64,
          397,
          28,
          413,
          43
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_from_pretrained_dynamic_image_processor",
          171,
          206,
          196,
          44,
          196,
          86,
          171,
          54,
          206,
          87
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_image_processor_to_json_file",
          266,
          275,
          271,
          34,
          271,
          81,
          267,
          13,
          275,
          95
        ]
      ],
      "transformers/tests/models/imagegpt/test_image_processing_imagegpt.py": [
        [
          "test_image_processor_to_json_file",
          146,
          160,
          151,
          34,
          151,
          81,
          147,
          13,
          156,
          59
        ]
      ],
      "transformers/tests/models/oneformer/test_image_processing_oneformer.py": [
        [
          "test_can_load_with_local_metadata",
          359,
          378,
          369,
          33,
          369,
          73,
          367,
          13,
          378,
          64
        ]
      ],
      "transformers/tests/utils/test_model_card.py": [
        [
          "test_model_card_to_json_file",
          66,
          74,
          70,
          24,
          70,
          65,
          66,
          38,
          74,
          81
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_debugger_outputs",
          52,
          63,
          58,
          32,
          58,
          75,
          52,
          35,
          60,
          55
        ],
        [
          "test_debugger_outputs",
          52,
          63,
          59,
          29,
          59,
          77,
          52,
          35,
          60,
          55
        ],
        [
          "test_layer_pruning_behavior",
          96,
          122,
          102,
          32,
          102,
          97,
          96,
          41,
          106,
          43
        ],
        [
          "test_layer_pruning_behavior",
          96,
          122,
          117,
          32,
          117,
          97,
          113,
          18,
          122,
          99
        ]
      ],
      "transformers/tests/models/align/test_modeling_align.py": [
        [
          "_create_and_check_torchscript",
          491,
          560,
          511,
          32,
          511,
          76,
          510,
          18,
          514,
          25
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "_create_and_check_torchscript",
          467,
          536,
          487,
          32,
          487,
          76,
          486,
          18,
          490,
          25
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip.py": [
        [
          "_create_and_check_torchscript",
          459,
          528,
          479,
          32,
          479,
          76,
          478,
          18,
          482,
          25
        ],
        [
          "_create_and_check_torchscript",
          949,
          1018,
          969,
          32,
          969,
          76,
          968,
          18,
          972,
          25
        ],
        [
          "_create_and_check_torchscript",
          1138,
          1207,
          1158,
          32,
          1158,
          76,
          1157,
          18,
          1161,
          25
        ]
      ],
      "transformers/tests/models/chinese_clip/test_modeling_chinese_clip.py": [
        [
          "_create_and_check_torchscript",
          574,
          643,
          594,
          32,
          594,
          76,
          593,
          18,
          597,
          25
        ]
      ],
      "transformers/tests/models/clap/test_modeling_clap.py": [
        [
          "_create_and_check_torchscript",
          528,
          597,
          548,
          32,
          548,
          76,
          547,
          18,
          551,
          25
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "_create_and_check_torchscript",
          493,
          562,
          513,
          32,
          513,
          76,
          512,
          18,
          516,
          25
        ]
      ],
      "transformers/tests/models/clip/test_modeling_clip.py": [
        [
          "_create_and_check_torchscript",
          565,
          634,
          585,
          32,
          585,
          76,
          584,
          18,
          588,
          25
        ]
      ],
      "transformers/tests/models/dac/test_modeling_dac.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          208,
          32,
          208,
          76,
          207,
          18,
          211,
          25
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "test_save_load",
          710,
          755,
          735,
          48,
          735,
          84,
          723,
          13,
          751,
          39
        ],
        [
          "test_save_load",
          710,
          755,
          737,
          58,
          737,
          105,
          723,
          13,
          751,
          39
        ],
        [
          "test_save_load_keys_to_ignore_on_save",
          787,
          817,
          803,
          37,
          803,
          79,
          801,
          18,
          806,
          48
        ],
        [
          "test_torch_save_load",
          975,
          1022,
          1018,
          38,
          1018,
          82,
          991,
          29,
          1022,
          64
        ],
        [
          "_create_and_check_torchscript",
          1385,
          1521,
          1467,
          36,
          1467,
          80,
          1466,
          22,
          1470,
          29
        ],
        [
          "test_model_weights_reload_no_missing_tied_weights",
          2530,
          2586,
          2540,
          50,
          2540,
          91,
          2531,
          13,
          2553,
          71
        ]
      ],
      "transformers/tests/models/encodec/test_modeling_encodec.py": [
        [
          "_create_and_check_torchscript",
          212,
          300,
          235,
          32,
          235,
          76,
          234,
          18,
          238,
          25
        ]
      ],
      "transformers/tests/models/flava/test_modeling_flava.py": [
        [
          "_create_and_check_torchscript",
          920,
          999,
          948,
          32,
          948,
          76,
          947,
          18,
          951,
          25
        ]
      ],
      "transformers/tests/models/groupvit/test_modeling_groupvit.py": [
        [
          "_create_and_check_torchscript",
          569,
          638,
          589,
          32,
          589,
          76,
          588,
          18,
          592,
          25
        ]
      ],
      "transformers/tests/models/hubert/test_modeling_hubert.py": [
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          506,
          33,
          506,
          71,
          505,
          18,
          508,
          50
        ]
      ],
      "transformers/tests/models/kosmos2/test_modeling_kosmos2.py": [
        [
          "_create_and_check_torchscript",
          490,
          568,
          514,
          32,
          514,
          76,
          513,
          18,
          517,
          25
        ]
      ],
      "transformers/tests/models/megatron_gpt2/test_modeling_megatron_gpt2.py": [
        [
          "test_inference_no_head",
          34,
          84,
          37,
          25,
          37,
          68,
          37,
          25,
          37,
          21
        ]
      ],
      "transformers/tests/models/megatron_bert/test_modeling_megatron_bert.py": [
        [
          "test_inference_no_head",
          365,
          384,
          368,
          25,
          368,
          68,
          368,
          25,
          368,
          21
        ]
      ],
      "transformers/tests/models/metaclip_2/test_modeling_metaclip_2.py": [
        [
          "_create_and_check_torchscript",
          575,
          644,
          595,
          32,
          595,
          76,
          594,
          18,
          598,
          25
        ]
      ],
      "transformers/tests/models/mimi/test_modeling_mimi.py": [
        [
          "_create_and_check_torchscript",
          225,
          313,
          248,
          32,
          248,
          76,
          247,
          18,
          251,
          25
        ]
      ],
      "transformers/tests/models/modernbert/test_modeling_modernbert.py": [
        [
          "test_saved_config_excludes_reference_compile",
          363,
          369,
          367,
          23,
          367,
          61,
          363,
          54,
          369,
          62
        ]
      ],
      "transformers/tests/models/mt5/test_modeling_mt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          686,
          33,
          686,
          71,
          685,
          18,
          688,
          50
        ]
      ],
      "transformers/tests/models/owlv2/test_modeling_owlv2.py": [
        [
          "_create_and_check_torchscript",
          462,
          527,
          481,
          32,
          481,
          76,
          480,
          18,
          484,
          25
        ],
        [
          "_create_and_check_torchscript",
          671,
          736,
          690,
          32,
          690,
          76,
          689,
          18,
          693,
          25
        ]
      ],
      "transformers/tests/models/owlvit/test_modeling_owlvit.py": [
        [
          "_create_and_check_torchscript",
          457,
          522,
          476,
          32,
          476,
          76,
          475,
          18,
          479,
          25
        ],
        [
          "_create_and_check_torchscript",
          664,
          729,
          683,
          32,
          683,
          76,
          682,
          18,
          686,
          25
        ]
      ],
      "transformers/tests/models/pix2struct/test_modeling_pix2struct.py": [
        [
          "_create_and_check_torchscript",
          623,
          692,
          643,
          32,
          643,
          76,
          642,
          18,
          646,
          25
        ]
      ]
    },
    "open": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUpClass",
          1066,
          1077,
          1076,
          14,
          1076,
          39,
          1066,
          20,
          1077,
          38
        ],
        [
          "setUp",
          113,
          178,
          137,
          14,
          137,
          57,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          171,
          14,
          171,
          57,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          173,
          14,
          173,
          58,
          113,
          15,
          178,
          55
        ],
        [
          "setUpClass",
          685,
          696,
          695,
          14,
          695,
          39,
          685,
          20,
          696,
          38
        ]
      ],
      "transformers/tests/models/t5/test_modeling_t5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          696,
          26,
          696,
          50,
          693,
          18,
          696,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          698,
          26,
          698,
          50,
          698,
          26,
          698,
          50
        ]
      ],
      "transformers/tests/models/umt5/test_modeling_umt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          384,
          26,
          384,
          50,
          381,
          18,
          384,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          386,
          26,
          386,
          50,
          386,
          26,
          386,
          50
        ]
      ],
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "remove_dtype",
          654,
          660,
          656,
          18,
          656,
          45,
          654,
          26,
          660,
          31
        ],
        [
          "remove_dtype",
          654,
          660,
          659,
          18,
          659,
          50,
          654,
          26,
          660,
          31
        ],
        [
          "test_model_from_pretrained_dtype",
          641,
          726,
          688,
          14,
          688,
          46,
          641,
          42,
          726,
          53
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          815,
          22,
          815,
          55,
          815,
          22,
          824,
          77
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1322,
          22,
          1322,
          68,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          1998,
          18,
          1998,
          62,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2024,
          18,
          2024,
          62,
          2006,
          66,
          2030,
          85
        ],
        [
          "test_device_map_works_with_unexpected_keys_sharded",
          2109,
          2147,
          2133,
          14,
          2133,
          83,
          2109,
          60,
          2139,
          54
        ]
      ],
      "transformers/tests/models/wav2vec2/test_modeling_wav2vec2.py": [
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          762,
          26,
          762,
          50,
          759,
          18,
          762,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          764,
          26,
          764,
          50,
          764,
          26,
          764,
          50
        ]
      ],
      "transformers/tests/sagemaker/test_multi_node_data_parallel.py": [
        [
          "test_script",
          74,
          99,
          98,
          14,
          98,
          68,
          95,
          9,
          99,
          117
        ]
      ],
      "transformers/tests/sagemaker/test_multi_node_model_parallel.py": [
        [
          "test_scripz",
          94,
          119,
          118,
          14,
          118,
          68,
          115,
          9,
          119,
          117
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_common.py": [
        [
          "test_push_to_hub_dynamic_pipeline",
          886,
          964,
          902,
          18,
          902,
          56,
          886,
          43,
          964,
          9
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_text_to_text.py": [
        [
          "test_model_pt_chat_template_image_url_base64",
          370,
          388,
          371,
          14,
          371,
          79,
          370,
          54,
          388,
          82
        ]
      ],
      "transformers/tests/models/align/test_processing_align.py": [
        [
          "setUp",
          39,
          72,
          60,
          14,
          60,
          57,
          39,
          15,
          72,
          46
        ],
        [
          "setUp",
          39,
          72,
          71,
          14,
          71,
          67,
          39,
          15,
          72,
          46
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "setUpClass",
          40,
          84,
          64,
          14,
          64,
          56,
          40,
          20,
          84,
          49
        ],
        [
          "setUpClass",
          40,
          84,
          78,
          14,
          78,
          66,
          40,
          20,
          84,
          49
        ]
      ],
      "transformers/tests/models/clipseg/test_processing_clipseg.py": [
        [
          "setUp",
          39,
          65,
          49,
          14,
          49,
          57,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          51,
          14,
          51,
          58,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          64,
          14,
          64,
          67,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/flava/test_processing_flava.py": [
        [
          "setUp",
          46,
          81,
          52,
          14,
          52,
          57,
          46,
          15,
          81,
          46
        ],
        [
          "setUp",
          46,
          81,
          80,
          14,
          80,
          67,
          46,
          15,
          81,
          46
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "setUpClass",
          48,
          80,
          53,
          14,
          53,
          56,
          48,
          20,
          80,
          22
        ],
        [
          "setUpClass",
          48,
          80,
          67,
          14,
          67,
          66,
          48,
          20,
          80,
          22
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "setUpClass",
          49,
          67,
          58,
          14,
          58,
          69,
          49,
          20,
          67,
          49
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_processing_layoutlmv2.py": [
        [
          "setUp",
          42,
          73,
          69,
          14,
          69,
          57,
          42,
          15,
          73,
          60
        ],
        [
          "setUp",
          42,
          73,
          72,
          14,
          72,
          68,
          42,
          15,
          73,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_processing_layoutlmv3.py": [
        [
          "setUp",
          42,
          86,
          73,
          14,
          73,
          57,
          42,
          15,
          86,
          60
        ],
        [
          "setUp",
          42,
          86,
          75,
          14,
          75,
          58,
          42,
          15,
          86,
          60
        ],
        [
          "setUp",
          42,
          86,
          85,
          14,
          85,
          70,
          42,
          15,
          86,
          60
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "setUp",
          50,
          70,
          58,
          14,
          58,
          57,
          50,
          15,
          70,
          46
        ],
        [
          "setUp",
          50,
          70,
          69,
          14,
          69,
          67,
          50,
          15,
          70,
          46
        ]
      ],
      "transformers/tests/models/markuplm/test_processing_markuplm.py": [
        [
          "setUp",
          47,
          70,
          60,
          14,
          60,
          57,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          62,
          14,
          62,
          58,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          64,
          14,
          64,
          68,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          69,
          14,
          69,
          70,
          47,
          15,
          70,
          62
        ]
      ],
      "transformers/tests/models/owlvit/test_processing_owlvit.py": [
        [
          "setUp",
          39,
          65,
          49,
          14,
          49,
          57,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          51,
          14,
          51,
          58,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          64,
          14,
          64,
          67,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/oneformer/test_processing_oneformer.py": [
        [
          "prepare_metadata",
          43,
          58,
          44,
          10,
          44,
          79,
          43,
          22,
          50,
          39
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_processing_shieldgemma2.py": [
        [
          "test_policy_definitions_saved_in_config",
          102,
          110,
          105,
          14,
          105,
          46,
          102,
          49,
          110,
          62
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "setUpClass",
          31,
          42,
          36,
          14,
          36,
          56,
          31,
          20,
          42,
          49
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "setUpClass",
          41,
          65,
          64,
          14,
          64,
          69,
          41,
          20,
          65,
          62
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "setUpClass",
          39,
          61,
          44,
          14,
          44,
          56,
          39,
          20,
          61,
          49
        ],
        [
          "setUpClass",
          39,
          61,
          55,
          14,
          55,
          66,
          39,
          20,
          61,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "setUpClass",
          35,
          63,
          56,
          14,
          56,
          56,
          35,
          20,
          63,
          49
        ],
        [
          "setUpClass",
          35,
          63,
          59,
          14,
          59,
          69,
          35,
          20,
          63,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "setUpClass",
          36,
          64,
          57,
          14,
          57,
          56,
          36,
          20,
          64,
          49
        ],
        [
          "setUpClass",
          36,
          64,
          60,
          14,
          60,
          69,
          36,
          20,
          64,
          49
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_processor_from_processor_class",
          97,
          123,
          110,
          22,
          110,
          72,
          109,
          32,
          111,
          46
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          114,
          18,
          114,
          70,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          118,
          18,
          118,
          75,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          137,
          22,
          137,
          67,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          141,
          22,
          141,
          72,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          145,
          18,
          145,
          70,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          149,
          18,
          149,
          75,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          168,
          22,
          168,
          67,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          172,
          22,
          172,
          72,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          176,
          18,
          176,
          71,
          176,
          18,
          185,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          180,
          18,
          180,
          76,
          176,
          18,
          185,
          59
        ],
        [
          "test_processor_from_local_directory_from_model_config",
          187,
          199,
          194,
          18,
          194,
          76,
          187,
          63,
          199,
          59
        ],
        [
          "test_new_processor_registration",
          234,
          270,
          249,
          22,
          249,
          60,
          248,
          17,
          249,
          60
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          466,
          22,
          466,
          60,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          486,
          22,
          486,
          73,
          456,
          44,
          505,
          85
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "setUp",
          50,
          77,
          70,
          14,
          70,
          57,
          50,
          15,
          77,
          25
        ],
        [
          "setUp",
          50,
          77,
          73,
          14,
          73,
          70,
          50,
          15,
          77,
          25
        ]
      ],
      "transformers/examples/pytorch/test_pytorch_examples.py": [
        [
          "get_results",
          85,
          93,
          89,
          14,
          89,
          23,
          89,
          14,
          93,
          18
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "setUp",
          43,
          105,
          68,
          14,
          68,
          57,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          102,
          14,
          102,
          57,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          104,
          14,
          104,
          58,
          43,
          15,
          105,
          39
        ]
      ],
      "transformers/tests/sagemaker/test_single_node_gpu.py": [
        [
          "test_glue",
          61,
          86,
          85,
          14,
          85,
          68,
          82,
          9,
          86,
          117
        ]
      ],
      "transformers/tests/models/bart/test_tokenization_bart.py": [
        [
          "setUpClass",
          36,
          70,
          69,
          14,
          69,
          57,
          36,
          20,
          70,
          39
        ],
        [
          "setUpClass",
          36,
          70,
          67,
          14,
          67,
          56,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          349,
          22,
          349,
          78,
          332,
          13,
          354,
          73
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          481,
          18,
          481,
          46,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          485,
          18,
          485,
          49,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          494,
          18,
          494,
          39,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          507,
          18,
          507,
          49,
          456,
          40,
          513,
          18
        ]
      ],
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "create_tmp_repo",
          85,
          168,
          102,
          10,
          102,
          52,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          108,
          10,
          108,
          63,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          110,
          10,
          110,
          58,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          115,
          10,
          115,
          45,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          117,
          10,
          117,
          40,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          119,
          10,
          119,
          44,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          124,
          10,
          124,
          45,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          130,
          14,
          130,
          49,
          127,
          9,
          136,
          34
        ],
        [
          "create_tmp_repo",
          85,
          168,
          132,
          14,
          132,
          63,
          127,
          9,
          136,
          34
        ],
        [
          "create_tmp_repo",
          85,
          168,
          134,
          14,
          134,
          58,
          127,
          9,
          136,
          34
        ],
        [
          "create_tmp_repo",
          85,
          168,
          140,
          10,
          140,
          56,
          138,
          16,
          143,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          147,
          14,
          147,
          68,
          143,
          9,
          150,
          13
        ],
        [
          "create_tmp_repo",
          85,
          168,
          156,
          10,
          156,
          62,
          152,
          19,
          168,
          15
        ],
        [
          "create_tmp_repo",
          85,
          168,
          160,
          10,
          160,
          44,
          152,
          19,
          168,
          15
        ],
        [
          "commit_changes",
          190,
          205,
          201,
          14,
          201,
          41,
          200,
          9,
          202,
          28
        ],
        [
          "test_checkout_commit",
          209,
          224,
          219,
          22,
          219,
          58,
          218,
          17,
          220,
          54
        ],
        [
          "test_checkout_commit",
          209,
          224,
          223,
          18,
          223,
          54,
          222,
          13,
          224,
          64
        ],
        [
          "test_extract_imports_relative",
          291,
          330,
          309,
          18,
          309,
          59,
          307,
          17,
          318,
          83
        ],
        [
          "test_extract_imports_relative",
          291,
          330,
          321,
          18,
          321,
          59,
          318,
          17,
          330,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          337,
          18,
          337,
          59,
          332,
          39,
          346,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          349,
          18,
          349,
          59,
          346,
          17,
          358,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          361,
          18,
          361,
          59,
          358,
          17,
          370,
          83
        ],
        [
          "test_get_module_dependencies",
          372,
          434,
          399,
          18,
          399,
          59,
          392,
          17,
          409,
          96
        ],
        [
          "test_get_module_dependencies",
          372,
          434,
          413,
          18,
          413,
          59,
          409,
          17,
          423,
          96
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          618,
          22,
          618,
          57,
          604,
          33,
          623,
          76
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          620,
          22,
          620,
          64,
          604,
          33,
          623,
          76
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          632,
          18,
          632,
          71,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          638,
          18,
          638,
          53,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          640,
          18,
          640,
          61,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          642,
          18,
          642,
          56,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          649,
          18,
          649,
          60,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          659,
          22,
          659,
          57,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          661,
          22,
          661,
          64,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          675,
          22,
          675,
          57,
          671,
          13,
          682,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          677,
          22,
          677,
          64,
          671,
          13,
          682,
          65
        ],
        [
          "test_infer_tests_to_run_with_test_modifs",
          686,
          703,
          700,
          22,
          700,
          57,
          686,
          50,
          703,
          76
        ],
        [
          "test_infer_tests_to_run_with_examples_modifs",
          706,
          739,
          721,
          22,
          721,
          64,
          706,
          54,
          724,
          86
        ],
        [
          "test_infer_tests_to_run_with_examples_modifs",
          706,
          739,
          736,
          22,
          736,
          64,
          724,
          13,
          739,
          86
        ]
      ],
      "transformers/tests/models/bartpho/test_tokenization_bartpho.py": [
        [
          "setUpClass",
          34,
          47,
          42,
          14,
          42,
          68,
          34,
          20,
          43,
          37
        ]
      ],
      "transformers/tests/models/bertweet/test_tokenization_bertweet.py": [
        [
          "setUpClass",
          29,
          44,
          40,
          14,
          40,
          56,
          29,
          20,
          41,
          37
        ],
        [
          "setUpClass",
          29,
          44,
          43,
          14,
          43,
          57,
          43,
          14,
          44,
          39
        ]
      ],
      "transformers/tests/models/biogpt/test_tokenization_biogpt.py": [
        [
          "setUpClass",
          33,
          68,
          65,
          14,
          65,
          38,
          33,
          20,
          68,
          39
        ],
        [
          "setUpClass",
          33,
          68,
          67,
          14,
          67,
          39,
          33,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/bert/test_tokenization_bert.py": [
        [
          "setUpClass",
          44,
          66,
          65,
          14,
          65,
          56,
          44,
          20,
          66,
          73
        ]
      ],
      "transformers/tests/models/blenderbot_small/test_tokenization_blenderbot_small.py": [
        [
          "setUpClass",
          35,
          49,
          46,
          14,
          46,
          56,
          35,
          20,
          49,
          39
        ],
        [
          "setUpClass",
          35,
          49,
          48,
          14,
          48,
          57,
          35,
          20,
          49,
          39
        ]
      ],
      "transformers/tests/models/bert_japanese/test_tokenization_bert_japanese.py": [
        [
          "setUpClass",
          44,
          77,
          76,
          14,
          76,
          56,
          44,
          20,
          77,
          73
        ],
        [
          "test_pickle_mecab_tokenizer",
          106,
          124,
          116,
          14,
          116,
          33,
          106,
          37,
          124,
          51
        ],
        [
          "test_pickle_mecab_tokenizer",
          106,
          124,
          119,
          14,
          119,
          33,
          106,
          37,
          124,
          51
        ],
        [
          "test_pickle_sudachi_tokenizer",
          202,
          220,
          212,
          14,
          212,
          33,
          202,
          39,
          220,
          51
        ],
        [
          "test_pickle_sudachi_tokenizer",
          202,
          220,
          215,
          14,
          215,
          33,
          202,
          39,
          220,
          51
        ],
        [
          "test_pickle_jumanpp_tokenizer",
          297,
          315,
          307,
          14,
          307,
          33,
          297,
          39,
          315,
          51
        ],
        [
          "test_pickle_jumanpp_tokenizer",
          297,
          315,
          310,
          14,
          310,
          33,
          297,
          39,
          315,
          51
        ],
        [
          "setUpClass",
          412,
          419,
          418,
          14,
          418,
          56,
          412,
          20,
          419,
          73
        ]
      ],
      "transformers/tests/models/clip/test_tokenization_clip.py": [
        [
          "setUpClass",
          37,
          50,
          49,
          14,
          49,
          57,
          37,
          20,
          50,
          39
        ],
        [
          "setUpClass",
          37,
          50,
          47,
          14,
          47,
          56,
          37,
          20,
          50,
          39
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          212,
          22,
          212,
          93,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          215,
          22,
          215,
          91,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          225,
          22,
          225,
          98,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          227,
          22,
          227,
          96,
          208,
          13,
          255,
          17
        ]
      ],
      "transformers/tests/models/clvp/test_tokenization_clvp.py": [
        [
          "setUpClass",
          34,
          71,
          70,
          14,
          70,
          57,
          34,
          20,
          71,
          39
        ],
        [
          "setUpClass",
          34,
          71,
          68,
          14,
          68,
          56,
          34,
          20,
          71,
          39
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          225,
          22,
          225,
          93,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          228,
          22,
          228,
          91,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          240,
          22,
          240,
          98,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          242,
          22,
          242,
          96,
          221,
          13,
          275,
          17
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_conversion",
          375,
          393,
          382,
          18,
          382,
          62,
          375,
          25,
          393,
          60
        ],
        [
          "test_conversion",
          375,
          393,
          389,
          30,
          389,
          41,
          375,
          25,
          393,
          60
        ],
        [
          "test_conversion",
          375,
          393,
          390,
          18,
          390,
          48,
          375,
          25,
          393,
          60
        ]
      ],
      "transformers/tests/models/cpmant/test_tokenization_cpmant.py": [
        [
          "setUpClass",
          31,
          54,
          53,
          14,
          53,
          56,
          31,
          20,
          54,
          73
        ]
      ],
      "transformers/tests/models/ctrl/test_tokenization_ctrl.py": [
        [
          "setUpClass",
          31,
          45,
          42,
          14,
          42,
          56,
          31,
          20,
          45,
          39
        ],
        [
          "setUpClass",
          31,
          45,
          44,
          14,
          44,
          57,
          31,
          20,
          45,
          39
        ]
      ],
      "transformers/tests/models/deberta/test_tokenization_deberta.py": [
        [
          "setUpClass",
          34,
          69,
          68,
          14,
          68,
          57,
          34,
          20,
          69,
          39
        ],
        [
          "setUpClass",
          34,
          69,
          66,
          14,
          66,
          56,
          34,
          20,
          69,
          39
        ]
      ],
      "transformers/tests/models/codegen/test_tokenization_codegen.py": [
        [
          "setUpClass",
          38,
          74,
          73,
          14,
          73,
          57,
          38,
          20,
          74,
          39
        ],
        [
          "setUpClass",
          38,
          74,
          71,
          14,
          71,
          56,
          38,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/electra/test_tokenization_electra.py": [
        [
          "setUpClass",
          43,
          65,
          64,
          14,
          64,
          56,
          43,
          20,
          65,
          73
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "setUpClass",
          233,
          255,
          252,
          14,
          252,
          82,
          252,
          14,
          255,
          22
        ],
        [
          "test_pickle_tokenizer",
          830,
          849,
          841,
          22,
          841,
          41,
          833,
          13,
          849,
          63
        ],
        [
          "test_pickle_tokenizer",
          830,
          849,
          844,
          22,
          844,
          41,
          833,
          13,
          849,
          63
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1712,
          53,
          1712,
          109,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1719,
          53,
          1719,
          109,
          1719,
          43,
          1728,
          111
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4234,
          22,
          4234,
          82,
          4229,
          13,
          4272,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4239,
          22,
          4239,
          87,
          4229,
          13,
          4272,
          17
        ]
      ],
      "transformers/tests/models/esm/test_tokenization_esm.py": [
        [
          "setUpClass",
          31,
          38,
          37,
          14,
          37,
          56,
          31,
          20,
          38,
          73
        ]
      ],
      "transformers/tests/models/flaubert/test_tokenization_flaubert.py": [
        [
          "setUpClass",
          33,
          47,
          44,
          14,
          44,
          56,
          33,
          20,
          47,
          39
        ],
        [
          "setUpClass",
          33,
          47,
          46,
          14,
          46,
          57,
          33,
          20,
          47,
          39
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_local_versioning",
          211,
          236,
          220,
          39,
          220,
          94,
          211,
          31,
          236,
          77
        ]
      ],
      "transformers/tests/models/funnel/test_tokenization_funnel.py": [
        [
          "setUpClass",
          35,
          55,
          54,
          14,
          54,
          56,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/gpt_neox_japanese/test_tokenization_gpt_neox_japanese.py": [
        [
          "setUpClass",
          37,
          72,
          69,
          14,
          69,
          56,
          37,
          20,
          72,
          56
        ],
        [
          "setUpClass",
          37,
          72,
          71,
          14,
          71,
          38,
          37,
          20,
          72,
          56
        ]
      ],
      "transformers/tests/models/gpt2/test_tokenization_gpt2.py": [
        [
          "setUpClass",
          37,
          73,
          70,
          14,
          70,
          56,
          37,
          20,
          73,
          39
        ],
        [
          "setUpClass",
          37,
          73,
          72,
          14,
          72,
          57,
          37,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/layoutlm/test_tokenization_layoutlm.py": [
        [
          "setUpClass",
          35,
          55,
          54,
          14,
          54,
          56,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/herbert/test_tokenization_herbert.py": [
        [
          "setUpClass",
          36,
          77,
          40,
          14,
          40,
          93,
          36,
          20,
          77,
          39
        ],
        [
          "setUpClass",
          36,
          77,
          74,
          14,
          74,
          38,
          36,
          20,
          77,
          39
        ],
        [
          "setUpClass",
          36,
          77,
          76,
          14,
          76,
          39,
          36,
          20,
          77,
          39
        ]
      ],
      "transformers/tests/models/fsmt/test_tokenization_fsmt.py": [
        [
          "setUpClass",
          37,
          85,
          78,
          14,
          78,
          42,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          80,
          14,
          80,
          42,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          82,
          14,
          82,
          39,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          84,
          14,
          84,
          35,
          37,
          20,
          85,
          40
        ]
      ],
      "transformers/tests/models/led/test_tokenization_led.py": [
        [
          "setUpClass",
          34,
          68,
          65,
          14,
          65,
          56,
          34,
          20,
          68,
          39
        ],
        [
          "setUpClass",
          34,
          68,
          67,
          14,
          67,
          57,
          34,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py": [
        [
          "setUpClass",
          136,
          158,
          157,
          14,
          157,
          56,
          136,
          20,
          158,
          73
        ]
      ],
      "transformers/tests/models/gemma/test_tokenization_gemma.py": [
        [
          "test_conversion",
          236,
          254,
          243,
          18,
          243,
          62,
          236,
          25,
          254,
          60
        ],
        [
          "test_conversion",
          236,
          254,
          250,
          30,
          250,
          41,
          236,
          25,
          254,
          60
        ],
        [
          "test_conversion",
          236,
          254,
          251,
          18,
          251,
          48,
          236,
          25,
          254,
          60
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_conversion",
          413,
          431,
          420,
          18,
          420,
          62,
          413,
          25,
          431,
          60
        ],
        [
          "test_conversion",
          413,
          431,
          427,
          30,
          427,
          41,
          413,
          25,
          431,
          60
        ],
        [
          "test_conversion",
          413,
          431,
          428,
          18,
          428,
          48,
          413,
          25,
          431,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "setUpClass",
          128,
          163,
          160,
          14,
          160,
          56,
          128,
          20,
          163,
          39
        ],
        [
          "setUpClass",
          128,
          163,
          162,
          14,
          162,
          57,
          128,
          20,
          163,
          39
        ]
      ],
      "transformers/tests/models/longformer/test_tokenization_longformer.py": [
        [
          "setUpClass",
          39,
          74,
          73,
          14,
          73,
          57,
          39,
          20,
          74,
          39
        ],
        [
          "setUpClass",
          39,
          74,
          71,
          14,
          71,
          56,
          39,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/lxmert/test_tokenization_lxmert.py": [
        [
          "setUpClass",
          35,
          55,
          54,
          14,
          54,
          56,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/mgp_str/test_tokenization_mgp_str.py": [
        [
          "setUpClass",
          36,
          44,
          43,
          14,
          43,
          56,
          36,
          20,
          44,
          53
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "setUpClass",
          52,
          71,
          68,
          14,
          68,
          57,
          52,
          20,
          71,
          62
        ],
        [
          "setUpClass",
          52,
          71,
          66,
          14,
          66,
          56,
          52,
          20,
          71,
          62
        ],
        [
          "setUpClass",
          52,
          71,
          70,
          14,
          70,
          67,
          52,
          20,
          71,
          62
        ]
      ],
      "transformers/tests/models/mobilebert/test_tokenization_mobilebert.py": [
        [
          "setUpClass",
          44,
          71,
          65,
          14,
          65,
          56,
          44,
          20,
          68,
          27
        ]
      ],
      "transformers/tests/models/mpnet/test_tokenization_mpnet.py": [
        [
          "setUpClass",
          35,
          57,
          56,
          14,
          56,
          56,
          35,
          20,
          57,
          73
        ]
      ],
      "transformers/tests/models/mvp/test_tokenization_mvp.py": [
        [
          "setUpClass",
          36,
          70,
          69,
          14,
          69,
          57,
          36,
          20,
          70,
          39
        ],
        [
          "setUpClass",
          36,
          70,
          67,
          14,
          67,
          56,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/models/openai/test_tokenization_openai.py": [
        [
          "setUpClass",
          38,
          73,
          70,
          14,
          70,
          38,
          38,
          20,
          73,
          39
        ],
        [
          "setUpClass",
          38,
          73,
          72,
          14,
          72,
          39,
          38,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/phobert/test_tokenization_phobert.py": [
        [
          "setUpClass",
          29,
          45,
          44,
          14,
          44,
          57,
          44,
          14,
          45,
          39
        ],
        [
          "setUpClass",
          29,
          45,
          41,
          14,
          41,
          56,
          29,
          20,
          42,
          37
        ]
      ],
      "transformers/tests/models/prophetnet/test_tokenization_prophetnet.py": [
        [
          "setUpClass",
          39,
          61,
          60,
          14,
          60,
          56,
          39,
          20,
          61,
          73
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          208,
          22,
          208,
          93,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          211,
          22,
          211,
          91,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          223,
          22,
          223,
          98,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          225,
          22,
          225,
          96,
          204,
          13,
          257,
          17
        ]
      ],
      "transformers/tests/models/pop2piano/test_tokenization_pop2piano.py": [
        [
          "test_pickle_tokenizer",
          227,
          242,
          234,
          14,
          234,
          33,
          227,
          31,
          242,
          55
        ],
        [
          "test_pickle_tokenizer",
          227,
          242,
          237,
          14,
          237,
          33,
          227,
          31,
          242,
          55
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "setUp",
          38,
          100,
          63,
          14,
          63,
          57,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          97,
          14,
          97,
          57,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          99,
          14,
          99,
          58,
          38,
          15,
          100,
          39
        ]
      ],
      "transformers/tests/models/qwen2/test_tokenization_qwen2.py": [
        [
          "setUpClass",
          40,
          92,
          89,
          14,
          89,
          56,
          40,
          20,
          92,
          39
        ],
        [
          "setUpClass",
          40,
          92,
          91,
          14,
          91,
          57,
          40,
          20,
          92,
          39
        ]
      ],
      "transformers/tests/models/roberta/test_tokenization_roberta.py": [
        [
          "setUpClass",
          37,
          72,
          69,
          14,
          69,
          56,
          37,
          20,
          72,
          39
        ],
        [
          "setUpClass",
          37,
          72,
          71,
          14,
          71,
          57,
          37,
          20,
          72,
          39
        ]
      ],
      "transformers/tests/models/roc_bert/test_tokenization_roc_bert.py": [
        [
          "setUpClass",
          44,
          61,
          56,
          14,
          56,
          56,
          53,
          26,
          61,
          88
        ],
        [
          "setUpClass",
          44,
          61,
          60,
          14,
          60,
          69,
          53,
          26,
          61,
          88
        ],
        [
          "setUpClass",
          44,
          61,
          58,
          14,
          58,
          61,
          53,
          26,
          61,
          88
        ]
      ],
      "transformers/tests/models/siglip/test_tokenization_siglip.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          255,
          22,
          255,
          93,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          258,
          22,
          258,
          91,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          270,
          22,
          270,
          98,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          272,
          22,
          272,
          96,
          251,
          13,
          305,
          17
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          103,
          18,
          103,
          45,
          102,
          9,
          103,
          45
        ],
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          90,
          18,
          90,
          37,
          89,
          13,
          90,
          37
        ],
        [
          "test_push_to_hub",
          122,
          132,
          126,
          22,
          126,
          60,
          122,
          26,
          132,
          70
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          134,
          146,
          138,
          22,
          138,
          60,
          134,
          46,
          146,
          70
        ],
        [
          "test_push_to_hub_in_organization",
          148,
          158,
          152,
          22,
          152,
          60,
          148,
          42,
          158,
          70
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          160,
          172,
          164,
          22,
          164,
          60,
          160,
          62,
          172,
          70
        ],
        [
          "test_push_to_hub_dynamic_tokenizer",
          175,
          189,
          180,
          22,
          180,
          60,
          175,
          44,
          189,
          77
        ],
        [
          "test_push_to_hub_dynamic_tokenizer_with_both_slow_and_fast_classes",
          192,
          215,
          201,
          22,
          201,
          60,
          192,
          76,
          215,
          77
        ]
      ],
      "transformers/tests/models/tapas/test_tokenization_tapas.py": [
        [
          "setUpClass",
          113,
          135,
          134,
          14,
          134,
          56,
          113,
          20,
          135,
          73
        ]
      ],
      "transformers/tests/models/vits/test_tokenization_vits.py": [
        [
          "setUpClass",
          35,
          52,
          51,
          14,
          51,
          56,
          35,
          20,
          52,
          53
        ]
      ],
      "transformers/tests/models/t5/test_tokenization_t5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          306,
          22,
          306,
          93,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          309,
          22,
          309,
          91,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          321,
          22,
          321,
          98,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          323,
          22,
          323,
          96,
          302,
          13,
          356,
          17
        ]
      ],
      "transformers/tests/models/wav2vec2_phoneme/test_tokenization_wav2vec2_phoneme.py": [
        [
          "setUpClass",
          35,
          59,
          58,
          14,
          58,
          56,
          35,
          20,
          59,
          53
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "setUpClass",
          60,
          71,
          70,
          14,
          70,
          56,
          60,
          20,
          71,
          53
        ],
        [
          "setUpClass",
          379,
          390,
          389,
          14,
          389,
          56,
          379,
          20,
          390,
          53
        ],
        [
          "test_special_characters_in_vocab",
          478,
          496,
          484,
          14,
          484,
          34,
          478,
          42,
          496,
          45
        ],
        [
          "test_nested_vocab",
          789,
          832,
          819,
          18,
          819,
          41,
          789,
          27,
          832,
          60
        ]
      ],
      "transformers/tests/models/xlm/test_tokenization_xlm.py": [
        [
          "setUpClass",
          32,
          67,
          64,
          14,
          64,
          38,
          32,
          20,
          67,
          39
        ],
        [
          "setUpClass",
          32,
          67,
          66,
          14,
          66,
          39,
          32,
          20,
          67,
          39
        ]
      ],
      "transformers/tests/trainer/test_trainer_distributed_loss.py": [
        [
          "test_trainer",
          29,
          61,
          45,
          14,
          45,
          51,
          45,
          14,
          61,
          45
        ],
        [
          "test_trainer",
          29,
          61,
          47,
          14,
          47,
          53,
          45,
          14,
          61,
          45
        ],
        [
          "test_trainer",
          29,
          61,
          49,
          14,
          49,
          52,
          45,
          14,
          61,
          45
        ],
        [
          "run_distributed_training",
          64,
          101,
          100,
          10,
          100,
          61,
          64,
          30,
          101,
          42
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          723,
          14,
          723,
          52,
          712,
          22,
          727,
          60
        ],
        [
          "test_accelerator_config_from_yaml",
          4532,
          4555,
          4537,
          18,
          4537,
          37,
          4532,
          43,
          4555,
          77
        ]
      ],
      "transformers/tests/models/auto/test_video_processing_auto.py": [
        [
          "test_video_processor_from_local_directory_from_key",
          49,
          63,
          58,
          17,
          58,
          44,
          49,
          60,
          63,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_key",
          49,
          63,
          60,
          58,
          60,
          82,
          49,
          60,
          63,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_preprocessor_key",
          65,
          80,
          75,
          17,
          75,
          44,
          65,
          73,
          80,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_preprocessor_key",
          65,
          80,
          77,
          58,
          77,
          82,
          65,
          73,
          80,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          94,
          17,
          94,
          44,
          82,
          63,
          114,
          67
        ],
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          96,
          58,
          96,
          82,
          82,
          63,
          114,
          67
        ],
        [
          "test_video_processor_from_local_file",
          116,
          128,
          124,
          17,
          124,
          44,
          116,
          46,
          128,
          71
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          193,
          21,
          193,
          48,
          190,
          25,
          193,
          48
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          195,
          62,
          195,
          86,
          195,
          28,
          195,
          86
        ]
      ],
      "transformers/tests/generation/test_utils.py": [
        [
          "test_custom_generate_local_directory",
          4625,
          4644,
          4630,
          18,
          4630,
          63,
          4625,
          46,
          4644,
          37
        ],
        [
          "test_custom_generate_local_directory",
          4625,
          4644,
          4632,
          18,
          4632,
          61,
          4625,
          46,
          4644,
          37
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "diff_is_docstring_only",
          185,
          208,
          199,
          14,
          199,
          59,
          185,
          28,
          208,
          49
        ],
        [
          "diff_is_docstring_only",
          185,
          208,
          202,
          10,
          202,
          55,
          185,
          28,
          208,
          49
        ],
        [
          "diff_contains_doc_examples",
          211,
          234,
          225,
          14,
          225,
          59,
          211,
          32,
          234,
          49
        ],
        [
          "diff_contains_doc_examples",
          211,
          234,
          228,
          10,
          228,
          55,
          211,
          32,
          234,
          49
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          270,
          18,
          270,
          92,
          268,
          9,
          287,
          30
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          273,
          14,
          273,
          88,
          268,
          9,
          287,
          30
        ],
        [
          "get_all_doctest_files",
          429,
          459,
          453,
          10,
          453,
          40,
          430,
          5,
          459,
          36
        ],
        [
          "get_new_doctest_files",
          462,
          486,
          477,
          18,
          477,
          80,
          475,
          18,
          485,
          38
        ],
        [
          "get_new_doctest_files",
          462,
          486,
          479,
          14,
          479,
          76,
          475,
          18,
          485,
          38
        ],
        [
          "get_doctest_files",
          489,
          534,
          525,
          10,
          525,
          51,
          518,
          29,
          534,
          36
        ],
        [
          "extract_imports",
          558,
          637,
          577,
          10,
          577,
          65,
          577,
          10,
          597,
          43
        ],
        [
          "init_test_examples_dependencies",
          798,
          827,
          819,
          14,
          819,
          51,
          818,
          9,
          826,
          116
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          1037,
          14,
          1037,
          54,
          1036,
          24,
          1038,
          43
        ],
        [
          "filter_tests",
          1041,
          1065,
          1052,
          10,
          1052,
          49,
          1052,
          10,
          1055,
          27
        ],
        [
          "filter_tests",
          1041,
          1065,
          1064,
          10,
          1064,
          49,
          1064,
          10,
          1065,
          37
        ],
        [
          "create_test_list_from_filter",
          1109,
          1121,
          1120,
          18,
          1120,
          37,
          1120,
          18,
          1121,
          49
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "save_vocabulary",
          302,
          317,
          313,
          18,
          313,
          43,
          313,
          18,
          315,
          46
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "__init__",
          155,
          207,
          180,
          14,
          180,
          47,
          178,
          22,
          207,
          9
        ],
        [
          "__init__",
          155,
          207,
          186,
          14,
          186,
          48,
          178,
          22,
          207,
          9
        ],
        [
          "save_vocabulary",
          282,
          309,
          293,
          14,
          293,
          52,
          290,
          30,
          299,
          95
        ],
        [
          "save_vocabulary",
          282,
          309,
          297,
          14,
          297,
          52,
          290,
          30,
          299,
          95
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez.py": [
        [
          "save_vocabulary",
          273,
          288,
          284,
          18,
          284,
          43,
          284,
          18,
          286,
          46
        ]
      ],
      "transformers/src/transformers/models/bartpho/tokenization_bartpho.py": [
        [
          "__init__",
          109,
          161,
          142,
          14,
          142,
          64,
          142,
          14,
          143,
          37
        ],
        [
          "save_vocabulary",
          286,
          315,
          301,
          18,
          301,
          43,
          301,
          18,
          303,
          46
        ],
        [
          "save_vocabulary",
          286,
          315,
          310,
          18,
          310,
          72,
          310,
          18,
          311,
          55
        ]
      ],
      "transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py": [
        [
          "save_vocabulary",
          159,
          174,
          170,
          18,
          170,
          43,
          170,
          18,
          172,
          46
        ]
      ],
      "transformers/src/transformers/models/bert/tokenization_bert.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          239,
          257,
          247,
          14,
          247,
          52,
          247,
          14,
          248,
          86
        ]
      ],
      "transformers/src/transformers/models/bert_japanese/tokenization_bert_japanese.py": [
        [
          "load_vocab",
          40,
          48,
          43,
          10,
          43,
          48,
          40,
          16,
          45,
          41
        ],
        [
          "save_vocabulary",
          312,
          342,
          327,
          18,
          327,
          39,
          327,
          18,
          329,
          50
        ],
        [
          "save_vocabulary",
          312,
          342,
          331,
          18,
          331,
          56,
          331,
          18,
          333,
          90
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2286,
          14,
          2286,
          49,
          2285,
          9,
          2289,
          42
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2316,
          10,
          2316,
          49,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2321,
          10,
          2321,
          50,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2326,
          10,
          2326,
          49,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2330,
          10,
          2330,
          42,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2334,
          10,
          2334,
          44,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2348,
          10,
          2348,
          49,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2352,
          10,
          2352,
          41,
          2295,
          5,
          2359,
          25
        ],
        [
          "check_json_file_has_correct_format",
          2496,
          2510,
          2497,
          10,
          2497,
          24,
          2496,
          40,
          2499,
          26
        ],
        [
          "_get_test_info",
          3345,
          3459,
          3432,
          10,
          3432,
          31,
          3424,
          19,
          3459,
          5
        ],
        [
          "_get_test_info",
          3345,
          3459,
          3438,
          10,
          3438,
          26,
          3424,
          19,
          3459,
          5
        ],
        [
          "_prepare_debugging_info",
          3522,
          3531,
          3528,
          10,
          3528,
          21,
          3522,
          29,
          3531,
          15
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "save_vocabulary",
          233,
          248,
          244,
          18,
          244,
          43,
          244,
          18,
          246,
          46
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "__init__",
          107,
          165,
          145,
          14,
          145,
          48,
          132,
          27,
          165,
          9
        ],
        [
          "save_vocabulary",
          373,
          394,
          387,
          18,
          387,
          43,
          387,
          18,
          389,
          46
        ],
        [
          "add_from_file",
          402,
          423,
          408,
          22,
          408,
          51,
          407,
          13,
          408,
          51
        ]
      ],
      "transformers/src/transformers/models/biogpt/tokenization_biogpt.py": [
        [
          "__init__",
          92,
          134,
          118,
          14,
          118,
          47,
          104,
          20,
          134,
          9
        ],
        [
          "__init__",
          92,
          134,
          121,
          14,
          121,
          48,
          104,
          20,
          134,
          9
        ],
        [
          "save_vocabulary",
          284,
          310,
          295,
          14,
          295,
          52,
          292,
          30,
          300,
          95
        ],
        [
          "save_vocabulary",
          284,
          310,
          299,
          14,
          299,
          52,
          292,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/auto/tokenization_auto.py": [
        [
          "get_tokenizer_config",
          821,
          924,
          921,
          10,
          921,
          53,
          919,
          19,
          924,
          17
        ]
      ],
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "__init__",
          81,
          99,
          91,
          14,
          91,
          47,
          82,
          9,
          99,
          118
        ],
        [
          "__init__",
          81,
          99,
          94,
          14,
          94,
          48,
          82,
          9,
          99,
          118
        ],
        [
          "save_vocabulary",
          192,
          219,
          203,
          14,
          203,
          52,
          200,
          30,
          209,
          95
        ],
        [
          "save_vocabulary",
          192,
          219,
          207,
          14,
          207,
          52,
          200,
          30,
          209,
          95
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "__init__",
          162,
          220,
          193,
          14,
          193,
          47,
          186,
          13,
          220,
          9
        ],
        [
          "__init__",
          162,
          220,
          199,
          14,
          199,
          48,
          186,
          13,
          220,
          9
        ],
        [
          "save_vocabulary",
          305,
          332,
          316,
          14,
          316,
          52,
          313,
          30,
          322,
          95
        ],
        [
          "save_vocabulary",
          305,
          332,
          320,
          14,
          320,
          52,
          313,
          30,
          322,
          95
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert.py": [
        [
          "save_vocabulary",
          229,
          244,
          240,
          18,
          240,
          43,
          240,
          18,
          242,
          46
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "__init__",
          283,
          330,
          306,
          14,
          306,
          47,
          306,
          14,
          330,
          9
        ],
        [
          "__init__",
          283,
          330,
          312,
          14,
          312,
          48,
          306,
          14,
          330,
          9
        ],
        [
          "save_vocabulary",
          489,
          516,
          500,
          14,
          500,
          52,
          497,
          30,
          506,
          95
        ],
        [
          "save_vocabulary",
          489,
          516,
          504,
          14,
          504,
          52,
          497,
          30,
          506,
          95
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "__init__",
          140,
          189,
          163,
          14,
          163,
          47,
          157,
          21,
          189,
          9
        ],
        [
          "__init__",
          140,
          189,
          169,
          14,
          169,
          48,
          157,
          21,
          189,
          9
        ],
        [
          "save_vocabulary",
          337,
          364,
          348,
          14,
          348,
          52,
          345,
          30,
          354,
          95
        ],
        [
          "save_vocabulary",
          337,
          364,
          352,
          14,
          352,
          52,
          345,
          30,
          354,
          95
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama.py": [
        [
          "get_spm_processor",
          186,
          197,
          188,
          14,
          188,
          40,
          186,
          27,
          197,
          24
        ],
        [
          "save_vocabulary",
          331,
          356,
          352,
          18,
          352,
          43,
          352,
          18,
          354,
          46
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "__init__",
          140,
          188,
          163,
          14,
          163,
          47,
          163,
          14,
          188,
          9
        ],
        [
          "__init__",
          140,
          188,
          169,
          14,
          169,
          48,
          163,
          14,
          188,
          9
        ],
        [
          "save_vocabulary",
          276,
          303,
          287,
          14,
          287,
          52,
          284,
          30,
          293,
          95
        ],
        [
          "save_vocabulary",
          276,
          303,
          291,
          14,
          291,
          52,
          284,
          30,
          293,
          95
        ]
      ],
      "transformers/src/transformers/models/convbert/tokenization_convbert.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          242,
          260,
          250,
          14,
          250,
          52,
          250,
          14,
          251,
          86
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "save_vocabulary",
          327,
          342,
          338,
          18,
          338,
          43,
          338,
          18,
          340,
          46
        ]
      ],
      "transformers/src/transformers/models/cpmant/tokenization_cpmant.py": [
        [
          "load_vocab",
          36,
          44,
          39,
          10,
          39,
          48,
          36,
          16,
          41,
          41
        ],
        [
          "save_vocabulary",
          198,
          223,
          213,
          14,
          213,
          52,
          212,
          24,
          214,
          58
        ]
      ],
      "transformers/src/transformers/models/ctrl/tokenization_ctrl.py": [
        [
          "__init__",
          130,
          139,
          134,
          14,
          134,
          48,
          130,
          18,
          139,
          55
        ],
        [
          "__init__",
          130,
          139,
          131,
          14,
          131,
          47,
          130,
          18,
          139,
          55
        ],
        [
          "save_vocabulary",
          215,
          242,
          226,
          14,
          226,
          52,
          223,
          30,
          232,
          95
        ],
        [
          "save_vocabulary",
          215,
          242,
          230,
          14,
          230,
          52,
          223,
          30,
          232,
          95
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "__init__",
          140,
          195,
          167,
          14,
          167,
          47,
          164,
          22,
          195,
          9
        ],
        [
          "__init__",
          140,
          195,
          173,
          14,
          173,
          48,
          164,
          22,
          195,
          9
        ],
        [
          "save_vocabulary",
          330,
          357,
          341,
          14,
          341,
          52,
          338,
          30,
          347,
          95
        ],
        [
          "save_vocabulary",
          330,
          357,
          345,
          14,
          345,
          52,
          338,
          30,
          347,
          95
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2.py": [
        [
          "save_pretrained",
          440,
          447,
          445,
          14,
          445,
          34,
          444,
          21,
          447,
          27
        ]
      ],
      "transformers/src/transformers/models/distilbert/tokenization_distilbert.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          251,
          269,
          259,
          14,
          259,
          52,
          259,
          14,
          260,
          86
        ]
      ],
      "transformers/src/transformers/models/electra/tokenization_electra.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          241,
          259,
          249,
          14,
          249,
          52,
          249,
          14,
          250,
          86
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": [
        [
          "__init__",
          55,
          85,
          67,
          14,
          67,
          47,
          56,
          9,
          85,
          32
        ],
        [
          "save_vocabulary",
          146,
          167,
          164,
          14,
          164,
          52,
          161,
          30,
          167,
          28
        ]
      ],
      "transformers/src/transformers/models/deprecated/ernie_m/tokenization_ernie_m.py": [
        [
          "load_vocab",
          373,
          380,
          375,
          14,
          375,
          50,
          373,
          20,
          376,
          43
        ],
        [
          "save_vocabulary",
          382,
          406,
          390,
          14,
          390,
          52,
          390,
          14,
          391,
          86
        ],
        [
          "save_vocabulary",
          382,
          406,
          402,
          14,
          402,
          45,
          401,
          32,
          406,
          28
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "save_vocabulary",
          489,
          515,
          500,
          14,
          500,
          52,
          497,
          30,
          505,
          95
        ],
        [
          "save_vocabulary",
          489,
          515,
          504,
          14,
          504,
          52,
          497,
          30,
          505,
          95
        ],
        [
          "__init__",
          178,
          260,
          239,
          14,
          239,
          47,
          236,
          34,
          260,
          9
        ],
        [
          "__init__",
          178,
          260,
          242,
          14,
          242,
          48,
          236,
          34,
          260,
          9
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "save_vocabulary",
          296,
          311,
          307,
          18,
          307,
          43,
          307,
          18,
          309,
          46
        ]
      ],
      "transformers/src/transformers/models/esm/tokenization_esm.py": [
        [
          "load_vocab_file",
          29,
          32,
          30,
          10,
          30,
          30,
          29,
          21,
          32,
          41
        ],
        [
          "save_vocabulary",
          136,
          140,
          138,
          14,
          138,
          34,
          137,
          52,
          140,
          28
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "__init__",
          163,
          227,
          206,
          14,
          206,
          51,
          198,
          44,
          227,
          9
        ],
        [
          "__init__",
          163,
          227,
          208,
          14,
          208,
          51,
          198,
          44,
          227,
          9
        ],
        [
          "__init__",
          163,
          227,
          211,
          14,
          211,
          48,
          198,
          44,
          227,
          9
        ],
        [
          "save_vocabulary",
          433,
          467,
          448,
          14,
          448,
          56,
          445,
          30,
          457,
          95
        ],
        [
          "save_vocabulary",
          433,
          467,
          451,
          14,
          451,
          56,
          445,
          30,
          457,
          95
        ],
        [
          "save_vocabulary",
          433,
          467,
          456,
          14,
          456,
          53,
          445,
          30,
          457,
          95
        ]
      ],
      "transformers/src/transformers/models/funnel/tokenization_funnel.py": [
        [
          "load_vocab",
          45,
          53,
          48,
          10,
          48,
          48,
          45,
          16,
          50,
          41
        ],
        [
          "save_vocabulary",
          301,
          319,
          309,
          14,
          309,
          52,
          309,
          14,
          310,
          86
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma.py": [
        [
          "save_vocabulary",
          197,
          222,
          218,
          18,
          218,
          43,
          218,
          18,
          220,
          46
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "save_vocabulary",
          298,
          325,
          309,
          14,
          309,
          52,
          306,
          30,
          315,
          95
        ],
        [
          "__init__",
          133,
          178,
          153,
          14,
          153,
          47,
          149,
          21,
          178,
          9
        ],
        [
          "__init__",
          133,
          178,
          159,
          14,
          159,
          48,
          149,
          21,
          178,
          9
        ],
        [
          "save_vocabulary",
          298,
          325,
          313,
          14,
          313,
          52,
          306,
          30,
          315,
          95
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "save_vocabulary",
          236,
          251,
          247,
          18,
          247,
          43,
          247,
          18,
          249,
          46
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "load_vocab_and_emoji",
          35,
          52,
          43,
          10,
          43,
          48,
          35,
          26,
          46,
          34
        ],
        [
          "load_vocab_and_emoji",
          35,
          52,
          37,
          10,
          37,
          48,
          35,
          26,
          46,
          34
        ],
        [
          "save_vocabulary",
          165,
          193,
          181,
          14,
          181,
          52,
          181,
          14,
          182,
          64
        ],
        [
          "save_vocabulary",
          165,
          193,
          191,
          14,
          191,
          52,
          191,
          14,
          193,
          37
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "save_vocabulary",
          240,
          268,
          266,
          14,
          266,
          52,
          266,
          14,
          268,
          37
        ],
        [
          "load_vocab_and_emoji",
          43,
          60,
          45,
          10,
          45,
          48,
          43,
          26,
          54,
          34
        ],
        [
          "load_vocab_and_emoji",
          43,
          60,
          51,
          10,
          51,
          48,
          43,
          26,
          54,
          34
        ],
        [
          "save_vocabulary",
          240,
          268,
          256,
          14,
          256,
          52,
          256,
          14,
          257,
          64
        ]
      ],
      "transformers/src/transformers/models/layoutlm/tokenization_layoutlm.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          242,
          260,
          250,
          14,
          250,
          52,
          250,
          14,
          251,
          86
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "__init__",
          294,
          376,
          347,
          14,
          347,
          47,
          344,
          34,
          371,
          31
        ],
        [
          "__init__",
          294,
          376,
          350,
          14,
          350,
          48,
          344,
          34,
          371,
          31
        ],
        [
          "save_vocabulary",
          568,
          594,
          579,
          14,
          579,
          52,
          576,
          30,
          584,
          95
        ],
        [
          "save_vocabulary",
          568,
          594,
          583,
          14,
          583,
          52,
          576,
          30,
          584,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "__init__",
          100,
          141,
          123,
          14,
          123,
          48,
          111,
          21,
          128,
          41
        ],
        [
          "__init__",
          100,
          141,
          117,
          14,
          117,
          49,
          111,
          21,
          128,
          41
        ],
        [
          "__init__",
          100,
          141,
          120,
          14,
          120,
          48,
          111,
          21,
          128,
          41
        ],
        [
          "save_vocabulary",
          336,
          370,
          355,
          14,
          355,
          54,
          353,
          30,
          359,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          361,
          14,
          361,
          53,
          359,
          30,
          365,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          367,
          14,
          367,
          53,
          365,
          30,
          370,
          55
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py": [
        [
          "load_vocab",
          146,
          154,
          149,
          10,
          149,
          48,
          146,
          16,
          151,
          41
        ],
        [
          "save_vocabulary",
          360,
          378,
          368,
          14,
          368,
          52,
          368,
          14,
          369,
          86
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "__init__",
          257,
          326,
          287,
          14,
          287,
          47,
          285,
          22,
          326,
          9
        ],
        [
          "__init__",
          257,
          326,
          293,
          14,
          293,
          48,
          285,
          22,
          326,
          9
        ],
        [
          "save_vocabulary",
          411,
          438,
          422,
          14,
          422,
          52,
          419,
          30,
          428,
          95
        ],
        [
          "save_vocabulary",
          411,
          438,
          426,
          14,
          426,
          52,
          419,
          30,
          428,
          95
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm.py": [
        [
          "save_vocabulary",
          421,
          436,
          432,
          18,
          432,
          43,
          432,
          18,
          434,
          46
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "__init__",
          160,
          212,
          185,
          14,
          185,
          47,
          183,
          22,
          212,
          9
        ],
        [
          "__init__",
          160,
          212,
          191,
          14,
          191,
          48,
          183,
          22,
          212,
          9
        ],
        [
          "save_vocabulary",
          295,
          322,
          306,
          14,
          306,
          52,
          303,
          30,
          312,
          95
        ],
        [
          "save_vocabulary",
          295,
          322,
          310,
          14,
          310,
          52,
          303,
          30,
          312,
          95
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "__init__",
          156,
          214,
          193,
          14,
          193,
          48,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          306,
          14,
          306,
          52,
          299,
          30,
          308,
          95
        ],
        [
          "__init__",
          156,
          214,
          187,
          14,
          187,
          47,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          302,
          14,
          302,
          52,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/lxmert/tokenization_lxmert.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          241,
          259,
          249,
          14,
          249,
          52,
          249,
          14,
          250,
          86
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama.py": [
        [
          "get_spm_processor",
          195,
          210,
          201,
          14,
          201,
          40,
          201,
          14,
          210,
          24
        ],
        [
          "save_vocabulary",
          306,
          331,
          327,
          18,
          327,
          43,
          327,
          18,
          329,
          46
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "save_vocabulary",
          287,
          330,
          325,
          22,
          325,
          46,
          325,
          22,
          328,
          49
        ],
        [
          "save_json",
          386,
          388,
          387,
          10,
          387,
          24,
          386,
          15,
          388,
          36
        ],
        [
          "load_json",
          391,
          393,
          392,
          10,
          392,
          24,
          391,
          15,
          393,
          27
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "__init__",
          184,
          264,
          215,
          14,
          215,
          47,
          213,
          22,
          264,
          37
        ],
        [
          "__init__",
          184,
          264,
          223,
          14,
          223,
          48,
          213,
          22,
          264,
          37
        ],
        [
          "save_vocabulary",
          369,
          398,
          381,
          14,
          381,
          52,
          377,
          30,
          388,
          95
        ],
        [
          "save_vocabulary",
          369,
          398,
          386,
          14,
          386,
          52,
          377,
          30,
          388,
          95
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "__init__",
          273,
          387,
          308,
          14,
          308,
          47,
          306,
          22,
          328,
          46
        ],
        [
          "__init__",
          273,
          387,
          314,
          14,
          314,
          48,
          306,
          22,
          328,
          46
        ],
        [
          "__init__",
          273,
          387,
          339,
          14,
          339,
          54,
          332,
          13,
          341,
          111
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1702,
          14,
          1702,
          52,
          1699,
          30,
          1708,
          95
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1706,
          14,
          1706,
          52,
          1699,
          30,
          1708,
          95
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1722,
          14,
          1722,
          59,
          1719,
          30,
          1725,
          56
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart.py": [
        [
          "save_vocabulary",
          294,
          309,
          305,
          18,
          305,
          43,
          305,
          18,
          307,
          46
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50.py": [
        [
          "save_vocabulary",
          242,
          257,
          253,
          18,
          253,
          43,
          253,
          18,
          255,
          46
        ]
      ],
      "transformers/src/transformers/models/m2m_100/tokenization_m2m_100.py": [
        [
          "save_vocabulary",
          295,
          315,
          311,
          18,
          311,
          42,
          311,
          18,
          313,
          46
        ],
        [
          "load_json",
          374,
          376,
          375,
          10,
          375,
          24,
          374,
          15,
          376,
          27
        ],
        [
          "save_json",
          379,
          381,
          380,
          10,
          380,
          24,
          379,
          15,
          381,
          36
        ]
      ],
      "transformers/src/transformers/models/mgp_str/tokenization_mgp_str.py": [
        [
          "__init__",
          54,
          64,
          55,
          14,
          55,
          47,
          54,
          18,
          64,
          9
        ],
        [
          "save_vocabulary",
          90,
          101,
          98,
          14,
          98,
          52,
          95,
          30,
          101,
          28
        ]
      ],
      "transformers/src/transformers/models/mobilebert/tokenization_mobilebert.py": [
        [
          "load_vocab",
          33,
          41,
          36,
          10,
          36,
          48,
          33,
          16,
          38,
          41
        ],
        [
          "save_vocabulary",
          243,
          261,
          251,
          14,
          251,
          52,
          251,
          14,
          252,
          86
        ]
      ],
      "transformers/src/transformers/models/mpnet/tokenization_mpnet.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          296,
          314,
          304,
          14,
          304,
          52,
          304,
          14,
          305,
          86
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "__init__",
          221,
          331,
          283,
          14,
          283,
          54,
          262,
          32,
          285,
          111
        ],
        [
          "save_vocabulary",
          1530,
          1553,
          1542,
          18,
          1542,
          43,
          1542,
          18,
          1544,
          46
        ],
        [
          "save_vocabulary",
          1530,
          1553,
          1550,
          14,
          1550,
          59,
          1547,
          30,
          1553,
          48
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "__init__",
          155,
          206,
          179,
          14,
          179,
          47,
          178,
          22,
          206,
          9
        ],
        [
          "__init__",
          155,
          206,
          185,
          14,
          185,
          48,
          178,
          22,
          206,
          9
        ],
        [
          "save_vocabulary",
          283,
          310,
          294,
          14,
          294,
          52,
          291,
          30,
          300,
          95
        ],
        [
          "save_vocabulary",
          283,
          310,
          298,
          14,
          298,
          52,
          291,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/myt5/tokenization_myt5.py": [
        [
          "__init__",
          46,
          57,
          48,
          18,
          48,
          43,
          48,
          18,
          49,
          31
        ],
        [
          "__init__",
          165,
          209,
          197,
          36,
          197,
          56,
          190,
          21,
          209,
          9
        ],
        [
          "save_vocabulary",
          368,
          377,
          375,
          14,
          375,
          52,
          375,
          14,
          377,
          28
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb.py": [
        [
          "save_vocabulary",
          332,
          347,
          343,
          18,
          343,
          43,
          343,
          18,
          345,
          46
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "save_vocabulary",
          366,
          393,
          381,
          14,
          381,
          52,
          374,
          30,
          383,
          95
        ],
        [
          "__init__",
          259,
          281,
          272,
          14,
          272,
          47,
          272,
          14,
          281,
          55
        ],
        [
          "__init__",
          259,
          281,
          275,
          14,
          275,
          48,
          272,
          14,
          281,
          55
        ],
        [
          "save_vocabulary",
          366,
          393,
          377,
          14,
          377,
          52,
          374,
          30,
          383,
          95
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus.py": [
        [
          "save_vocabulary",
          274,
          289,
          285,
          18,
          285,
          43,
          285,
          18,
          287,
          46
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "__init__",
          102,
          144,
          128,
          14,
          128,
          48,
          103,
          9,
          144,
          9
        ],
        [
          "save_vocabulary",
          298,
          319,
          312,
          18,
          312,
          43,
          312,
          18,
          314,
          46
        ],
        [
          "add_from_file",
          327,
          348,
          333,
          22,
          333,
          51,
          332,
          13,
          333,
          51
        ]
      ],
      "transformers/src/transformers/models/pop2piano/tokenization_pop2piano.py": [
        [
          "__init__",
          93,
          125,
          113,
          14,
          113,
          30,
          107,
          21,
          125,
          9
        ],
        [
          "save_vocabulary",
          344,
          365,
          362,
          14,
          362,
          38,
          360,
          30,
          365,
          32
        ]
      ],
      "transformers/src/transformers/models/plbart/tokenization_plbart.py": [
        [
          "save_vocabulary",
          370,
          385,
          381,
          18,
          381,
          43,
          381,
          18,
          383,
          46
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "__init__",
          137,
          208,
          172,
          14,
          172,
          47,
          167,
          13,
          180,
          51
        ],
        [
          "__init__",
          137,
          208,
          179,
          14,
          179,
          48,
          167,
          13,
          180,
          51
        ],
        [
          "save_vocabulary",
          308,
          335,
          319,
          14,
          319,
          52,
          316,
          30,
          325,
          95
        ],
        [
          "save_vocabulary",
          308,
          335,
          323,
          14,
          323,
          52,
          316,
          30,
          325,
          95
        ]
      ],
      "transformers/src/transformers/models/prophetnet/tokenization_prophetnet.py": [
        [
          "load_vocab",
          261,
          269,
          264,
          10,
          264,
          48,
          261,
          16,
          266,
          41
        ],
        [
          "save_vocabulary",
          435,
          453,
          443,
          14,
          443,
          52,
          443,
          14,
          444,
          86
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/tokenization_realm.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          307,
          325,
          315,
          14,
          315,
          52,
          315,
          14,
          316,
          86
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer.py": [
        [
          "save_vocabulary",
          158,
          173,
          169,
          18,
          169,
          43,
          169,
          18,
          171,
          46
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert.py": [
        [
          "save_vocabulary",
          219,
          234,
          230,
          18,
          230,
          43,
          230,
          18,
          232,
          46
        ]
      ],
      "transformers/src/transformers/models/deprecated/retribert/tokenization_retribert.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          236,
          254,
          244,
          14,
          244,
          52,
          244,
          14,
          245,
          86
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "__init__",
          156,
          214,
          193,
          14,
          193,
          48,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          306,
          14,
          306,
          52,
          299,
          30,
          308,
          95
        ],
        [
          "__init__",
          156,
          214,
          187,
          14,
          187,
          47,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          302,
          14,
          302,
          52,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/roformer/tokenization_roformer.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          490,
          508,
          498,
          14,
          498,
          52,
          498,
          14,
          499,
          86
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "get_spm_processor",
          139,
          150,
          141,
          14,
          141,
          40,
          139,
          27,
          150,
          24
        ],
        [
          "save_vocabulary",
          362,
          377,
          373,
          18,
          373,
          43,
          373,
          18,
          375,
          46
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t.py": [
        [
          "get_spm_processor",
          421,
          436,
          427,
          14,
          427,
          40,
          427,
          14,
          436,
          24
        ],
        [
          "save_vocabulary",
          497,
          512,
          508,
          18,
          508,
          43,
          508,
          18,
          510,
          46
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/tokenization_speech_to_text.py": [
        [
          "save_vocabulary",
          257,
          276,
          272,
          18,
          272,
          42,
          272,
          18,
          274,
          46
        ],
        [
          "load_json",
          285,
          287,
          286,
          10,
          286,
          24,
          285,
          15,
          287,
          27
        ],
        [
          "save_json",
          290,
          292,
          291,
          10,
          291,
          24,
          290,
          15,
          292,
          36
        ]
      ],
      "transformers/src/transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py": [
        [
          "__init__",
          82,
          118,
          95,
          14,
          95,
          47,
          83,
          9,
          99,
          30
        ],
        [
          "__init__",
          82,
          118,
          105,
          18,
          105,
          52,
          105,
          18,
          110,
          22
        ],
        [
          "save_vocabulary",
          220,
          249,
          231,
          14,
          231,
          52,
          228,
          30,
          235,
          33
        ],
        [
          "save_vocabulary",
          220,
          249,
          238,
          14,
          238,
          53,
          238,
          14,
          239,
          95
        ]
      ],
      "transformers/src/transformers/models/splinter/tokenization_splinter.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          280,
          298,
          288,
          14,
          288,
          52,
          288,
          14,
          289,
          86
        ]
      ],
      "transformers/src/transformers/models/speecht5/tokenization_speecht5.py": [
        [
          "save_vocabulary",
          205,
          220,
          216,
          18,
          216,
          43,
          216,
          18,
          218,
          46
        ]
      ],
      "transformers/src/transformers/models/squeezebert/tokenization_squeezebert.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          242,
          260,
          250,
          14,
          250,
          52,
          250,
          14,
          251,
          86
        ]
      ],
      "transformers/src/transformers/models/roc_bert/tokenization_roc_bert.py": [
        [
          "load_vocab",
          52,
          60,
          55,
          10,
          55,
          48,
          52,
          16,
          57,
          41
        ],
        [
          "__init__",
          117,
          172,
          143,
          14,
          143,
          56,
          141,
          22,
          152,
          28
        ],
        [
          "__init__",
          117,
          172,
          146,
          14,
          146,
          64,
          141,
          22,
          152,
          28
        ],
        [
          "save_vocabulary",
          827,
          869,
          848,
          14,
          848,
          52,
          840,
          18,
          849,
          86
        ],
        [
          "save_vocabulary",
          827,
          869,
          859,
          14,
          859,
          56,
          859,
          14,
          869,
          9
        ],
        [
          "save_vocabulary",
          827,
          869,
          862,
          14,
          862,
          64,
          859,
          14,
          869,
          9
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "get_spm_processor",
          200,
          215,
          206,
          14,
          206,
          40,
          206,
          14,
          215,
          24
        ],
        [
          "save_vocabulary",
          430,
          445,
          441,
          18,
          441,
          43,
          441,
          18,
          443,
          46
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "save_vocabulary",
          465,
          492,
          476,
          14,
          476,
          52,
          473,
          30,
          482,
          95
        ],
        [
          "__init__",
          251,
          315,
          278,
          14,
          278,
          47,
          276,
          22,
          315,
          28
        ],
        [
          "__init__",
          251,
          315,
          284,
          14,
          284,
          48,
          276,
          22,
          315,
          28
        ],
        [
          "save_vocabulary",
          465,
          492,
          480,
          14,
          480,
          52,
          473,
          30,
          482,
          95
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "save_vocabulary",
          491,
          506,
          502,
          18,
          502,
          43,
          502,
          18,
          504,
          46
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "load_vocab",
          89,
          97,
          92,
          10,
          92,
          48,
          89,
          16,
          94,
          41
        ],
        [
          "save_vocabulary",
          372,
          390,
          380,
          14,
          380,
          52,
          380,
          14,
          381,
          86
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "_build_from_file",
          302,
          315,
          306,
          14,
          306,
          52,
          302,
          26,
          307,
          25
        ],
        [
          "__init__",
          158,
          264,
          212,
          22,
          212,
          54,
          212,
          22,
          212,
          54
        ],
        [
          "count_file",
          275,
          289,
          281,
          14,
          281,
          46,
          278,
          9,
          282,
          41
        ],
        [
          "save_vocabulary",
          317,
          327,
          325,
          14,
          325,
          35,
          325,
          14,
          327,
          28
        ],
        [
          "encode_file",
          350,
          365,
          355,
          14,
          355,
          46,
          353,
          9,
          356,
          41
        ],
        [
          "get_lm_corpus",
          784,
          821,
          800,
          14,
          800,
          27,
          800,
          14,
          801,
          18
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "__init__",
          72,
          104,
          84,
          14,
          84,
          47,
          73,
          9,
          104,
          9
        ],
        [
          "save_vocabulary",
          231,
          243,
          240,
          14,
          240,
          52,
          237,
          30,
          243,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        [
          "__init__",
          107,
          145,
          130,
          14,
          130,
          47,
          130,
          14,
          145,
          9
        ],
        [
          "save_vocabulary",
          558,
          569,
          566,
          14,
          566,
          52,
          563,
          30,
          569,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py": [
        [
          "__init__",
          140,
          187,
          159,
          14,
          159,
          47,
          141,
          9,
          164,
          34
        ],
        [
          "save_vocabulary",
          624,
          635,
          632,
          14,
          632,
          52,
          629,
          30,
          635,
          28
        ],
        [
          "__init__",
          698,
          738,
          723,
          14,
          723,
          47,
          699,
          9,
          738,
          9
        ],
        [
          "save_vocabulary",
          901,
          912,
          909,
          14,
          909,
          52,
          906,
          30,
          912,
          28
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "__init__",
          87,
          141,
          132,
          18,
          132,
          56,
          132,
          18,
          133,
          48
        ],
        [
          "save_vocabulary",
          439,
          452,
          447,
          18,
          447,
          61,
          447,
          18,
          450,
          17
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "_save_pretrained",
          695,
          742,
          728,
          22,
          728,
          67,
          728,
          22,
          730,
          36
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "from_pretrained",
          1859,
          2128,
          2042,
          30,
          2042,
          73,
          2042,
          30,
          2044,
          73
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2172,
          18,
          2172,
          62,
          2172,
          18,
          2177,
          37
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2191,
          18,
          2191,
          59,
          2191,
          18,
          2192,
          41
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2198,
          18,
          2198,
          53,
          2197,
          29,
          2199,
          45
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2296,
          22,
          2296,
          68,
          2296,
          22,
          2298,
          64
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2328,
          22,
          2328,
          62,
          2328,
          22,
          2330,
          65
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2342,
          22,
          2342,
          59,
          2342,
          22,
          2345,
          53
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2438,
          18,
          2438,
          64,
          2438,
          18,
          2442,
          50
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2449,
          26,
          2449,
          72,
          2449,
          26,
          2452,
          76
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2456,
          26,
          2456,
          71,
          2454,
          21,
          2459,
          75
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2606,
          14,
          2606,
          63,
          2606,
          14,
          2638,
          25
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2615,
          14,
          2615,
          65,
          2606,
          14,
          2638,
          25
        ],
        [
          "_save_pretrained",
          2640,
          2673,
          2666,
          18,
          2666,
          63,
          2666,
          18,
          2669,
          78
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm.py": [
        [
          "save_vocabulary",
          284,
          299,
          295,
          18,
          295,
          43,
          295,
          18,
          297,
          46
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "__init__",
          254,
          326,
          305,
          18,
          305,
          56,
          305,
          18,
          306,
          48
        ],
        [
          "__init__",
          254,
          326,
          291,
          14,
          291,
          47,
          286,
          13,
          304,
          38
        ],
        [
          "__init__",
          254,
          326,
          297,
          14,
          297,
          48,
          286,
          13,
          304,
          38
        ],
        [
          "save_vocabulary",
          801,
          837,
          815,
          14,
          815,
          52,
          812,
          30,
          821,
          95
        ],
        [
          "save_vocabulary",
          801,
          837,
          819,
          14,
          819,
          52,
          812,
          30,
          821,
          95
        ],
        [
          "save_vocabulary",
          801,
          837,
          832,
          18,
          832,
          61,
          832,
          18,
          835,
          17
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "__init__",
          194,
          266,
          246,
          14,
          246,
          47,
          243,
          34,
          266,
          9
        ],
        [
          "__init__",
          194,
          266,
          249,
          14,
          249,
          48,
          243,
          34,
          266,
          9
        ],
        [
          "save_vocabulary",
          532,
          558,
          543,
          14,
          543,
          52,
          540,
          30,
          548,
          95
        ],
        [
          "save_vocabulary",
          532,
          558,
          547,
          14,
          547,
          52,
          540,
          30,
          548,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        [
          "save_vocabulary",
          279,
          294,
          290,
          18,
          290,
          43,
          290,
          18,
          292,
          46
        ],
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py": [
        [
          "save_vocabulary",
          283,
          298,
          294,
          18,
          294,
          43,
          294,
          18,
          296,
          46
        ]
      ],
      "transformers/scripts/distributed/torch-distributed-gpu-test.py": [
        [
          "printflock",
          53,
          60,
          55,
          10,
          55,
          28,
          53,
          17,
          58,
          23
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "save_vocabulary",
          369,
          384,
          380,
          18,
          380,
          43,
          380,
          18,
          382,
          46
        ]
      ],
      "transformers/src/transformers/trainer_callback.py": [
        [
          "save_to_json",
          144,
          148,
          147,
          14,
          147,
          51,
          144,
          22,
          148,
          32
        ],
        [
          "load_from_json",
          151,
          155,
          153,
          14,
          153,
          46,
          151,
          24,
          155,
          38
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "save_metrics",
          884,
          919,
          906,
          10,
          906,
          24,
          905,
          12,
          909,
          15
        ],
        [
          "save_metrics",
          884,
          919,
          912,
          18,
          912,
          27,
          912,
          18,
          913,
          27
        ],
        [
          "save_metrics",
          884,
          919,
          918,
          14,
          918,
          28,
          917,
          9,
          919,
          63
        ],
        [
          "from_json_file",
          1156,
          1168,
          1159,
          14,
          1159,
          56,
          1158,
          21,
          1163,
          30
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "__post_init__",
          1467,
          1917,
          1765,
          18,
          1765,
          57,
          1765,
          18,
          1766,
          32
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "create_model_card",
          4790,
          4862,
          4858,
          14,
          4858,
          43,
          4845,
          28,
          4861,
          26
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4880,
          22,
          4880,
          37,
          4879,
          17,
          4883,
          50
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5029,
          18,
          5029,
          70,
          5029,
          18,
          5030,
          31
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5045,
          18,
          5045,
          75,
          5045,
          18,
          5047,
          32
        ]
      ],
      "transformers/utils/update_metadata.py": [
        [
          "update_metadata",
          232,
          312,
          270,
          10,
          270,
          34,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          279,
          10,
          279,
          37,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          286,
          14,
          286,
          59,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          288,
          14,
          288,
          62,
          232,
          21,
          294,
          27
        ]
      ],
      "transformers/utils/update_tiny_models.py": [
        [
          "get_tiny_model_names_from_repo",
          57,
          64,
          58,
          10,
          58,
          52,
          58,
          10,
          61,
          42
        ],
        [
          "get_tiny_model_summary_from_hub",
          67,
          142,
          141,
          14,
          141,
          80,
          136,
          40,
          142,
          64
        ]
      ],
      "transformers/src/transformers/data/processors/utils.py": [
        [
          "_read_tsv",
          119,
          122,
          121,
          14,
          121,
          56,
          119,
          19,
          122,
          75
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "_read_txt",
          191,
          199,
          195,
          18,
          195,
          45,
          194,
          13,
          198,
          38
        ],
        [
          "_read_csv",
          247,
          249,
          248,
          14,
          248,
          47,
          247,
          19,
          249,
          38
        ],
        [
          "_read_csv",
          296,
          298,
          297,
          14,
          297,
          47,
          296,
          19,
          298,
          38
        ],
        [
          "_read_json",
          342,
          345,
          343,
          14,
          343,
          47,
          342,
          20,
          345,
          24
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "pickle_load",
          447,
          450,
          449,
          10,
          449,
          25,
          447,
          17,
          450,
          29
        ],
        [
          "pickle_save",
          453,
          456,
          455,
          10,
          455,
          25,
          453,
          17,
          456,
          34
        ],
        [
          "save_json",
          469,
          471,
          470,
          10,
          470,
          24,
          469,
          15,
          471,
          80
        ],
        [
          "load_json",
          474,
          476,
          475,
          10,
          475,
          19,
          474,
          15,
          476,
          27
        ]
      ],
      "transformers/examples/pytorch/question-answering/utils_qa.py": [
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          246,
          18,
          246,
          42,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          246,
          18,
          246,
          42,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          433,
          14,
          433,
          39,
          432,
          9,
          438,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          433,
          14,
          433,
          39,
          428,
          30,
          441,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          436,
          14,
          436,
          34,
          432,
          9,
          438,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          436,
          14,
          436,
          34,
          428,
          30,
          441,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          440,
          18,
          440,
          42,
          428,
          30,
          441,
          75
        ]
      ],
      "transformers/src/transformers/models/auto/video_processing_auto.py": [
        [
          "get_video_processor_config",
          105,
          197,
          196,
          10,
          196,
          53,
          196,
          10,
          197,
          32
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "get_video_processor_dict",
          611,
          724,
          708,
          18,
          708,
          75,
          662,
          45,
          708,
          75
        ],
        [
          "get_video_processor_dict",
          611,
          724,
          708,
          18,
          708,
          75,
          706,
          9,
          708,
          75
        ],
        [
          "to_json_file",
          806,
          815,
          814,
          14,
          814,
          56,
          806,
          22,
          815,
          47
        ],
        [
          "from_json_file",
          821,
          837,
          834,
          14,
          834,
          51,
          821,
          24,
          837,
          42
        ]
      ],
      "transformers/src/transformers/pipelines/zero_shot_audio_classification.py": [
        [
          "preprocess",
          105,
          131,
          112,
          22,
          112,
          38,
          112,
          22,
          113,
          25
        ]
      ],
      "transformers/.github/scripts/assign_reviewers.py": [
        [
          "main",
          74,
          117,
          76,
          10,
          76,
          58,
          75,
          18,
          88,
          54
        ],
        [
          "main",
          74,
          117,
          81,
          10,
          81,
          46,
          75,
          18,
          88,
          54
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_paper_link",
          54,
          91,
          61,
          10,
          61,
          47,
          59,
          5,
          70,
          26
        ],
        [
          "replace_paper_links",
          139,
          177,
          142,
          10,
          142,
          47,
          139,
          25,
          155,
          31
        ],
        [
          "replace_paper_links",
          139,
          177,
          174,
          14,
          174,
          51,
          174,
          14,
          176,
          19
        ],
        [
          "insert_dates",
          180,
          250,
          202,
          14,
          202,
          51,
          198,
          13,
          205,
          28
        ],
        [
          "insert_dates",
          180,
          250,
          210,
          18,
          210,
          55,
          206,
          13,
          212,
          19
        ],
        [
          "insert_dates",
          180,
          250,
          239,
          22,
          239,
          59,
          235,
          28,
          240,
          36
        ],
        [
          "insert_dates",
          180,
          250,
          248,
          18,
          248,
          55,
          244,
          28,
          250,
          66
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_to_model_init",
          33,
          146,
          39,
          10,
          39,
          95,
          34,
          5,
          44,
          28
        ],
        [
          "add_fast_image_processor_to_model_init",
          33,
          146,
          145,
          10,
          145,
          95,
          145,
          10,
          146,
          32
        ],
        [
          "add_fast_image_processor_to_auto",
          149,
          163,
          153,
          10,
          153,
          104,
          149,
          38,
          163,
          32
        ],
        [
          "add_fast_image_processor_to_auto",
          149,
          163,
          162,
          10,
          162,
          104,
          149,
          38,
          163,
          32
        ],
        [
          "add_fast_image_processor_to_doc",
          166,
          197,
          185,
          14,
          185,
          50,
          184,
          9,
          188,
          41
        ],
        [
          "add_fast_image_processor_to_doc",
          166,
          197,
          196,
          18,
          196,
          54,
          190,
          31,
          197,
          40
        ],
        [
          "add_fast_image_processor_to_tests",
          200,
          272,
          210,
          10,
          210,
          47,
          210,
          10,
          252,
          48
        ],
        [
          "add_fast_image_processor_to_tests",
          200,
          272,
          271,
          10,
          271,
          47,
          271,
          10,
          272,
          32
        ],
        [
          "write_default_fast_image_processor_file",
          311,
          339,
          338,
          10,
          338,
          71,
          312,
          5,
          339,
          24
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          445,
          10,
          445,
          71,
          441,
          5,
          446,
          24
        ],
        [
          "add_fast_image_processor",
          449,
          507,
          466,
          10,
          466,
          66,
          466,
          10,
          471,
          31
        ]
      ],
      "transformers/utils/add_pipeline_model_mapping_to_test.py": [
        [
          "add_pipeline_model_mapping",
          155,
          264,
          261,
          10,
          261,
          64,
          247,
          19,
          264,
          22
        ]
      ],
      "transformers/src/transformers/pipelines/__init__.py": [
        [
          "pipeline",
          514,
          1094,
          785,
          22,
          785,
          68,
          785,
          22,
          788,
          25
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "create_test_files",
          427,
          474,
          464,
          18,
          464,
          46,
          464,
          18,
          468,
          15
        ],
        [
          "add_content_to_file",
          128,
          147,
          140,
          10,
          140,
          47,
          128,
          25,
          147,
          28
        ],
        [
          "add_content_to_file",
          128,
          147,
          146,
          10,
          146,
          47,
          128,
          25,
          147,
          28
        ],
        [
          "add_model_to_auto_mappings",
          150,
          214,
          201,
          18,
          201,
          71,
          200,
          24,
          207,
          39
        ],
        [
          "insert_model_in_doc_toc",
          273,
          293,
          286,
          10,
          286,
          28,
          273,
          29,
          293,
          5
        ],
        [
          "find_all_classes_from_file",
          334,
          347,
          342,
          10,
          342,
          49,
          334,
          32,
          347,
          50
        ],
        [
          "create_new_model_like",
          477,
          571,
          512,
          10,
          512,
          74,
          504,
          26,
          537,
          47
        ],
        [
          "create_new_model_like",
          477,
          571,
          517,
          10,
          517,
          53,
          504,
          26,
          537,
          47
        ],
        [
          "create_new_model_like",
          477,
          571,
          534,
          10,
          534,
          48,
          504,
          26,
          537,
          47
        ],
        [
          "create_new_model_like",
          477,
          571,
          538,
          14,
          538,
          47,
          537,
          9,
          539,
          28
        ],
        [
          "create_new_model_like",
          477,
          571,
          543,
          10,
          543,
          99,
          542,
          16,
          548,
          34
        ]
      ],
      "transformers/src/transformers/pipelines/audio_classification.py": [
        [
          "preprocess",
          166,
          239,
          173,
          22,
          173,
          39,
          173,
          22,
          174,
          26
        ]
      ],
      "transformers/src/transformers/audio_utils.py": [
        [
          "load_audio_as",
          143,
          219,
          183,
          18,
          183,
          34,
          183,
          18,
          183,
          34
        ]
      ],
      "transformers/src/transformers/pipelines/automatic_speech_recognition.py": [
        [
          "preprocess",
          353,
          494,
          360,
          22,
          360,
          39,
          360,
          22,
          361,
          26
        ]
      ],
      "transformers/src/transformers/models/auto/auto_factory.py": [
        [
          "from_pretrained",
          251,
          391,
          312,
          22,
          312,
          68,
          312,
          22,
          316,
          49
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          143,
          14,
          143,
          64,
          133,
          9,
          144,
          44
        ],
        [
          "combine_summaries",
          149,
          195,
          190,
          10,
          190,
          61,
          190,
          10,
          195,
          19
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "save_binary",
          458,
          474,
          471,
          14,
          471,
          37,
          458,
          21,
          474,
          26
        ],
        [
          "__iter__",
          533,
          540,
          534,
          14,
          534,
          39,
          533,
          18,
          536,
          29
        ],
        [
          "save",
          542,
          553,
          549,
          14,
          549,
          40,
          542,
          14,
          550,
          28
        ],
        [
          "__init__",
          568,
          578,
          577,
          14,
          577,
          34,
          569,
          9,
          578,
          25
        ],
        [
          "save",
          587,
          595,
          594,
          14,
          594,
          40,
          587,
          14,
          595,
          30
        ]
      ],
      "transformers/utils/check_bad_commit.py": [
        [
          "create_script",
          26,
          69,
          68,
          10,
          68,
          38,
          26,
          19,
          69,
          32
        ],
        [
          "find_bad_commit",
          72,
          133,
          95,
          10,
          95,
          39,
          87,
          5,
          106,
          50
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "save_chat",
          395,
          411,
          409,
          14,
          409,
          32,
          408,
          9,
          411,
          40
        ],
        [
          "_inner_run",
          667,
          752,
          695,
          18,
          695,
          41,
          695,
          18,
          696,
          24
        ]
      ],
      "transformers/benchmark_v2/benchmark_framework.py": [
        [
          "save_results",
          1171,
          1199,
          1195,
          14,
          1195,
          32,
          1195,
          14,
          1199,
          23
        ]
      ],
      "transformers/utils/check_doc_toc.py": [
        [
          "check_model_doc",
          79,
          125,
          88,
          10,
          88,
          44,
          79,
          21,
          92,
          11
        ],
        [
          "check_model_doc",
          79,
          125,
          120,
          18,
          120,
          57,
          118,
          46,
          121,
          63
        ]
      ],
      "transformers/utils/check_config_attributes.py": [
        [
          "check_config_attributes_being_used",
          457,
          499,
          484,
          18,
          484,
          44,
          484,
          18,
          485,
          50
        ]
      ],
      "transformers/utils/check_doctest_list.py": [
        [
          "clean_doctest_list",
          44,
          76,
          56,
          10,
          56,
          50,
          44,
          24,
          57,
          21
        ],
        [
          "clean_doctest_list",
          44,
          76,
          75,
          14,
          75,
          54,
          75,
          14,
          76,
          51
        ]
      ],
      "transformers/utils/check_dummies.py": [
        [
          "read_init",
          95,
          137,
          102,
          10,
          102,
          101,
          96,
          5,
          106,
          14
        ],
        [
          "check_dummies",
          186,
          248,
          208,
          18,
          208,
          69,
          208,
          18,
          209,
          39
        ],
        [
          "check_dummies",
          186,
          248,
          221,
          22,
          221,
          89,
          217,
          17,
          222,
          49
        ]
      ],
      "transformers/utils/check_inits.py": [
        [
          "parse_init",
          92,
          232,
          105,
          10,
          105,
          61,
          92,
          16,
          109,
          14
        ],
        [
          "check_submodules",
          320,
          349,
          333,
          10,
          333,
          69,
          321,
          5,
          343,
          37
        ]
      ],
      "transformers/utils/check_modular_conversion.py": [
        [
          "process_file",
          27,
          67,
          37,
          10,
          37,
          47,
          34,
          24,
          51,
          16
        ],
        [
          "process_file",
          27,
          67,
          56,
          14,
          56,
          65,
          56,
          14,
          59,
          20
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "find_code_in_transformers",
          386,
          460,
          433,
          10,
          433,
          91,
          433,
          10,
          439,
          30
        ],
        [
          "is_copy_consistent",
          635,
          826,
          655,
          10,
          655,
          60,
          653,
          17,
          660,
          78
        ],
        [
          "is_copy_consistent",
          635,
          826,
          824,
          14,
          824,
          64,
          823,
          9,
          825,
          31
        ],
        [
          "get_model_list",
          862,
          898,
          874,
          10,
          874,
          85,
          862,
          20,
          877,
          15
        ]
      ],
      "transformers/utils/check_self_hosted_runner.py": [
        [
          "get_runner_status",
          6,
          34,
          29,
          10,
          29,
          41,
          29,
          10,
          32,
          31
        ]
      ],
      "transformers/utils/check_pipeline_typing.py": [
        [
          "main",
          30,
          78,
          70,
          14,
          70,
          42,
          64,
          9,
          71,
          31
        ],
        [
          "main",
          30,
          78,
          31,
          10,
          31,
          38,
          30,
          10,
          53,
          41
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "find_tested_models",
          602,
          650,
          613,
          10,
          613,
          90,
          602,
          24,
          621,
          26
        ],
        [
          "check_decorator_order",
          872,
          895,
          882,
          10,
          882,
          60,
          872,
          27,
          886,
          35
        ],
        [
          "find_all_documented_objects",
          914,
          939,
          926,
          14,
          926,
          64,
          925,
          9,
          931,
          31
        ]
      ],
      "transformers/utils/compare_test_runs.py": [
        [
          "parse_summary_file",
          34,
          47,
          36,
          10,
          36,
          47,
          34,
          24,
          38,
          21
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "fix_docstring",
          798,
          870,
          857,
          10,
          857,
          46,
          856,
          16,
          870,
          33
        ],
        [
          "fix_docstring",
          798,
          870,
          869,
          10,
          869,
          46,
          856,
          16,
          870,
          33
        ],
        [
          "find_files_with_auto_docstring",
          943,
          968,
          949,
          14,
          949,
          51,
          948,
          9,
          951,
          45
        ],
        [
          "update_file_with_new_docstrings",
          1235,
          1326,
          1319,
          14,
          1319,
          56,
          1319,
          14,
          1320,
          42
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1349,
          14,
          1349,
          56,
          1348,
          9,
          1357,
          42
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          598,
          14,
          598,
          57,
          596,
          27,
          605,
          9
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          651,
          10,
          651,
          36,
          647,
          14,
          674,
          43
        ]
      ],
      "transformers/src/transformers/distributed/configuration_utils.py": [
        [
          "to_json_file",
          52,
          66,
          62,
          14,
          62,
          56,
          52,
          22,
          66,
          37
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "_dict_from_json_file",
          948,
          951,
          949,
          14,
          949,
          51,
          948,
          30,
          951,
          31
        ],
        [
          "to_json_file",
          1089,
          1101,
          1100,
          14,
          1100,
          56,
          1089,
          22,
          1101,
          64
        ],
        [
          "to_json_file",
          1199,
          1210,
          1206,
          14,
          1206,
          56,
          1199,
          22,
          1210,
          37
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "_dict_from_json_file",
          853,
          856,
          854,
          14,
          854,
          46,
          853,
          30,
          856,
          31
        ],
        [
          "to_json_file",
          979,
          991,
          990,
          14,
          990,
          56,
          979,
          22,
          991,
          64
        ]
      ],
      "transformers/examples/pytorch/continuous_batching.py": [
        [
          "batch_generate",
          94,
          178,
          175,
          14,
          175,
          35,
          175,
          14,
          176,
          40
        ]
      ],
      "transformers/src/transformers/models/audio_spectrogram_transformer/convert_audio_spectrogram_transformer_original_to_pytorch.py": [
        [
          "get_audio_spectrogram_transformer_config",
          34,
          66,
          61,
          26,
          61,
          91,
          61,
          16,
          66,
          17
        ]
      ],
      "transformers/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py": [
        [
          "convert_beit_checkpoint",
          170,
          357,
          191,
          30,
          191,
          95,
          188,
          45,
          198,
          23
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          204,
          30,
          204,
          95,
          201,
          45,
          208,
          34
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          217,
          30,
          217,
          95,
          214,
          45,
          222,
          19
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "shard_on_the_fly",
          70,
          149,
          145,
          10,
          145,
          81,
          142,
          17,
          149,
          26
        ]
      ],
      "transformers/src/transformers/models/bit/convert_bit_to_pytorch.py": [
        [
          "get_config",
          38,
          57,
          41,
          26,
          41,
          91,
          38,
          16,
          45,
          50
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "add_from_file",
          107,
          144,
          113,
          22,
          113,
          51,
          112,
          13,
          113,
          51
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          184,
          10,
          184,
          52,
          179,
          16,
          189,
          40
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          224,
          10,
          224,
          62,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          241,
          10,
          241,
          66,
          192,
          19,
          251,
          24
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          150,
          14,
          150,
          66,
          147,
          18,
          154,
          32
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          152,
          14,
          152,
          110,
          147,
          18,
          154,
          32
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          210,
          14,
          210,
          66,
          208,
          9,
          211,
          44
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "merge_configurations",
          22,
          174,
          25,
          10,
          25,
          31,
          22,
          26,
          36,
          73
        ],
        [
          "merge_configurations",
          22,
          174,
          28,
          10,
          28,
          39,
          22,
          26,
          36,
          73
        ],
        [
          "create_tokenizer_config",
          280,
          296,
          295,
          10,
          295,
          34,
          280,
          29,
          296,
          48
        ],
        [
          "convert_hf_blt_to_unified",
          362,
          410,
          388,
          10,
          388,
          31,
          363,
          5,
          391,
          36
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "read_json",
          74,
          76,
          75,
          10,
          75,
          24,
          74,
          15,
          76,
          27
        ],
        [
          "write_json",
          79,
          81,
          80,
          10,
          80,
          24,
          79,
          16,
          81,
          26
        ],
        [
          "write_model",
          84,
          436,
          329,
          10,
          329,
          77,
          326,
          26,
          337,
          53
        ],
        [
          "write_model",
          84,
          436,
          341,
          10,
          341,
          91,
          341,
          10,
          355,
          42
        ],
        [
          "write_model",
          84,
          436,
          352,
          10,
          352,
          68,
          341,
          10,
          355,
          42
        ]
      ],
      "transformers/src/transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_conditional_detr_checkpoint",
          222,
          308,
          241,
          30,
          241,
          95,
          238,
          29,
          261,
          32
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_convnext_upernet_to_pytorch.py": [
        [
          "get_upernet_config",
          28,
          68,
          53,
          26,
          53,
          91,
          50,
          18,
          68,
          17
        ]
      ],
      "transformers/src/transformers/models/convnext/convert_convnext_to_pytorch.py": [
        [
          "get_convnext_config",
          36,
          78,
          66,
          26,
          66,
          91,
          64,
          15,
          68,
          33
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "get_convnextv2_config",
          37,
          79,
          71,
          26,
          71,
          91,
          65,
          18,
          79,
          33
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "write_model",
          121,
          196,
          142,
          26,
          142,
          91,
          139,
          25,
          152,
          23
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "main",
          249,
          351,
          281,
          30,
          281,
          95,
          259,
          16,
          290,
          15
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "load_model_state_dict",
          203,
          233,
          214,
          14,
          214,
          34,
          212,
          9,
          219,
          44
        ]
      ],
      "transformers/src/transformers/models/deit/convert_deit_timm_to_pytorch.py": [
        [
          "convert_deit_checkpoint",
          131,
          201,
          144,
          26,
          144,
          91,
          131,
          29,
          151,
          39
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "load_model_state_dict",
          176,
          206,
          187,
          14,
          187,
          34,
          185,
          9,
          192,
          44
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "get_d_fine_config",
          36,
          153,
          42,
          26,
          42,
          91,
          41,
          16,
          53,
          75
        ],
        [
          "get_d_fine_config",
          36,
          153,
          42,
          26,
          42,
          91,
          41,
          73,
          53,
          75
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_detr_checkpoint",
          179,
          264,
          198,
          30,
          198,
          95,
          195,
          29,
          218,
          32
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_to_pytorch.py": [
        [
          "get_detr_config",
          34,
          58,
          53,
          30,
          53,
          95,
          50,
          29,
          56,
          23
        ]
      ],
      "transformers/src/transformers/models/vit/convert_dino_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          131,
          195,
          146,
          30,
          146,
          95,
          143,
          29,
          151,
          50
        ]
      ],
      "transformers/src/transformers/models/dinov2_with_registers/convert_dinov2_with_registers_to_hf.py": [
        [
          "get_dinov2_with_registers_config",
          45,
          73,
          70,
          37,
          70,
          102,
          67,
          19,
          71,
          23
        ]
      ],
      "transformers/src/transformers/models/dinov2/convert_dinov2_to_hf.py": [
        [
          "get_dinov2_config",
          40,
          68,
          65,
          37,
          65,
          102,
          62,
          19,
          66,
          23
        ]
      ],
      "transformers/src/transformers/models/doge/convert_doge_weights_to_hf.py": [
        [
          "convert_doge_model",
          94,
          109,
          96,
          10,
          96,
          53,
          94,
          24,
          106,
          33
        ]
      ],
      "transformers/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py": [
        [
          "convert_dit_checkpoint",
          133,
          210,
          154,
          30,
          154,
          95,
          151,
          29,
          163,
          32
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "get_efficientnet_config",
          122,
          139,
          134,
          26,
          134,
          91,
          122,
          29,
          139,
          17
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "load_model_state_dict",
          158,
          188,
          169,
          14,
          169,
          34,
          167,
          9,
          174,
          44
        ],
        [
          "convert_model",
          191,
          286,
          216,
          10,
          216,
          59,
          207,
          8,
          228,
          39
        ],
        [
          "convert_model",
          191,
          286,
          216,
          10,
          216,
          59,
          211,
          5,
          228,
          39
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_tiktoken",
          105,
          210,
          187,
          10,
          187,
          76,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          190,
          10,
          190,
          80,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          193,
          10,
          193,
          87,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          196,
          10,
          196,
          89,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          208,
          10,
          208,
          76,
          105,
          22,
          210,
          35
        ],
        [
          "convert_model",
          255,
          408,
          281,
          10,
          281,
          50,
          255,
          19,
          308,
          31
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_FastSpeech2ConformerModel_checkpoint",
          155,
          188,
          178,
          14,
          178,
          34,
          156,
          5,
          185,
          14
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          131,
          10,
          131,
          52,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          147,
          10,
          147,
          52,
          142,
          16,
          152,
          34
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          156,
          10,
          156,
          49,
          156,
          10,
          168,
          35
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          160,
          10,
          160,
          49,
          156,
          10,
          168,
          35
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          210,
          10,
          210,
          60,
          209,
          5,
          243,
          24
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          223,
          10,
          223,
          64,
          209,
          5,
          243,
          24
        ]
      ],
      "transformers/src/transformers/models/focalnet/convert_focalnet_to_hf_format.py": [
        [
          "get_focalnet_config",
          30,
          87,
          71,
          26,
          71,
          91,
          71,
          16,
          87,
          17
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "convert_glm_model",
          156,
          173,
          158,
          10,
          158,
          53,
          156,
          23,
          173,
          41
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "convert_glm4_model",
          161,
          178,
          163,
          10,
          163,
          53,
          161,
          24,
          178,
          41
        ]
      ],
      "transformers/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_gpt2_checkpoint_to_pytorch",
          86,
          104,
          103,
          10,
          103,
          62,
          92,
          13,
          104,
          40
        ]
      ],
      "transformers/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          112,
          133,
          114,
          29,
          114,
          50,
          112,
          38,
          133,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/convert_gptsan_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_gptsan_to_pt",
          28,
          171,
          30,
          25,
          30,
          44,
          28,
          29,
          31,
          17
        ]
      ],
      "transformers/src/transformers/models/hiera/convert_hiera_to_hf.py": [
        [
          "get_labels_for_classifier",
          158,
          168,
          163,
          26,
          163,
          91,
          158,
          31,
          168,
          41
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "main",
          700,
          805,
          786,
          10,
          786,
          91,
          743,
          28,
          797,
          82
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_tokenizer",
          426,
          772,
          771,
          14,
          771,
          42,
          769,
          9,
          772,
          68
        ],
        [
          "create_safetensors_index",
          317,
          322,
          321,
          10,
          321,
          76,
          321,
          10,
          322,
          39
        ]
      ],
      "transformers/src/transformers/models/hubert/convert_hubert_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_hubert_checkpoint",
          183,
          246,
          209,
          18,
          209,
          56,
          208,
          13,
          229,
          63
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "save_sharded_model",
          174,
          247,
          244,
          10,
          244,
          30,
          243,
          18,
          247,
          22
        ],
        [
          "merge_tp_weights",
          250,
          625,
          266,
          10,
          266,
          36,
          265,
          5,
          281,
          33
        ],
        [
          "merge_tp_weights",
          250,
          625,
          622,
          10,
          622,
          31,
          621,
          19,
          625,
          63
        ]
      ],
      "transformers/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py": [
        [
          "convert_imagegpt_checkpoint_to_pytorch",
          141,
          158,
          157,
          10,
          157,
          62,
          141,
          44,
          158,
          40
        ]
      ],
      "transformers/src/transformers/models/idefics3/convert_idefics3_weights_to_hf.py": [
        [
          "get_config",
          118,
          153,
          123,
          10,
          123,
          28,
          118,
          16,
          129,
          35
        ]
      ],
      "transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py": [
        [
          "convert_weights_and_push",
          83,
          149,
          89,
          26,
          89,
          91,
          83,
          30,
          142,
          17
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "load_model_state_dict",
          209,
          239,
          220,
          14,
          220,
          34,
          218,
          9,
          225,
          44
        ],
        [
          "convert_model",
          242,
          447,
          278,
          10,
          278,
          59,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          280,
          10,
          280,
          72,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          282,
          10,
          282,
          71,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          284,
          10,
          284,
          69,
          278,
          10,
          295,
          42
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "convert_openai_checkpoint",
          213,
          260,
          221,
          13,
          221,
          75,
          219,
          17,
          221,
          92
        ],
        [
          "convert_openai_checkpoint",
          213,
          260,
          254,
          10,
          254,
          62,
          253,
          5,
          260,
          22
        ]
      ],
      "transformers/src/transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          153,
          248,
          156,
          10,
          156,
          23,
          153,
          25,
          160,
          53
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "write_model",
          213,
          554,
          223,
          10,
          223,
          64,
          214,
          5,
          244,
          32
        ],
        [
          "max_context_length",
          199,
          210,
          204,
          10,
          204,
          59,
          204,
          10,
          207,
          37
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          99,
          10,
          99,
          23,
          95,
          25,
          103,
          53
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          98,
          357,
          102,
          10,
          102,
          23,
          98,
          25,
          106,
          103
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "read_json",
          174,
          176,
          175,
          10,
          175,
          24,
          174,
          15,
          176,
          27
        ],
        [
          "write_json",
          179,
          181,
          180,
          10,
          180,
          24,
          179,
          16,
          181,
          26
        ]
      ],
      "transformers/src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          28,
          131,
          30,
          10,
          30,
          28,
          28,
          29,
          62,
          54
        ],
        [
          "convert_luke_checkpoint",
          28,
          131,
          50,
          10,
          50,
          112,
          28,
          29,
          62,
          54
        ],
        [
          "load_entity_vocab",
          134,
          141,
          136,
          10,
          136,
          55,
          134,
          23,
          137,
          39
        ]
      ],
      "transformers/src/transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py": [
        [
          "convert_mamba2_checkpoint_file_to_huggingface_model_file",
          116,
          142,
          127,
          10,
          127,
          49,
          117,
          5,
          138,
          48
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "save_sharded_safetensors",
          143,
          167,
          160,
          10,
          160,
          91,
          144,
          5,
          165,
          50
        ],
        [
          "convert_mamba_ssm_checkpoint_file_to_huggingface_model_file",
          171,
          234,
          204,
          10,
          204,
          49,
          196,
          9,
          225,
          48
        ]
      ],
      "transformers/src/transformers/models/mamba/convert_mamba_ssm_checkpoint_to_pytorch.py": [
        [
          "convert_mamba_checkpoint_file_to_huggingface_model_file",
          97,
          126,
          111,
          10,
          111,
          54,
          108,
          5,
          126,
          41
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "get_maskformer_config",
          36,
          71,
          68,
          26,
          68,
          91,
          68,
          16,
          71,
          17
        ],
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          239,
          10,
          239,
          36,
          231,
          5,
          248,
          32
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "make_registry",
          281,
          295,
          293,
          24,
          293,
          44,
          293,
          19,
          294,
          27
        ],
        [
          "load_yaml",
          681,
          685,
          684,
          10,
          684,
          37,
          681,
          15,
          685,
          51
        ],
        [
          "save_json",
          688,
          690,
          689,
          10,
          689,
          24,
          688,
          15,
          690,
          29
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "get_maskformer_config",
          36,
          76,
          71,
          26,
          71,
          91,
          71,
          16,
          76,
          17
        ],
        [
          "convert_maskformer_checkpoint",
          261,
          350,
          270,
          10,
          270,
          36,
          262,
          5,
          276,
          32
        ]
      ],
      "transformers/src/transformers/models/mask2former/convert_mask2former_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "__call__",
          113,
          193,
          134,
          30,
          134,
          95,
          134,
          20,
          138,
          37
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "__init__",
          56,
          72,
          59,
          40,
          59,
          99,
          57,
          9,
          61,
          34
        ],
        [
          "__init__",
          56,
          72,
          61,
          21,
          61,
          34,
          57,
          9,
          61,
          34
        ],
        [
          "write_model_card",
          129,
          275,
          274,
          14,
          274,
          67,
          274,
          14,
          275,
          41
        ],
        [
          "parse_metadata",
          290,
          318,
          305,
          39,
          305,
          55,
          302,
          68,
          306,
          79
        ],
        [
          "parse_metadata",
          290,
          318,
          313,
          39,
          313,
          56,
          308,
          32,
          314,
          80
        ]
      ],
      "transformers/src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          125,
          10,
          125,
          79,
          124,
          39,
          191,
          42
        ]
      ],
      "transformers/src/transformers/models/mistral3/convert_mistral3_weights_to_hf.py": [
        [
          "read_json",
          74,
          76,
          75,
          10,
          75,
          24,
          74,
          15,
          76,
          27
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "read_json",
          62,
          64,
          63,
          10,
          63,
          24,
          62,
          15,
          64,
          27
        ]
      ],
      "transformers/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py": [
        [
          "read_json",
          51,
          53,
          52,
          10,
          52,
          24,
          51,
          15,
          53,
          27
        ],
        [
          "write_json",
          56,
          58,
          57,
          10,
          57,
          24,
          56,
          16,
          58,
          26
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "load_orig_config_file",
          41,
          64,
          55,
          10,
          55,
          33,
          41,
          27,
          57,
          22
        ],
        [
          "get_mobilevitv2_config",
          67,
          122,
          117,
          26,
          117,
          91,
          102,
          5,
          122,
          17
        ],
        [
          "get_mobilevitv2_config",
          67,
          122,
          117,
          26,
          117,
          91,
          116,
          15,
          122,
          17
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          29,
          183,
          31,
          10,
          31,
          28,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          54,
          10,
          54,
          83,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          57,
          10,
          57,
          83,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          60,
          10,
          60,
          113,
          29,
          29,
          74,
          61
        ],
        [
          "load_original_entity_vocab",
          186,
          200,
          189,
          42,
          189,
          64,
          186,
          32,
          192,
          21
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "get_mobilevit_config",
          39,
          70,
          65,
          26,
          65,
          91,
          64,
          15,
          70,
          17
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_tokenizer",
          497,
          565,
          564,
          14,
          564,
          42,
          562,
          9,
          565,
          68
        ],
        [
          "write_model",
          209,
          471,
          218,
          10,
          218,
          64,
          210,
          5,
          252,
          49
        ],
        [
          "write_image_processor",
          568,
          587,
          569,
          10,
          569,
          31,
          568,
          27,
          587,
          45
        ]
      ],
      "transformers/src/transformers/models/vit_msn/convert_msn_to_pytorch.py": [
        [
          "convert_vit_msn_checkpoint",
          148,
          228,
          154,
          26,
          154,
          70,
          148,
          32,
          159,
          30
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          122,
          10,
          122,
          81,
          119,
          17,
          126,
          26
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "main",
          287,
          300,
          297,
          29,
          297,
          66,
          288,
          5,
          300,
          82
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "read_json",
          58,
          60,
          59,
          10,
          59,
          24,
          58,
          15,
          60,
          27
        ],
        [
          "write_json",
          63,
          65,
          64,
          10,
          64,
          24,
          63,
          16,
          65,
          26
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "read_json",
          55,
          57,
          56,
          10,
          56,
          24,
          55,
          15,
          57,
          27
        ],
        [
          "write_json",
          60,
          62,
          61,
          10,
          61,
          24,
          60,
          16,
          62,
          26
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "read_json",
          81,
          83,
          82,
          10,
          82,
          24,
          81,
          15,
          83,
          27
        ],
        [
          "write_json",
          86,
          88,
          87,
          10,
          87,
          24,
          86,
          16,
          88,
          26
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "convert_hf_config",
          93,
          131,
          131,
          26,
          131,
          67,
          131,
          5,
          131,
          78
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "write_json",
          74,
          76,
          75,
          10,
          75,
          24,
          74,
          16,
          76,
          26
        ],
        [
          "read_json",
          69,
          71,
          70,
          10,
          70,
          24,
          69,
          15,
          71,
          27
        ],
        [
          "get_bytes_range",
          87,
          90,
          88,
          10,
          88,
          25,
          87,
          21,
          90,
          32
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          42,
          10,
          42,
          94,
          40,
          5,
          57,
          62
        ],
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          44,
          10,
          44,
          91,
          40,
          5,
          57,
          62
        ],
        [
          "convert_openai_checkpoint_to_pytorch",
          109,
          127,
          126,
          10,
          126,
          62,
          115,
          13,
          127,
          40
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v1_config",
          142,
          164,
          158,
          26,
          158,
          91,
          155,
          25,
          164,
          17
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "convert_tiktoken_to_hf",
          291,
          327,
          315,
          14,
          315,
          52,
          295,
          43,
          320,
          36
        ],
        [
          "_download",
          147,
          182,
          158,
          23,
          158,
          49,
          158,
          23,
          159,
          78
        ],
        [
          "_download",
          147,
          182,
          164,
          49,
          164,
          75,
          164,
          10,
          167,
          17
        ],
        [
          "_download",
          147,
          182,
          176,
          19,
          176,
          45,
          171,
          21,
          177,
          74
        ],
        [
          "convert_tiktoken_to_hf",
          291,
          327,
          318,
          14,
          318,
          52,
          295,
          43,
          320,
          36
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v2_config",
          209,
          242,
          231,
          26,
          231,
          91,
          230,
          15,
          233,
          32
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          310,
          14,
          310,
          35,
          292,
          9,
          315,
          20
        ],
        [
          "convert_checkpoint",
          266,
          360,
          332,
          55,
          332,
          88,
          332,
          55,
          336,
          17
        ],
        [
          "convert_checkpoint",
          266,
          360,
          339,
          14,
          339,
          49,
          338,
          10,
          357,
          14
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "read_json",
          176,
          178,
          177,
          10,
          177,
          24,
          176,
          15,
          178,
          27
        ],
        [
          "write_json",
          181,
          183,
          182,
          10,
          182,
          24,
          181,
          16,
          183,
          26
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          269,
          10,
          269,
          32,
          263,
          34,
          273,
          35
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          320,
          30,
          320,
          95,
          308,
          30,
          324,
          49
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          369,
          30,
          369,
          95,
          345,
          30,
          372,
          23
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/convert_phi4_multimodal_weights_to_hf.py": [
        [
          "convert_and_save_processor",
          169,
          213,
          201,
          27,
          201,
          67,
          169,
          32,
          213,
          81
        ],
        [
          "read_json",
          138,
          140,
          139,
          10,
          139,
          24,
          138,
          15,
          140,
          27
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          196,
          23,
          196,
          59,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          199,
          22,
          199,
          58,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          208,
          26,
          208,
          66,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          210,
          34,
          210,
          81,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          213,
          33,
          213,
          80,
          169,
          32,
          213,
          81
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "convert_poolformer_checkpoint",
          93,
          195,
          109,
          26,
          109,
          91,
          93,
          35,
          113,
          20
        ]
      ],
      "transformers/src/transformers/models/pixtral/convert_pixtral_weights_to_hf.py": [
        [
          "convert_mistral_model",
          145,
          210,
          148,
          14,
          148,
          45,
          148,
          14,
          151,
          50
        ],
        [
          "main",
          213,
          241,
          240,
          35,
          240,
          63,
          240,
          35,
          240,
          31
        ]
      ],
      "transformers/src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py": [
        [
          "convert_trax_checkpoint_to_pytorch",
          185,
          198,
          191,
          10,
          191,
          40,
          185,
          40,
          198,
          53
        ]
      ],
      "transformers/src/transformers/models/resnet/convert_resnet_to_pytorch.py": [
        [
          "convert_weights_and_push",
          125,
          164,
          131,
          26,
          131,
          91,
          125,
          30,
          159,
          17
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "get_rt_detr_v2_config",
          37,
          73,
          43,
          26,
          43,
          91,
          37,
          27,
          48,
          38
        ]
      ],
      "transformers/src/transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": [
        [
          "get_rt_detr_config",
          35,
          84,
          41,
          26,
          41,
          91,
          35,
          24,
          46,
          35
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          135,
          14,
          135,
          57,
          133,
          27,
          149,
          37
        ]
      ],
      "transformers/src/transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          223,
          290,
          269,
          18,
          269,
          56,
          268,
          13,
          281,
          63
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "convert_segformer_checkpoint",
          120,
          368,
          153,
          26,
          153,
          91,
          153,
          16,
          157,
          19
        ],
        [
          "convert_segformer_checkpoint",
          120,
          368,
          153,
          26,
          153,
          91,
          144,
          24,
          157,
          19
        ]
      ],
      "transformers/src/transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          235,
          302,
          281,
          18,
          281,
          56,
          280,
          13,
          293,
          63
        ]
      ],
      "transformers/src/transformers/models/speech_encoder_decoder/convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py": [
        [
          "create_vocab_dict",
          195,
          210,
          196,
          10,
          196,
          47,
          195,
          23,
          210,
          21
        ],
        [
          "convert_wav2vec2_checkpoint",
          214,
          284,
          268,
          10,
          268,
          72,
          215,
          5,
          284,
          63
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "convert_swiftformer_checkpoint",
          89,
          153,
          101,
          26,
          101,
          91,
          89,
          36,
          107,
          43
        ]
      ],
      "transformers/src/transformers/convert_slow_tokenizer.py": [
        [
          "__init__",
          550,
          569,
          559,
          14,
          559,
          59,
          550,
          18,
          563,
          48
        ],
        [
          "__init__",
          1416,
          1427,
          1425,
          14,
          1425,
          35,
          1416,
          18,
          1427,
          18
        ],
        [
          "__init__",
          1457,
          1467,
          1465,
          14,
          1465,
          35,
          1457,
          18,
          1467,
          18
        ],
        [
          "__init__",
          1546,
          1557,
          1555,
          14,
          1555,
          35,
          1546,
          18,
          1557,
          18
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_timm_to_pytorch.py": [
        [
          "get_swin_config",
          13,
          56,
          44,
          30,
          44,
          95,
          41,
          23,
          47,
          23
        ]
      ],
      "transformers/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py": [
        [
          "get_swinv2_config",
          30,
          89,
          68,
          30,
          68,
          95,
          65,
          23,
          71,
          23
        ],
        [
          "get_swinv2_config",
          30,
          89,
          77,
          30,
          77,
          95,
          74,
          23,
          80,
          23
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_swin_upernet_to_pytorch.py": [
        [
          "get_upernet_config",
          31,
          78,
          59,
          26,
          59,
          91,
          56,
          18,
          78,
          17
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "convert_textnet_checkpoint",
          116,
          181,
          119,
          10,
          119,
          30,
          116,
          32,
          124,
          62
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": [
        [
          "convert_gin_to_config",
          264,
          282,
          268,
          10,
          268,
          28,
          264,
          27,
          273,
          35
        ]
      ],
      "transformers/src/transformers/models/timesformer/convert_timesformer_to_pytorch.py": [
        [
          "get_timesformer_config",
          28,
          55,
          50,
          26,
          50,
          91,
          50,
          16,
          55,
          17
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          173,
          14,
          173,
          48,
          173,
          14,
          185,
          67
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          208,
          14,
          208,
          66,
          198,
          9,
          209,
          44
        ]
      ],
      "transformers/src/transformers/models/unispeech/convert_unispeech_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_unispeech_checkpoint",
          190,
          258,
          221,
          18,
          221,
          56,
          215,
          13,
          241,
          63
        ]
      ],
      "transformers/src/transformers/models/deprecated/van/convert_van_to_pytorch.py": [
        [
          "convert_weights_and_push",
          166,
          241,
          171,
          26,
          171,
          91,
          166,
          30,
          223,
          17
        ]
      ],
      "transformers/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py": [
        [
          "convert_vilt_checkpoint",
          168,
          282,
          184,
          30,
          184,
          95,
          180,
          21,
          208,
          32
        ]
      ],
      "transformers/src/transformers/models/vivit/convert_vivit_flax_to_pytorch.py": [
        [
          "get_vivit_config",
          43,
          54,
          50,
          26,
          50,
          91,
          44,
          14,
          54,
          17
        ],
        [
          "download_checkpoint",
          34,
          40,
          37,
          10,
          37,
          25,
          34,
          25,
          39,
          58
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_classifier_to_hf.py": [
        [
          "get_id2label_mapping",
          94,
          103,
          100,
          10,
          100,
          24,
          94,
          26,
          103,
          19
        ]
      ],
      "transformers/src/transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          165,
          262,
          196,
          26,
          196,
          91,
          192,
          5,
          202,
          31
        ]
      ],
      "transformers/src/transformers/models/videomae/convert_videomae_to_pytorch.py": [
        [
          "get_videomae_config",
          33,
          56,
          51,
          30,
          51,
          95,
          51,
          20,
          54,
          23
        ]
      ],
      "transformers/src/transformers/models/voxtral/convert_voxtral_weights_to_hf.py": [
        [
          "write_model",
          174,
          234,
          189,
          10,
          189,
          31,
          175,
          5,
          234,
          41
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_conformer/convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_conformer_checkpoint",
          220,
          294,
          254,
          18,
          254,
          56,
          248,
          13,
          274,
          63
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "read_txt_into_dict",
          74,
          84,
          76,
          10,
          76,
          28,
          74,
          24,
          77,
          48
        ],
        [
          "convert_wav2vec2_checkpoint",
          274,
          358,
          318,
          18,
          318,
          56,
          312,
          13,
          338,
          63
        ]
      ],
      "transformers/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          59,
          10,
          59,
          62,
          44,
          14,
          64,
          51
        ],
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          63,
          10,
          63,
          61,
          44,
          14,
          64,
          51
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "convert_checkpoint",
          185,
          261,
          187,
          10,
          187,
          31,
          185,
          24,
          205,
          38
        ]
      ],
      "transformers/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          225,
          10,
          225,
          62,
          217,
          5,
          226,
          40
        ]
      ],
      "transformers/utils/create_dependency_mapping.py": [
        [
          "extract_model_imports_from_file",
          70,
          81,
          73,
          10,
          73,
          47,
          70,
          37,
          77,
          30
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "get_yolos_config",
          34,
          66,
          61,
          26,
          61,
          91,
          58,
          25,
          66,
          17
        ]
      ],
      "transformers/.circleci/create_circleci_config.py": [
        [
          "__post_init__",
          98,
          129,
          123,
          22,
          123,
          36,
          123,
          22,
          126,
          47
        ],
        [
          "create_circleci_config",
          354,
          393,
          392,
          10,
          392,
          64,
          392,
          10,
          393,
          141
        ]
      ],
      "transformers/utils/custom_init_isort.py": [
        [
          "sort_imports",
          235,
          305,
          243,
          10,
          243,
          37,
          235,
          18,
          247,
          38
        ],
        [
          "sort_imports",
          235,
          305,
          304,
          18,
          304,
          50,
          303,
          13,
          305,
          47
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1295,
          10,
          1295,
          67,
          1294,
          36,
          1299,
          38
        ],
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1297,
          10,
          1297,
          52,
          1294,
          36,
          1299,
          38
        ],
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1317,
          10,
          1317,
          80,
          1317,
          10,
          1318,
          65
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1401,
          14,
          1401,
          72,
          1401,
          14,
          1402,
          51
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1409,
          10,
          1409,
          72,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1412,
          10,
          1412,
          80,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1418,
          10,
          1418,
          67,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1424,
          10,
          1424,
          66,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1428,
          10,
          1428,
          73,
          1408,
          26,
          1431,
          84
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "update_relative_imports",
          112,
          124,
          123,
          10,
          123,
          28,
          123,
          10,
          124,
          42
        ],
        [
          "insert_tip_to_model_doc",
          59,
          77,
          62,
          10,
          62,
          34,
          59,
          29,
          69,
          21
        ],
        [
          "insert_tip_to_model_doc",
          59,
          77,
          76,
          10,
          76,
          34,
          76,
          10,
          77,
          43
        ],
        [
          "update_relative_imports",
          112,
          124,
          113,
          10,
          113,
          28,
          112,
          29,
          117,
          37
        ],
        [
          "remove_copied_from_statements",
          127,
          143,
          133,
          14,
          133,
          33,
          132,
          21,
          137,
          42
        ],
        [
          "remove_copied_from_statements",
          127,
          143,
          142,
          14,
          142,
          33,
          142,
          14,
          143,
          46
        ],
        [
          "update_main_init_file",
          173,
          193,
          181,
          10,
          181,
          28,
          173,
          27,
          185,
          23
        ],
        [
          "update_main_init_file",
          173,
          193,
          189,
          10,
          189,
          28,
          189,
          10,
          193,
          47
        ],
        [
          "remove_model_references_from_file",
          196,
          216,
          206,
          10,
          206,
          28,
          196,
          39,
          210,
          51
        ],
        [
          "remove_model_references_from_file",
          196,
          216,
          215,
          10,
          215,
          28,
          215,
          10,
          216,
          42
        ],
        [
          "remove_model_config_classes_from_config_check",
          219,
          266,
          227,
          10,
          227,
          28,
          219,
          51,
          235,
          51
        ],
        [
          "remove_model_config_classes_from_config_check",
          219,
          266,
          265,
          10,
          265,
          28,
          265,
          10,
          266,
          42
        ],
        [
          "add_models_to_deprecated_models_in_config_auto",
          269,
          300,
          275,
          10,
          275,
          28,
          269,
          52,
          281,
          39
        ],
        [
          "add_models_to_deprecated_models_in_config_auto",
          269,
          300,
          299,
          10,
          299,
          28,
          299,
          10,
          300,
          42
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "format_mrpc",
          57,
          106,
          78,
          10,
          78,
          69,
          75,
          5,
          79,
          25
        ],
        [
          "format_mrpc",
          57,
          106,
          83,
          9,
          83,
          46,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          84,
          9,
          84,
          71,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          85,
          9,
          85,
          69,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          98,
          9,
          98,
          45,
          98,
          9,
          103,
          42
        ],
        [
          "format_mrpc",
          57,
          106,
          99,
          9,
          99,
          70,
          98,
          9,
          103,
          42
        ]
      ],
      "transformers/utils/extract_warnings.py": [
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          47,
          22,
          47,
          36,
          47,
          22,
          48,
          34
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_relative_imports",
          125,
          143,
          135,
          10,
          135,
          44,
          125,
          26,
          143,
          38
        ],
        [
          "get_imports",
          178,
          230,
          188,
          10,
          188,
          41,
          178,
          17,
          230,
          35
        ],
        [
          "check_python_requirements",
          779,
          832,
          795,
          14,
          795,
          36,
          794,
          9,
          795,
          36
        ]
      ],
      "transformers/src/transformers/models/auto/feature_extraction_auto.py": [
        [
          "get_feature_extractor_config",
          106,
          201,
          200,
          10,
          200,
          53,
          200,
          10,
          201,
          32
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "get_feature_extractor_dict",
          417,
          529,
          512,
          18,
          512,
          72,
          467,
          47,
          512,
          72
        ],
        [
          "get_feature_extractor_dict",
          417,
          529,
          512,
          18,
          512,
          72,
          510,
          9,
          512,
          72
        ],
        [
          "from_json_file",
          584,
          600,
          597,
          14,
          597,
          46,
          584,
          24,
          600,
          44
        ],
        [
          "to_json_file",
          623,
          632,
          631,
          14,
          631,
          56,
          623,
          22,
          632,
          47
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "download_artifact",
          93,
          109,
          108,
          10,
          108,
          30,
          104,
          14,
          109,
          34
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_last_daily_ci_reports",
          123,
          159,
          155,
          26,
          155,
          40,
          155,
          26,
          157,
          56
        ]
      ],
      "transformers/utils/get_pr_run_slow_jobs.py": [
        [
          "get_jobs_to_run",
          10,
          46,
          15,
          10,
          15,
          29,
          15,
          10,
          34,
          27
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          714,
          14,
          714,
          69,
          714,
          14,
          716,
          47
        ],
        [
          "is_timm_local_checkpoint",
          693,
          718,
          708,
          14,
          708,
          40,
          708,
          14,
          710,
          47
        ]
      ],
      "transformers/src/transformers/hf_argparser.py": [
        [
          "parse_json_file",
          386,
          408,
          405,
          14,
          405,
          52,
          387,
          9,
          408,
          29
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "get_checkpoint_shard_files",
          1011,
          1078,
          1049,
          10,
          1049,
          29,
          1049,
          10,
          1058,
          51
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "get_image_processor_dict",
          264,
          382,
          365,
          18,
          365,
          70,
          320,
          45,
          365,
          70
        ],
        [
          "get_image_processor_dict",
          264,
          382,
          365,
          18,
          365,
          70,
          363,
          9,
          365,
          70
        ],
        [
          "from_json_file",
          442,
          458,
          455,
          14,
          455,
          46,
          442,
          24,
          458,
          42
        ],
        [
          "to_json_file",
          481,
          490,
          489,
          14,
          489,
          56,
          481,
          22,
          490,
          47
        ]
      ],
      "transformers/src/transformers/models/auto/image_processing_auto.py": [
        [
          "get_image_processor_config",
          243,
          338,
          337,
          10,
          337,
          53,
          337,
          10,
          338,
          32
        ]
      ],
      "transformers/src/transformers/models/oneformer/image_processing_oneformer.py": [
        [
          "load_metadata",
          382,
          397,
          394,
          10,
          394,
          25,
          394,
          10,
          397,
          21
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/lightning_base.py": [
        [
          "on_test_end",
          287,
          296,
          292,
          14,
          292,
          48,
          287,
          21,
          293,
          38
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          41,
          100,
          82,
          22,
          82,
          54,
          79,
          17,
          87,
          83
        ],
        [
          "__init__",
          41,
          100,
          72,
          22,
          72,
          53,
          71,
          25,
          76,
          17
        ],
        [
          "__init__",
          41,
          100,
          96,
          22,
          96,
          53,
          95,
          25,
          100,
          17
        ],
        [
          "__init__",
          110,
          129,
          124,
          14,
          124,
          46,
          122,
          9,
          129,
          21
        ],
        [
          "__init__",
          139,
          173,
          155,
          14,
          155,
          46,
          153,
          9,
          161,
          32
        ],
        [
          "__init__",
          139,
          173,
          159,
          14,
          159,
          45,
          153,
          9,
          161,
          32
        ],
        [
          "__init__",
          187,
          226,
          205,
          18,
          205,
          50,
          204,
          28,
          208,
          42
        ],
        [
          "__init__",
          335,
          418,
          384,
          22,
          384,
          53,
          383,
          25,
          388,
          17
        ],
        [
          "__init__",
          335,
          418,
          393,
          22,
          393,
          54,
          390,
          17,
          393,
          59
        ],
        [
          "__init__",
          335,
          418,
          414,
          22,
          414,
          53,
          413,
          25,
          418,
          17
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "save_model_architecture_to_file",
          754,
          761,
          755,
          10,
          755,
          59,
          754,
          37,
          756,
          45
        ]
      ],
      "transformers/src/transformers/utils/logging.py": [
        [
          "_configure_library_root_logger",
          80,
          104,
          90,
          26,
          90,
          46,
          90,
          26,
          90,
          22
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2203,
          14,
          2203,
          73,
          2203,
          14,
          2216,
          72
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "from_json_file",
          225,
          230,
          227,
          14,
          227,
          46,
          225,
          24,
          230,
          30
        ],
        [
          "to_json_file",
          247,
          250,
          249,
          14,
          249,
          56,
          247,
          22,
          250,
          47
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "log_model_debug_trace",
          228,
          268,
          244,
          10,
          244,
          29,
          238,
          5,
          268,
          41
        ],
        [
          "log_model_debug_trace",
          228,
          268,
          267,
          10,
          267,
          32,
          238,
          5,
          268,
          41
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "load_sharded_checkpoint",
          372,
          444,
          409,
          10,
          409,
          48,
          407,
          18,
          419,
          13
        ],
        [
          "load_state_dict",
          469,
          536,
          523,
          18,
          523,
          38,
          521,
          5,
          523,
          38
        ],
        [
          "_can_set_attn_implementation",
          2621,
          2636,
          2626,
          14,
          2626,
          34,
          2621,
          38,
          2629,
          62
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4063,
          18,
          4063,
          61,
          4060,
          31,
          4070,
          13
        ],
        [
          "from_pretrained",
          4261,
          4989,
          4623,
          22,
          4623,
          69,
          4623,
          22,
          4625,
          49
        ]
      ],
      "transformers/utils/models_to_deprecate.py": [
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          273,
          14,
          273,
          42,
          273,
          14,
          274,
          47
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          188,
          14,
          188,
          42,
          188,
          14,
          191,
          46
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "build_index",
          417,
          450,
          447,
          14,
          447,
          53,
          440,
          9,
          450,
          22
        ],
        [
          "build_index",
          417,
          450,
          445,
          14,
          445,
          56,
          440,
          9,
          450,
          22
        ],
        [
          "analyze_file",
          518,
          576,
          538,
          14,
          538,
          82,
          536,
          16,
          559,
          63
        ],
        [
          "analyze_file",
          518,
          576,
          541,
          14,
          541,
          79,
          536,
          16,
          559,
          63
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "get_module_source_from_name",
          48,
          56,
          54,
          10,
          54,
          49,
          54,
          10,
          56,
          22
        ],
        [
          "convert_modular_file",
          1686,
          1715,
          1693,
          14,
          1693,
          54,
          1691,
          22,
          1699,
          68
        ],
        [
          "save_modeling_files",
          1718,
          1727,
          1726,
          14,
          1726,
          55,
          1722,
          28,
          1727,
          47
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "retrieve_artifact",
          276,
          288,
          283,
          22,
          283,
          69,
          283,
          62,
          283,
          69
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "model_failures",
          372,
          528,
          484,
          14,
          484,
          51,
          457,
          17,
          497,
          45
        ],
        [
          "model_failures",
          372,
          528,
          494,
          14,
          494,
          51,
          457,
          17,
          497,
          45
        ],
        [
          "model_failures",
          372,
          528,
          515,
          26,
          515,
          63,
          508,
          35,
          526,
          21
        ],
        [
          "payload",
          556,
          698,
          602,
          22,
          602,
          59,
          596,
          28,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          602,
          22,
          602,
          59,
          600,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          602,
          22,
          602,
          59,
          598,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          636,
          22,
          636,
          59,
          635,
          29,
          663,
          40
        ],
        [
          "payload",
          556,
          698,
          636,
          22,
          636,
          59,
          635,
          29,
          670,
          156
        ],
        [
          "retrieve_artifact",
          944,
          959,
          954,
          22,
          954,
          60,
          954,
          22,
          954,
          60
        ]
      ],
      "transformers/examples/pytorch/old_test_xla_examples.py": [
        [
          "get_results",
          31,
          39,
          35,
          14,
          35,
          23,
          35,
          14,
          39,
          18
        ]
      ],
      "transformers/.circleci/parse_test_outputs.py": [
        [
          "parse_pytest_output",
          5,
          17,
          8,
          10,
          8,
          29,
          5,
          25,
          9,
          24
        ],
        [
          "parse_pytest_failure_output",
          19,
          33,
          22,
          10,
          22,
          29,
          19,
          33,
          23,
          24
        ],
        [
          "parse_pytest_errors_output",
          35,
          50,
          39,
          10,
          39,
          29,
          35,
          32,
          40,
          24
        ]
      ],
      "transformers/examples/legacy/benchmarking/plot_csv_file.py": [
        [
          "__init__",
          84,
          103,
          88,
          14,
          88,
          49,
          84,
          18,
          90,
          29
        ]
      ],
      "transformers/utils/process_test_artifacts.py": [
        [
          "count_lines",
          30,
          36,
          33,
          14,
          33,
          32,
          30,
          17,
          33,
          32
        ],
        [
          "process_artifacts",
          47,
          69,
          49,
          10,
          49,
          30,
          47,
          23,
          54,
          37
        ],
        [
          "process_artifacts",
          47,
          69,
          68,
          10,
          68,
          31,
          68,
          10,
          69,
          48
        ]
      ],
      "transformers/src/transformers/models/bark/processing_bark.py": [
        [
          "from_pretrained",
          67,
          122,
          112,
          22,
          112,
          50,
          112,
          22,
          113,
          38
        ],
        [
          "save_pretrained",
          124,
          178,
          175,
          18,
          175,
          86,
          175,
          18,
          176,
          46
        ]
      ],
      "transformers/src/transformers/models/auto/processing_auto.py": [
        [
          "from_pretrained",
          204,
          425,
          350,
          22,
          350,
          66,
          350,
          22,
          354,
          69
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "to_json_file",
          707,
          716,
          715,
          14,
          715,
          56,
          707,
          22,
          716,
          88
        ],
        [
          "save_pretrained",
          723,
          896,
          820,
          22,
          820,
          81,
          820,
          22,
          822,
          88
        ],
        [
          "save_pretrained",
          723,
          896,
          828,
          30,
          828,
          89,
          828,
          30,
          830,
          96
        ],
        [
          "save_pretrained",
          723,
          896,
          834,
          30,
          834,
          75,
          832,
          25,
          836,
          82
        ],
        [
          "save_pretrained",
          723,
          896,
          842,
          22,
          842,
          82,
          840,
          21,
          844,
          89
        ],
        [
          "save_pretrained",
          723,
          896,
          876,
          22,
          876,
          77,
          869,
          41,
          877,
          54
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1072,
          18,
          1072,
          68,
          1072,
          18,
          1075,
          58
        ],
        [
          "dictcomp",
          1083,
          1084,
          1084,
          32,
          1084,
          73,
          1085,
          21,
          1084,
          80
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1088,
          22,
          1088,
          81,
          1088,
          22,
          1089,
          45
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1106,
          22,
          1106,
          68,
          1104,
          13,
          1106,
          68
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1133,
          26,
          1133,
          83,
          1133,
          26,
          1135,
          36
        ]
      ],
      "transformers/src/transformers/utils/quantization_config.py": [
        [
          "to_json_file",
          137,
          152,
          148,
          14,
          148,
          56,
          137,
          22,
          152,
          37
        ]
      ],
      "transformers/utils/release.py": [
        [
          "update_version_in_file",
          81,
          96,
          90,
          10,
          90,
          57,
          81,
          28,
          96,
          21
        ],
        [
          "update_version_in_file",
          81,
          96,
          95,
          10,
          95,
          57,
          81,
          28,
          96,
          21
        ],
        [
          "get_version",
          153,
          160,
          157,
          10,
          157,
          41,
          154,
          5,
          160,
          51
        ]
      ],
      "transformers/examples/legacy/seq2seq/rouge_cli.py": [
        [
          "calculate_rouge_path",
          20,
          27,
          22,
          36,
          22,
          50,
          20,
          26,
          25,
          28
        ],
        [
          "calculate_rouge_path",
          20,
          27,
          23,
          35,
          23,
          48,
          20,
          26,
          25,
          28
        ]
      ],
      "transformers/src/transformers/models/rag/retrieval_rag.py": [
        [
          "_load_passages",
          133,
          145,
          143,
          14,
          143,
          38,
          143,
          14,
          145,
          23
        ],
        [
          "_deserialize_index",
          147,
          163,
          159,
          14,
          159,
          43,
          159,
          14,
          161,
          63
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "generate_summary_report",
          164,
          190,
          186,
          10,
          186,
          32,
          165,
          5,
          190,
          23
        ]
      ],
      "transformers/examples/legacy/run_chinese_ref.py": [
        [
          "main",
          116,
          129,
          119,
          10,
          119,
          47,
          116,
          10,
          129,
          26
        ],
        [
          "main",
          116,
          129,
          127,
          10,
          127,
          52,
          116,
          10,
          129,
          26
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          735,
          18,
          735,
          47,
          735,
          18,
          738,
          57
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_distributed_eval.py": [
        [
          "run_generate",
          119,
          227,
          207,
          14,
          207,
          27,
          206,
          20,
          212,
          46
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval.py": [
        [
          "run_generate",
          85,
          178,
          176,
          27,
          176,
          52,
          176,
          9,
          176,
          53
        ],
        [
          "run_generate",
          85,
          178,
          133,
          86,
          133,
          106,
          133,
          86,
          134,
          21
        ],
        [
          "run_generate",
          85,
          178,
          162,
          39,
          162,
          58,
          161,
          16,
          167,
          21
        ],
        [
          "run_generate",
          85,
          178,
          163,
          42,
          163,
          66,
          161,
          16,
          167,
          21
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          311,
          18,
          311,
          72,
          308,
          19,
          312,
          44
        ],
        [
          "main",
          268,
          722,
          718,
          18,
          718,
          77,
          718,
          18,
          719,
          56
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          634,
          22,
          634,
          51,
          634,
          22,
          637,
          61
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "pil_loader",
          79,
          82,
          80,
          10,
          80,
          25,
          79,
          16,
          82,
          32
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          273,
          18,
          273,
          72,
          270,
          19,
          274,
          44
        ],
        [
          "main",
          235,
          692,
          688,
          14,
          688,
          73,
          687,
          51,
          689,
          37
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          907,
          18,
          907,
          77,
          907,
          18,
          908,
          56
        ],
        [
          "main",
          328,
          911,
          377,
          18,
          377,
          72,
          373,
          23,
          378,
          44
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          521,
          22,
          521,
          48,
          521,
          22,
          524,
          61
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "main",
          234,
          650,
          278,
          18,
          278,
          72,
          275,
          19,
          279,
          44
        ],
        [
          "main",
          234,
          650,
          646,
          18,
          646,
          77,
          645,
          55,
          647,
          41
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "main",
          197,
          364,
          356,
          18,
          356,
          44,
          356,
          18,
          358,
          48
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "handle_repository_creation",
          387,
          410,
          401,
          18,
          401,
          72,
          398,
          19,
          402,
          44
        ],
        [
          "main",
          413,
          747,
          731,
          18,
          731,
          77,
          731,
          18,
          736,
          31
        ]
      ],
      "transformers/examples/legacy/multiple_choice/run_multiple_choice.py": [
        [
          "main",
          90,
          234,
          226,
          18,
          226,
          44,
          226,
          18,
          228,
          48
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          430,
          18,
          430,
          72,
          427,
          19,
          431,
          44
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          318,
          18,
          318,
          72,
          315,
          19,
          319,
          44
        ],
        [
          "main",
          275,
          760,
          756,
          18,
          756,
          77,
          756,
          18,
          757,
          56
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          277,
          18,
          277,
          44,
          277,
          18,
          279,
          48
        ],
        [
          "main",
          101,
          315,
          303,
          18,
          303,
          52,
          303,
          18,
          304,
          49
        ],
        [
          "main",
          101,
          315,
          311,
          18,
          311,
          56,
          311,
          18,
          313,
          94
        ],
        [
          "main",
          101,
          315,
          312,
          22,
          312,
          71,
          311,
          18,
          313,
          94
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          636,
          18,
          636,
          51,
          636,
          18,
          637,
          50
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          322,
          18,
          322,
          72,
          319,
          19,
          323,
          44
        ],
        [
          "main",
          284,
          835,
          825,
          18,
          825,
          77,
          825,
          18,
          827,
          53
        ]
      ],
      "transformers/examples/legacy/run_openai_gpt.py": [
        [
          "load_rocstories_dataset",
          62,
          70,
          64,
          10,
          64,
          45,
          62,
          29,
          68,
          27
        ],
        [
          "main",
          104,
          315,
          311,
          14,
          311,
          40,
          307,
          22,
          313,
          44
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection_no_trainer.py": [
        [
          "main",
          411,
          796,
          449,
          18,
          449,
          72,
          446,
          19,
          450,
          44
        ],
        [
          "main",
          411,
          796,
          780,
          18,
          780,
          77,
          780,
          18,
          785,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          342,
          18,
          342,
          72,
          339,
          19,
          343,
          44
        ],
        [
          "save_prefixed_metrics",
          64,
          84,
          83,
          10,
          83,
          55,
          83,
          10,
          84,
          39
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          268,
          26,
          268,
          86,
          268,
          16,
          307,
          30
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "main",
          253,
          637,
          291,
          18,
          291,
          72,
          288,
          19,
          292,
          44
        ],
        [
          "main",
          253,
          637,
          327,
          26,
          327,
          86,
          327,
          16,
          345,
          46
        ],
        [
          "main",
          253,
          637,
          633,
          18,
          633,
          77,
          631,
          89,
          634,
          51
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "save_prefixed_metrics",
          69,
          89,
          88,
          10,
          88,
          55,
          88,
          10,
          89,
          39
        ],
        [
          "main",
          338,
          1035,
          381,
          18,
          381,
          72,
          378,
          19,
          382,
          44
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          580,
          22,
          580,
          42,
          571,
          17,
          581,
          47
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          584,
          22,
          584,
          42,
          584,
          22,
          585,
          47
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "read_swag_examples",
          98,
          121,
          99,
          10,
          99,
          43,
          98,
          24,
          102,
          18
        ],
        [
          "evaluate",
          413,
          470,
          464,
          10,
          464,
          36,
          459,
          17,
          466,
          40
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          281,
          18,
          281,
          72,
          278,
          19,
          282,
          44
        ],
        [
          "main",
          238,
          654,
          650,
          18,
          650,
          77,
          649,
          55,
          651,
          41
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          392,
          18,
          392,
          72,
          389,
          19,
          393,
          44
        ],
        [
          "main",
          339,
          809,
          808,
          18,
          808,
          77,
          807,
          55,
          809,
          41
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          755,
          22,
          755,
          54,
          748,
          31,
          756,
          56
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          677,
          22,
          677,
          72,
          670,
          31,
          678,
          56
        ]
      ],
      "transformers/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py": [
        [
          "main",
          406,
          804,
          443,
          18,
          443,
          72,
          440,
          19,
          444,
          44
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          369,
          18,
          369,
          72,
          366,
          19,
          370,
          44
        ],
        [
          "main",
          329,
          796,
          792,
          14,
          792,
          73,
          792,
          14,
          793,
          61
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_xnli.py": [
        [
          "main",
          194,
          461,
          457,
          18,
          457,
          47,
          457,
          18,
          459,
          57
        ]
      ],
      "transformers/utils/sort_auto_mappings.py": [
        [
          "sort_auto_mapping",
          50,
          99,
          62,
          10,
          62,
          43,
          50,
          23,
          67,
          12
        ],
        [
          "sort_auto_mapping",
          50,
          99,
          96,
          14,
          96,
          47,
          96,
          14,
          97,
          41
        ]
      ],
      "transformers/setup.py": [
        [
          "run",
          238,
          252,
          251,
          14,
          251,
          62,
          238,
          13,
          252,
          39
        ]
      ],
      "transformers/src/transformers/data/metrics/squad_metrics.py": [
        [
          "compute_predictions_logits",
          383,
          587,
          576,
          14,
          576,
          46,
          575,
          8,
          583,
          32
        ],
        [
          "compute_predictions_logits",
          383,
          587,
          580,
          14,
          580,
          41,
          575,
          8,
          583,
          32
        ],
        [
          "compute_predictions_logits",
          383,
          587,
          584,
          14,
          584,
          49,
          584,
          14,
          585,
          71
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          769,
          10,
          769,
          42,
          769,
          10,
          775,
          30
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          772,
          10,
          772,
          37,
          769,
          10,
          775,
          30
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          776,
          14,
          776,
          49,
          776,
          14,
          777,
          71
        ]
      ],
      "transformers/examples/legacy/token-classification/tasks.py": [
        [
          "read_examples_from_file",
          17,
          43,
          23,
          14,
          23,
          46,
          20,
          21,
          26,
          25
        ],
        [
          "get_labels",
          58,
          66,
          60,
          18,
          60,
          27,
          60,
          18,
          62,
          32
        ],
        [
          "get_labels",
          74,
          104,
          76,
          18,
          76,
          27,
          76,
          18,
          78,
          32
        ],
        [
          "read_examples_from_file",
          108,
          126,
          115,
          14,
          115,
          46,
          111,
          21,
          116,
          41
        ],
        [
          "get_labels",
          139,
          162,
          141,
          18,
          141,
          27,
          141,
          18,
          142,
          44
        ]
      ],
      "transformers/src/transformers/data/processors/squad.py": [
        [
          "get_train_examples",
          500,
          520,
          516,
          14,
          518,
          9,
          517,
          36,
          520,
          57
        ],
        [
          "get_dev_examples",
          522,
          541,
          537,
          14,
          539,
          9,
          538,
          36,
          541,
          55
        ]
      ],
      "transformers/src/transformers/integrations/tensor_parallel.py": [
        [
          "initialize_tensor_parallelism",
          41,
          94,
          89,
          22,
          89,
          42,
          86,
          16,
          89,
          18
        ],
        [
          "initialize_tensor_parallelism",
          41,
          94,
          88,
          22,
          88,
          42,
          86,
          16,
          89,
          18
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "get_results",
          49,
          57,
          53,
          14,
          53,
          23,
          53,
          14,
          57,
          18
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "assertFileIsEqual",
          84,
          87,
          85,
          14,
          85,
          32,
          84,
          27,
          87,
          57
        ],
        [
          "assertInFile",
          89,
          92,
          90,
          14,
          90,
          32,
          89,
          22,
          92,
          42
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "replace_in_file",
          241,
          248,
          242,
          10,
          242,
          41,
          241,
          21,
          248,
          24
        ],
        [
          "replace_in_file",
          241,
          248,
          247,
          10,
          247,
          60,
          241,
          21,
          248,
          24
        ],
        [
          "create_tmp_repo",
          251,
          275,
          274,
          14,
          274,
          93,
          271,
          9,
          275,
          25
        ],
        [
          "test_is_copy_consistent",
          310,
          332,
          331,
          22,
          331,
          58,
          310,
          33,
          332,
          67
        ],
        [
          "test_is_copy_consistent_with_ignored_no_match",
          344,
          368,
          367,
          22,
          367,
          58,
          344,
          55,
          368,
          70
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_pattern_matching_fallback",
          63,
          71,
          68,
          18,
          68,
          63,
          63,
          40,
          71,
          57
        ]
      ],
      "transformers/tests/utils/test_configuration_utils.py": [
        [
          "test_local_versioning",
          237,
          257,
          244,
          48,
          244,
          100,
          237,
          31,
          257,
          64
        ]
      ],
      "transformers/tests/deepspeed/test_deepspeed.py": [
        [
          "load_json",
          81,
          83,
          82,
          10,
          82,
          19,
          81,
          15,
          83,
          27
        ],
        [
          "setUp",
          417,
          450,
          439,
          14,
          439,
          63,
          417,
          15,
          447,
          27
        ],
        [
          "setUp",
          417,
          450,
          441,
          14,
          441,
          63,
          417,
          15,
          447,
          27
        ]
      ],
      "transformers/tests/trainer/test_data_collator.py": [
        [
          "setUp",
          46,
          52,
          51,
          14,
          51,
          57,
          46,
          15,
          52,
          73
        ],
        [
          "setUp",
          721,
          727,
          726,
          14,
          726,
          57,
          721,
          15,
          727,
          73
        ],
        [
          "setUp",
          1043,
          1049,
          1048,
          14,
          1048,
          57,
          1043,
          15,
          1049,
          73
        ],
        [
          "setUp",
          1548,
          1554,
          1553,
          14,
          1553,
          57,
          1548,
          15,
          1554,
          73
        ]
      ],
      "transformers/tests/utils/test_dynamic_module_utils.py": [
        [
          "test_import_parsing",
          123,
          129,
          125,
          10,
          125,
          33,
          123,
          25,
          129,
          35
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_cached_file",
          44,
          62,
          51,
          14,
          51,
          58,
          51,
          14,
          62,
          107
        ],
        [
          "test_non_existence_is_cached",
          74,
          96,
          78,
          14,
          78,
          58,
          74,
          38,
          96,
          37
        ],
        [
          "test_get_file_from_repo_distant",
          114,
          156,
          155,
          29,
          155,
          47,
          114,
          41,
          156,
          52
        ]
      ],
      "transformers/tests/utils/test_hf_argparser.py": [
        [
          "test_11_parse_json",
          378,
          395,
          390,
          18,
          390,
          54,
          378,
          28,
          395,
          43
        ],
        [
          "test_12_parse_yaml",
          397,
          413,
          409,
          18,
          409,
          54,
          397,
          28,
          413,
          43
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_new_image_processor_registration",
          208,
          237,
          221,
          21,
          221,
          48,
          220,
          22,
          221,
          48
        ],
        [
          "test_image_processor_from_local_directory_from_key",
          50,
          61,
          56,
          17,
          56,
          44,
          50,
          60,
          61,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_key",
          50,
          61,
          58,
          47,
          58,
          71,
          50,
          60,
          61,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_feature_extractor_key",
          63,
          77,
          72,
          17,
          72,
          44,
          63,
          78,
          77,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_feature_extractor_key",
          63,
          77,
          74,
          47,
          74,
          71,
          63,
          78,
          77,
          61
        ],
        [
          "test_image_processor_from_new_filename",
          79,
          90,
          85,
          17,
          85,
          44,
          79,
          48,
          90,
          61
        ],
        [
          "test_image_processor_from_new_filename",
          79,
          90,
          87,
          47,
          87,
          71,
          79,
          48,
          90,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          101,
          17,
          101,
          44,
          92,
          63,
          121,
          57
        ],
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          103,
          47,
          103,
          71,
          92,
          63,
          121,
          57
        ],
        [
          "test_image_processor_from_local_file",
          123,
          132,
          128,
          17,
          128,
          44,
          123,
          46,
          132,
          61
        ],
        [
          "test_new_image_processor_registration",
          208,
          237,
          223,
          51,
          223,
          75,
          223,
          28,
          223,
          75
        ]
      ],
      "transformers/tests/models/conditional_detr/test_image_processing_conditional_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          170,
          212,
          173,
          14,
          173,
          77,
          170,
          59,
          178,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          215,
          263,
          218,
          14,
          218,
          86,
          215,
          58,
          225,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          383,
          271,
          14,
          271,
          77,
          267,
          49,
          280,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          386,
          507,
          391,
          14,
          391,
          86,
          386,
          48,
          399,
          58
        ]
      ],
      "transformers/tests/models/deformable_detr/test_image_processing_deformable_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          175,
          217,
          178,
          14,
          178,
          77,
          175,
          59,
          183,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          220,
          268,
          223,
          14,
          223,
          86,
          220,
          58,
          230,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          272,
          388,
          276,
          14,
          276,
          77,
          272,
          49,
          285,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          391,
          512,
          396,
          14,
          396,
          86,
          391,
          48,
          404,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          618,
          671,
          621,
          14,
          621,
          77,
          618,
          84,
          671,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          676,
          740,
          679,
          14,
          679,
          86,
          676,
          83,
          740,
          114
        ]
      ],
      "transformers/tests/models/detr/test_image_processing_detr.py": [
        [
          "test_should_raise_if_annotation_format_invalid",
          178,
          199,
          181,
          14,
          181,
          77,
          178,
          56,
          193,
          63
        ],
        [
          "test_valid_coco_detection_annotations",
          201,
          235,
          204,
          14,
          204,
          77,
          201,
          47,
          209,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          238,
          280,
          241,
          14,
          241,
          77,
          238,
          59,
          246,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          283,
          331,
          286,
          14,
          286,
          86,
          283,
          58,
          293,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          334,
          450,
          338,
          14,
          338,
          77,
          334,
          49,
          347,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          452,
          573,
          457,
          14,
          457,
          86,
          452,
          48,
          465,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          678,
          729,
          681,
          14,
          681,
          77,
          678,
          84,
          729,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          734,
          796,
          737,
          14,
          737,
          86,
          734,
          83,
          796,
          114
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          706,
          14,
          706,
          57,
          702,
          57,
          754,
          51
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          717,
          14,
          717,
          66,
          702,
          57,
          754,
          51
        ]
      ],
      "transformers/tests/models/grounding_dino/test_image_processing_grounding_dino.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          207,
          249,
          210,
          14,
          210,
          77,
          207,
          59,
          215,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          253,
          369,
          257,
          14,
          257,
          77,
          253,
          49,
          266,
          57
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          373,
          421,
          376,
          14,
          376,
          86,
          373,
          58,
          383,
          63
        ],
        [
          "test_batched_coco_panoptic_annotations",
          425,
          546,
          430,
          14,
          430,
          86,
          425,
          48,
          438,
          58
        ]
      ],
      "transformers/tests/models/oneformer/test_image_processing_oneformer.py": [
        [
          "test_can_load_with_local_metadata",
          359,
          378,
          370,
          22,
          370,
          45,
          367,
          13,
          378,
          64
        ]
      ],
      "transformers/tests/models/rt_detr/test_image_processing_rt_detr.py": [
        [
          "test_batched_coco_detection_annotations",
          267,
          379,
          271,
          14,
          271,
          77,
          267,
          49,
          280,
          57
        ],
        [
          "test_valid_coco_detection_annotations",
          125,
          159,
          128,
          14,
          128,
          77,
          125,
          47,
          133,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          162,
          204,
          165,
          14,
          165,
          77,
          162,
          59,
          170,
          63
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          385,
          436,
          388,
          14,
          388,
          77,
          385,
          84,
          436,
          114
        ]
      ],
      "transformers/tests/models/yolos/test_image_processing_yolos.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          226,
          268,
          229,
          14,
          229,
          77,
          226,
          59,
          234,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          271,
          319,
          274,
          14,
          274,
          86,
          271,
          58,
          281,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          323,
          439,
          327,
          14,
          327,
          77,
          323,
          49,
          336,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          442,
          564,
          447,
          14,
          447,
          86,
          442,
          48,
          455,
          58
        ]
      ],
      "transformers/tests/utils/test_import_structure.py": [
        [
          "test_transformers_specific_model_import",
          81,
          118,
          107,
          26,
          107,
          79,
          106,
          21,
          111,
          39
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_layer_pruning_behavior",
          96,
          122,
          103,
          22,
          103,
          39,
          96,
          41,
          106,
          43
        ],
        [
          "test_layer_pruning_behavior",
          96,
          122,
          118,
          22,
          118,
          39,
          113,
          18,
          122,
          99
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "test_load_img_base64_prefix",
          741,
          756,
          744,
          18,
          744,
          37,
          743,
          13,
          744,
          37
        ],
        [
          "test_load_img_base64_prefix",
          741,
          756,
          749,
          18,
          749,
          49,
          749,
          18,
          749,
          49
        ],
        [
          "test_load_img_base64",
          758,
          773,
          761,
          18,
          761,
          37,
          760,
          13,
          761,
          37
        ],
        [
          "test_load_img_base64",
          758,
          773,
          766,
          18,
          766,
          49,
          766,
          18,
          766,
          49
        ],
        [
          "test_load_img_base64_encoded_bytes",
          775,
          790,
          778,
          18,
          778,
          37,
          777,
          13,
          778,
          37
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "test_can_init_all_missing_weights",
          901,
          973,
          907,
          14,
          907,
          27,
          901,
          43,
          910,
          104
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "distributed_worker",
          110,
          193,
          153,
          18,
          153,
          40,
          153,
          18,
          157,
          38
        ],
        [
          "test_model_outputs",
          319,
          374,
          333,
          18,
          333,
          40,
          333,
          18,
          337,
          38
        ]
      ],
      "transformers/tests/models/hubert/test_modeling_hubert.py": [
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          508,
          26,
          508,
          50,
          505,
          18,
          508,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          510,
          26,
          510,
          50,
          510,
          26,
          510,
          50
        ]
      ],
      "transformers/tests/models/modernbert/test_modeling_modernbert.py": [
        [
          "test_saved_config_excludes_reference_compile",
          363,
          369,
          367,
          18,
          367,
          62,
          363,
          54,
          369,
          62
        ]
      ],
      "transformers/tests/models/mt5/test_modeling_mt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          688,
          26,
          688,
          50,
          685,
          18,
          688,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          690,
          26,
          690,
          50,
          690,
          26,
          690,
          50
        ]
      ],
      "transformers/tests/models/parakeet/test_modeling_parakeet.py": [
        [
          "test_1b_model_integration",
          330,
          352,
          336,
          14,
          336,
          36,
          330,
          35,
          352,
          76
        ],
        [
          "test_1b_model_integration_batched",
          355,
          378,
          362,
          14,
          362,
          36,
          355,
          43,
          378,
          76
        ]
      ]
    },
    "tempfile.mkdtemp": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUp",
          113,
          178,
          114,
          27,
          114,
          44,
          113,
          15,
          178,
          55
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_modeling_seamless_m4t.py": [
        [
          "setUp",
          632,
          635,
          635,
          27,
          635,
          44,
          632,
          15,
          635,
          23
        ]
      ],
      "transformers/tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py": [
        [
          "setUp",
          639,
          642,
          642,
          27,
          642,
          44,
          639,
          15,
          642,
          23
        ]
      ],
      "transformers/tests/models/align/test_processing_align.py": [
        [
          "setUp",
          39,
          72,
          40,
          27,
          40,
          44,
          39,
          15,
          72,
          46
        ]
      ],
      "transformers/tests/models/altclip/test_processing_altclip.py": [
        [
          "setUpClass",
          30,
          38,
          32,
          26,
          32,
          43,
          30,
          20,
          38,
          49
        ]
      ],
      "transformers/tests/models/aya_vision/test_processing_aya_vision.py": [
        [
          "setUpClass",
          39,
          64,
          40,
          26,
          40,
          43,
          39,
          20,
          64,
          23
        ]
      ],
      "transformers/tests/models/blip_2/test_processing_blip_2.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          49
        ]
      ],
      "transformers/tests/models/blip/test_processing_blip.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          49
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "setUpClass",
          40,
          84,
          41,
          26,
          41,
          43,
          40,
          20,
          84,
          49
        ]
      ],
      "transformers/tests/models/bridgetower/test_processing_bridgetower.py": [
        [
          "setUpClass",
          38,
          46,
          39,
          26,
          39,
          43,
          38,
          20,
          46,
          49
        ]
      ],
      "transformers/tests/models/bark/test_processing_bark.py": [
        [
          "setUp",
          28,
          34,
          30,
          27,
          30,
          44,
          28,
          15,
          34,
          41
        ]
      ],
      "transformers/tests/models/chameleon/test_processing_chameleon.py": [
        [
          "setUpClass",
          37,
          46,
          38,
          26,
          38,
          43,
          37,
          20,
          46,
          23
        ]
      ],
      "transformers/tests/models/aria/test_processing_aria.py": [
        [
          "setUpClass",
          35,
          66,
          36,
          26,
          36,
          43,
          35,
          20,
          66,
          25
        ]
      ],
      "transformers/tests/models/clip/test_processing_clip.py": [
        [
          "setUpClass",
          40,
          48,
          41,
          26,
          41,
          43,
          40,
          20,
          48,
          49
        ]
      ],
      "transformers/tests/models/clap/test_processing_clap.py": [
        [
          "setUp",
          28,
          30,
          30,
          27,
          30,
          44,
          28,
          15,
          30,
          23
        ]
      ],
      "transformers/tests/models/clipseg/test_processing_clipseg.py": [
        [
          "setUp",
          39,
          65,
          40,
          27,
          40,
          44,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/clvp/test_processing_clvp.py": [
        [
          "setUp",
          29,
          31,
          31,
          27,
          31,
          44,
          29,
          15,
          31,
          23
        ]
      ],
      "transformers/tests/models/cohere2_vision/test_processing_cohere2_vision.py": [
        [
          "setUpClass",
          40,
          55,
          41,
          26,
          41,
          43,
          40,
          20,
          55,
          23
        ]
      ],
      "transformers/tests/models/colpali/test_processing_colpali.py": [
        [
          "setUpClass",
          45,
          51,
          46,
          26,
          46,
          43,
          45,
          20,
          51,
          49
        ]
      ],
      "transformers/tests/models/colqwen2/test_processing_colqwen2.py": [
        [
          "setUpClass",
          45,
          48,
          46,
          26,
          46,
          43,
          45,
          20,
          48,
          49
        ]
      ],
      "transformers/tests/models/deepseek_vl/test_processing_deepseek_vl.py": [
        [
          "setUp",
          35,
          51,
          36,
          27,
          36,
          44,
          35,
          15,
          51,
          50
        ]
      ],
      "transformers/tests/models/deepseek_vl_hybrid/test_processing_deepseek_vl_hybrid.py": [
        [
          "setUp",
          35,
          51,
          36,
          27,
          36,
          44,
          35,
          15,
          51,
          50
        ]
      ],
      "transformers/tests/models/csm/test_processing_csm.py": [
        [
          "setUpClass",
          40,
          48,
          47,
          26,
          47,
          43,
          40,
          20,
          48,
          49
        ]
      ],
      "transformers/tests/models/donut/test_processing_donut.py": [
        [
          "setUpClass",
          29,
          38,
          31,
          26,
          31,
          43,
          29,
          20,
          38,
          49
        ]
      ],
      "transformers/tests/models/emu3/test_processing_emu3.py": [
        [
          "setUpClass",
          35,
          54,
          36,
          26,
          36,
          43,
          35,
          20,
          54,
          23
        ]
      ],
      "transformers/tests/models/evolla/test_processing_evolla.py": [
        [
          "setUp",
          42,
          49,
          43,
          27,
          43,
          44,
          42,
          15,
          49,
          23
        ]
      ],
      "transformers/tests/models/flava/test_processing_flava.py": [
        [
          "setUp",
          46,
          81,
          47,
          27,
          47,
          44,
          46,
          15,
          81,
          46
        ]
      ],
      "transformers/tests/models/dia/test_processing_dia.py": [
        [
          "setUp",
          43,
          59,
          46,
          27,
          46,
          44,
          43,
          15,
          59,
          26
        ]
      ],
      "transformers/tests/models/gemma3/test_processing_gemma3.py": [
        [
          "setUpClass",
          38,
          59,
          39,
          26,
          39,
          43,
          38,
          20,
          59,
          23
        ]
      ],
      "transformers/tests/models/git/test_processing_git.py": [
        [
          "setUpClass",
          35,
          45,
          36,
          26,
          36,
          43,
          35,
          20,
          45,
          49
        ]
      ],
      "transformers/tests/models/gemma3n/test_processing_gemma3n.py": [
        [
          "setUp",
          38,
          42,
          41,
          27,
          41,
          60,
          38,
          15,
          42,
          20
        ]
      ],
      "transformers/tests/models/got_ocr2/test_processing_got_ocr2.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          23
        ]
      ],
      "transformers/tests/models/fuyu/test_processing_fuyu.py": [
        [
          "setUpClass",
          30,
          43,
          31,
          26,
          31,
          43,
          30,
          20,
          43,
          25
        ]
      ],
      "transformers/tests/models/idefics/test_processing_idefics.py": [
        [
          "setUpClass",
          47,
          57,
          48,
          26,
          48,
          43,
          47,
          20,
          57,
          22
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "setUpClass",
          48,
          80,
          49,
          26,
          49,
          43,
          48,
          20,
          80,
          22
        ]
      ],
      "transformers/tests/models/granite_speech/test_processing_granite_speech.py": [
        [
          "setUp",
          40,
          44,
          41,
          27,
          41,
          44,
          40,
          15,
          44,
          50
        ]
      ],
      "transformers/tests/models/florence2/test_processing_florence2.py": [
        [
          "setUpClass",
          38,
          50,
          39,
          26,
          39,
          43,
          38,
          20,
          50,
          23
        ]
      ],
      "transformers/tests/models/idefics2/test_processing_idefics2.py": [
        [
          "setUpClass",
          40,
          67,
          41,
          26,
          41,
          43,
          40,
          20,
          67,
          25
        ]
      ],
      "transformers/tests/models/instructblip/test_processing_instructblip.py": [
        [
          "setUpClass",
          42,
          51,
          43,
          26,
          43,
          43,
          42,
          20,
          51,
          49
        ]
      ],
      "transformers/tests/models/internvl/test_processing_internvl.py": [
        [
          "setUpClass",
          43,
          78,
          44,
          26,
          44,
          43,
          43,
          20,
          78,
          23
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_processing_instructblipvideo.py": [
        [
          "setUpClass",
          45,
          54,
          46,
          26,
          46,
          43,
          45,
          20,
          54,
          49
        ]
      ],
      "transformers/tests/models/idefics3/test_processing_idefics3.py": [
        [
          "setUpClass",
          35,
          62,
          36,
          26,
          36,
          43,
          35,
          20,
          62,
          25
        ]
      ],
      "transformers/tests/models/janus/test_processing_janus.py": [
        [
          "setUp",
          30,
          46,
          31,
          27,
          31,
          44,
          30,
          15,
          46,
          50
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "setUpClass",
          49,
          67,
          56,
          26,
          56,
          43,
          49,
          20,
          67,
          49
        ]
      ],
      "transformers/tests/models/llama4/test_processing_llama4.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          23
        ]
      ],
      "transformers/tests/models/kosmos2/test_processing_kosmos2.py": [
        [
          "setUpClass",
          61,
          71,
          62,
          26,
          62,
          43,
          61,
          20,
          71,
          49
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_processing_layoutlmv2.py": [
        [
          "setUp",
          42,
          73,
          67,
          27,
          67,
          44,
          42,
          15,
          73,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_processing_layoutlmv3.py": [
        [
          "setUp",
          42,
          86,
          66,
          27,
          66,
          44,
          42,
          15,
          86,
          60
        ]
      ],
      "transformers/tests/models/lfm2_vl/test_processing_lfm2_vl.py": [
        [
          "setUpClass",
          42,
          70,
          43,
          26,
          43,
          43,
          42,
          20,
          70,
          36
        ]
      ],
      "transformers/tests/models/llava/test_processing_llava.py": [
        [
          "setUpClass",
          35,
          44,
          36,
          26,
          36,
          43,
          35,
          20,
          44,
          23
        ]
      ],
      "transformers/tests/models/llava_next/test_processing_llava_next.py": [
        [
          "setUpClass",
          40,
          49,
          41,
          26,
          41,
          43,
          40,
          20,
          49,
          23
        ]
      ],
      "transformers/tests/models/llava_next_video/test_processing_llava_next_video.py": [
        [
          "setUpClass",
          41,
          54,
          42,
          26,
          42,
          43,
          41,
          20,
          54,
          23
        ]
      ],
      "transformers/tests/models/llava_onevision/test_processing_llava_onevision.py": [
        [
          "setUpClass",
          46,
          59,
          47,
          26,
          47,
          43,
          46,
          20,
          59,
          23
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "setUp",
          50,
          70,
          52,
          27,
          52,
          44,
          50,
          15,
          70,
          46
        ]
      ],
      "transformers/tests/models/mistral3/test_processing_mistral3.py": [
        [
          "setUpClass",
          39,
          56,
          48,
          26,
          48,
          43,
          39,
          20,
          56,
          23
        ]
      ],
      "transformers/tests/models/markuplm/test_processing_markuplm.py": [
        [
          "setUp",
          47,
          70,
          50,
          27,
          50,
          44,
          47,
          15,
          70,
          62
        ]
      ],
      "transformers/tests/models/musicgen/test_processing_musicgen.py": [
        [
          "setUp",
          53,
          55,
          55,
          27,
          55,
          44,
          53,
          15,
          55,
          23
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_processing_musicgen_melody.py": [
        [
          "setUp",
          55,
          58,
          58,
          27,
          58,
          44,
          55,
          15,
          58,
          23
        ]
      ],
      "transformers/tests/models/omdet_turbo/test_processing_omdet_turbo.py": [
        [
          "setUpClass",
          48,
          68,
          49,
          26,
          49,
          43,
          48,
          20,
          68,
          21
        ]
      ],
      "transformers/tests/models/owlv2/test_processing_owlv2.py": [
        [
          "setUpClass",
          16,
          19,
          17,
          26,
          17,
          43,
          16,
          20,
          19,
          49
        ]
      ],
      "transformers/tests/models/mllama/test_processing_mllama.py": [
        [
          "setUpClass",
          40,
          51,
          50,
          26,
          50,
          43,
          40,
          20,
          51,
          49
        ]
      ],
      "transformers/tests/models/parakeet/test_processing_parakeet.py": [
        [
          "setUpClass",
          32,
          36,
          33,
          26,
          33,
          43,
          32,
          20,
          36,
          49
        ]
      ],
      "transformers/tests/models/paligemma/test_processing_paligemma.py": [
        [
          "setUpClass",
          37,
          45,
          38,
          26,
          38,
          43,
          37,
          20,
          45,
          23
        ]
      ],
      "transformers/tests/models/perception_lm/test_processing_perception_lm.py": [
        [
          "setUpClass",
          47,
          62,
          48,
          26,
          48,
          43,
          47,
          20,
          62,
          26
        ]
      ],
      "transformers/tests/models/owlvit/test_processing_owlvit.py": [
        [
          "setUp",
          39,
          65,
          40,
          27,
          40,
          44,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/pix2struct/test_processing_pix2struct.py": [
        [
          "setUpClass",
          44,
          52,
          45,
          26,
          45,
          43,
          44,
          20,
          52,
          49
        ]
      ],
      "transformers/tests/models/pixtral/test_processing_pixtral.py": [
        [
          "setUp",
          45,
          48,
          46,
          27,
          46,
          44,
          45,
          15,
          48,
          50
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_processing_qwen2_5_omni.py": [
        [
          "setUpClass",
          213,
          218,
          214,
          26,
          214,
          43,
          213,
          20,
          218,
          49
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_processing_qwen2_5_vl.py": [
        [
          "setUpClass",
          44,
          50,
          45,
          26,
          45,
          43,
          44,
          20,
          50,
          23
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_processing_qwen2_vl.py": [
        [
          "setUpClass",
          47,
          53,
          48,
          26,
          48,
          43,
          47,
          20,
          53,
          23
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_processing_qwen2_audio.py": [
        [
          "setUpClass",
          30,
          36,
          32,
          26,
          32,
          43,
          30,
          20,
          36,
          23
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_processing_qwen3_omni_moe.py": [
        [
          "setUpClass",
          214,
          219,
          215,
          26,
          215,
          43,
          214,
          20,
          219,
          49
        ]
      ],
      "transformers/tests/models/pop2piano/test_processing_pop2piano.py": [
        [
          "setUpClass",
          66,
          73,
          67,
          26,
          67,
          43,
          66,
          20,
          73,
          49
        ]
      ],
      "transformers/tests/models/qwen3_vl/test_processing_qwen3_vl.py": [
        [
          "setUpClass",
          44,
          50,
          45,
          26,
          45,
          43,
          44,
          20,
          50,
          23
        ]
      ],
      "transformers/tests/models/sam_hq/test_processing_samhq.py": [
        [
          "setUp",
          41,
          45,
          42,
          27,
          42,
          44,
          41,
          15,
          45,
          50
        ]
      ],
      "transformers/tests/models/sam/test_processing_sam.py": [
        [
          "setUpClass",
          43,
          47,
          44,
          26,
          44,
          43,
          43,
          20,
          47,
          49
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_processing_shieldgemma2.py": [
        [
          "setUpClass",
          76,
          89,
          77,
          26,
          77,
          43,
          76,
          20,
          89,
          49
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "setUpClass",
          31,
          42,
          32,
          26,
          32,
          43,
          31,
          20,
          42,
          49
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "setUpClass",
          41,
          65,
          42,
          26,
          42,
          43,
          41,
          20,
          65,
          62
        ]
      ],
      "transformers/tests/models/speech_to_text/test_processing_speech_to_text.py": [
        [
          "setUpClass",
          37,
          58,
          38,
          26,
          38,
          43,
          37,
          20,
          44,
          66
        ]
      ],
      "transformers/tests/models/smolvlm/test_processing_smolvlm.py": [
        [
          "setUpClass",
          37,
          68,
          38,
          26,
          38,
          43,
          37,
          20,
          68,
          25
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_processing_seamless_m4t.py": [
        [
          "setUp",
          31,
          33,
          33,
          27,
          33,
          44,
          31,
          15,
          33,
          23
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "setUpClass",
          39,
          61,
          40,
          26,
          40,
          43,
          39,
          20,
          61,
          49
        ]
      ],
      "transformers/tests/models/udop/test_processing_udop.py": [
        [
          "setUpClass",
          58,
          74,
          59,
          26,
          59,
          43,
          58,
          20,
          74,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "setUpClass",
          35,
          63,
          53,
          26,
          53,
          43,
          35,
          20,
          63,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "setUpClass",
          36,
          64,
          54,
          26,
          54,
          43,
          36,
          20,
          64,
          49
        ]
      ],
      "transformers/tests/models/glm4v/test_processor_glm4v.py": [
        [
          "setUpClass",
          42,
          48,
          43,
          26,
          43,
          43,
          42,
          20,
          48,
          23
        ]
      ],
      "transformers/tests/models/ovis2/test_processor_ovis2.py": [
        [
          "setUp",
          40,
          47,
          41,
          27,
          41,
          44,
          40,
          15,
          47,
          50
        ]
      ],
      "transformers/tests/models/sam2/test_processor_sam2.py": [
        [
          "setUp",
          38,
          42,
          39,
          27,
          39,
          44,
          38,
          15,
          42,
          50
        ]
      ],
      "transformers/tests/models/whisper/test_processing_whisper.py": [
        [
          "setUp",
          40,
          42,
          42,
          27,
          42,
          44,
          40,
          15,
          42,
          23
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_processor_kosmos2_5.py": [
        [
          "setUp",
          52,
          57,
          53,
          27,
          53,
          44,
          52,
          15,
          57,
          50
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "setUp",
          50,
          77,
          67,
          27,
          67,
          44,
          50,
          15,
          77,
          25
        ]
      ],
      "transformers/tests/models/sam2_video/test_processor_sam2_video.py": [
        [
          "setUp",
          38,
          43,
          39,
          27,
          39,
          44,
          38,
          15,
          43,
          50
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "setUp",
          43,
          105,
          44,
          27,
          44,
          44,
          43,
          15,
          105,
          39
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_save_and_load_tokenizer",
          89,
          141,
          101,
          30,
          101,
          47,
          98,
          13,
          111,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          89,
          141,
          117,
          30,
          117,
          47,
          114,
          13,
          141,
          41
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_save_and_load_tokenizer",
          160,
          209,
          172,
          30,
          172,
          47,
          169,
          13,
          182,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          160,
          209,
          188,
          30,
          188,
          47,
          185,
          13,
          209,
          41
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_save_pretrained",
          145,
          213,
          157,
          31,
          157,
          48,
          152,
          13,
          172,
          58
        ],
        [
          "test_save_pretrained",
          145,
          213,
          178,
          31,
          178,
          48,
          175,
          17,
          191,
          58
        ],
        [
          "test_save_pretrained",
          145,
          213,
          197,
          31,
          197,
          48,
          194,
          17,
          210,
          58
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "setUpClass",
          233,
          255,
          255,
          26,
          255,
          43,
          252,
          14,
          255,
          22
        ],
        [
          "test_save_sentencepiece_tokenizer",
          545,
          570,
          555,
          24,
          555,
          41,
          550,
          16,
          570,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          545,
          570,
          556,
          24,
          556,
          41,
          550,
          16,
          570,
          78
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          747,
          30,
          747,
          47,
          744,
          13,
          760,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          766,
          30,
          766,
          47,
          763,
          13,
          793,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          802,
          30,
          802,
          47,
          800,
          18,
          828,
          41
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4040,
          31,
          4040,
          48,
          4035,
          13,
          4046,
          70
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4068,
          31,
          4068,
          48,
          4065,
          17,
          4081,
          58
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4087,
          31,
          4087,
          48,
          4084,
          17,
          4100,
          58
        ],
        [
          "test_split_special_tokens",
          4508,
          4563,
          4551,
          27,
          4551,
          44,
          4513,
          13,
          4554,
          48
        ]
      ],
      "transformers/tests/models/esm/test_tokenization_esm.py": [
        [
          "setUpClass",
          31,
          38,
          34,
          26,
          34,
          43,
          31,
          20,
          38,
          73
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_training_new_tokenizer",
          82,
          97,
          88,
          39,
          88,
          56,
          88,
          39,
          88,
          56
        ],
        [
          "test_training_new_tokenizer_with_special_tokens_change",
          99,
          114,
          105,
          39,
          105,
          56,
          105,
          39,
          105,
          56
        ],
        [
          "test_init_from_tokenizers_model",
          125,
          171,
          145,
          22,
          145,
          39,
          125,
          41,
          148,
          52
        ],
        [
          "test_init_from_tokenizers_model",
          125,
          171,
          161,
          22,
          161,
          39,
          156,
          9,
          164,
          52
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py": [
        [
          "test_save_and_load_tokenizer",
          1080,
          1105,
          1093,
          30,
          1093,
          47,
          1089,
          13,
          1105,
          41
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_save_pretrained",
          148,
          211,
          155,
          31,
          155,
          48,
          150,
          13,
          170,
          58
        ],
        [
          "test_save_pretrained",
          148,
          211,
          176,
          31,
          176,
          48,
          173,
          17,
          189,
          58
        ],
        [
          "test_save_pretrained",
          148,
          211,
          195,
          31,
          195,
          48,
          192,
          17,
          208,
          58
        ],
        [
          "test_tiktoken_llama",
          850,
          915,
          895,
          22,
          895,
          39,
          850,
          29,
          915,
          45
        ]
      ],
      "transformers/tests/models/layoutxlm/test_tokenization_layoutxlm.py": [
        [
          "test_save_sentencepiece_tokenizer",
          148,
          182,
          161,
          24,
          161,
          41,
          153,
          24,
          182,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          148,
          182,
          162,
          24,
          162,
          41,
          153,
          24,
          182,
          78
        ],
        [
          "test_split_special_tokens",
          184,
          218,
          210,
          30,
          210,
          47,
          185,
          13,
          218,
          80
        ],
        [
          "test_save_and_load_tokenizer",
          1011,
          1036,
          1024,
          30,
          1024,
          47,
          1020,
          13,
          1036,
          41
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1703,
          31,
          1703,
          48,
          1698,
          13,
          1718,
          58
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1726,
          31,
          1726,
          48,
          1723,
          17,
          1739,
          58
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1745,
          31,
          1745,
          48,
          1742,
          17,
          1758,
          58
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "test_save_and_load_tokenizer",
          967,
          992,
          980,
          30,
          980,
          47,
          976,
          13,
          992,
          41
        ]
      ],
      "transformers/tests/models/marian/test_tokenization_marian.py": [
        [
          "test_tokenizer_equivalence_en_de",
          91,
          102,
          98,
          20,
          98,
          37,
          91,
          42,
          102,
          49
        ]
      ],
      "transformers/tests/models/mbart/test_tokenization_mbart.py": [
        [
          "test_save_pretrained",
          135,
          204,
          146,
          31,
          146,
          48,
          141,
          13,
          161,
          58
        ],
        [
          "test_save_pretrained",
          135,
          204,
          169,
          31,
          169,
          48,
          166,
          17,
          182,
          58
        ],
        [
          "test_save_pretrained",
          135,
          204,
          188,
          31,
          188,
          48,
          185,
          17,
          201,
          58
        ],
        [
          "test_special_tokens_unaffacted_by_save_load",
          265,
          270,
          266,
          22,
          266,
          39,
          265,
          53,
          270,
          84
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "test_save_and_load_tokenizer",
          859,
          884,
          872,
          30,
          872,
          47,
          868,
          13,
          884,
          41
        ]
      ],
      "transformers/tests/models/mbart50/test_tokenization_mbart50.py": [
        [
          "test_save_pretrained",
          113,
          182,
          124,
          31,
          124,
          48,
          119,
          13,
          139,
          58
        ],
        [
          "test_save_pretrained",
          113,
          182,
          147,
          31,
          147,
          48,
          144,
          17,
          160,
          58
        ],
        [
          "test_save_pretrained",
          113,
          182,
          166,
          31,
          166,
          48,
          163,
          17,
          179,
          58
        ],
        [
          "test_special_tokens_unaffacted_by_save_load",
          240,
          245,
          241,
          22,
          241,
          39,
          240,
          53,
          245,
          84
        ]
      ],
      "transformers/tests/models/nllb/test_tokenization_nllb.py": [
        [
          "test_save_pretrained",
          143,
          206,
          150,
          31,
          150,
          48,
          145,
          13,
          165,
          58
        ],
        [
          "test_save_pretrained",
          143,
          206,
          171,
          31,
          171,
          48,
          168,
          17,
          184,
          58
        ],
        [
          "test_save_pretrained",
          143,
          206,
          190,
          31,
          190,
          48,
          187,
          17,
          203,
          58
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_save_and_load_tokenizer",
          143,
          192,
          155,
          30,
          155,
          47,
          152,
          13,
          165,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          143,
          192,
          171,
          30,
          171,
          47,
          168,
          13,
          192,
          41
        ]
      ],
      "transformers/tests/models/pop2piano/test_tokenization_pop2piano.py": [
        [
          "test_save_and_load_tokenizer",
          203,
          225,
          204,
          22,
          204,
          39,
          203,
          38,
          225,
          33
        ],
        [
          "test_pickle_tokenizer",
          227,
          242,
          228,
          22,
          228,
          39,
          227,
          31,
          242,
          55
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "setUp",
          38,
          100,
          39,
          27,
          39,
          44,
          38,
          15,
          100,
          39
        ]
      ],
      "transformers/tests/models/plbart/test_tokenization_plbart.py": [
        [
          "test_special_tokens_unaffacted_by_save_load",
          310,
          315,
          311,
          22,
          311,
          39,
          310,
          53,
          315,
          84
        ]
      ],
      "transformers/tests/models/udop/test_tokenization_udop.py": [
        [
          "test_save_sentencepiece_tokenizer",
          141,
          175,
          154,
          24,
          154,
          41,
          146,
          24,
          175,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          141,
          175,
          155,
          24,
          155,
          41,
          146,
          24,
          175,
          78
        ],
        [
          "test_save_and_load_tokenizer",
          939,
          964,
          952,
          30,
          952,
          47,
          948,
          13,
          964,
          41
        ],
        [
          "test_split_special_tokens",
          1835,
          1878,
          1870,
          30,
          1870,
          47,
          1836,
          13,
          1878,
          80
        ]
      ],
      "transformers/tests/models/tapas/test_tokenization_tapas.py": [
        [
          "test_save_and_load_tokenizer",
          854,
          880,
          867,
          30,
          867,
          47,
          863,
          13,
          880,
          41
        ]
      ],
      "transformers/tests/models/vits/test_tokenization_vits.py": [
        [
          "setUpClass",
          35,
          52,
          49,
          26,
          49,
          43,
          35,
          20,
          52,
          53
        ],
        [
          "test_save_and_load_tokenizer",
          79,
          104,
          91,
          30,
          91,
          47,
          88,
          13,
          104,
          41
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "setUpClass",
          60,
          71,
          68,
          26,
          68,
          43,
          60,
          20,
          71,
          53
        ],
        [
          "test_save_pretrained",
          240,
          258,
          243,
          23,
          243,
          40,
          240,
          30,
          255,
          47
        ],
        [
          "test_save_and_load_tokenizer",
          273,
          318,
          276,
          22,
          276,
          39,
          273,
          38,
          318,
          33
        ],
        [
          "test_save_and_load_tokenizer",
          273,
          318,
          295,
          22,
          295,
          39,
          273,
          38,
          318,
          33
        ],
        [
          "setUpClass",
          379,
          390,
          387,
          26,
          387,
          43,
          379,
          20,
          390,
          53
        ]
      ],
      "transformers/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py": [
        [
          "test_save_pretrained",
          143,
          212,
          154,
          31,
          154,
          48,
          149,
          13,
          169,
          58
        ],
        [
          "test_save_pretrained",
          143,
          212,
          177,
          31,
          177,
          48,
          174,
          17,
          190,
          58
        ],
        [
          "test_save_pretrained",
          143,
          212,
          196,
          31,
          196,
          48,
          193,
          17,
          209,
          58
        ]
      ],
      "transformers/tests/trainer/test_trainer_callback.py": [
        [
          "setUp",
          108,
          109,
          109,
          27,
          109,
          44,
          108,
          15,
          109,
          23
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "get_auto_remove_tmp_dir",
          2045,
          2111,
          2105,
          23,
          2105,
          40,
          2105,
          23,
          2107,
          24
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_tatoeba_conversion.py": [
        [
          "resolver",
          27,
          29,
          28,
          19,
          28,
          36,
          27,
          18,
          29,
          49
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "setUpClass",
          66,
          71,
          68,
          22,
          68,
          39,
          66,
          20,
          71,
          24
        ]
      ],
      "transformers/tests/commands/test_chat.py": [
        [
          "test_save_and_clear_chat",
          83,
          94,
          84,
          20,
          84,
          37,
          83,
          34,
          94,
          37
        ]
      ],
      "transformers/tests/trainer/test_data_collator.py": [
        [
          "setUp",
          46,
          52,
          47,
          27,
          47,
          44,
          46,
          15,
          52,
          73
        ],
        [
          "setUp",
          721,
          727,
          722,
          27,
          722,
          44,
          721,
          15,
          727,
          73
        ],
        [
          "setUp",
          1043,
          1049,
          1044,
          27,
          1044,
          44,
          1043,
          15,
          1049,
          73
        ],
        [
          "setUp",
          1548,
          1554,
          1549,
          27,
          1549,
          44,
          1548,
          15,
          1554,
          73
        ]
      ]
    },
    "os.makedirs": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUp",
          113,
          178,
          135,
          9,
          135,
          54,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          168,
          9,
          168,
          55,
          113,
          15,
          178,
          55
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "setUp",
          43,
          105,
          66,
          9,
          66,
          54,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          99,
          9,
          99,
          55,
          43,
          15,
          105,
          39
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          478,
          13,
          478,
          34,
          456,
          40,
          513,
          18
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "setUp",
          38,
          100,
          94,
          9,
          94,
          55,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          61,
          9,
          61,
          54,
          38,
          15,
          100,
          39
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "check_checkpoint_deletion",
          4081,
          4088,
          4084,
          13,
          4084,
          96,
          4083,
          13,
          4084,
          96
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "create_test_list_from_filter",
          1109,
          1121,
          1110,
          5,
          1110,
          40,
          1109,
          34,
          1112,
          53
        ]
      ],
      "transformers/src/transformers/models/rag/tokenization_rag.py": [
        [
          "save_pretrained",
          35,
          42,
          38,
          9,
          38,
          50,
          38,
          9,
          42,
          54
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "save_pretrained",
          2471,
          2638,
          2531,
          9,
          2531,
          50,
          2531,
          9,
          2533,
          22
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "__init__",
          399,
          764,
          669,
          13,
          669,
          60,
          669,
          13,
          669,
          60
        ],
        [
          "_save_rng_state",
          3219,
          3267,
          3262,
          9,
          3262,
          46,
          3262,
          9,
          3264,
          36
        ],
        [
          "save_model",
          4003,
          4055,
          4017,
          13,
          4017,
          50,
          4017,
          13,
          4019,
          36
        ],
        [
          "_save_tpu",
          4057,
          4127,
          4065,
          13,
          4065,
          50,
          4065,
          13,
          4066,
          79
        ],
        [
          "_save",
          4129,
          4170,
          4132,
          9,
          4132,
          46,
          4131,
          22,
          4135,
          73
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "save_pretrained",
          549,
          608,
          580,
          9,
          580,
          50,
          580,
          9,
          582,
          22
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "create_new_model_like",
          477,
          571,
          508,
          5,
          508,
          49,
          504,
          26,
          537,
          47
        ],
        [
          "create_new_model_like",
          477,
          571,
          532,
          5,
          532,
          44,
          504,
          26,
          537,
          47
        ]
      ],
      "transformers/benchmark/benchmarks_entrypoint.py": [
        [
          "export_to_csv",
          208,
          226,
          217,
          13,
          217,
          35,
          217,
          13,
          218,
          71
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "save_pretrained",
          956,
          1024,
          989,
          9,
          989,
          50,
          989,
          9,
          991,
          44
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "save_chat",
          395,
          411,
          408,
          9,
          408,
          61,
          408,
          9,
          411,
          40
        ]
      ],
      "transformers/benchmark_v2/benchmark_framework.py": [
        [
          "__init__",
          948,
          951,
          951,
          9,
          951,
          46,
          948,
          18,
          951,
          46
        ],
        [
          "save_results",
          1171,
          1199,
          1175,
          9,
          1175,
          45,
          1171,
          22,
          1185,
          58
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          618,
          5,
          618,
          46,
          608,
          54,
          621,
          37
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          656,
          5,
          656,
          43,
          647,
          14,
          674,
          43
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          722,
          21,
          722,
          62,
          721,
          38,
          726,
          21
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          901,
          13,
          901,
          54,
          900,
          30,
          903,
          46
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "save_pretrained",
          695,
          766,
          746,
          9,
          746,
          50,
          746,
          9,
          748,
          22
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "save_pretrained",
          432,
          494,
          464,
          9,
          464,
          50,
          464,
          9,
          466,
          22
        ]
      ],
      "transformers/src/transformers/models/aimv2/convert_aimv2_original_pytorch_to_hf.py": [
        [
          "write_model",
          146,
          212,
          162,
          5,
          162,
          42,
          147,
          5,
          171,
          56
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "shard_on_the_fly",
          70,
          149,
          77,
          5,
          77,
          41,
          70,
          22,
          83,
          32
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          163,
          5,
          163,
          56,
          163,
          5,
          169,
          42
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          202,
          9,
          202,
          60,
          199,
          9,
          206,
          35
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "convert_hf_blt_to_unified",
          362,
          410,
          385,
          5,
          385,
          42,
          363,
          5,
          391,
          36
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          85,
          5,
          85,
          42,
          84,
          17,
          91,
          46
        ]
      ],
      "transformers/src/transformers/models/csm/convert_csm.py": [
        [
          "write_model",
          79,
          232,
          87,
          5,
          87,
          42,
          80,
          5,
          173,
          36
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "convert_model",
          236,
          360,
          243,
          9,
          243,
          46,
          243,
          9,
          246,
          38
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "convert_model",
          209,
          322,
          216,
          9,
          216,
          46,
          216,
          9,
          219,
          38
        ]
      ],
      "transformers/src/transformers/models/depth_pro/convert_depth_pro_weights_to_hf.py": [
        [
          "write_model",
          132,
          202,
          137,
          5,
          137,
          42,
          133,
          5,
          178,
          23
        ]
      ],
      "transformers/src/transformers/models/dialogpt/convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_dialogpt_checkpoint",
          29,
          33,
          32,
          5,
          32,
          56,
          29,
          33,
          33,
          71
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          201,
          5,
          201,
          40,
          156,
          5,
          206,
          23
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          295,
          5,
          295,
          40,
          253,
          5,
          300,
          23
        ]
      ],
      "transformers/src/transformers/models/efficientloftr/convert_efficientloftr_to_hf.py": [
        [
          "write_model",
          128,
          199,
          136,
          5,
          136,
          42,
          129,
          5,
          159,
          23
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "ensure_model_downloaded",
          120,
          155,
          137,
          13,
          137,
          49,
          137,
          13,
          138,
          58
        ],
        [
          "convert_model",
          191,
          286,
          208,
          9,
          208,
          46,
          208,
          9,
          209,
          65
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_tiktoken",
          105,
          210,
          149,
          5,
          149,
          42,
          105,
          22,
          210,
          35
        ],
        [
          "convert_model",
          255,
          408,
          256,
          5,
          256,
          42,
          255,
          19,
          308,
          31
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          93,
          5,
          93,
          56,
          92,
          5,
          137,
          22
        ]
      ],
      "transformers/src/transformers/models/got_ocr2/convert_got_ocr2_weights_to_hf.py": [
        [
          "write_model",
          98,
          157,
          103,
          5,
          103,
          42,
          99,
          5,
          120,
          23
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_model",
          146,
          284,
          153,
          5,
          153,
          42,
          147,
          5,
          154,
          41
        ],
        [
          "save_sharded_model",
          287,
          314,
          291,
          5,
          291,
          42,
          287,
          24,
          299,
          32
        ]
      ],
      "transformers/src/transformers/models/hubert/convert_hubert_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_hubert_checkpoint",
          183,
          246,
          208,
          13,
          208,
          64,
          208,
          13,
          229,
          63
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "save_sharded_model",
          174,
          247,
          175,
          5,
          175,
          43,
          174,
          24,
          178,
          38
        ]
      ],
      "transformers/src/transformers/models/internvl/convert_internvl_weights_to_hf.py": [
        [
          "write_model",
          235,
          342,
          241,
          5,
          241,
          42,
          236,
          5,
          246,
          18
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "convert_model",
          242,
          447,
          260,
          9,
          260,
          46,
          260,
          9,
          261,
          65
        ],
        [
          "ensure_model_downloaded",
          171,
          206,
          188,
          13,
          188,
          49,
          188,
          13,
          189,
          58
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "convert_openai_checkpoint",
          213,
          260,
          220,
          13,
          220,
          70,
          219,
          17,
          221,
          92
        ]
      ],
      "transformers/src/transformers/models/kyutai_speech_to_text/convert_kyutai_speech_to_text_to_hf.py": [
        [
          "write_model",
          181,
          263,
          191,
          5,
          191,
          42,
          182,
          5,
          263,
          41
        ]
      ],
      "transformers/src/transformers/models/lightglue/convert_lightglue_to_hf.py": [
        [
          "write_model",
          149,
          226,
          156,
          5,
          156,
          42,
          150,
          5,
          183,
          23
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "write_model",
          213,
          554,
          221,
          5,
          221,
          42,
          214,
          5,
          244,
          32
        ]
      ],
      "transformers/src/transformers/models/metaclip_2/convert_metaclip_2_to_hf.py": [
        [
          "main",
          373,
          423,
          417,
          9,
          417,
          51,
          417,
          9,
          419,
          50
        ]
      ],
      "transformers/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py": [
        [
          "write_model",
          61,
          217,
          62,
          5,
          62,
          42,
          61,
          17,
          68,
          80
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_model",
          209,
          471,
          216,
          5,
          216,
          42,
          210,
          5,
          252,
          49
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          75,
          5,
          75,
          41,
          72,
          22,
          77,
          36
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "write_model",
          68,
          216,
          77,
          5,
          77,
          42,
          69,
          5,
          84,
          58
        ],
        [
          "write_model",
          68,
          216,
          79,
          5,
          79,
          46,
          69,
          5,
          84,
          58
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "write_model",
          65,
          183,
          66,
          5,
          66,
          42,
          65,
          17,
          83,
          54
        ],
        [
          "write_model",
          65,
          183,
          68,
          5,
          68,
          46,
          65,
          17,
          83,
          54
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "write_model",
          91,
          215,
          92,
          5,
          92,
          42,
          91,
          17,
          99,
          23
        ],
        [
          "write_model",
          91,
          215,
          94,
          5,
          94,
          46,
          91,
          17,
          99,
          23
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "convert",
          134,
          295,
          291,
          5,
          291,
          63,
          287,
          27,
          295,
          59
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "write_model",
          272,
          398,
          280,
          5,
          280,
          42,
          273,
          5,
          299,
          59
        ],
        [
          "write_model",
          272,
          398,
          282,
          5,
          282,
          46,
          273,
          5,
          299,
          59
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_download",
          147,
          182,
          148,
          5,
          148,
          36,
          147,
          15,
          154,
          38
        ]
      ],
      "transformers/src/transformers/models/ovis2/convert_ovis2_weights_to_hf.py": [
        [
          "main",
          309,
          400,
          349,
          5,
          349,
          45,
          340,
          17,
          360,
          23
        ]
      ],
      "transformers/src/transformers/models/pix2struct/convert_pix2struct_original_pytorch_to_hf.py": [
        [
          "convert_pix2struct_original_pytorch_checkpoint_to_hf",
          105,
          142,
          137,
          5,
          137,
          56,
          111,
          26,
          142,
          55
        ],
        [
          "convert_pix2struct_original_pytorch_checkpoint_to_hf",
          105,
          142,
          137,
          5,
          137,
          56,
          114,
          26,
          142,
          55
        ]
      ],
      "transformers/src/transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          223,
          290,
          268,
          13,
          268,
          64,
          268,
          13,
          281,
          63
        ]
      ],
      "transformers/src/transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          235,
          302,
          280,
          13,
          280,
          64,
          280,
          13,
          293,
          63
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "convert_siglip_checkpoint",
          380,
          506,
          498,
          9,
          498,
          60,
          497,
          36,
          502,
          59
        ]
      ],
      "transformers/src/transformers/models/bark/convert_suno_to_hf.py": [
        [
          "_download",
          87,
          89,
          88,
          5,
          88,
          41,
          87,
          15,
          89,
          82
        ]
      ],
      "transformers/src/transformers/models/superglue/convert_superglue_to_hf.py": [
        [
          "write_model",
          223,
          300,
          229,
          5,
          229,
          42,
          224,
          5,
          265,
          61
        ]
      ],
      "transformers/src/transformers/models/timesfm/convert_timesfm_orignal_to_hf.py": [
        [
          "write_model",
          36,
          147,
          37,
          5,
          37,
          42,
          36,
          17,
          43,
          55
        ],
        [
          "write_model",
          36,
          147,
          39,
          5,
          39,
          46,
          36,
          17,
          43,
          55
        ]
      ],
      "transformers/src/transformers/models/unispeech/convert_unispeech_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_unispeech_checkpoint",
          190,
          258,
          215,
          13,
          215,
          64,
          215,
          13,
          241,
          63
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "write_model",
          190,
          396,
          387,
          9,
          387,
          46,
          387,
          9,
          389,
          51
        ]
      ],
      "transformers/src/transformers/models/voxtral/convert_voxtral_weights_to_hf.py": [
        [
          "write_model",
          174,
          234,
          182,
          5,
          182,
          42,
          175,
          5,
          234,
          41
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_conformer/convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_conformer_checkpoint",
          220,
          294,
          248,
          13,
          248,
          64,
          248,
          13,
          274,
          63
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          274,
          358,
          312,
          13,
          312,
          64,
          312,
          13,
          338,
          63
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "create_tiny_models",
          1321,
          1431,
          1337,
          5,
          1337,
          43,
          1336,
          19,
          1348,
          14
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "move_model_files_to_deprecated",
          146,
          159,
          151,
          9,
          151,
          42,
          151,
          9,
          151,
          42
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "create_dynamic_module",
          103,
          122,
          116,
          5,
          116,
          51,
          116,
          5,
          118,
          29
        ],
        [
          "init_hf_modules",
          87,
          100,
          96,
          5,
          96,
          48,
          95,
          5,
          98,
          29
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "save_pretrained",
          355,
          414,
          386,
          9,
          386,
          50,
          386,
          9,
          388,
          22
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "save_pretrained",
          202,
          261,
          233,
          9,
          233,
          50,
          233,
          9,
          235,
          22
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "log_model_debug_trace",
          228,
          268,
          231,
          13,
          231,
          50,
          231,
          25,
          231,
          50
        ],
        [
          "_attach_debugger_logic",
          271,
          395,
          299,
          13,
          299,
          50,
          299,
          25,
          299,
          50
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/modeling_jukebox.py": [
        [
          "_sample",
          2433,
          2569,
          2562,
          21,
          2562,
          39,
          2562,
          21,
          2562,
          39
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "save_pretrained",
          3648,
          4088,
          3759,
          9,
          3759,
          50,
          3759,
          9,
          3761,
          22
        ],
        [
          "_load_pretrained_model",
          5108,
          5377,
          5204,
          17,
          5204,
          63,
          5204,
          17,
          5204,
          63
        ]
      ],
      "transformers/src/transformers/models/bark/processing_bark.py": [
        [
          "save_pretrained",
          124,
          178,
          153,
          13,
          153,
          104,
          153,
          13,
          159,
          58
        ]
      ],
      "transformers/src/transformers/models/instructblip/processing_instructblip.py": [
        [
          "save_pretrained",
          156,
          172,
          159,
          9,
          159,
          50,
          159,
          9,
          165,
          26
        ]
      ],
      "transformers/src/transformers/models/instructblipvideo/processing_instructblipvideo.py": [
        [
          "save_pretrained",
          184,
          200,
          187,
          9,
          187,
          50,
          187,
          9,
          193,
          26
        ]
      ],
      "transformers/src/transformers/models/pop2piano/processing_pop2piano.py": [
        [
          "save_pretrained",
          126,
          130,
          129,
          9,
          129,
          50,
          129,
          9,
          130,
          64
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "save_pretrained",
          723,
          896,
          832,
          25,
          832,
          69,
          832,
          25,
          836,
          82
        ],
        [
          "save_pretrained",
          723,
          896,
          764,
          9,
          764,
          50,
          764,
          9,
          766,
          22
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "main",
          278,
          491,
          376,
          5,
          376,
          47,
          279,
          5,
          380,
          40
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          317,
          13,
          317,
          55,
          317,
          13,
          317,
          55
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/run_glue.py": [
        [
          "main",
          176,
          197,
          188,
          9,
          188,
          36,
          184,
          27,
          188,
          36
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          279,
          13,
          279,
          55,
          279,
          13,
          279,
          55
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          383,
          13,
          383,
          55,
          383,
          13,
          383,
          55
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "parse_args",
          71,
          231,
          229,
          9,
          229,
          51,
          229,
          9,
          229,
          51
        ],
        [
          "main",
          234,
          650,
          284,
          13,
          284,
          55,
          284,
          13,
          284,
          55
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "parse_args",
          71,
          229,
          227,
          9,
          227,
          51,
          227,
          9,
          227,
          51
        ],
        [
          "handle_repository_creation",
          387,
          410,
          407,
          13,
          407,
          55,
          407,
          13,
          407,
          55
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          437,
          13,
          437,
          55,
          437,
          13,
          437,
          55
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          324,
          13,
          324,
          55,
          324,
          13,
          324,
          55
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          328,
          13,
          328,
          55,
          328,
          13,
          328,
          55
        ]
      ],
      "transformers/examples/legacy/run_openai_gpt.py": [
        [
          "main",
          104,
          315,
          171,
          9,
          171,
          36,
          171,
          9,
          171,
          36
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection_no_trainer.py": [
        [
          "parse_args",
          240,
          408,
          406,
          9,
          406,
          51,
          406,
          9,
          406,
          51
        ],
        [
          "main",
          411,
          796,
          455,
          13,
          455,
          55,
          455,
          13,
          455,
          55
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          348,
          13,
          348,
          55,
          348,
          13,
          348,
          55
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "parse_args",
          87,
          250,
          248,
          9,
          248,
          51,
          248,
          9,
          248,
          51
        ],
        [
          "main",
          253,
          637,
          297,
          13,
          297,
          55,
          297,
          13,
          297,
          55
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "main",
          338,
          1035,
          387,
          13,
          387,
          55,
          387,
          13,
          387,
          55
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          571,
          17,
          571,
          66,
          571,
          17,
          581,
          47
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          570,
          17,
          570,
          66,
          570,
          17,
          580,
          56
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "evaluate",
          266,
          397,
          270,
          9,
          270,
          36,
          270,
          9,
          270,
          36
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "evaluate",
          413,
          470,
          417,
          9,
          417,
          36,
          417,
          9,
          417,
          36
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          287,
          13,
          287,
          55,
          287,
          13,
          287,
          55
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          398,
          13,
          398,
          55,
          398,
          13,
          398,
          55
        ]
      ],
      "transformers/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py": [
        [
          "parse_args",
          61,
          294,
          292,
          9,
          292,
          51,
          292,
          9,
          292,
          51
        ],
        [
          "main",
          406,
          804,
          449,
          13,
          449,
          55,
          449,
          13,
          449,
          55
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          375,
          13,
          375,
          55,
          375,
          13,
          375,
          55
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "setUpClass",
          35,
          76,
          40,
          9,
          40,
          96,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          41,
          9,
          41,
          82,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          42,
          9,
          42,
          100,
          35,
          20,
          56,
          35
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_pattern_matching_fallback",
          63,
          71,
          67,
          13,
          67,
          46,
          63,
          40,
          71,
          57
        ]
      ]
    },
    "shutil.rmtree": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "tearDown",
          196,
          200,
          197,
          9,
          197,
          38,
          196,
          18,
          200,
          29
        ]
      ],
      "transformers/tests/models/align/test_processing_align.py": [
        [
          "tearDown",
          83,
          84,
          84,
          9,
          84,
          38,
          83,
          18,
          84,
          38
        ]
      ],
      "transformers/tests/models/aya_vision/test_processing_aya_vision.py": [
        [
          "tearDownClass",
          80,
          81,
          81,
          9,
          81,
          57,
          80,
          23,
          81,
          57
        ]
      ],
      "transformers/tests/models/blip_2/test_processing_blip_2.py": [
        [
          "tearDownClass",
          55,
          56,
          56,
          9,
          56,
          57,
          55,
          23,
          56,
          57
        ]
      ],
      "transformers/tests/models/blip/test_processing_blip.py": [
        [
          "tearDownClass",
          52,
          53,
          53,
          9,
          53,
          57,
          52,
          23,
          53,
          57
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "tearDownClass",
          99,
          100,
          100,
          9,
          100,
          57,
          99,
          23,
          100,
          57
        ]
      ],
      "transformers/tests/models/bridgetower/test_processing_bridgetower.py": [
        [
          "tearDownClass",
          55,
          56,
          56,
          9,
          56,
          57,
          55,
          23,
          56,
          57
        ]
      ],
      "transformers/tests/models/bark/test_processing_bark.py": [
        [
          "tearDown",
          39,
          40,
          40,
          9,
          40,
          38,
          39,
          18,
          40,
          38
        ]
      ],
      "transformers/tests/models/aria/test_processing_aria.py": [
        [
          "tearDownClass",
          85,
          89,
          89,
          9,
          89,
          57,
          85,
          23,
          89,
          57
        ]
      ],
      "transformers/tests/models/clip/test_processing_clip.py": [
        [
          "tearDownClass",
          63,
          64,
          64,
          9,
          64,
          37,
          63,
          23,
          64,
          37
        ]
      ],
      "transformers/tests/models/clap/test_processing_clap.py": [
        [
          "tearDown",
          38,
          39,
          39,
          9,
          39,
          38,
          38,
          18,
          39,
          38
        ]
      ],
      "transformers/tests/models/clipseg/test_processing_clipseg.py": [
        [
          "tearDown",
          76,
          77,
          77,
          9,
          77,
          38,
          76,
          18,
          77,
          38
        ]
      ],
      "transformers/tests/models/clvp/test_processing_clvp.py": [
        [
          "tearDown",
          33,
          36,
          35,
          9,
          35,
          38,
          33,
          18,
          36,
          20
        ]
      ],
      "transformers/tests/models/cohere2_vision/test_processing_cohere2_vision.py": [
        [
          "tearDownClass",
          71,
          72,
          72,
          9,
          72,
          57,
          71,
          23,
          72,
          57
        ]
      ],
      "transformers/tests/models/colpali/test_processing_colpali.py": [
        [
          "tearDownClass",
          54,
          55,
          55,
          9,
          55,
          57,
          54,
          23,
          55,
          57
        ]
      ],
      "transformers/tests/models/colqwen2/test_processing_colqwen2.py": [
        [
          "tearDownClass",
          57,
          58,
          58,
          9,
          58,
          37,
          57,
          23,
          58,
          37
        ]
      ],
      "transformers/tests/models/csm/test_processing_csm.py": [
        [
          "tearDownClass",
          51,
          52,
          52,
          9,
          52,
          57,
          51,
          23,
          52,
          57
        ]
      ],
      "transformers/tests/models/evolla/test_processing_evolla.py": [
        [
          "tearDown",
          173,
          174,
          174,
          9,
          174,
          38,
          173,
          18,
          174,
          38
        ]
      ],
      "transformers/tests/models/flava/test_processing_flava.py": [
        [
          "tearDown",
          92,
          93,
          93,
          9,
          93,
          38,
          92,
          18,
          93,
          38
        ]
      ],
      "transformers/tests/models/dia/test_processing_dia.py": [
        [
          "tearDown",
          70,
          72,
          71,
          9,
          71,
          38,
          70,
          18,
          72,
          26
        ]
      ],
      "transformers/tests/models/gemma3/test_processing_gemma3.py": [
        [
          "tearDownClass",
          75,
          76,
          76,
          9,
          76,
          57,
          75,
          23,
          76,
          57
        ]
      ],
      "transformers/tests/models/git/test_processing_git.py": [
        [
          "tearDownClass",
          54,
          55,
          55,
          9,
          55,
          57,
          54,
          23,
          55,
          57
        ]
      ],
      "transformers/tests/models/gemma3n/test_processing_gemma3n.py": [
        [
          "tearDown",
          53,
          54,
          54,
          9,
          54,
          38,
          53,
          18,
          54,
          38
        ]
      ],
      "transformers/tests/models/got_ocr2/test_processing_got_ocr2.py": [
        [
          "tearDownClass",
          52,
          53,
          53,
          9,
          53,
          57,
          52,
          23,
          53,
          57
        ]
      ],
      "transformers/tests/models/fuyu/test_processing_fuyu.py": [
        [
          "tearDownClass",
          46,
          47,
          47,
          9,
          47,
          30,
          46,
          23,
          47,
          30
        ]
      ],
      "transformers/tests/models/idefics/test_processing_idefics.py": [
        [
          "tearDownClass",
          66,
          67,
          67,
          9,
          67,
          57,
          66,
          23,
          67,
          57
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "tearDownClass",
          112,
          113,
          113,
          9,
          113,
          57,
          112,
          23,
          113,
          57
        ]
      ],
      "transformers/tests/models/granite_speech/test_processing_granite_speech.py": [
        [
          "tearDown",
          52,
          53,
          53,
          9,
          53,
          38,
          52,
          18,
          53,
          38
        ]
      ],
      "transformers/tests/models/florence2/test_processing_florence2.py": [
        [
          "tearDownClass",
          77,
          78,
          78,
          9,
          78,
          57,
          77,
          23,
          78,
          57
        ]
      ],
      "transformers/tests/models/idefics2/test_processing_idefics2.py": [
        [
          "tearDownClass",
          83,
          87,
          87,
          9,
          87,
          57,
          83,
          23,
          87,
          57
        ]
      ],
      "transformers/tests/models/instructblip/test_processing_instructblip.py": [
        [
          "tearDownClass",
          66,
          67,
          67,
          9,
          67,
          57,
          66,
          23,
          67,
          57
        ]
      ],
      "transformers/tests/models/internvl/test_processing_internvl.py": [
        [
          "tearDownClass",
          97,
          98,
          98,
          9,
          98,
          57,
          97,
          23,
          98,
          57
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_processing_instructblipvideo.py": [
        [
          "tearDownClass",
          69,
          70,
          70,
          9,
          70,
          57,
          69,
          23,
          70,
          57
        ]
      ],
      "transformers/tests/models/idefics3/test_processing_idefics3.py": [
        [
          "tearDownClass",
          112,
          116,
          116,
          9,
          116,
          57,
          112,
          23,
          116,
          57
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "tearDownClass",
          86,
          87,
          87,
          9,
          87,
          57,
          86,
          23,
          87,
          57
        ]
      ],
      "transformers/tests/models/llama4/test_processing_llama4.py": [
        [
          "tearDownClass",
          52,
          53,
          53,
          9,
          53,
          37,
          52,
          23,
          53,
          37
        ]
      ],
      "transformers/tests/models/kosmos2/test_processing_kosmos2.py": [
        [
          "tearDownClass",
          97,
          98,
          98,
          9,
          98,
          57,
          97,
          23,
          98,
          57
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_processing_layoutlmv2.py": [
        [
          "tearDown",
          87,
          88,
          88,
          9,
          88,
          38,
          87,
          18,
          88,
          38
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_processing_layoutlmv3.py": [
        [
          "tearDown",
          100,
          101,
          101,
          9,
          101,
          38,
          100,
          18,
          101,
          38
        ]
      ],
      "transformers/tests/models/lfm2_vl/test_processing_lfm2_vl.py": [
        [
          "tearDownClass",
          129,
          130,
          130,
          9,
          130,
          57,
          129,
          23,
          130,
          57
        ]
      ],
      "transformers/tests/models/llava/test_processing_llava.py": [
        [
          "tearDownClass",
          53,
          54,
          54,
          9,
          54,
          57,
          53,
          23,
          54,
          57
        ]
      ],
      "transformers/tests/models/llava_next/test_processing_llava_next.py": [
        [
          "tearDownClass",
          58,
          59,
          59,
          9,
          59,
          57,
          58,
          23,
          59,
          57
        ]
      ],
      "transformers/tests/models/llava_next_video/test_processing_llava_next_video.py": [
        [
          "tearDownClass",
          66,
          67,
          67,
          9,
          67,
          57,
          66,
          23,
          67,
          57
        ]
      ],
      "transformers/tests/models/llava_onevision/test_processing_llava_onevision.py": [
        [
          "tearDownClass",
          71,
          72,
          72,
          9,
          72,
          57,
          71,
          23,
          72,
          57
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "tearDown",
          89,
          90,
          90,
          9,
          90,
          38,
          89,
          18,
          90,
          38
        ]
      ],
      "transformers/tests/models/mistral3/test_processing_mistral3.py": [
        [
          "lambda",
          49,
          49,
          49,
          60,
          49,
          81,
          49,
          36,
          49,
          81
        ]
      ],
      "transformers/tests/models/markuplm/test_processing_markuplm.py": [
        [
          "tearDown",
          84,
          85,
          85,
          9,
          85,
          38,
          84,
          18,
          85,
          38
        ]
      ],
      "transformers/tests/models/musicgen/test_processing_musicgen.py": [
        [
          "tearDown",
          63,
          64,
          64,
          9,
          64,
          38,
          63,
          18,
          64,
          38
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_processing_musicgen_melody.py": [
        [
          "tearDown",
          66,
          67,
          67,
          9,
          67,
          38,
          66,
          18,
          67,
          38
        ]
      ],
      "transformers/tests/models/omdet_turbo/test_processing_omdet_turbo.py": [
        [
          "tearDownClass",
          77,
          78,
          78,
          9,
          78,
          57,
          77,
          23,
          78,
          57
        ]
      ],
      "transformers/tests/models/owlv2/test_processing_owlv2.py": [
        [
          "tearDownClass",
          22,
          23,
          23,
          9,
          23,
          57,
          22,
          23,
          23,
          57
        ]
      ],
      "transformers/tests/models/mllama/test_processing_mllama.py": [
        [
          "tearDownClass",
          54,
          57,
          57,
          9,
          57,
          57,
          54,
          23,
          57,
          57
        ]
      ],
      "transformers/tests/models/parakeet/test_processing_parakeet.py": [
        [
          "tearDownClass",
          48,
          49,
          49,
          9,
          49,
          57,
          48,
          23,
          49,
          57
        ]
      ],
      "transformers/tests/models/paligemma/test_processing_paligemma.py": [
        [
          "tearDownClass",
          48,
          49,
          49,
          9,
          49,
          57,
          48,
          23,
          49,
          57
        ]
      ],
      "transformers/tests/models/perception_lm/test_processing_perception_lm.py": [
        [
          "tearDownClass",
          71,
          72,
          72,
          9,
          72,
          57,
          71,
          23,
          72,
          57
        ]
      ],
      "transformers/tests/models/owlvit/test_processing_owlvit.py": [
        [
          "tearDown",
          76,
          77,
          77,
          9,
          77,
          38,
          76,
          18,
          77,
          38
        ]
      ],
      "transformers/tests/models/pix2struct/test_processing_pix2struct.py": [
        [
          "tearDownClass",
          61,
          62,
          62,
          9,
          62,
          57,
          61,
          23,
          62,
          57
        ]
      ],
      "transformers/tests/models/pixtral/test_processing_pixtral.py": [
        [
          "tearDown",
          50,
          51,
          51,
          9,
          51,
          38,
          50,
          18,
          51,
          38
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_processing_qwen2_5_omni.py": [
        [
          "tearDownClass",
          236,
          237,
          237,
          9,
          237,
          57,
          236,
          23,
          237,
          57
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_processing_qwen2_5_vl.py": [
        [
          "tearDownClass",
          65,
          66,
          66,
          9,
          66,
          57,
          65,
          23,
          66,
          57
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_processing_qwen2_vl.py": [
        [
          "tearDownClass",
          68,
          69,
          69,
          9,
          69,
          57,
          68,
          23,
          69,
          57
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_processing_qwen2_audio.py": [
        [
          "tearDownClass",
          48,
          49,
          49,
          9,
          49,
          57,
          48,
          23,
          49,
          57
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_processing_qwen3_omni_moe.py": [
        [
          "tearDownClass",
          237,
          238,
          238,
          9,
          238,
          57,
          237,
          23,
          238,
          57
        ]
      ],
      "transformers/tests/models/pop2piano/test_processing_pop2piano.py": [
        [
          "tearDownClass",
          82,
          83,
          83,
          9,
          83,
          57,
          82,
          23,
          83,
          57
        ]
      ],
      "transformers/tests/models/qwen3_vl/test_processing_qwen3_vl.py": [
        [
          "tearDownClass",
          65,
          66,
          66,
          9,
          66,
          57,
          65,
          23,
          66,
          57
        ]
      ],
      "transformers/tests/models/sam_hq/test_processing_samhq.py": [
        [
          "tearDown",
          51,
          52,
          52,
          9,
          52,
          38,
          51,
          18,
          52,
          38
        ]
      ],
      "transformers/tests/models/sam/test_processing_sam.py": [
        [
          "tearDownClass",
          53,
          54,
          54,
          9,
          54,
          57,
          53,
          23,
          54,
          57
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_processing_shieldgemma2.py": [
        [
          "tearDownClass",
          92,
          93,
          93,
          9,
          93,
          57,
          92,
          23,
          93,
          57
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "tearDownClass",
          45,
          46,
          46,
          9,
          46,
          57,
          45,
          23,
          46,
          57
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "tearDownClass",
          74,
          75,
          75,
          9,
          75,
          57,
          74,
          23,
          75,
          57
        ]
      ],
      "transformers/tests/models/speech_to_text/test_processing_speech_to_text.py": [
        [
          "tearDownClass",
          67,
          68,
          68,
          9,
          68,
          57,
          67,
          23,
          68,
          57
        ]
      ],
      "transformers/tests/models/smolvlm/test_processing_smolvlm.py": [
        [
          "tearDownClass",
          71,
          75,
          75,
          9,
          75,
          57,
          71,
          23,
          75,
          57
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_processing_seamless_m4t.py": [
        [
          "tearDown",
          41,
          42,
          42,
          9,
          42,
          38,
          41,
          18,
          42,
          38
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "tearDownClass",
          74,
          75,
          75,
          9,
          75,
          57,
          74,
          23,
          75,
          57
        ]
      ],
      "transformers/tests/models/udop/test_processing_udop.py": [
        [
          "tearDownClass",
          93,
          94,
          94,
          9,
          94,
          57,
          93,
          23,
          94,
          57
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "tearDownClass",
          75,
          76,
          76,
          9,
          76,
          57,
          75,
          23,
          76,
          57
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "tearDownClass",
          76,
          77,
          77,
          9,
          77,
          57,
          76,
          23,
          77,
          57
        ]
      ],
      "transformers/tests/models/glm4v/test_processor_glm4v.py": [
        [
          "tearDownClass",
          63,
          64,
          64,
          9,
          64,
          57,
          63,
          23,
          64,
          57
        ]
      ],
      "transformers/tests/models/ovis2/test_processor_ovis2.py": [
        [
          "tearDown",
          80,
          81,
          81,
          9,
          81,
          38,
          80,
          18,
          81,
          38
        ]
      ],
      "transformers/tests/models/sam2/test_processor_sam2.py": [
        [
          "tearDown",
          47,
          48,
          48,
          9,
          48,
          38,
          47,
          18,
          48,
          38
        ]
      ],
      "transformers/tests/models/whisper/test_processing_whisper.py": [
        [
          "tearDown",
          50,
          51,
          51,
          9,
          51,
          38,
          50,
          18,
          51,
          38
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_processor_kosmos2_5.py": [
        [
          "tearDown",
          65,
          66,
          66,
          9,
          66,
          38,
          65,
          18,
          66,
          38
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "tearDown",
          90,
          91,
          91,
          9,
          91,
          38,
          90,
          18,
          91,
          38
        ]
      ],
      "transformers/tests/models/sam2_video/test_processor_sam2_video.py": [
        [
          "tearDown",
          51,
          52,
          52,
          9,
          52,
          38,
          51,
          18,
          52,
          38
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "tearDown",
          116,
          117,
          117,
          9,
          117,
          38,
          116,
          18,
          117,
          38
        ]
      ],
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "create_tmp_repo",
          85,
          168,
          92,
          9,
          92,
          30,
          92,
          9,
          92,
          30
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_save_and_load_tokenizer",
          89,
          141,
          111,
          17,
          111,
          41,
          98,
          13,
          111,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          89,
          141,
          141,
          17,
          141,
          41,
          114,
          13,
          141,
          41
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_save_and_load_tokenizer",
          160,
          209,
          182,
          17,
          182,
          41,
          169,
          13,
          182,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          160,
          209,
          209,
          17,
          209,
          41,
          185,
          13,
          209,
          41
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_save_pretrained",
          145,
          213,
          213,
          17,
          213,
          42,
          213,
          17,
          213,
          42
        ],
        [
          "test_save_pretrained",
          145,
          213,
          175,
          17,
          175,
          42,
          175,
          17,
          191,
          58
        ],
        [
          "test_save_pretrained",
          145,
          213,
          194,
          17,
          194,
          42,
          194,
          17,
          210,
          58
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "tearDownClass",
          258,
          259,
          259,
          9,
          259,
          57,
          258,
          23,
          259,
          57
        ],
        [
          "test_save_sentencepiece_tokenizer",
          545,
          570,
          562,
          9,
          562,
          35,
          550,
          16,
          570,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          545,
          570,
          567,
          9,
          567,
          35,
          550,
          16,
          570,
          78
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          760,
          17,
          760,
          41,
          744,
          13,
          760,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          793,
          17,
          793,
          41,
          763,
          13,
          793,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          828,
          17,
          828,
          41,
          800,
          18,
          828,
          41
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4065,
          17,
          4065,
          42,
          4065,
          17,
          4081,
          58
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4084,
          17,
          4084,
          42,
          4084,
          17,
          4100,
          58
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4103,
          17,
          4103,
          42,
          4103,
          17,
          4103,
          42
        ],
        [
          "test_split_special_tokens",
          4508,
          4563,
          4557,
          21,
          4557,
          42,
          4555,
          21,
          4563,
          80
        ],
        [
          "test_split_special_tokens",
          4508,
          4563,
          4557,
          21,
          4557,
          42,
          4557,
          21,
          4557,
          42
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_training_new_tokenizer",
          82,
          97,
          96,
          21,
          96,
          50,
          96,
          21,
          97,
          35
        ],
        [
          "test_training_new_tokenizer_with_special_tokens_change",
          99,
          114,
          113,
          21,
          113,
          50,
          113,
          21,
          114,
          35
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py": [
        [
          "test_save_and_load_tokenizer",
          1080,
          1105,
          1105,
          17,
          1105,
          41,
          1089,
          13,
          1105,
          41
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_save_pretrained",
          148,
          211,
          173,
          17,
          173,
          42,
          173,
          17,
          189,
          58
        ],
        [
          "test_save_pretrained",
          148,
          211,
          192,
          17,
          192,
          42,
          192,
          17,
          208,
          58
        ],
        [
          "test_save_pretrained",
          148,
          211,
          211,
          17,
          211,
          42,
          211,
          17,
          211,
          42
        ],
        [
          "test_tiktoken_llama",
          850,
          915,
          902,
          9,
          902,
          33,
          850,
          29,
          915,
          45
        ]
      ],
      "transformers/tests/models/layoutxlm/test_tokenization_layoutxlm.py": [
        [
          "test_save_sentencepiece_tokenizer",
          148,
          182,
          171,
          9,
          171,
          35,
          153,
          24,
          182,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          148,
          182,
          179,
          9,
          179,
          35,
          153,
          24,
          182,
          78
        ],
        [
          "test_save_and_load_tokenizer",
          1011,
          1036,
          1036,
          17,
          1036,
          41,
          1020,
          13,
          1036,
          41
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1723,
          17,
          1723,
          42,
          1723,
          17,
          1739,
          58
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1742,
          17,
          1742,
          42,
          1742,
          17,
          1758,
          58
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1761,
          17,
          1761,
          42,
          1761,
          17,
          1761,
          42
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "test_save_and_load_tokenizer",
          967,
          992,
          992,
          17,
          992,
          41,
          976,
          13,
          992,
          41
        ]
      ],
      "transformers/tests/models/mbart/test_tokenization_mbart.py": [
        [
          "test_save_pretrained",
          135,
          204,
          185,
          17,
          185,
          42,
          185,
          17,
          201,
          58
        ],
        [
          "test_save_pretrained",
          135,
          204,
          166,
          17,
          166,
          42,
          166,
          17,
          182,
          58
        ],
        [
          "test_save_pretrained",
          135,
          204,
          204,
          17,
          204,
          42,
          204,
          17,
          204,
          42
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "test_save_and_load_tokenizer",
          859,
          884,
          884,
          17,
          884,
          41,
          868,
          13,
          884,
          41
        ]
      ],
      "transformers/tests/models/mbart50/test_tokenization_mbart50.py": [
        [
          "test_save_pretrained",
          113,
          182,
          144,
          17,
          144,
          42,
          144,
          17,
          160,
          58
        ],
        [
          "test_save_pretrained",
          113,
          182,
          163,
          17,
          163,
          42,
          163,
          17,
          179,
          58
        ],
        [
          "test_save_pretrained",
          113,
          182,
          182,
          17,
          182,
          42,
          182,
          17,
          182,
          42
        ]
      ],
      "transformers/tests/models/nllb/test_tokenization_nllb.py": [
        [
          "test_save_pretrained",
          143,
          206,
          168,
          17,
          168,
          42,
          168,
          17,
          184,
          58
        ],
        [
          "test_save_pretrained",
          143,
          206,
          187,
          17,
          187,
          42,
          187,
          17,
          203,
          58
        ],
        [
          "test_save_pretrained",
          143,
          206,
          206,
          17,
          206,
          42,
          206,
          17,
          206,
          42
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_save_and_load_tokenizer",
          143,
          192,
          165,
          17,
          165,
          41,
          152,
          13,
          165,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          143,
          192,
          192,
          17,
          192,
          41,
          168,
          13,
          192,
          41
        ]
      ],
      "transformers/tests/models/pop2piano/test_tokenization_pop2piano.py": [
        [
          "test_save_and_load_tokenizer",
          203,
          225,
          225,
          9,
          225,
          33,
          203,
          38,
          225,
          33
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "tearDown",
          108,
          109,
          109,
          9,
          109,
          38,
          108,
          18,
          109,
          38
        ]
      ],
      "transformers/tests/models/udop/test_tokenization_udop.py": [
        [
          "test_save_sentencepiece_tokenizer",
          141,
          175,
          164,
          9,
          164,
          35,
          146,
          24,
          175,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          141,
          175,
          172,
          9,
          172,
          35,
          146,
          24,
          175,
          78
        ],
        [
          "test_save_and_load_tokenizer",
          939,
          964,
          964,
          17,
          964,
          41,
          948,
          13,
          964,
          41
        ]
      ],
      "transformers/tests/models/tapas/test_tokenization_tapas.py": [
        [
          "test_save_and_load_tokenizer",
          854,
          880,
          880,
          17,
          880,
          41,
          863,
          13,
          880,
          41
        ]
      ],
      "transformers/tests/models/vits/test_tokenization_vits.py": [
        [
          "test_save_and_load_tokenizer",
          79,
          104,
          104,
          17,
          104,
          41,
          88,
          13,
          104,
          41
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "test_save_and_load_tokenizer",
          273,
          318,
          290,
          9,
          290,
          33,
          273,
          38,
          318,
          33
        ],
        [
          "test_save_pretrained",
          240,
          258,
          258,
          9,
          258,
          34,
          258,
          9,
          258,
          34
        ],
        [
          "test_save_and_load_tokenizer",
          273,
          318,
          318,
          9,
          318,
          33,
          273,
          38,
          318,
          33
        ]
      ],
      "transformers/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py": [
        [
          "test_save_pretrained",
          143,
          212,
          193,
          17,
          193,
          42,
          193,
          17,
          209,
          58
        ],
        [
          "test_save_pretrained",
          143,
          212,
          174,
          17,
          174,
          42,
          174,
          17,
          190,
          58
        ],
        [
          "test_save_pretrained",
          143,
          212,
          212,
          17,
          212,
          42,
          212,
          17,
          212,
          42
        ]
      ],
      "transformers/tests/trainer/test_trainer_callback.py": [
        [
          "tearDown",
          111,
          112,
          112,
          9,
          112,
          38,
          111,
          18,
          112,
          38
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "get_auto_remove_tmp_dir",
          2045,
          2111,
          2090,
          17,
          2090,
          58,
          2090,
          17,
          2090,
          58
        ],
        [
          "tearDown",
          2146,
          2158,
          2149,
          13,
          2149,
          51,
          2148,
          13,
          2149,
          51
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_inner_training_loop",
          2252,
          2734,
          2722,
          21,
          2722,
          65,
          2721,
          21,
          2722,
          65
        ],
        [
          "_rotate_checkpoints",
          4220,
          4243,
          4243,
          13,
          4243,
          57,
          4241,
          13,
          4243,
          57
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "write_model",
          68,
          216,
          216,
          9,
          216,
          37,
          216,
          9,
          216,
          37
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "write_model",
          65,
          183,
          183,
          5,
          183,
          33,
          177,
          5,
          183,
          33
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "write_model",
          91,
          215,
          215,
          5,
          215,
          33,
          209,
          5,
          215,
          33
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "write_model",
          272,
          398,
          398,
          9,
          398,
          37,
          398,
          9,
          398,
          37
        ]
      ],
      "transformers/src/transformers/models/timesfm/convert_timesfm_orignal_to_hf.py": [
        [
          "write_model",
          36,
          147,
          147,
          5,
          147,
          33,
          146,
          5,
          147,
          33
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "__del__",
          1823,
          1827,
          1825,
          13,
          1825,
          77,
          1825,
          13,
          1825,
          77
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_distributed_eval.py": [
        [
          "run_generate",
          119,
          227,
          227,
          13,
          227,
          40,
          227,
          13,
          227,
          40
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "tearDownClass",
          74,
          75,
          75,
          9,
          75,
          33,
          74,
          23,
          75,
          33
        ]
      ],
      "transformers/tests/utils/test_cli.py": [
        [
          "test_cli_download",
          37,
          49,
          41,
          9,
          41,
          95,
          37,
          27,
          49,
          103
        ],
        [
          "test_cli_download_trust_remote",
          63,
          77,
          67,
          9,
          67,
          112,
          63,
          40,
          77,
          9
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "create_tmp_repo",
          251,
          275,
          257,
          9,
          257,
          30,
          257,
          9,
          257,
          30
        ]
      ],
      "transformers/tests/trainer/test_data_collator.py": [
        [
          "tearDown",
          54,
          55,
          55,
          9,
          55,
          38,
          54,
          18,
          55,
          38
        ],
        [
          "tearDown",
          729,
          730,
          730,
          9,
          730,
          38,
          729,
          18,
          730,
          38
        ],
        [
          "tearDown",
          1051,
          1052,
          1052,
          9,
          1052,
          38,
          1051,
          18,
          1052,
          38
        ],
        [
          "tearDown",
          1556,
          1557,
          1557,
          9,
          1557,
          38,
          1556,
          18,
          1557,
          38
        ]
      ]
    },
    "os.listdir": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          794,
          30,
          794,
          48,
          789,
          17,
          794,
          48
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          819,
          44,
          819,
          62,
          815,
          22,
          824,
          77
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          2003,
          66,
          2003,
          87,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          2004,
          52,
          2004,
          73,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2029,
          66,
          2029,
          87,
          2006,
          66,
          2030,
          85
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2030,
          63,
          2030,
          84,
          2006,
          66,
          2030,
          85
        ]
      ],
      "transformers/tests/peft_integration/test_peft_integration.py": [
        [
          "test_peft_save_pretrained",
          122,
          149,
          134,
          68,
          134,
          89,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_save_pretrained",
          122,
          149,
          135,
          62,
          135,
          83,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_save_pretrained",
          122,
          149,
          137,
          58,
          137,
          79,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_save_pretrained",
          122,
          149,
          138,
          64,
          138,
          85,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_save_pretrained",
          122,
          149,
          139,
          64,
          139,
          85,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_save_pretrained",
          122,
          149,
          145,
          60,
          145,
          81,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_save_pretrained",
          122,
          149,
          146,
          62,
          146,
          83,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          533,
          68,
          533,
          89,
          521,
          17,
          536,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          534,
          62,
          534,
          83,
          521,
          17,
          536,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          535,
          64,
          535,
          85,
          521,
          17,
          536,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          536,
          64,
          536,
          85,
          521,
          17,
          536,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          553,
          68,
          553,
          89,
          540,
          17,
          556,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          554,
          62,
          554,
          83,
          540,
          17,
          556,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          555,
          64,
          555,
          85,
          540,
          17,
          556,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          556,
          64,
          556,
          85,
          540,
          17,
          556,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          579,
          60,
          579,
          81,
          567,
          17,
          582,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          580,
          62,
          580,
          83,
          567,
          17,
          582,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          581,
          64,
          581,
          85,
          567,
          17,
          582,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          582,
          64,
          582,
          85,
          567,
          17,
          582,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          599,
          60,
          599,
          81,
          586,
          17,
          602,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          600,
          62,
          600,
          83,
          586,
          17,
          602,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          601,
          64,
          601,
          85,
          586,
          17,
          602,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          602,
          64,
          602,
          85,
          586,
          17,
          602,
          86
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "test_decoder_download_ignores_files",
          354,
          369,
          360,
          36,
          360,
          65,
          354,
          45,
          369,
          78
        ],
        [
          "test_decoder_local_files",
          371,
          386,
          379,
          31,
          379,
          51,
          371,
          34,
          386,
          73
        ],
        [
          "test_decoder_local_files",
          371,
          386,
          380,
          34,
          380,
          63,
          371,
          34,
          386,
          73
        ]
      ],
      "transformers/tests/tensor_parallel/test_tensor_parallel.py": [
        [
          "test_model_save",
          176,
          215,
          205,
          29,
          205,
          57,
          202,
          33,
          205,
          57
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_saving_tokenizer_trainer",
          4452,
          4470,
          4470,
          53,
          4470,
          99,
          4453,
          13,
          4470,
          100
        ]
      ],
      "transformers/tests/extended/test_trainer_ext.py": [
        [
          "test_run_seq2seq",
          139,
          162,
          159,
          20,
          159,
          41,
          156,
          9,
          161,
          54
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "test_save_collator_tokenizer_by_default",
          3195,
          3211,
          3210,
          80,
          3210,
          98,
          3195,
          49,
          3211,
          76
        ],
        [
          "test_resume_training_with_randomness",
          3434,
          3487,
          3478,
          39,
          3478,
          57,
          3442,
          25,
          3487,
          53
        ],
        [
          "test_save_best_checkpoint",
          4837,
          4903,
          4866,
          38,
          4866,
          55,
          4837,
          35,
          4903,
          17
        ],
        [
          "test_save_best_checkpoint",
          4837,
          4903,
          4898,
          38,
          4898,
          55,
          4837,
          35,
          4903,
          17
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4951,
          24,
          4951,
          41,
          4950,
          13,
          4951,
          71
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4972,
          24,
          4972,
          41,
          4971,
          13,
          4972,
          47
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4976,
          20,
          4976,
          37,
          4975,
          13,
          4976,
          82
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5012,
          24,
          5012,
          41,
          5010,
          13,
          5012,
          76
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5048,
          24,
          5048,
          41,
          5046,
          13,
          5048,
          71
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5084,
          24,
          5084,
          41,
          5082,
          13,
          5084,
          47
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5118,
          24,
          5118,
          41,
          5116,
          13,
          5118,
          76
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "get_all_tests",
          156,
          182,
          167,
          13,
          167,
          37,
          157,
          5,
          178,
          33
        ],
        [
          "get_all_tests",
          156,
          182,
          172,
          26,
          172,
          61,
          157,
          5,
          178,
          33
        ],
        [
          "filter_tests",
          1041,
          1065,
          1060,
          57,
          1060,
          75,
          1060,
          57,
          1060,
          18
        ]
      ],
      "transformers/src/transformers/tokenization_mistral_common.py": [
        [
          "from_pretrained",
          1685,
          1809,
          1778,
          25,
          1778,
          65,
          1771,
          37,
          1778,
          65
        ]
      ],
      "transformers/src/transformers/trainer_utils.py": [
        [
          "get_last_checkpoint",
          202,
          211,
          203,
          15,
          203,
          32,
          202,
          25,
          209,
          28
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2771,
          36,
          2771,
          69,
          2769,
          13,
          2773,
          13
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2781,
          36,
          2781,
          69,
          2781,
          36,
          2787,
          13
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3360,
          44,
          3360,
          65,
          3358,
          25,
          3362,
          21
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "check_output_dir",
          644,
          665,
          657,
          17,
          657,
          43,
          657,
          13,
          657,
          61
        ],
        [
          "check_output_dir",
          644,
          665,
          663,
          24,
          663,
          50,
          661,
          15,
          665,
          9
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_all_model_cards",
          253,
          263,
          256,
          17,
          256,
          37,
          254,
          5,
          258,
          25
        ]
      ],
      "transformers/utils/check_config_attributes.py": [
        [
          "check_config_attributes_being_used",
          457,
          499,
          478,
          61,
          478,
          81,
          476,
          26,
          482,
          30
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "check_model_list",
          442,
          470,
          451,
          18,
          451,
          39,
          443,
          5,
          451,
          39
        ],
        [
          "check_model_list",
          442,
          470,
          455,
          58,
          455,
          78,
          455,
          41,
          455,
          78
        ],
        [
          "get_model_test_files",
          565,
          597,
          583,
          14,
          583,
          40,
          566,
          5,
          583,
          40
        ],
        [
          "get_model_test_files",
          565,
          597,
          589,
          28,
          589,
          49,
          588,
          9,
          589,
          49
        ],
        [
          "check_all_decorator_order",
          898,
          911,
          901,
          18,
          901,
          42,
          899,
          5,
          901,
          42
        ],
        [
          "check_deprecated_constant_is_up_to_date",
          1170,
          1196,
          1175,
          37,
          1175,
          65,
          1171,
          5,
          1180,
          31
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          336,
          16,
          336,
          41,
          325,
          54,
          338,
          36
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          340,
          37,
          340,
          85,
          340,
          37,
          342,
          17
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          638,
          28,
          638,
          53,
          638,
          28,
          639,
          25
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          90,
          22,
          90,
          54,
          90,
          22,
          100,
          44
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          158,
          22,
          158,
          54,
          156,
          17,
          162,
          44
        ]
      ],
      "transformers/src/transformers/models/dia/convert_dia_to_hf.py": [
        [
          "convert_dia_model_to_hf",
          78,
          155,
          98,
          13,
          98,
          39,
          78,
          29,
          99,
          21
        ]
      ],
      "transformers/src/transformers/models/doge/convert_doge_weights_to_hf.py": [
        [
          "load_weights",
          49,
          66,
          50,
          61,
          50,
          81,
          49,
          18,
          54,
          23
        ]
      ],
      "transformers/src/transformers/models/gemma2/convert_gemma2_weights_to_hf.py": [
        [
          "write_model",
          84,
          158,
          96,
          35,
          96,
          61,
          93,
          9,
          98,
          25
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "load_weights",
          40,
          61,
          41,
          61,
          41,
          81,
          40,
          18,
          46,
          23
        ],
        [
          "load_weights",
          40,
          61,
          42,
          54,
          42,
          74,
          40,
          18,
          46,
          23
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "load_weights",
          45,
          66,
          46,
          61,
          46,
          81,
          45,
          18,
          51,
          23
        ],
        [
          "load_weights",
          45,
          66,
          47,
          54,
          47,
          74,
          45,
          18,
          51,
          23
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_model",
          146,
          284,
          179,
          22,
          179,
          48,
          154,
          20,
          179,
          49
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "write_model",
          184,
          433,
          235,
          56,
          235,
          82,
          235,
          31,
          237,
          18
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "parse_metadata",
          290,
          318,
          303,
          32,
          303,
          44,
          302,
          68,
          306,
          79
        ],
        [
          "parse_metadata",
          290,
          318,
          308,
          32,
          308,
          44,
          308,
          32,
          314,
          80
        ]
      ],
      "transformers/src/transformers/models/mistral3/convert_mistral3_weights_to_hf.py": [
        [
          "convert_and_write_model",
          171,
          188,
          178,
          32,
          178,
          52,
          171,
          29,
          179,
          28
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "convert_and_write_model",
          194,
          220,
          202,
          36,
          202,
          56,
          202,
          36,
          203,
          32
        ],
        [
          "convert_and_write_model",
          194,
          220,
          209,
          36,
          209,
          56,
          209,
          36,
          214,
          23
        ],
        [
          "convert_and_write_tokenizer",
          223,
          240,
          226,
          25,
          226,
          45,
          223,
          33,
          226,
          45
        ],
        [
          "convert_and_write_tokenizer",
          223,
          240,
          231,
          44,
          231,
          64,
          231,
          44,
          232,
          17
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/convert_phi4_multimodal_weights_to_hf.py": [
        [
          "convert_and_write_model",
          143,
          166,
          149,
          32,
          149,
          52,
          143,
          29,
          150,
          28
        ],
        [
          "extract_adapters_data",
          216,
          249,
          220,
          32,
          220,
          52,
          216,
          27,
          221,
          28
        ]
      ],
      "transformers/src/transformers/models/pixtral/convert_pixtral_weights_to_hf.py": [
        [
          "convert_mistral_model",
          145,
          210,
          198,
          50,
          198,
          70,
          184,
          20,
          199,
          34
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "create_tiny_models",
          1321,
          1431,
          1381,
          27,
          1381,
          49,
          1380,
          21,
          1381,
          49
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1385,
          25,
          1385,
          73,
          1385,
          25,
          1385,
          73
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "remove_copied_from_statements",
          127,
          143,
          129,
          17,
          129,
          38,
          127,
          35,
          129,
          38
        ],
        [
          "move_model_files_to_deprecated",
          146,
          159,
          153,
          17,
          153,
          38,
          153,
          17,
          153,
          38
        ]
      ],
      "transformers/utils/extract_warnings.py": [
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          41,
          25,
          41,
          49,
          41,
          25,
          41,
          49
        ],
        [
          "extract_warnings",
          67,
          76,
          72,
          53,
          72,
          76,
          67,
          22,
          73,
          18
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "get_all_errors",
          159,
          168,
          164,
          53,
          164,
          76,
          159,
          20,
          165,
          18
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_last_daily_ci_reports",
          123,
          159,
          150,
          24,
          150,
          45,
          145,
          26,
          151,
          36
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "_get_files_timestamps",
          744,
          748,
          748,
          76,
          748,
          98,
          744,
          31,
          748,
          99
        ],
        [
          "_upload_modified_files",
          750,
          827,
          779,
          22,
          779,
          44,
          779,
          22,
          792,
          34
        ],
        [
          "_upload_modified_files",
          750,
          827,
          795,
          26,
          795,
          68,
          795,
          26,
          795,
          68
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          187,
          226,
          200,
          26,
          200,
          45,
          196,
          9,
          200,
          45
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "_objective",
          258,
          284,
          261,
          31,
          261,
          56,
          261,
          31,
          261,
          56
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2177,
          14,
          2177,
          36,
          2174,
          17,
          2177,
          36
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "save_pretrained",
          3648,
          4088,
          3988,
          25,
          3988,
          50,
          3988,
          25,
          3988,
          50
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "retrieve_artifact",
          276,
          288,
          280,
          17,
          280,
          32,
          280,
          17,
          281,
          25
        ],
        [
          "retrieve_available_artifacts",
          291,
          313,
          305,
          41,
          305,
          52,
          292,
          5,
          306,
          32
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "retrieve_artifact",
          944,
          959,
          951,
          17,
          951,
          41,
          951,
          17,
          952,
          25
        ],
        [
          "retrieve_available_artifacts",
          962,
          1011,
          978,
          41,
          978,
          52,
          963,
          5,
          979,
          32
        ]
      ],
      "transformers/src/transformers/utils/peft_utils.py": [
        [
          "find_adapter_config_file",
          29,
          100,
          80,
          29,
          80,
          48,
          80,
          29,
          81,
          51
        ]
      ],
      "transformers/examples/pytorch/audio-classification/run_audio_classification.py": [
        [
          "main",
          208,
          435,
          252,
          44,
          252,
          79,
          252,
          40,
          252,
          84
        ]
      ],
      "transformers/examples/pytorch/contrastive-image-text/run_clip.py": [
        [
          "main",
          236,
          533,
          278,
          44,
          278,
          79,
          278,
          40,
          278,
          84
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          328,
          44,
          328,
          79,
          328,
          40,
          328,
          84
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm.py": [
        [
          "main",
          282,
          720,
          324,
          44,
          324,
          79,
          324,
          40,
          324,
          84
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim.py": [
        [
          "main",
          309,
          854,
          351,
          44,
          351,
          79,
          351,
          40,
          351,
          84
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          273,
          44,
          273,
          79,
          273,
          40,
          273,
          84
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "main",
          191,
          445,
          232,
          44,
          232,
          79,
          232,
          40,
          232,
          84
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          205,
          44,
          205,
          79,
          205,
          40,
          205,
          84
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "main",
          197,
          364,
          212,
          13,
          212,
          48,
          212,
          13,
          212,
          48
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation.py": [
        [
          "find_last_checkpoint",
          331,
          350,
          339,
          39,
          339,
          74,
          339,
          35,
          339,
          79
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mae.py": [
        [
          "main",
          183,
          403,
          224,
          44,
          224,
          79,
          224,
          40,
          224,
          84
        ]
      ],
      "transformers/examples/legacy/multiple_choice/run_multiple_choice.py": [
        [
          "main",
          90,
          234,
          100,
          13,
          100,
          48,
          100,
          13,
          100,
          48
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim.py": [
        [
          "main",
          247,
          483,
          288,
          44,
          288,
          79,
          288,
          40,
          288,
          84
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm.py": [
        [
          "main",
          254,
          678,
          297,
          44,
          297,
          79,
          297,
          40,
          297,
          84
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          116,
          13,
          116,
          48,
          116,
          13,
          116,
          48
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          270,
          44,
          270,
          79,
          270,
          40,
          270,
          84
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection.py": [
        [
          "main",
          339,
          534,
          382,
          39,
          382,
          74,
          382,
          35,
          382,
          79
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_plm.py": [
        [
          "main",
          234,
          575,
          276,
          44,
          276,
          79,
          276,
          40,
          276,
          84
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa.py": [
        [
          "main",
          227,
          701,
          269,
          44,
          269,
          79,
          269,
          40,
          269,
          84
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search.py": [
        [
          "main",
          225,
          728,
          267,
          44,
          267,
          79,
          267,
          40,
          267,
          84
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          228,
          44,
          228,
          79,
          228,
          40,
          228,
          84
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          436,
          44,
          436,
          79,
          436,
          40,
          436,
          84
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_seq2seq_qa.py": [
        [
          "main",
          272,
          729,
          314,
          44,
          314,
          79,
          314,
          40,
          314,
          84
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad_trainer.py": [
        [
          "main",
          65,
          176,
          81,
          13,
          81,
          48,
          81,
          13,
          81,
          48
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py": [
        [
          "main",
          302,
          657,
          347,
          44,
          347,
          79,
          347,
          40,
          347,
          84
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          413,
          44,
          413,
          79,
          413,
          40,
          413,
          84
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag.py": [
        [
          "main",
          178,
          442,
          220,
          44,
          220,
          79,
          220,
          40,
          220,
          84
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "main",
          470,
          835,
          682,
          13,
          682,
          39,
          682,
          13,
          682,
          39
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "main",
          473,
          717,
          589,
          13,
          589,
          39,
          589,
          13,
          589,
          39
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          381,
          44,
          381,
          79,
          381,
          40,
          381,
          84
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          329,
          44,
          329,
          79,
          329,
          40,
          329,
          84
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_xnli.py": [
        [
          "main",
          194,
          461,
          231,
          44,
          231,
          79,
          231,
          40,
          231,
          84
        ]
      ],
      "transformers/utils/sort_auto_mappings.py": [
        [
          "sort_all_auto_mappings",
          102,
          117,
          109,
          61,
          109,
          91,
          102,
          28,
          112,
          20
        ]
      ],
      "transformers/tests/generation/test_configuration_utils.py": [
        [
          "test_refuse_to_save",
          233,
          273,
          245,
          33,
          245,
          51,
          233,
          29,
          273,
          57
        ],
        [
          "test_refuse_to_save",
          233,
          273,
          259,
          33,
          259,
          51,
          233,
          29,
          273,
          57
        ],
        [
          "test_refuse_to_save",
          233,
          273,
          273,
          34,
          273,
          52,
          233,
          29,
          273,
          57
        ]
      ],
      "transformers/tests/utils/test_doc_samples.py": [
        [
          "analyze_directory",
          32,
          82,
          51,
          35,
          51,
          55,
          33,
          9,
          53,
          33
        ]
      ],
      "transformers/tests/fsdp/test_fsdp.py": [
        [
          "test_training_and_can_resume_normally",
          297,
          329,
          315,
          36,
          315,
          57,
          313,
          13,
          317,
          13
        ],
        [
          "test_accelerate_fsdp2_integration",
          353,
          394,
          380,
          36,
          380,
          57,
          378,
          13,
          382,
          13
        ]
      ],
      "transformers/tests/utils/test_import_structure.py": [
        [
          "test_transformers_specific_model_import",
          81,
          118,
          88,
          29,
          88,
          56,
          81,
          49,
          88,
          56
        ]
      ]
    },
    "os.path.isfile": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          801,
          33,
          801,
          58,
          799,
          30,
          805,
          61
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          802,
          34,
          802,
          84,
          799,
          30,
          805,
          61
        ],
        [
          "test_checkpoint_variant_local_bin",
          834,
          852,
          843,
          29,
          843,
          56,
          834,
          43,
          851,
          69
        ],
        [
          "test_checkpoint_variant_local_bin",
          834,
          852,
          844,
          30,
          844,
          80,
          834,
          43,
          851,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          862,
          29,
          862,
          62,
          854,
          51,
          865,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          863,
          30,
          863,
          86,
          854,
          51,
          865,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          868,
          33,
          868,
          65,
          865,
          17,
          868,
          66
        ],
        [
          "test_checkpoint_variant_local_safe",
          878,
          896,
          887,
          29,
          887,
          56,
          878,
          44,
          895,
          69
        ],
        [
          "test_checkpoint_variant_local_safe",
          878,
          896,
          888,
          30,
          888,
          85,
          878,
          44,
          895,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          906,
          29,
          906,
          62,
          898,
          52,
          909,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          907,
          30,
          907,
          91,
          898,
          52,
          909,
          32
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          912,
          33,
          912,
          65,
          909,
          17,
          912,
          66
        ],
        [
          "test_checkpoint_loading_only_safetensors_available",
          922,
          953,
          935,
          29,
          935,
          62,
          922,
          60,
          937,
          32
        ],
        [
          "test_checkpoint_loading_only_safetensors_available",
          922,
          953,
          940,
          33,
          940,
          65,
          937,
          17,
          940,
          66
        ],
        [
          "test_checkpoint_loading_only_pytorch_bin_available",
          955,
          986,
          968,
          29,
          968,
          62,
          955,
          60,
          970,
          32
        ],
        [
          "test_checkpoint_loading_only_pytorch_bin_available",
          955,
          986,
          973,
          33,
          973,
          65,
          970,
          17,
          973,
          66
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1037,
          29,
          1037,
          79,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1042,
          29,
          1042,
          79,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1045,
          29,
          1045,
          79,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_safetensors_save_and_load",
          1331,
          1343,
          1336,
          29,
          1336,
          84,
          1331,
          40,
          1342,
          73
        ],
        [
          "test_safetensors_save_and_load",
          1331,
          1343,
          1337,
          30,
          1337,
          80,
          1331,
          40,
          1342,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1358,
          30,
          1358,
          86,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1359,
          29,
          1359,
          90,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1361,
          30,
          1361,
          80,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1362,
          30,
          1362,
          85,
          1353,
          48,
          1367,
          73
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_processor_from_processor_class",
          97,
          123,
          107,
          20,
          107,
          75,
          97,
          45,
          107,
          75
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          135,
          16,
          135,
          71,
          125,
          55,
          135,
          71
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          166,
          16,
          166,
          71,
          156,
          55,
          166,
          71
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          497,
          33,
          497,
          101,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          498,
          33,
          498,
          95,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          499,
          33,
          499,
          93,
          456,
          44,
          505,
          85
        ]
      ],
      "transformers/examples/pytorch/test_pytorch_examples.py": [
        [
          "test_run_speech_recognition_ctc_adapter",
          446,
          476,
          475,
          29,
          475,
          94,
          472,
          14,
          476,
          70
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          99,
          12,
          99,
          43,
          93,
          13,
          99,
          43
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "check_saved_checkpoints",
          624,
          637,
          637,
          33,
          637,
          82,
          636,
          17,
          637,
          83
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          264,
          12,
          264,
          73,
          264,
          12,
          264,
          73
        ],
        [
          "filter_tests",
          1041,
          1065,
          1049,
          12,
          1049,
          38,
          1041,
          18,
          1049,
          38
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "save_vocabulary",
          302,
          317,
          310,
          84,
          310,
          114,
          310,
          84,
          310,
          114
        ],
        [
          "save_vocabulary",
          302,
          317,
          312,
          18,
          312,
          48,
          312,
          18,
          312,
          48
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez.py": [
        [
          "save_vocabulary",
          273,
          288,
          281,
          84,
          281,
          114,
          281,
          84,
          281,
          114
        ],
        [
          "save_vocabulary",
          273,
          288,
          283,
          18,
          283,
          48,
          283,
          18,
          283,
          48
        ]
      ],
      "transformers/src/transformers/models/bartpho/tokenization_bartpho.py": [
        [
          "save_vocabulary",
          286,
          315,
          298,
          84,
          298,
          114,
          298,
          84,
          298,
          114
        ],
        [
          "save_vocabulary",
          286,
          315,
          300,
          18,
          300,
          48,
          300,
          18,
          300,
          48
        ],
        [
          "save_vocabulary",
          286,
          315,
          307,
          15,
          307,
          57,
          307,
          15,
          307,
          57
        ],
        [
          "save_vocabulary",
          286,
          315,
          309,
          18,
          309,
          60,
          309,
          18,
          309,
          60
        ]
      ],
      "transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py": [
        [
          "save_vocabulary",
          159,
          174,
          167,
          84,
          167,
          114,
          167,
          84,
          167,
          114
        ],
        [
          "save_vocabulary",
          159,
          174,
          169,
          18,
          169,
          48,
          169,
          18,
          169,
          48
        ]
      ],
      "transformers/src/transformers/models/bert/tokenization_bert.py": [
        [
          "__init__",
          98,
          145,
          114,
          16,
          114,
          41,
          99,
          9,
          114,
          41
        ]
      ],
      "transformers/src/transformers/models/bert_japanese/tokenization_bert_japanese.py": [
        [
          "__init__",
          94,
          185,
          115,
          20,
          115,
          43,
          115,
          20,
          115,
          43
        ],
        [
          "__init__",
          94,
          185,
          122,
          20,
          122,
          45,
          122,
          20,
          122,
          45
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "save_vocabulary",
          233,
          248,
          241,
          84,
          241,
          114,
          241,
          84,
          241,
          114
        ],
        [
          "save_vocabulary",
          233,
          248,
          243,
          18,
          243,
          48,
          243,
          18,
          243,
          48
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "save_vocabulary",
          373,
          394,
          384,
          84,
          384,
          114,
          384,
          84,
          384,
          114
        ],
        [
          "save_vocabulary",
          373,
          394,
          386,
          18,
          386,
          48,
          386,
          18,
          386,
          48
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert.py": [
        [
          "save_vocabulary",
          229,
          244,
          237,
          84,
          237,
          114,
          237,
          84,
          237,
          114
        ],
        [
          "save_vocabulary",
          229,
          244,
          239,
          18,
          239,
          48,
          239,
          18,
          239,
          48
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama.py": [
        [
          "save_vocabulary",
          331,
          356,
          351,
          18,
          351,
          48,
          351,
          18,
          351,
          48
        ],
        [
          "save_vocabulary",
          331,
          356,
          349,
          84,
          349,
          114,
          349,
          84,
          349,
          114
        ]
      ],
      "transformers/src/transformers/models/convbert/tokenization_convbert.py": [
        [
          "__init__",
          101,
          148,
          117,
          16,
          117,
          41,
          102,
          9,
          117,
          41
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "save_vocabulary",
          327,
          342,
          335,
          84,
          335,
          114,
          335,
          84,
          335,
          114
        ],
        [
          "save_vocabulary",
          327,
          342,
          337,
          18,
          337,
          48,
          337,
          18,
          337,
          48
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2.py": [
        [
          "__init__",
          86,
          128,
          103,
          16,
          103,
          41,
          101,
          32,
          103,
          41
        ]
      ],
      "transformers/src/transformers/models/distilbert/tokenization_distilbert.py": [
        [
          "__init__",
          101,
          147,
          117,
          16,
          117,
          41,
          102,
          9,
          117,
          41
        ]
      ],
      "transformers/src/transformers/models/electra/tokenization_electra.py": [
        [
          "__init__",
          100,
          147,
          116,
          16,
          116,
          41,
          101,
          9,
          116,
          41
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "save_vocabulary",
          296,
          311,
          304,
          84,
          304,
          114,
          304,
          84,
          304,
          114
        ],
        [
          "save_vocabulary",
          296,
          311,
          306,
          18,
          306,
          48,
          306,
          18,
          306,
          48
        ]
      ],
      "transformers/src/transformers/models/funnel/tokenization_funnel.py": [
        [
          "__init__",
          118,
          168,
          136,
          16,
          136,
          41,
          119,
          9,
          136,
          41
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma.py": [
        [
          "save_vocabulary",
          197,
          222,
          215,
          84,
          215,
          114,
          215,
          84,
          215,
          114
        ],
        [
          "save_vocabulary",
          197,
          222,
          217,
          18,
          217,
          48,
          217,
          18,
          217,
          48
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "save_vocabulary",
          236,
          251,
          244,
          84,
          244,
          114,
          244,
          84,
          244,
          114
        ],
        [
          "save_vocabulary",
          236,
          251,
          246,
          18,
          246,
          48,
          246,
          18,
          246,
          48
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "__init__",
          106,
          139,
          117,
          16,
          117,
          41,
          107,
          9,
          117,
          41
        ],
        [
          "__init__",
          106,
          139,
          122,
          16,
          122,
          41,
          122,
          16,
          122,
          41
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "__init__",
          144,
          180,
          156,
          16,
          156,
          41,
          145,
          9,
          156,
          41
        ],
        [
          "__init__",
          144,
          180,
          161,
          16,
          161,
          41,
          161,
          16,
          161,
          41
        ]
      ],
      "transformers/src/transformers/models/layoutlm/tokenization_layoutlm.py": [
        [
          "__init__",
          101,
          148,
          117,
          16,
          117,
          41,
          102,
          9,
          117,
          41
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py": [
        [
          "__init__",
          198,
          268,
          226,
          16,
          226,
          41,
          224,
          22,
          226,
          41
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm.py": [
        [
          "save_vocabulary",
          421,
          436,
          429,
          84,
          429,
          114,
          429,
          84,
          429,
          114
        ],
        [
          "save_vocabulary",
          421,
          436,
          431,
          18,
          431,
          48,
          431,
          18,
          431,
          48
        ]
      ],
      "transformers/src/transformers/models/lxmert/tokenization_lxmert.py": [
        [
          "__init__",
          100,
          147,
          116,
          16,
          116,
          41,
          101,
          9,
          116,
          41
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama.py": [
        [
          "save_vocabulary",
          306,
          331,
          324,
          84,
          324,
          114,
          324,
          84,
          324,
          114
        ],
        [
          "save_vocabulary",
          306,
          331,
          326,
          18,
          326,
          48,
          326,
          18,
          326,
          48
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "save_vocabulary",
          287,
          330,
          321,
          85,
          321,
          113,
          321,
          85,
          321,
          113
        ],
        [
          "save_vocabulary",
          287,
          330,
          324,
          22,
          324,
          50,
          324,
          22,
          324,
          50
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart.py": [
        [
          "save_vocabulary",
          294,
          309,
          302,
          84,
          302,
          114,
          302,
          84,
          302,
          114
        ],
        [
          "save_vocabulary",
          294,
          309,
          304,
          18,
          304,
          48,
          304,
          18,
          304,
          48
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50.py": [
        [
          "save_vocabulary",
          242,
          257,
          250,
          84,
          250,
          114,
          250,
          84,
          250,
          114
        ],
        [
          "save_vocabulary",
          242,
          257,
          252,
          18,
          252,
          48,
          252,
          18,
          252,
          48
        ]
      ],
      "transformers/src/transformers/models/m2m_100/tokenization_m2m_100.py": [
        [
          "save_vocabulary",
          295,
          315,
          308,
          81,
          308,
          109,
          308,
          81,
          308,
          109
        ],
        [
          "save_vocabulary",
          295,
          315,
          310,
          18,
          310,
          46,
          310,
          18,
          310,
          46
        ]
      ],
      "transformers/src/transformers/models/mobilebert/tokenization_mobilebert.py": [
        [
          "__init__",
          102,
          149,
          118,
          16,
          118,
          41,
          103,
          9,
          118,
          41
        ]
      ],
      "transformers/src/transformers/models/mpnet/tokenization_mpnet.py": [
        [
          "__init__",
          119,
          179,
          147,
          16,
          147,
          41,
          145,
          22,
          147,
          41
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "save_vocabulary",
          1530,
          1553,
          1539,
          84,
          1539,
          114,
          1539,
          84,
          1539,
          114
        ],
        [
          "save_vocabulary",
          1530,
          1553,
          1541,
          18,
          1541,
          48,
          1541,
          18,
          1541,
          48
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb.py": [
        [
          "save_vocabulary",
          332,
          347,
          340,
          84,
          340,
          114,
          340,
          84,
          340,
          114
        ],
        [
          "save_vocabulary",
          332,
          347,
          342,
          18,
          342,
          48,
          342,
          18,
          342,
          48
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus.py": [
        [
          "save_vocabulary",
          274,
          289,
          282,
          84,
          282,
          114,
          282,
          84,
          282,
          114
        ],
        [
          "save_vocabulary",
          274,
          289,
          284,
          18,
          284,
          48,
          284,
          18,
          284,
          48
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "save_vocabulary",
          298,
          319,
          309,
          84,
          309,
          114,
          309,
          84,
          309,
          114
        ],
        [
          "save_vocabulary",
          298,
          319,
          311,
          18,
          311,
          48,
          311,
          18,
          311,
          48
        ]
      ],
      "transformers/src/transformers/models/plbart/tokenization_plbart.py": [
        [
          "save_vocabulary",
          370,
          385,
          378,
          84,
          378,
          114,
          378,
          84,
          378,
          114
        ],
        [
          "save_vocabulary",
          370,
          385,
          380,
          18,
          380,
          48,
          380,
          18,
          380,
          48
        ]
      ],
      "transformers/src/transformers/models/rag/tokenization_rag.py": [
        [
          "save_pretrained",
          35,
          42,
          36,
          12,
          36,
          41,
          35,
          25,
          36,
          41
        ]
      ],
      "transformers/src/transformers/models/prophetnet/tokenization_prophetnet.py": [
        [
          "__init__",
          324,
          370,
          340,
          16,
          340,
          41,
          325,
          9,
          340,
          41
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/tokenization_realm.py": [
        [
          "__init__",
          99,
          142,
          114,
          16,
          114,
          41,
          100,
          9,
          114,
          41
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer.py": [
        [
          "save_vocabulary",
          158,
          173,
          166,
          84,
          166,
          114,
          166,
          84,
          166,
          114
        ],
        [
          "save_vocabulary",
          158,
          173,
          168,
          18,
          168,
          48,
          168,
          18,
          168,
          48
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert.py": [
        [
          "save_vocabulary",
          219,
          234,
          227,
          84,
          227,
          114,
          227,
          84,
          227,
          114
        ],
        [
          "save_vocabulary",
          219,
          234,
          229,
          18,
          229,
          48,
          229,
          18,
          229,
          48
        ]
      ],
      "transformers/src/transformers/models/deprecated/retribert/tokenization_retribert.py": [
        [
          "__init__",
          97,
          142,
          112,
          16,
          112,
          41,
          98,
          9,
          112,
          41
        ]
      ],
      "transformers/src/transformers/models/roformer/tokenization_roformer.py": [
        [
          "__init__",
          326,
          378,
          341,
          16,
          341,
          41,
          327,
          9,
          341,
          41
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "save_vocabulary",
          362,
          377,
          370,
          84,
          370,
          114,
          370,
          84,
          370,
          114
        ],
        [
          "save_vocabulary",
          362,
          377,
          372,
          18,
          372,
          48,
          372,
          18,
          372,
          48
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t.py": [
        [
          "save_vocabulary",
          497,
          512,
          505,
          84,
          505,
          114,
          505,
          84,
          505,
          114
        ],
        [
          "save_vocabulary",
          497,
          512,
          507,
          18,
          507,
          48,
          507,
          18,
          507,
          48
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/tokenization_speech_to_text.py": [
        [
          "save_vocabulary",
          257,
          276,
          269,
          81,
          269,
          109,
          269,
          81,
          269,
          109
        ],
        [
          "save_vocabulary",
          257,
          276,
          271,
          18,
          271,
          46,
          271,
          18,
          271,
          46
        ]
      ],
      "transformers/src/transformers/models/splinter/tokenization_splinter.py": [
        [
          "__init__",
          98,
          144,
          114,
          16,
          114,
          41,
          99,
          9,
          114,
          41
        ]
      ],
      "transformers/src/transformers/models/speecht5/tokenization_speecht5.py": [
        [
          "save_vocabulary",
          205,
          220,
          213,
          84,
          213,
          114,
          213,
          84,
          213,
          114
        ],
        [
          "save_vocabulary",
          205,
          220,
          215,
          18,
          215,
          48,
          215,
          18,
          215,
          48
        ]
      ],
      "transformers/src/transformers/models/squeezebert/tokenization_squeezebert.py": [
        [
          "__init__",
          101,
          148,
          117,
          16,
          117,
          41,
          102,
          9,
          117,
          41
        ]
      ],
      "transformers/src/transformers/models/roc_bert/tokenization_roc_bert.py": [
        [
          "__init__",
          117,
          172,
          135,
          40,
          135,
          63,
          135,
          40,
          135,
          63
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "save_vocabulary",
          430,
          445,
          438,
          84,
          438,
          114,
          438,
          84,
          438,
          114
        ],
        [
          "save_vocabulary",
          430,
          445,
          440,
          18,
          440,
          48,
          440,
          18,
          440,
          48
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "save_vocabulary",
          491,
          506,
          499,
          84,
          499,
          114,
          499,
          84,
          499,
          114
        ],
        [
          "save_vocabulary",
          491,
          506,
          501,
          18,
          501,
          48,
          501,
          18,
          501,
          48
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "__init__",
          235,
          331,
          270,
          16,
          270,
          41,
          270,
          16,
          270,
          41
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "can_save_slow_tokenizer",
          227,
          238,
          235,
          24,
          235,
          54,
          235,
          24,
          235,
          54
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "from_pretrained",
          1859,
          2128,
          1979,
          12,
          1979,
          56,
          1973,
          41,
          1979,
          56
        ],
        [
          "from_pretrained",
          1859,
          2128,
          2074,
          20,
          2074,
          44,
          2074,
          20,
          2074,
          44
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2527,
          12,
          2527,
          41,
          2527,
          12,
          2527,
          41
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm.py": [
        [
          "save_vocabulary",
          284,
          299,
          292,
          84,
          292,
          114,
          292,
          84,
          292,
          114
        ],
        [
          "save_vocabulary",
          284,
          299,
          294,
          18,
          294,
          48,
          294,
          18,
          294,
          48
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        [
          "save_vocabulary",
          279,
          294,
          287,
          84,
          287,
          114,
          287,
          84,
          287,
          114
        ],
        [
          "save_vocabulary",
          279,
          294,
          289,
          18,
          289,
          48,
          289,
          18,
          289,
          48
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py": [
        [
          "save_vocabulary",
          283,
          298,
          291,
          84,
          291,
          114,
          291,
          84,
          291,
          114
        ],
        [
          "save_vocabulary",
          283,
          298,
          293,
          18,
          293,
          48,
          293,
          18,
          293,
          48
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "save_vocabulary",
          369,
          384,
          377,
          84,
          377,
          114,
          377,
          84,
          377,
          114
        ],
        [
          "save_vocabulary",
          369,
          384,
          379,
          18,
          379,
          48,
          379,
          18,
          379,
          48
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "remove_dummy_checkpoint",
          996,
          1001,
          1000,
          16,
          1000,
          35,
          998,
          13,
          1000,
          35
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_inner_training_loop",
          2252,
          2734,
          2423,
          51,
          2425,
          9,
          2423,
          51,
          2425,
          9
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2775,
          16,
          2775,
          93,
          2775,
          16,
          2775,
          93
        ],
        [
          "listcomp",
          2779,
          2780,
          2784,
          21,
          2784,
          107,
          2784,
          21,
          2784,
          107
        ],
        [
          "listcomp",
          2779,
          2780,
          2785,
          24,
          2785,
          115,
          2785,
          24,
          2785,
          115
        ],
        [
          "genexpr",
          2797,
          2797,
          2797,
          17,
          2797,
          33,
          2798,
          21,
          2797,
          33
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2814,
          12,
          2814,
          38,
          2795,
          12,
          2814,
          38
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2824,
          12,
          2824,
          39,
          2824,
          12,
          2824,
          39
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2824,
          44,
          2824,
          76,
          2824,
          44,
          2824,
          76
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2840,
          51,
          2840,
          83,
          2840,
          51,
          2840,
          83
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2977,
          55,
          2977,
          90,
          2977,
          55,
          2977,
          90
        ],
        [
          "_load_rng_state",
          3078,
          3119,
          3086,
          20,
          3086,
          43,
          3084,
          29,
          3086,
          43
        ],
        [
          "_load_rng_state",
          3078,
          3119,
          3094,
          20,
          3094,
          43,
          3093,
          24,
          3094,
          43
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3354,
          17,
          3354,
          72,
          3354,
          17,
          3354,
          72
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3355,
          20,
          3355,
          79,
          3355,
          20,
          3355,
          79
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3371,
          39,
          3371,
          94,
          3371,
          39,
          3371,
          94
        ],
        [
          "_load_scaler",
          3458,
          3483,
          3463,
          34,
          3463,
          86,
          3463,
          34,
          3465,
          33
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4878,
          16,
          4878,
          41,
          4876,
          13,
          4878,
          41
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4887,
          16,
          4887,
          77,
          4886,
          13,
          4887,
          77
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "save_pretrained",
          549,
          608,
          577,
          12,
          577,
          41,
          577,
          12,
          577,
          41
        ],
        [
          "get_video_processor_dict",
          611,
          724,
          661,
          12,
          661,
          56,
          659,
          41,
          661,
          56
        ]
      ],
      "transformers/src/transformers/video_utils.py": [
        [
          "load_video",
          618,
          714,
          689,
          10,
          689,
          30,
          689,
          10,
          689,
          30
        ]
      ],
      "transformers/src/transformers/pipelines/__init__.py": [
        [
          "pipeline",
          514,
          1094,
          1009,
          57,
          1009,
          82,
          1009,
          72,
          1009,
          82
        ]
      ],
      "transformers/src/transformers/audio_utils.py": [
        [
          "load_audio_librosa",
          115,
          140,
          138,
          10,
          138,
          30,
          138,
          10,
          138,
          30
        ],
        [
          "load_audio_as",
          143,
          219,
          182,
          14,
          182,
          34,
          182,
          29,
          182,
          34
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          84,
          16,
          84,
          73,
          81,
          9,
          84,
          73
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "save_pretrained",
          956,
          1024,
          986,
          12,
          986,
          41,
          986,
          12,
          986,
          41
        ]
      ],
      "transformers/utils/check_config_attributes.py": [
        [
          "check_config_attributes_being_used",
          457,
          499,
          483,
          12,
          483,
          31,
          482,
          9,
          483,
          31
        ]
      ],
      "transformers/utils/check_doctest_list.py": [
        [
          "clean_doctest_list",
          44,
          76,
          60,
          21,
          60,
          40,
          57,
          13,
          60,
          40
        ]
      ],
      "transformers/utils/check_dummies.py": [
        [
          "check_dummies",
          186,
          248,
          207,
          12,
          207,
          36,
          206,
          9,
          207,
          36
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "find_code_in_transformers",
          386,
          460,
          424,
          34,
          424,
          88,
          424,
          34,
          424,
          88
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "get_model_test_files",
          565,
          597,
          591,
          16,
          591,
          35,
          589,
          13,
          591,
          35
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1052,
          67,
          1054,
          5,
          1052,
          67,
          1054,
          5
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "find_matching_model_files",
          903,
          940,
          932,
          12,
          932,
          36,
          931,
          9,
          932,
          36
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "get_megatron_sharded_states",
          285,
          306,
          301,
          16,
          301,
          46,
          299,
          13,
          301,
          46
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "save_pretrained",
          695,
          766,
          743,
          12,
          743,
          41,
          741,
          28,
          743,
          41
        ],
        [
          "from_pretrained",
          769,
          945,
          888,
          12,
          888,
          63,
          884,
          23,
          888,
          63
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "save_pretrained",
          432,
          494,
          449,
          12,
          449,
          41,
          432,
          25,
          449,
          41
        ],
        [
          "_get_config_dict",
          669,
          760,
          699,
          12,
          699,
          81,
          696,
          41,
          699,
          81
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          169,
          12,
          169,
          42,
          163,
          5,
          169,
          42
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          177,
          12,
          177,
          36,
          171,
          13,
          177,
          36
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          189,
          12,
          189,
          40,
          179,
          16,
          189,
          40
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          91,
          8,
          91,
          46,
          84,
          17,
          91,
          46
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "convert_openai_checkpoint",
          213,
          260,
          218,
          16,
          218,
          82,
          217,
          9,
          218,
          82
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/convert_megatron_to_pytorch.py": [
        [
          "main",
          147,
          183,
          152,
          8,
          152,
          30,
          147,
          10,
          152,
          30
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          79,
          12,
          79,
          38,
          77,
          9,
          79,
          38
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_download",
          147,
          182,
          154,
          48,
          154,
          78,
          154,
          48,
          154,
          78
        ],
        [
          "_download",
          147,
          182,
          157,
          8,
          157,
          38,
          157,
          8,
          157,
          38
        ]
      ],
      "transformers/src/transformers/models/pixtral/convert_pixtral_weights_to_hf.py": [
        [
          "convert_mistral_model",
          145,
          210,
          147,
          8,
          147,
          49,
          145,
          27,
          147,
          49
        ]
      ],
      "transformers/.circleci/create_circleci_config.py": [
        [
          "listcomp",
          358,
          358,
          358,
          37,
          358,
          117,
          358,
          19,
          358,
          117
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "format_mrpc",
          57,
          106,
          71,
          12,
          71,
          42,
          71,
          12,
          71,
          42
        ],
        [
          "format_mrpc",
          57,
          106,
          73,
          12,
          73,
          41,
          73,
          12,
          73,
          41
        ]
      ],
      "transformers/src/transformers/commands/env.py": [
        [
          "run",
          59,
          140,
          73,
          60,
          73,
          94,
          73,
          60,
          73,
          94
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "save_pretrained",
          355,
          414,
          383,
          12,
          383,
          41,
          383,
          12,
          383,
          41
        ],
        [
          "get_feature_extractor_dict",
          417,
          529,
          466,
          12,
          466,
          56,
          466,
          12,
          466,
          56
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_last_daily_ci_reports",
          123,
          159,
          144,
          12,
          144,
          44,
          142,
          9,
          144,
          44
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          703,
          15,
          703,
          51,
          701,
          29,
          707,
          14
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "cached_files",
          319,
          579,
          422,
          20,
          422,
          48,
          421,
          29,
          422,
          48
        ],
        [
          "has_file",
          609,
          701,
          645,
          16,
          645,
          67,
          645,
          16,
          645,
          67
        ],
        [
          "listcomp",
          784,
          785,
          787,
          16,
          787,
          59,
          786,
          17,
          787,
          59
        ],
        [
          "get_checkpoint_shard_files",
          1011,
          1078,
          1046,
          12,
          1046,
          41,
          1046,
          12,
          1046,
          41
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "save_pretrained",
          202,
          261,
          230,
          12,
          230,
          41,
          230,
          12,
          230,
          41
        ],
        [
          "get_image_processor_dict",
          264,
          382,
          319,
          12,
          319,
          56,
          319,
          12,
          319,
          56
        ]
      ],
      "transformers/src/transformers/models/oneformer/image_processing_oneformer.py": [
        [
          "load_metadata",
          382,
          397,
          385,
          41,
          385,
          61,
          385,
          41,
          385,
          61
        ]
      ],
      "transformers/src/transformers/image_utils.py": [
        [
          "load_image",
          444,
          483,
          463,
          14,
          463,
          34,
          463,
          14,
          463,
          34
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          41,
          100,
          55,
          12,
          55,
          36,
          42,
          9,
          55,
          45
        ],
        [
          "__init__",
          110,
          129,
          117,
          12,
          117,
          36,
          110,
          18,
          117,
          45
        ],
        [
          "__init__",
          139,
          173,
          146,
          12,
          146,
          36,
          139,
          18,
          146,
          45
        ],
        [
          "__init__",
          139,
          173,
          148,
          12,
          148,
          35,
          148,
          12,
          148,
          44
        ],
        [
          "__init__",
          187,
          226,
          202,
          16,
          202,
          40,
          200,
          13,
          202,
          49
        ],
        [
          "__init__",
          335,
          418,
          350,
          16,
          350,
          40,
          336,
          9,
          350,
          40
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2171,
          8,
          2171,
          34,
          2117,
          39,
          2171,
          34
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "from_pretrained",
          126,
          217,
          180,
          12,
          180,
          56,
          179,
          20,
          180,
          56
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "load_sharded_checkpoint",
          372,
          444,
          399,
          21,
          399,
          46,
          372,
          29,
          402,
          24
        ],
        [
          "load_sharded_checkpoint",
          372,
          444,
          400,
          26,
          400,
          56,
          372,
          29,
          402,
          24
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          943,
          51,
          945,
          13,
          943,
          51,
          945,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          950,
          51,
          952,
          13,
          950,
          51,
          952,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          958,
          42,
          960,
          13,
          958,
          42,
          960,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          965,
          42,
          967,
          13,
          965,
          42,
          967,
          13
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          983,
          14,
          983,
          83,
          983,
          14,
          983,
          83
        ],
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          1138,
          12,
          1138,
          36,
          1138,
          12,
          1138,
          36
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3755,
          12,
          3755,
          41,
          3755,
          12,
          3755,
          41
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4000,
          21,
          4000,
          49,
          4000,
          21,
          4000,
          49
        ],
        [
          "from_pretrained",
          4261,
          4989,
          4622,
          52,
          4622,
          86,
          4622,
          52,
          4622,
          86
        ]
      ],
      "transformers/src/transformers/models/instructblip/processing_instructblip.py": [
        [
          "save_pretrained",
          156,
          172,
          157,
          12,
          157,
          41,
          156,
          25,
          157,
          41
        ]
      ],
      "transformers/src/transformers/models/instructblipvideo/processing_instructblipvideo.py": [
        [
          "save_pretrained",
          184,
          200,
          185,
          12,
          185,
          41,
          184,
          25,
          185,
          41
        ]
      ],
      "transformers/src/transformers/models/pop2piano/processing_pop2piano.py": [
        [
          "save_pretrained",
          126,
          130,
          127,
          12,
          127,
          41,
          126,
          25,
          127,
          41
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py": [
        [
          "from_pretrained",
          121,
          189,
          155,
          60,
          155,
          104,
          155,
          60,
          155,
          104
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "get_processor_dict",
          899,
          1149,
          945,
          12,
          945,
          56,
          943,
          42,
          945,
          56
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          561,
          55,
          561,
          80,
          561,
          55,
          561,
          80
        ],
        [
          "main",
          419,
          839,
          570,
          20,
          570,
          45,
          569,
          14,
          570,
          45
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          560,
          55,
          560,
          80,
          560,
          55,
          560,
          80
        ],
        [
          "main",
          396,
          837,
          569,
          20,
          569,
          45,
          568,
          14,
          569,
          45
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "train",
          73,
          263,
          103,
          8,
          103,
          76,
          89,
          17,
          103,
          76
        ],
        [
          "train",
          73,
          263,
          103,
          82,
          105,
          5,
          103,
          82,
          105,
          5
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "test_phi4_with_all_processors",
          374,
          826,
          410,
          25,
          410,
          101,
          374,
          39,
          826,
          101
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          119,
          25,
          119,
          86,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          120,
          25,
          120,
          87,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          121,
          25,
          121,
          92,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          122,
          25,
          122,
          79,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          123,
          25,
          123,
          94,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          124,
          25,
          124,
          79,
          94,
          39,
          372,
          100
        ],
        [
          "test_llama_without_tokenizers",
          94,
          372,
          125,
          25,
          125,
          92,
          94,
          39,
          372,
          100
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          399,
          25,
          399,
          87,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          400,
          25,
          400,
          88,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          401,
          25,
          401,
          93,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          402,
          25,
          402,
          101,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          403,
          25,
          403,
          98,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          404,
          25,
          404,
          90,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          405,
          25,
          405,
          79,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          406,
          25,
          406,
          95,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          407,
          25,
          407,
          79,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          408,
          25,
          408,
          93,
          374,
          39,
          826,
          101
        ],
        [
          "test_phi4_with_all_processors",
          374,
          826,
          409,
          25,
          409,
          103,
          374,
          39,
          826,
          101
        ]
      ],
      "transformers/tests/commands/test_chat.py": [
        [
          "test_save_and_clear_chat",
          83,
          94,
          91,
          25,
          91,
          48,
          83,
          34,
          94,
          37
        ]
      ],
      "transformers/tests/deepspeed/test_deepspeed.py": [
        [
          "check_saved_checkpoints_deepspeed",
          805,
          833,
          825,
          33,
          825,
          52,
          823,
          17,
          825,
          87
        ],
        [
          "check_saved_checkpoints_deepspeed",
          805,
          833,
          833,
          33,
          833,
          52,
          829,
          17,
          833,
          87
        ]
      ],
      "transformers/tests/utils/test_doc_samples.py": [
        [
          "listcomp",
          51,
          51,
          51,
          60,
          51,
          104,
          51,
          27,
          51,
          104
        ]
      ],
      "transformers/tests/fsdp/test_fsdp.py": [
        [
          "test_training_and_can_resume_normally",
          297,
          329,
          319,
          16,
          319,
          81,
          319,
          16,
          319,
          81
        ],
        [
          "test_accelerate_fsdp2_integration",
          353,
          394,
          384,
          16,
          384,
          81,
          384,
          16,
          384,
          81
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_cached_file",
          44,
          62,
          54,
          25,
          54,
          52,
          51,
          14,
          62,
          107
        ],
        [
          "test_non_existence_is_cached",
          74,
          96,
          80,
          25,
          80,
          97,
          74,
          38,
          96,
          37
        ]
      ],
      "transformers/tests/utils/test_import_structure.py": [
        [
          "test_transformers_specific_model_import",
          81,
          118,
          90,
          17,
          90,
          63,
          88,
          13,
          90,
          63
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_debugger_outputs",
          52,
          63,
          60,
          33,
          60,
          55,
          52,
          35,
          60,
          55
        ],
        [
          "test_debugger_outputs",
          52,
          63,
          60,
          61,
          60,
          80,
          60,
          61,
          60,
          80
        ]
      ]
    },
    "glob.glob": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_use_safetensors",
          1275,
          1329,
          1294,
          36,
          1294,
          100,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1307,
          36,
          1307,
          100,
          1275,
          30,
          1329,
          9
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "infer_tests_to_run",
          956,
          1038,
          1003,
          29,
          1003,
          76,
          1003,
          29,
          1006,
          63
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          1003,
          80,
          1005,
          9,
          1003,
          29,
          1006,
          63
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "build_corpus",
          729,
          761,
          745,
          27,
          745,
          55,
          739,
          34,
          745,
          23
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3351,
          13,
          3351,
          70,
          3351,
          13,
          3351,
          70
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3367,
          13,
          3367,
          100,
          3367,
          13,
          3367,
          100
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "_read_txt",
          191,
          199,
          193,
          17,
          193,
          46,
          191,
          19,
          194,
          55
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          77,
          15,
          77,
          90,
          60,
          15,
          81,
          33
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "check_copies",
          829,
          859,
          843,
          21,
          843,
          89,
          843,
          21,
          845,
          17
        ],
        [
          "check_copies",
          829,
          859,
          844,
          26,
          844,
          92,
          843,
          21,
          845,
          17
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "find_matching_model_files",
          903,
          940,
          927,
          23,
          927,
          54,
          926,
          29,
          931,
          36
        ],
        [
          "find_matching_model_files",
          903,
          940,
          929,
          24,
          929,
          63,
          926,
          29,
          931,
          36
        ]
      ],
      "transformers/src/transformers/models/aria/convert_aria_weights_to_hf.py": [
        [
          "load_original_state_dict",
          57,
          67,
          61,
          17,
          61,
          48,
          57,
          30,
          61,
          48
        ]
      ],
      "transformers/src/transformers/models/colqwen2/convert_colqwen2_weights_to_hf.py": [
        [
          "load_original_state_dict",
          57,
          75,
          65,
          17,
          65,
          48,
          57,
          30,
          65,
          48
        ]
      ],
      "transformers/src/transformers/models/colpali/convert_colpali_weights_to_hf.py": [
        [
          "load_original_state_dict",
          73,
          93,
          81,
          17,
          81,
          48,
          73,
          30,
          81,
          48
        ]
      ],
      "transformers/src/transformers/models/got_ocr2/convert_got_ocr2_weights_to_hf.py": [
        [
          "load_original_state_dict",
          79,
          89,
          83,
          17,
          83,
          48,
          79,
          30,
          83,
          48
        ]
      ],
      "transformers/src/transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py": [
        [
          "load_original_state_dict",
          127,
          137,
          131,
          17,
          131,
          48,
          127,
          30,
          131,
          48
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "load_original_state_dict",
          63,
          73,
          67,
          17,
          67,
          48,
          63,
          30,
          67,
          48
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "load_original_state_dict",
          62,
          76,
          66,
          17,
          66,
          48,
          62,
          30,
          66,
          48
        ]
      ],
      "transformers/src/transformers/models/llava/convert_llava_weights_to_hf.py": [
        [
          "load_original_state_dict",
          65,
          82,
          69,
          17,
          69,
          48,
          65,
          30,
          69,
          48
        ]
      ],
      "transformers/src/transformers/integrations/deepspeed.py": [
        [
          "deepspeed_load_checkpoint",
          464,
          485,
          471,
          40,
          471,
          83,
          464,
          31,
          473,
          41
        ]
      ],
      "transformers/utils/models_to_deprecate.py": [
        [
          "get_list_of_repo_model_paths",
          155,
          169,
          157,
          14,
          157,
          67,
          155,
          34,
          162,
          45
        ],
        [
          "get_list_of_repo_model_paths",
          155,
          169,
          160,
          25,
          160,
          78,
          155,
          34,
          162,
          45
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/run_glue.py": [
        [
          "main",
          176,
          197,
          195,
          30,
          195,
          112,
          195,
          23,
          197,
          34
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "get_dataset",
          161,
          194,
          192,
          52,
          192,
          78,
          192,
          16,
          192,
          80
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "main",
          470,
          835,
          812,
          37,
          812,
          102,
          812,
          30,
          810,
          27
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "main",
          473,
          717,
          697,
          52,
          697,
          117,
          697,
          45,
          696,
          23
        ]
      ]
    },
    "tempfile.NamedTemporaryFile": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_loading_is_fast_on_gpu",
          1904,
          1956,
          1947,
          14,
          1947,
          65,
          1904,
          37,
          1954,
          30
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_picklable",
          296,
          301,
          297,
          14,
          297,
          42,
          296,
          24,
          301,
          39
        ],
        [
          "test_conversion",
          375,
          393,
          386,
          14,
          386,
          42,
          375,
          25,
          393,
          60
        ]
      ],
      "transformers/tests/models/gemma/test_tokenization_gemma.py": [
        [
          "test_conversion",
          236,
          254,
          247,
          14,
          247,
          42,
          236,
          25,
          254,
          60
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_picklable",
          294,
          299,
          295,
          14,
          295,
          42,
          294,
          24,
          299,
          39
        ],
        [
          "test_conversion",
          413,
          431,
          424,
          14,
          424,
          42,
          413,
          25,
          431,
          60
        ]
      ],
      "transformers/tests/models/moshi/test_tokenization_moshi.py": [
        [
          "test_picklable",
          174,
          184,
          175,
          14,
          175,
          42,
          174,
          24,
          184,
          39
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          89,
          24,
          89,
          64,
          89,
          59,
          89,
          64
        ]
      ],
      "transformers/tests/models/xglm/test_tokenization_xglm.py": [
        [
          "test_picklable_without_disk",
          144,
          149,
          145,
          14,
          145,
          42,
          144,
          37,
          149,
          39
        ]
      ],
      "transformers/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py": [
        [
          "test_picklable_without_disk",
          218,
          223,
          219,
          14,
          219,
          42,
          218,
          37,
          223,
          39
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "torchrun",
          3771,
          3788,
          3773,
          10,
          3773,
          61,
          3771,
          14,
          3777,
          22
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          338,
          10,
          338,
          38,
          338,
          10,
          357,
          14
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_to_hf.py": [
        [
          "upload_original_ckpts",
          204,
          219,
          208,
          10,
          208,
          38,
          204,
          27,
          219,
          35
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "get_processor_inputs_from_inbound_messages",
          911,
          954,
          945,
          40,
          945,
          95,
          942,
          46,
          948,
          53
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "test_load_img_base64_prefix",
          741,
          756,
          743,
          24,
          743,
          64,
          743,
          59,
          743,
          64
        ],
        [
          "test_load_img_base64",
          758,
          773,
          760,
          24,
          760,
          64,
          760,
          59,
          760,
          64
        ],
        [
          "test_load_img_base64_encoded_bytes",
          775,
          790,
          777,
          24,
          777,
          64,
          777,
          59,
          777,
          64
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "run_distributed_test",
          238,
          274,
          261,
          14,
          261,
          80,
          238,
          30,
          274,
          27
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py": [
        [
          "test_small_model_integration_test_with_video",
          688,
          733,
          707,
          14,
          707,
          55,
          688,
          54,
          712,
          18
        ]
      ]
    },
    "os.path.exists": {
      "transformers/tests/models/vits/test_modeling_vits.py": [
        [
          "test_save_load",
          309,
          349,
          334,
          33,
          334,
          85,
          322,
          13,
          345,
          39
        ],
        [
          "test_save_load",
          309,
          349,
          336,
          43,
          336,
          106,
          322,
          13,
          345,
          39
        ]
      ],
      "transformers/examples/pytorch/test_pytorch_examples.py": [
        [
          "get_results",
          85,
          93,
          88,
          8,
          88,
          27,
          85,
          17,
          88,
          27
        ]
      ],
      "transformers/tests/commands/test_serving.py": [
        [
          "test_processor_inputs_from_inbound_messages_vlm_text_and_image_in_base_64",
          339,
          401,
          399,
          41,
          399,
          82,
          399,
          25,
          399,
          83
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          346,
          21,
          346,
          76,
          332,
          13,
          354,
          73
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1714,
          45,
          1714,
          109,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1716,
          33,
          1716,
          119,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1728,
          46,
          1728,
          110,
          1719,
          43,
          1728,
          111
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4047,
          24,
          4047,
          48,
          4046,
          21,
          4047,
          48
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3224,
          16,
          3224,
          93,
          3213,
          40,
          3224,
          93
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3228,
          16,
          3228,
          68,
          3224,
          9,
          3228,
          68
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3247,
          16,
          3247,
          69,
          3228,
          9,
          3247,
          69
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3249,
          16,
          3249,
          69,
          3247,
          9,
          3249,
          69
        ],
        [
          "test_load_best_model_with_save",
          3213,
          3259,
          3251,
          20,
          3251,
          72,
          3249,
          9,
          3251,
          72
        ],
        [
          "test_resume_from_interrupted_training",
          5199,
          5305,
          5269,
          25,
          5269,
          55,
          5199,
          47,
          5305,
          98
        ],
        [
          "test_resume_from_interrupted_training",
          5199,
          5305,
          5300,
          25,
          5300,
          61,
          5199,
          47,
          5305,
          98
        ],
        [
          "test_resume_from_interrupted_training",
          5199,
          5305,
          5305,
          25,
          5305,
          56,
          5199,
          47,
          5305,
          98
        ]
      ],
      "transformers/tests/test_training_args.py": [
        [
          "test_output_dir_creation",
          20,
          40,
          26,
          30,
          26,
          55,
          20,
          34,
          40,
          56
        ],
        [
          "test_output_dir_creation",
          20,
          40,
          35,
          30,
          35,
          55,
          20,
          34,
          40,
          56
        ],
        [
          "test_output_dir_creation",
          20,
          40,
          40,
          30,
          40,
          55,
          20,
          34,
          40,
          56
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2.py": [
        [
          "__init__",
          246,
          269,
          253,
          16,
          253,
          41,
          251,
          32,
          253,
          41
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "count_file",
          275,
          289,
          278,
          16,
          278,
          35,
          277,
          13,
          278,
          35
        ],
        [
          "count_file",
          275,
          289,
          278,
          16,
          278,
          35,
          278,
          16,
          278,
          35
        ],
        [
          "encode_file",
          350,
          365,
          353,
          16,
          353,
          35,
          352,
          13,
          353,
          35
        ],
        [
          "encode_file",
          350,
          365,
          353,
          16,
          353,
          35,
          353,
          16,
          353,
          35
        ],
        [
          "get_lm_corpus",
          784,
          821,
          787,
          8,
          787,
          25,
          784,
          19,
          787,
          25
        ],
        [
          "get_lm_corpus",
          784,
          821,
          791,
          10,
          791,
          27,
          791,
          10,
          791,
          27
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "save_metrics",
          884,
          919,
          911,
          12,
          911,
          31,
          910,
          16,
          911,
          31
        ],
        [
          "from_json_file",
          1156,
          1168,
          1158,
          32,
          1158,
          56,
          1156,
          24,
          1158,
          56
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2860,
          20,
          2860,
          57,
          2860,
          20,
          2860,
          57
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2916,
          13,
          2916,
          43,
          2916,
          13,
          2916,
          43
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2917,
          16,
          2917,
          51,
          2917,
          16,
          2917,
          51
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2918,
          16,
          2918,
          54,
          2918,
          16,
          2918,
          54
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2919,
          16,
          2919,
          59,
          2919,
          16,
          2919,
          59
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2944,
          28,
          2944,
          66,
          2944,
          28,
          2944,
          66
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2944,
          71,
          2944,
          114,
          2944,
          71,
          2944,
          114
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2989,
          14,
          2989,
          100,
          2989,
          14,
          2989,
          100
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2989,
          105,
          2991,
          9,
          2989,
          105,
          2991,
          9
        ],
        [
          "_save_checkpoint",
          3159,
          3217,
          3187,
          16,
          3187,
          50,
          3184,
          38,
          3187,
          50
        ],
        [
          "create_model_card",
          4790,
          4862,
          4832,
          12,
          4832,
          46,
          4830,
          31,
          4832,
          46
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5028,
          12,
          5028,
          74,
          5025,
          21,
          5028,
          74
        ]
      ],
      "transformers/src/transformers/generation/utils.py": [
        [
          "load_custom_generate",
          366,
          425,
          407,
          25,
          407,
          69,
          397,
          13,
          425,
          39
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "__init__",
          83,
          128,
          108,
          20,
          108,
          55,
          84,
          13,
          108,
          55
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "__init__",
          127,
          158,
          142,
          12,
          142,
          40,
          128,
          9,
          142,
          40
        ],
        [
          "check_output_dir",
          644,
          665,
          656,
          9,
          656,
          39,
          644,
          22,
          656,
          39
        ]
      ],
      "transformers/examples/legacy/token-classification/utils_ner.py": [
        [
          "__init__",
          216,
          262,
          237,
          20,
          237,
          55,
          217,
          13,
          237,
          55
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_first_commit_date",
          94,
          121,
          106,
          12,
          106,
          36,
          103,
          17,
          106,
          36
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_to_tests",
          200,
          272,
          206,
          12,
          206,
          36,
          200,
          39,
          206,
          36
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          349,
          8,
          349,
          56,
          343,
          5,
          349,
          56
        ]
      ],
      "transformers/benchmark/benchmarks_entrypoint.py": [
        [
          "export_to_csv",
          208,
          226,
          216,
          16,
          216,
          41,
          216,
          16,
          216,
          41
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "__init__",
          421,
          442,
          437,
          16,
          437,
          48,
          437,
          16,
          437,
          48
        ],
        [
          "__init__",
          421,
          442,
          441,
          20,
          441,
          51,
          441,
          20,
          441,
          51
        ]
      ],
      "transformers/utils/check_modular_conversion.py": [
        [
          "process_file",
          27,
          67,
          53,
          12,
          53,
          36,
          53,
          12,
          53,
          36
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "from_pretrained",
          769,
          945,
          887,
          20,
          887,
          46,
          884,
          23,
          888,
          63
        ]
      ],
      "transformers/src/transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_bart_checkpoint",
          88,
          142,
          92,
          12,
          92,
          42,
          88,
          29,
          92,
          42
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          161,
          12,
          161,
          49,
          159,
          42,
          161,
          49
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          132,
          16,
          132,
          44,
          130,
          13,
          132,
          44
        ]
      ],
      "transformers/src/transformers/models/clvp/convert_clvp_to_hf.py": [
        [
          "convert_clvp_weights",
          194,
          217,
          199,
          16,
          199,
          46,
          197,
          9,
          199,
          46
        ]
      ],
      "transformers/src/transformers/models/flava/convert_dalle_to_flava_codebook.py": [
        [
          "convert_dalle_checkpoint",
          57,
          92,
          64,
          8,
          64,
          38,
          57,
          30,
          64,
          38
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "load_model_state_dict",
          203,
          233,
          211,
          8,
          211,
          33,
          203,
          27,
          211,
          33
        ],
        [
          "load_model_state_dict",
          203,
          233,
          228,
          10,
          228,
          41,
          228,
          10,
          228,
          41
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "load_model_state_dict",
          176,
          206,
          184,
          8,
          184,
          33,
          176,
          27,
          184,
          33
        ],
        [
          "load_model_state_dict",
          176,
          206,
          201,
          10,
          201,
          41,
          201,
          10,
          201,
          41
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "ensure_model_downloaded",
          120,
          155,
          133,
          12,
          133,
          36,
          133,
          12,
          133,
          36
        ],
        [
          "load_model_state_dict",
          158,
          188,
          166,
          8,
          166,
          33,
          158,
          27,
          166,
          33
        ],
        [
          "load_model_state_dict",
          158,
          188,
          183,
          10,
          183,
          41,
          183,
          10,
          183,
          41
        ]
      ],
      "transformers/src/transformers/models/flava/convert_flava_original_pytorch_to_hf.py": [
        [
          "convert_flava_checkpoint",
          62,
          88,
          75,
          8,
          75,
          38,
          71,
          16,
          75,
          38
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          92,
          12,
          92,
          47,
          90,
          40,
          92,
          47
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          154,
          12,
          154,
          43,
          152,
          9,
          154,
          43
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "merge_tp_weights",
          250,
          625,
          299,
          27,
          299,
          77,
          298,
          5,
          327,
          32
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "ensure_model_downloaded",
          171,
          206,
          184,
          12,
          184,
          36,
          184,
          12,
          184,
          36
        ],
        [
          "load_model_state_dict",
          209,
          239,
          217,
          8,
          217,
          33,
          209,
          27,
          217,
          33
        ],
        [
          "load_model_state_dict",
          209,
          239,
          234,
          10,
          234,
          41,
          234,
          10,
          234,
          41
        ],
        [
          "listcomp",
          271,
          271,
          271,
          55,
          271,
          97,
          271,
          28,
          271,
          97
        ],
        [
          "convert_model",
          242,
          447,
          295,
          8,
          295,
          42,
          278,
          10,
          295,
          42
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "write_model",
          213,
          554,
          341,
          16,
          341,
          83,
          341,
          16,
          341,
          83
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "convert_all_sentencepiece_models",
          298,
          315,
          309,
          16,
          309,
          43,
          309,
          16,
          309,
          43
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "convert_models",
          74,
          89,
          83,
          20,
          83,
          60,
          83,
          20,
          83,
          60
        ],
        [
          "download_lang_info",
          277,
          288,
          283,
          16,
          283,
          39,
          277,
          28,
          283,
          39
        ],
        [
          "download_lang_info",
          277,
          288,
          285,
          16,
          285,
          45,
          285,
          16,
          285,
          45
        ]
      ],
      "transformers/src/transformers/models/metaclip_2/convert_metaclip_2_to_hf.py": [
        [
          "verify_conversion",
          295,
          358,
          302,
          28,
          302,
          58,
          302,
          28,
          302,
          58
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          246,
          12,
          246,
          42,
          236,
          29,
          246,
          42
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_model",
          209,
          471,
          341,
          12,
          341,
          79,
          341,
          12,
          341,
          79
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_download",
          147,
          182,
          154,
          8,
          154,
          38,
          147,
          15,
          154,
          38
        ]
      ],
      "transformers/src/transformers/models/phi/convert_phi_weights_to_hf.py": [
        [
          "convert_phi_weights",
          105,
          164,
          117,
          20,
          117,
          45,
          115,
          13,
          117,
          45
        ]
      ],
      "transformers/src/transformers/models/siglip2/convert_siglip2_to_hf.py": [
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          342,
          12,
          342,
          37,
          333,
          32,
          342,
          37
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "convert_siglip_checkpoint",
          380,
          506,
          390,
          12,
          390,
          37,
          380,
          31,
          390,
          37
        ]
      ],
      "transformers/src/transformers/models/bark/convert_suno_to_hf.py": [
        [
          "_load_model",
          92,
          158,
          109,
          12,
          109,
          36,
          107,
          17,
          109,
          36
        ]
      ],
      "transformers/src/transformers/models/timesfm/convert_timesfm_orignal_to_hf.py": [
        [
          "main",
          244,
          273,
          263,
          8,
          265,
          5,
          264,
          39,
          265,
          5
        ]
      ],
      "transformers/src/transformers/models/vivit/convert_vivit_flax_to_pytorch.py": [
        [
          "convert",
          190,
          222,
          193,
          12,
          193,
          42,
          190,
          13,
          193,
          42
        ]
      ],
      "transformers/.circleci/create_circleci_config.py": [
        [
          "__post_init__",
          98,
          129,
          122,
          16,
          122,
          40,
          120,
          25,
          122,
          40
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "move_model_files_to_deprecated",
          146,
          159,
          150,
          12,
          150,
          48,
          146,
          36,
          150,
          48
        ],
        [
          "get_model_doc_path",
          80,
          90,
          87,
          12,
          87,
          41,
          86,
          9,
          87,
          41
        ],
        [
          "extract_model_info",
          93,
          109,
          104,
          12,
          104,
          37,
          101,
          36,
          104,
          37
        ],
        [
          "delete_model_tests",
          162,
          166,
          165,
          8,
          165,
          33,
          162,
          24,
          165,
          33
        ]
      ],
      "transformers/utils/fetch_hub_objects_for_ci.py": [
        [
          "url_to_local_path",
          42,
          48,
          45,
          12,
          45,
          35,
          42,
          23,
          45,
          35
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          713,
          19,
          713,
          84,
          713,
          19,
          713,
          84
        ]
      ],
      "transformers/src/transformers/data/datasets/glue.py": [
        [
          "__init__",
          76,
          149,
          119,
          16,
          119,
          51,
          113,
          27,
          119,
          51
        ]
      ],
      "transformers/src/transformers/models/oneformer/image_processing_oneformer.py": [
        [
          "load_metadata",
          382,
          397,
          385,
          12,
          385,
          32,
          383,
          26,
          385,
          32
        ],
        [
          "load_metadata",
          382,
          397,
          385,
          12,
          385,
          32,
          383,
          53,
          385,
          32
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          41,
          100,
          70,
          16,
          70,
          51,
          62,
          13,
          70,
          51
        ],
        [
          "__init__",
          335,
          418,
          382,
          16,
          382,
          51,
          353,
          38,
          382,
          51
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/modeling_jukebox.py": [
        [
          "_sample",
          2433,
          2569,
          2561,
          24,
          2561,
          45,
          2553,
          17,
          2561,
          45
        ]
      ],
      "transformers/utils/models_to_deprecate.py": [
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          187,
          22,
          187,
          55,
          187,
          22,
          187,
          55
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          269,
          47,
          269,
          80,
          269,
          33,
          269,
          80
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "retrieve_artifact",
          276,
          288,
          279,
          8,
          279,
          27,
          276,
          23,
          279,
          27
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "retrieve_artifact",
          944,
          959,
          950,
          8,
          950,
          36,
          948,
          17,
          950,
          36
        ]
      ],
      "transformers/examples/pytorch/old_test_xla_examples.py": [
        [
          "get_results",
          31,
          39,
          34,
          8,
          34,
          27,
          31,
          17,
          34,
          27
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/run_glue.py": [
        [
          "prepare_data",
          49,
          74,
          57,
          16,
          57,
          51,
          55,
          13,
          57,
          51
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "main",
          197,
          364,
          211,
          9,
          211,
          48,
          211,
          9,
          211,
          48
        ]
      ],
      "transformers/examples/legacy/multiple_choice/run_multiple_choice.py": [
        [
          "main",
          90,
          234,
          99,
          9,
          99,
          48,
          95,
          14,
          99,
          48
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/run_ner.py": [
        [
          "prepare_data",
          59,
          86,
          64,
          16,
          64,
          51,
          62,
          13,
          64,
          51
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          115,
          9,
          115,
          48,
          115,
          9,
          115,
          48
        ]
      ],
      "transformers/examples/legacy/run_openai_gpt.py": [
        [
          "main",
          104,
          315,
          170,
          12,
          170,
          42,
          170,
          12,
          170,
          42
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad_trainer.py": [
        [
          "main",
          65,
          176,
          80,
          9,
          80,
          48,
          80,
          9,
          80,
          48
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "train",
          73,
          263,
          146,
          8,
          146,
          46,
          137,
          12,
          146,
          46
        ],
        [
          "evaluate",
          266,
          397,
          269,
          12,
          269,
          42,
          266,
          14,
          269,
          42
        ],
        [
          "load_and_cache_examples",
          400,
          467,
          417,
          8,
          417,
          43,
          410,
          13,
          417,
          43
        ],
        [
          "main",
          470,
          835,
          681,
          9,
          681,
          39,
          681,
          9,
          681,
          39
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "evaluate",
          413,
          470,
          416,
          12,
          416,
          42,
          413,
          14,
          416,
          42
        ],
        [
          "load_and_cache_examples",
          230,
          272,
          244,
          8,
          244,
          43,
          239,
          13,
          244,
          43
        ],
        [
          "main",
          473,
          717,
          588,
          9,
          588,
          39,
          474,
          14,
          588,
          39
        ]
      ],
      "transformers/src/transformers/data/datasets/squad.py": [
        [
          "__init__",
          115,
          189,
          145,
          16,
          145,
          51,
          137,
          13,
          145,
          51
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "get_results",
          49,
          57,
          52,
          8,
          52,
          27,
          49,
          17,
          52,
          27
        ],
        [
          "test_run_glue_no_trainer",
          78,
          99,
          98,
          25,
          98,
          72,
          78,
          34,
          99,
          81
        ],
        [
          "test_run_glue_no_trainer",
          78,
          99,
          99,
          25,
          99,
          80,
          78,
          34,
          99,
          81
        ],
        [
          "test_run_clm_no_trainer",
          103,
          127,
          126,
          25,
          126,
          72,
          123,
          9,
          127,
          80
        ],
        [
          "test_run_clm_no_trainer",
          103,
          127,
          127,
          25,
          127,
          79,
          123,
          9,
          127,
          80
        ],
        [
          "test_run_mlm_no_trainer",
          131,
          148,
          147,
          25,
          147,
          72,
          131,
          33,
          148,
          80
        ],
        [
          "test_run_mlm_no_trainer",
          131,
          148,
          148,
          25,
          148,
          79,
          131,
          33,
          148,
          80
        ],
        [
          "test_run_ner_no_trainer",
          151,
          176,
          175,
          25,
          175,
          72,
          153,
          18,
          176,
          80
        ],
        [
          "test_run_ner_no_trainer",
          151,
          176,
          176,
          25,
          176,
          79,
          153,
          18,
          176,
          80
        ],
        [
          "test_run_squad_no_trainer",
          179,
          204,
          203,
          25,
          203,
          72,
          179,
          35,
          204,
          79
        ],
        [
          "test_run_squad_no_trainer",
          179,
          204,
          204,
          25,
          204,
          78,
          179,
          35,
          204,
          79
        ],
        [
          "test_run_swag_no_trainer",
          207,
          226,
          226,
          25,
          226,
          80,
          207,
          34,
          226,
          81
        ],
        [
          "test_run_summarization_no_trainer",
          230,
          254,
          253,
          25,
          253,
          72,
          230,
          43,
          254,
          90
        ],
        [
          "test_run_summarization_no_trainer",
          230,
          254,
          254,
          25,
          254,
          89,
          230,
          43,
          254,
          90
        ],
        [
          "test_run_translation_no_trainer",
          258,
          284,
          283,
          25,
          283,
          72,
          258,
          41,
          284,
          88
        ],
        [
          "test_run_translation_no_trainer",
          258,
          284,
          284,
          25,
          284,
          87,
          258,
          41,
          284,
          88
        ],
        [
          "test_run_image_classification_no_trainer",
          309,
          332,
          331,
          25,
          331,
          71,
          309,
          50,
          332,
          97
        ],
        [
          "test_run_image_classification_no_trainer",
          309,
          332,
          332,
          25,
          332,
          96,
          309,
          50,
          332,
          97
        ]
      ],
      "transformers/tests/utils/test_cli.py": [
        [
          "test_cli_download",
          37,
          49,
          47,
          25,
          47,
          98,
          37,
          27,
          49,
          103
        ],
        [
          "test_cli_download",
          37,
          49,
          48,
          25,
          48,
          97,
          37,
          27,
          49,
          103
        ],
        [
          "test_cli_download",
          37,
          49,
          49,
          25,
          49,
          102,
          37,
          27,
          49,
          103
        ],
        [
          "test_cli_download_trust_remote",
          63,
          77,
          73,
          25,
          73,
          115,
          63,
          40,
          77,
          9
        ],
        [
          "test_cli_download_trust_remote",
          63,
          77,
          74,
          25,
          74,
          114,
          63,
          40,
          77,
          9
        ],
        [
          "test_cli_download_trust_remote",
          63,
          77,
          76,
          13,
          76,
          107,
          63,
          40,
          77,
          9
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_from_pretrained_dynamic_config",
          106,
          128,
          125,
          29,
          125,
          85,
          106,
          45,
          128,
          78
        ]
      ],
      "transformers/tests/models/auto/test_feature_extraction_auto.py": [
        [
          "test_from_pretrained_dynamic_feature_extractor",
          102,
          133,
          129,
          29,
          129,
          89,
          102,
          56,
          133,
          94
        ]
      ],
      "transformers/tests/fsdp/test_fsdp.py": [
        [
          "test_fsdp_cpu_offloading",
          334,
          346,
          336,
          16,
          336,
          77,
          334,
          34,
          336,
          77
        ],
        [
          "test_fsdp2_cpu_offloading",
          402,
          414,
          404,
          16,
          404,
          77,
          402,
          35,
          404,
          77
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_from_pretrained_dynamic_image_processor",
          171,
          206,
          196,
          29,
          196,
          87,
          171,
          54,
          206,
          87
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "_is_old_model_by_commit_date",
          647,
          674,
          653,
          24,
          653,
          58,
          653,
          39,
          653,
          58
        ]
      ],
      "transformers/tests/deepspeed/test_model_zoo.py": [
        [
          "test_zero_to_fp32",
          352,
          370,
          370,
          16,
          370,
          51,
          352,
          27,
          370,
          51
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "test_save_load",
          710,
          755,
          735,
          33,
          735,
          85,
          723,
          13,
          751,
          39
        ],
        [
          "test_save_load",
          710,
          755,
          737,
          43,
          737,
          106,
          723,
          13,
          751,
          39
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "distributed_worker",
          110,
          193,
          152,
          12,
          152,
          39,
          149,
          15,
          152,
          39
        ],
        [
          "test_model_outputs",
          319,
          374,
          332,
          12,
          332,
          39,
          319,
          28,
          332,
          39
        ]
      ]
    },
    "pathlib.Path.is_file": {
      "transformers/tests/test_processing_common.py": [
        [
          "test_chat_template_save_loading",
          939,
          984,
          949,
          29,
          949,
          76,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          950,
          30,
          950,
          78,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          959,
          29,
          959,
          77,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          960,
          30,
          960,
          77,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          971,
          29,
          971,
          77,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          972,
          30,
          972,
          77,
          945,
          39,
          984,
          77
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1186,
          33,
          1186,
          81,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1187,
          34,
          1187,
          81,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1198,
          33,
          1198,
          81,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1199,
          34,
          1199,
          81,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1210,
          34,
          1210,
          82,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1211,
          34,
          1211,
          81,
          1183,
          39,
          1217,
          110
        ]
      ],
      "transformers/src/transformers/trainer_seq2seq.py": [
        [
          "load_generation_config",
          92,
          133,
          114,
          16,
          114,
          46,
          109,
          37,
          114,
          46
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "_write_tokenizer",
          219,
          248,
          234,
          12,
          234,
          57,
          230,
          23,
          234,
          57
        ]
      ]
    },
    "pathlib.Path.is_dir": {
      "transformers/tests/test_processing_common.py": [
        [
          "test_chat_template_save_loading",
          939,
          984,
          961,
          30,
          961,
          83,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          973,
          29,
          973,
          82,
          945,
          39,
          984,
          77
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1188,
          34,
          1188,
          87,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1200,
          33,
          1200,
          86,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1212,
          34,
          1212,
          87,
          1183,
          39,
          1217,
          110
        ]
      ],
      "transformers/src/transformers/models/m2m_100/tokenization_m2m_100.py": [
        [
          "save_vocabulary",
          295,
          315,
          297,
          16,
          297,
          32,
          295,
          25,
          297,
          32
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/tokenization_speech_to_text.py": [
        [
          "save_vocabulary",
          257,
          276,
          259,
          16,
          259,
          32,
          257,
          25,
          259,
          32
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "from_pretrained",
          1859,
          2128,
          2051,
          28,
          2051,
          48,
          2050,
          40,
          2051,
          48
        ]
      ],
      "transformers/src/transformers/trainer_seq2seq.py": [
        [
          "load_generation_config",
          92,
          133,
          118,
          18,
          118,
          47,
          118,
          18,
          118,
          47
        ]
      ],
      "transformers/utils/collated_reports.py": [
        [
          "validate_path",
          49,
          53,
          52,
          12,
          52,
          24,
          49,
          19,
          52,
          24
        ]
      ],
      "transformers/utils/get_test_reports.py": [
        [
          "is_valid_test_dir",
          43,
          45,
          45,
          12,
          45,
          24,
          43,
          23,
          45,
          24
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "list_repo_templates",
          148,
          190,
          188,
          12,
          188,
          33,
          182,
          9,
          188,
          33
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "get_processor_dict",
          899,
          1149,
          962,
          20,
          962,
          40,
          961,
          32,
          962,
          40
        ]
      ],
      "transformers/utils/scan_skipped_tests.py": [
        [
          "get_models_and_test_files",
          45,
          50,
          46,
          12,
          46,
          30,
          45,
          31,
          46,
          30
        ]
      ]
    },
    "shutil.copyfile": {
      "transformers/tests/models/speech_to_text/test_processing_speech_to_text.py": [
        [
          "setUpClass",
          37,
          58,
          45,
          13,
          45,
          73,
          45,
          13,
          45,
          73
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_processor_from_local_directory_from_extractor_config",
          87,
          95,
          91,
          13,
          91,
          74,
          87,
          67,
          95,
          59
        ],
        [
          "test_processor_from_local_directory_from_extractor_config",
          87,
          95,
          90,
          13,
          90,
          95,
          87,
          67,
          95,
          59
        ],
        [
          "test_processor_from_local_directory_from_model_config",
          187,
          199,
          192,
          13,
          192,
          74,
          187,
          63,
          199,
          59
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_picklable",
          296,
          301,
          298,
          13,
          298,
          49,
          296,
          24,
          301,
          39
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_picklable",
          294,
          299,
          296,
          13,
          296,
          49,
          294,
          24,
          299,
          39
        ]
      ],
      "transformers/tests/models/m2m_100/test_tokenization_m2m_100.py": [
        [
          "setUpClass",
          58,
          69,
          66,
          13,
          66,
          73,
          66,
          13,
          66,
          73
        ]
      ],
      "transformers/tests/models/marian/test_tokenization_marian.py": [
        [
          "setUpClass",
          46,
          59,
          55,
          13,
          55,
          75,
          55,
          13,
          56,
          75
        ],
        [
          "setUpClass",
          46,
          59,
          56,
          13,
          56,
          75,
          55,
          13,
          56,
          75
        ]
      ],
      "transformers/tests/models/moshi/test_tokenization_moshi.py": [
        [
          "test_picklable",
          174,
          184,
          176,
          13,
          176,
          49,
          174,
          24,
          184,
          39
        ]
      ],
      "transformers/tests/models/speech_to_text/test_tokenization_speech_to_text.py": [
        [
          "setUpClass",
          46,
          62,
          59,
          13,
          59,
          76,
          59,
          13,
          59,
          76
        ]
      ],
      "transformers/tests/models/xglm/test_tokenization_xglm.py": [
        [
          "test_picklable_without_disk",
          144,
          149,
          146,
          13,
          146,
          49,
          144,
          37,
          149,
          39
        ]
      ],
      "transformers/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py": [
        [
          "test_picklable_without_disk",
          218,
          223,
          220,
          13,
          220,
          49,
          218,
          37,
          223,
          39
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "save_vocabulary",
          302,
          317,
          311,
          13,
          311,
          53,
          311,
          13,
          311,
          53
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert_fast.py": [
        [
          "save_vocabulary",
          158,
          175,
          173,
          13,
          173,
          53,
          173,
          13,
          173,
          53
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez.py": [
        [
          "save_vocabulary",
          273,
          288,
          282,
          13,
          282,
          53,
          282,
          13,
          282,
          53
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez_fast.py": [
        [
          "save_vocabulary",
          173,
          190,
          188,
          13,
          188,
          53,
          188,
          13,
          188,
          53
        ]
      ],
      "transformers/src/transformers/models/bartpho/tokenization_bartpho.py": [
        [
          "save_vocabulary",
          286,
          315,
          299,
          13,
          299,
          53,
          299,
          13,
          299,
          53
        ],
        [
          "save_vocabulary",
          286,
          315,
          308,
          13,
          308,
          77,
          308,
          13,
          308,
          77
        ]
      ],
      "transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py": [
        [
          "save_vocabulary",
          159,
          174,
          168,
          13,
          168,
          53,
          168,
          13,
          168,
          53
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "save_vocabulary",
          233,
          248,
          242,
          13,
          242,
          53,
          242,
          13,
          242,
          53
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "save_vocabulary",
          373,
          394,
          385,
          13,
          385,
          53,
          385,
          13,
          385,
          53
        ],
        [
          "save_vocabulary",
          373,
          394,
          392,
          13,
          392,
          54,
          392,
          13,
          392,
          54
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird_fast.py": [
        [
          "save_vocabulary",
          178,
          195,
          193,
          13,
          193,
          53,
          193,
          13,
          193,
          53
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert.py": [
        [
          "save_vocabulary",
          229,
          244,
          238,
          13,
          238,
          53,
          238,
          13,
          238,
          53
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert_fast.py": [
        [
          "save_vocabulary",
          177,
          194,
          192,
          13,
          192,
          53,
          192,
          13,
          192,
          53
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama.py": [
        [
          "save_vocabulary",
          331,
          356,
          350,
          13,
          350,
          53,
          350,
          13,
          350,
          53
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama_fast.py": [
        [
          "save_vocabulary",
          326,
          343,
          341,
          13,
          341,
          53,
          341,
          13,
          341,
          53
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "save_vocabulary",
          327,
          342,
          336,
          13,
          336,
          53,
          336,
          13,
          336,
          53
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm_fast.py": [
        [
          "save_vocabulary",
          205,
          222,
          220,
          13,
          220,
          53,
          220,
          13,
          220,
          53
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          187,
          13,
          187,
          53,
          187,
          13,
          187,
          53
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet_fast.py": [
        [
          "save_vocabulary",
          141,
          152,
          150,
          13,
          150,
          53,
          150,
          13,
          150,
          53
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "save_vocabulary",
          296,
          311,
          305,
          13,
          305,
          53,
          305,
          13,
          305,
          53
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma.py": [
        [
          "save_vocabulary",
          197,
          222,
          216,
          13,
          216,
          53,
          216,
          13,
          216,
          53
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma_fast.py": [
        [
          "save_vocabulary",
          163,
          180,
          178,
          13,
          178,
          53,
          178,
          13,
          178,
          53
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "save_vocabulary",
          236,
          251,
          245,
          13,
          245,
          53,
          245,
          13,
          245,
          53
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm.py": [
        [
          "save_vocabulary",
          421,
          436,
          430,
          13,
          430,
          53,
          430,
          13,
          430,
          53
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama_fast.py": [
        [
          "save_vocabulary",
          218,
          235,
          233,
          13,
          233,
          53,
          233,
          13,
          233,
          53
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py": [
        [
          "save_vocabulary",
          794,
          811,
          809,
          13,
          809,
          53,
          809,
          13,
          809,
          53
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama.py": [
        [
          "save_vocabulary",
          306,
          331,
          325,
          13,
          325,
          53,
          325,
          13,
          325,
          53
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "save_vocabulary",
          287,
          330,
          322,
          17,
          322,
          54,
          322,
          17,
          323,
          49
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart.py": [
        [
          "save_vocabulary",
          294,
          309,
          303,
          13,
          303,
          53,
          303,
          13,
          303,
          53
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50.py": [
        [
          "save_vocabulary",
          242,
          257,
          251,
          13,
          251,
          53,
          251,
          13,
          251,
          53
        ]
      ],
      "transformers/src/transformers/models/m2m_100/tokenization_m2m_100.py": [
        [
          "save_vocabulary",
          295,
          315,
          309,
          13,
          309,
          50,
          309,
          13,
          309,
          50
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50_fast.py": [
        [
          "save_vocabulary",
          238,
          255,
          253,
          13,
          253,
          53,
          253,
          13,
          253,
          53
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart_fast.py": [
        [
          "save_vocabulary",
          249,
          266,
          264,
          13,
          264,
          53,
          264,
          13,
          264,
          53
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "save_vocabulary",
          1530,
          1553,
          1540,
          13,
          1540,
          53,
          1540,
          13,
          1540,
          53
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb_fast.py": [
        [
          "save_vocabulary",
          307,
          324,
          322,
          13,
          322,
          53,
          322,
          13,
          322,
          53
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb.py": [
        [
          "save_vocabulary",
          332,
          347,
          341,
          13,
          341,
          53,
          341,
          13,
          341,
          53
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus_fast.py": [
        [
          "save_vocabulary",
          195,
          212,
          210,
          13,
          210,
          53,
          210,
          13,
          210,
          53
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus.py": [
        [
          "save_vocabulary",
          274,
          289,
          283,
          13,
          283,
          53,
          283,
          13,
          283,
          53
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "save_vocabulary",
          298,
          319,
          310,
          13,
          310,
          53,
          310,
          13,
          310,
          53
        ],
        [
          "save_vocabulary",
          298,
          319,
          317,
          13,
          317,
          54,
          317,
          13,
          317,
          54
        ]
      ],
      "transformers/src/transformers/models/plbart/tokenization_plbart.py": [
        [
          "save_vocabulary",
          370,
          385,
          379,
          13,
          379,
          53,
          379,
          13,
          379,
          53
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer.py": [
        [
          "save_vocabulary",
          158,
          173,
          167,
          13,
          167,
          53,
          167,
          13,
          167,
          53
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer_fast.py": [
        [
          "save_vocabulary",
          94,
          111,
          109,
          13,
          109,
          53,
          109,
          13,
          109,
          53
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert_fast.py": [
        [
          "save_vocabulary",
          184,
          195,
          193,
          13,
          193,
          53,
          193,
          13,
          193,
          53
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert.py": [
        [
          "save_vocabulary",
          219,
          234,
          228,
          13,
          228,
          53,
          228,
          13,
          228,
          53
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "save_vocabulary",
          362,
          377,
          371,
          13,
          371,
          53,
          371,
          13,
          371,
          53
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t_fast.py": [
        [
          "save_vocabulary",
          320,
          337,
          335,
          13,
          335,
          53,
          335,
          13,
          335,
          53
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t.py": [
        [
          "save_vocabulary",
          497,
          512,
          506,
          13,
          506,
          53,
          506,
          13,
          506,
          53
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/tokenization_speech_to_text.py": [
        [
          "save_vocabulary",
          257,
          276,
          270,
          13,
          270,
          50,
          270,
          13,
          270,
          50
        ]
      ],
      "transformers/src/transformers/models/speecht5/tokenization_speecht5.py": [
        [
          "save_vocabulary",
          205,
          220,
          214,
          13,
          214,
          53,
          214,
          13,
          214,
          53
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "save_vocabulary",
          430,
          445,
          439,
          13,
          439,
          53,
          439,
          13,
          439,
          53
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5_fast.py": [
        [
          "save_vocabulary",
          156,
          174,
          171,
          13,
          171,
          53,
          171,
          13,
          172,
          63
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "save_vocabulary",
          491,
          506,
          500,
          13,
          500,
          53,
          500,
          13,
          500,
          53
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop_fast.py": [
        [
          "save_vocabulary",
          1006,
          1023,
          1021,
          13,
          1021,
          53,
          1021,
          13,
          1021,
          53
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm.py": [
        [
          "save_vocabulary",
          284,
          299,
          293,
          13,
          293,
          53,
          293,
          13,
          293,
          53
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          187,
          13,
          187,
          53,
          187,
          13,
          187,
          53
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        [
          "save_vocabulary",
          279,
          294,
          288,
          13,
          288,
          53,
          288,
          13,
          288,
          53
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py": [
        [
          "save_vocabulary",
          174,
          191,
          189,
          13,
          189,
          53,
          189,
          13,
          189,
          53
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py": [
        [
          "save_vocabulary",
          283,
          298,
          292,
          13,
          292,
          53,
          292,
          13,
          292,
          53
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet_fast.py": [
        [
          "save_vocabulary",
          210,
          227,
          225,
          13,
          225,
          53,
          225,
          13,
          225,
          53
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "save_vocabulary",
          369,
          384,
          378,
          13,
          378,
          53,
          378,
          13,
          378,
          53
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          193,
          5,
          193,
          47,
          192,
          19,
          251,
          24
        ]
      ],
      "transformers/examples/legacy/seq2seq/pack_dataset.py": [
        [
          "pack_data_dir",
          58,
          72,
          71,
          9,
          71,
          64,
          69,
          9,
          72,
          64
        ],
        [
          "pack_data_dir",
          58,
          72,
          72,
          9,
          72,
          64,
          69,
          9,
          72,
          64
        ]
      ]
    },
    "os.path.dirname": {
      "transformers/examples/pytorch/test_pytorch_examples.py": [
        [
          "listcomp",
          33,
          34,
          34,
          18,
          34,
          42,
          35,
          9,
          34,
          52
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "test_auto_batch_size_finder",
          3493,
          3524,
          3498,
          26,
          3498,
          50,
          3497,
          19,
          3524,
          27
        ],
        [
          "test_end_to_end_example",
          4443,
          4485,
          4447,
          17,
          4447,
          41,
          4443,
          33,
          4485,
          45
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "get_tests_dir",
          1522,
          1542,
          1534,
          33,
          1534,
          63,
          1522,
          19,
          1534,
          13
        ],
        [
          "get_tests_dir",
          1522,
          1542,
          1537,
          21,
          1537,
          46,
          1537,
          21,
          1537,
          17
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "save_chat",
          395,
          411,
          408,
          21,
          408,
          45,
          408,
          9,
          411,
          40
        ],
        [
          "get_generation_parameterization",
          477,
          503,
          486,
          27,
          486,
          65,
          486,
          27,
          488,
          33
        ]
      ],
      "transformers/utils/check_config_attributes.py": [
        [
          "check_config_attributes_being_used",
          457,
          499,
          477,
          17,
          477,
          51,
          476,
          26,
          482,
          30
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          620,
          50,
          620,
          74,
          608,
          54,
          621,
          37
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          194,
          270,
          208,
          35,
          208,
          66,
          207,
          22,
          214,
          46
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          119,
          17,
          119,
          49,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          99,
          24,
          99,
          52,
          92,
          5,
          137,
          22
        ]
      ],
      "transformers/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py": [
        [
          "main",
          275,
          326,
          289,
          16,
          289,
          55,
          277,
          14,
          294,
          47
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py": [
        [
          "main",
          312,
          422,
          330,
          16,
          330,
          55,
          314,
          14,
          335,
          47
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "main",
          287,
          300,
          296,
          50,
          296,
          74,
          288,
          5,
          300,
          82
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "convert",
          134,
          295,
          291,
          17,
          291,
          47,
          287,
          27,
          295,
          59
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          38,
          41,
          38,
          86,
          38,
          41,
          38,
          37
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "convert_openai_whisper_to_tfms",
          185,
          251,
          189,
          16,
          189,
          56,
          189,
          16,
          189,
          56
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "create_tiny_models",
          1321,
          1431,
          1332,
          34,
          1332,
          75,
          1322,
          5,
          1333,
          32
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1332,
          50,
          1332,
          74,
          1322,
          5,
          1333,
          32
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "__init__",
          1775,
          1872,
          1853,
          30,
          1853,
          57,
          1851,
          29,
          1854,
          55
        ],
        [
          "__init__",
          1775,
          1872,
          1869,
          30,
          1869,
          57,
          1866,
          28,
          1870,
          55
        ],
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2172,
          23,
          2172,
          50,
          2172,
          23,
          2172,
          19
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "listcomp",
          810,
          811,
          811,
          21,
          811,
          38,
          812,
          25,
          811,
          38
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "load_and_cache_examples",
          230,
          272,
          237,
          9,
          237,
          35,
          235,
          18,
          239,
          29
        ],
        [
          "listcomp",
          696,
          697,
          697,
          17,
          697,
          34,
          697,
          40,
          697,
          34
        ]
      ]
    },
    "shutil.copy": {
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_tokenizer_from_type",
          103,
          115,
          105,
          13,
          105,
          89,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          111,
          13,
          111,
          91,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          112,
          13,
          112,
          91,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          120,
          13,
          120,
          89,
          118,
          39,
          130,
          63
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          126,
          13,
          126,
          91,
          118,
          39,
          130,
          63
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          127,
          13,
          127,
          91,
          118,
          39,
          130,
          63
        ]
      ],
      "transformers/src/transformers/tokenization_mistral_common.py": [
        [
          "save_pretrained",
          1811,
          1878,
          1861,
          9,
          1861,
          57,
          1858,
          26,
          1863,
          22
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4888,
          17,
          4888,
          116,
          4888,
          17,
          4888,
          116
        ]
      ],
      "transformers/utils/check_modular_conversion.py": [
        [
          "process_file",
          27,
          67,
          54,
          13,
          54,
          58,
          54,
          13,
          54,
          58
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "extract_nemotron_tokenizer",
          298,
          327,
          314,
          13,
          314,
          72,
          314,
          13,
          314,
          72
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_cached_module_file",
          316,
          485,
          435,
          13,
          435,
          75,
          434,
          14,
          436,
          41
        ],
        [
          "get_cached_module_file",
          316,
          485,
          443,
          17,
          443,
          79,
          443,
          17,
          444,
          45
        ],
        [
          "get_cached_module_file",
          316,
          485,
          457,
          13,
          457,
          75,
          457,
          13,
          458,
          41
        ],
        [
          "custom_object_save",
          608,
          681,
          672,
          5,
          672,
          39,
          668,
          14,
          676,
          61
        ],
        [
          "custom_object_save",
          608,
          681,
          678,
          9,
          678,
          43,
          676,
          9,
          679,
          32
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "setUpClass",
          35,
          76,
          65,
          17,
          65,
          79,
          64,
          27,
          65,
          79
        ],
        [
          "setUpClass",
          35,
          76,
          49,
          9,
          49,
          77,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          51,
          9,
          51,
          71,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          54,
          9,
          54,
          75,
          35,
          20,
          56,
          35
        ]
      ]
    },
    "os.chdir": {
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          513,
          17,
          513,
          33,
          513,
          26,
          513,
          33
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          524,
          17,
          524,
          34,
          524,
          17,
          524,
          34
        ]
      ]
    },
    "pathlib.Path.exists": {
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "create_tmp_repo",
          85,
          168,
          91,
          8,
          91,
          23,
          85,
          21,
          91,
          23
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "__init__",
          107,
          167,
          125,
          16,
          125,
          40,
          123,
          32,
          125,
          40
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "__init__",
          56,
          72,
          57,
          16,
          57,
          42,
          56,
          18,
          57,
          42
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "read_metadata",
          198,
          216,
          206,
          20,
          206,
          74,
          203,
          13,
          206,
          74
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_seq2seq_examples.py": [
        [
          "run_eval_tester",
          48,
          70,
          70,
          20,
          70,
          50,
          56,
          16,
          70,
          50
        ],
        [
          "test_run_eval_search",
          87,
          132,
          131,
          20,
          131,
          50,
          131,
          20,
          131,
          50
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "discover_benchmarks",
          51,
          101,
          61,
          12,
          61,
          32,
          51,
          25,
          61,
          32
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval.py": [
        [
          "run_generate",
          85,
          178,
          138,
          40,
          138,
          69,
          138,
          40,
          138,
          69
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "create_tmp_repo",
          251,
          275,
          256,
          8,
          256,
          23,
          251,
          21,
          256,
          23
        ]
      ]
    },
    "pathlib.Path.mkdir": {
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "create_tmp_repo",
          85,
          168,
          93,
          5,
          93,
          32,
          93,
          5,
          96,
          21
        ]
      ],
      "transformers/src/transformers/integrations/tiktoken.py": [
        [
          "convert_tiktoken_to_fast",
          8,
          43,
          21,
          5,
          21,
          35,
          8,
          30,
          30,
          21
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2260,
          5,
          2260,
          48,
          2254,
          14,
          2280,
          36
        ]
      ],
      "transformers/src/transformers/tokenization_mistral_common.py": [
        [
          "save_pretrained",
          1811,
          1878,
          1859,
          9,
          1859,
          57,
          1858,
          26,
          1863,
          22
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "save_chat_templates",
          2416,
          2469,
          2454,
          21,
          2454,
          64,
          2454,
          21,
          2459,
          75
        ]
      ],
      "transformers/src/transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_bart_checkpoint",
          88,
          142,
          141,
          5,
          141,
          55,
          141,
          5,
          142,
          51
        ]
      ],
      "transformers/src/transformers/models/audio_spectrogram_transformer/convert_audio_spectrogram_transformer_original_to_pytorch.py": [
        [
          "convert_audio_spectrogram_transformer_checkpoint",
          153,
          259,
          250,
          9,
          250,
          59,
          250,
          9,
          254,
          67
        ]
      ],
      "transformers/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py": [
        [
          "convert_beit_checkpoint",
          170,
          357,
          353,
          5,
          353,
          55,
          341,
          12,
          357,
          61
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          353,
          5,
          353,
          55,
          353,
          5,
          357,
          61
        ]
      ],
      "transformers/src/transformers/models/bit/convert_bit_to_pytorch.py": [
        [
          "convert_bit_checkpoint",
          83,
          155,
          147,
          9,
          147,
          59,
          147,
          9,
          150,
          59
        ]
      ],
      "transformers/src/transformers/models/colqwen2/convert_colqwen2_weights_to_hf.py": [
        [
          "convert_colqwen2_weights_to_hf",
          96,
          158,
          156,
          9,
          156,
          59,
          156,
          9,
          158,
          47
        ]
      ],
      "transformers/src/transformers/models/colpali/convert_colpali_weights_to_hf.py": [
        [
          "convert_colpali_weights_to_hf",
          97,
          163,
          161,
          9,
          161,
          59,
          161,
          9,
          163,
          47
        ]
      ],
      "transformers/src/transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_conditional_detr_checkpoint",
          222,
          308,
          306,
          5,
          306,
          55,
          300,
          5,
          308,
          61
        ],
        [
          "convert_conditional_detr_checkpoint",
          222,
          308,
          306,
          5,
          306,
          55,
          302,
          9,
          308,
          61
        ]
      ],
      "transformers/src/transformers/models/convnext/convert_convnext_to_pytorch.py": [
        [
          "convert_convnext_checkpoint",
          121,
          221,
          190,
          5,
          190,
          55,
          188,
          5,
          198,
          31
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "write_image_processor",
          109,
          117,
          113,
          5,
          113,
          55,
          109,
          27,
          116,
          18
        ],
        [
          "write_model",
          121,
          196,
          192,
          5,
          192,
          55,
          188,
          13,
          195,
          18
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_text_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          187,
          5,
          187,
          77,
          187,
          5,
          189,
          51
        ]
      ],
      "transformers/src/transformers/models/deit/convert_deit_timm_to_pytorch.py": [
        [
          "convert_deit_checkpoint",
          131,
          201,
          197,
          5,
          197,
          55,
          195,
          5,
          201,
          61
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          189,
          5,
          189,
          55,
          183,
          5,
          194,
          18
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "convert_d_fine_checkpoint",
          389,
          668,
          648,
          9,
          648,
          59,
          648,
          9,
          652,
          65
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_detr_checkpoint",
          179,
          264,
          262,
          5,
          262,
          55,
          256,
          5,
          264,
          61
        ],
        [
          "convert_detr_checkpoint",
          179,
          264,
          262,
          5,
          262,
          55,
          258,
          9,
          264,
          61
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          201,
          336,
          328,
          9,
          328,
          59,
          328,
          9,
          331,
          59
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_to_pytorch.py": [
        [
          "convert_detr_checkpoint",
          288,
          367,
          359,
          9,
          359,
          59,
          358,
          9,
          361,
          59
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "convert_deta_checkpoint",
          217,
          303,
          295,
          9,
          295,
          59,
          294,
          9,
          297,
          59
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "convert_deta_checkpoint",
          216,
          296,
          288,
          9,
          288,
          59,
          287,
          9,
          290,
          59
        ]
      ],
      "transformers/src/transformers/models/vit/convert_dino_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          131,
          195,
          191,
          5,
          191,
          55,
          189,
          9,
          195,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          195,
          191,
          5,
          191,
          55,
          185,
          9,
          195,
          61
        ]
      ],
      "transformers/src/transformers/models/dinov2_with_registers/convert_dinov2_with_registers_to_hf.py": [
        [
          "convert_dinov2_with_registers_checkpoint",
          152,
          261,
          241,
          9,
          241,
          59,
          241,
          9,
          245,
          59
        ]
      ],
      "transformers/src/transformers/models/dinov2/convert_dinov2_to_hf.py": [
        [
          "convert_dinov2_checkpoint",
          146,
          255,
          235,
          9,
          235,
          59,
          235,
          9,
          239,
          59
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dinov2_depth_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          243,
          351,
          343,
          9,
          343,
          59,
          343,
          9,
          346,
          59
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          147,
          215,
          207,
          9,
          207,
          59,
          207,
          9,
          210,
          59
        ]
      ],
      "transformers/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py": [
        [
          "convert_dit_checkpoint",
          133,
          210,
          188,
          5,
          188,
          55,
          186,
          5,
          194,
          18
        ]
      ],
      "transformers/src/transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py": [
        [
          "convert",
          110,
          117,
          112,
          5,
          112,
          33,
          110,
          13,
          117,
          35
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_beit_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          174,
          279,
          271,
          9,
          271,
          59,
          271,
          9,
          274,
          59
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_to_pytorch.py": [
        [
          "convert_dpt_checkpoint",
          188,
          253,
          234,
          9,
          234,
          59,
          234,
          9,
          238,
          65
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "convert_dpt_checkpoint",
          220,
          278,
          270,
          9,
          270,
          59,
          270,
          9,
          274,
          65
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_swinv2_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          186,
          290,
          282,
          9,
          282,
          59,
          282,
          9,
          285,
          59
        ]
      ],
      "transformers/src/transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_efficientformer_checkpoint",
          123,
          213,
          195,
          5,
          195,
          48,
          195,
          5,
          201,
          18
        ]
      ],
      "transformers/src/transformers/models/esm/convert_esm.py": [
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          370,
          9,
          370,
          81,
          356,
          16,
          379,
          19
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          370,
          9,
          370,
          81,
          370,
          9,
          379,
          19
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          218,
          366,
          243,
          5,
          243,
          39,
          238,
          13,
          252,
          73
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t_v2/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          219,
          374,
          241,
          5,
          241,
          39,
          219,
          16,
          250,
          73
        ]
      ],
      "transformers/src/transformers/models/git/convert_git_to_pytorch.py": [
        [
          "convert_git_checkpoint",
          254,
          423,
          415,
          9,
          415,
          59,
          415,
          9,
          418,
          59
        ]
      ],
      "transformers/src/transformers/models/ijepa/convert_ijepa_to_hf.py": [
        [
          "write_model",
          150,
          226,
          212,
          9,
          212,
          45,
          212,
          9,
          217,
          18
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "convert_openai_checkpoint",
          213,
          260,
          253,
          5,
          253,
          55,
          253,
          5,
          260,
          22
        ]
      ],
      "transformers/src/transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          153,
          248,
          240,
          9,
          240,
          59,
          239,
          9,
          242,
          59
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          188,
          5,
          188,
          55,
          187,
          5,
          204,
          53
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          98,
          357,
          188,
          5,
          188,
          55,
          121,
          23,
          214,
          76
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          297,
          9,
          297,
          59,
          296,
          9,
          299,
          65
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "convert_all_sentencepiece_models",
          298,
          315,
          302,
          5,
          302,
          33,
          298,
          38,
          304,
          25
        ],
        [
          "convert",
          663,
          678,
          665,
          5,
          665,
          33,
          663,
          13,
          678,
          35
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "convert_maskformer_checkpoint",
          261,
          350,
          343,
          9,
          343,
          59,
          342,
          9,
          345,
          65
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "convert_models",
          74,
          89,
          78,
          9,
          78,
          37,
          74,
          24,
          79,
          44
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "convert_mobilevitv2_checkpoint",
          235,
          281,
          277,
          5,
          277,
          55,
          277,
          5,
          281,
          61
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "convert_movilevit_checkpoint",
          195,
          283,
          264,
          5,
          264,
          55,
          264,
          5,
          270,
          18
        ]
      ],
      "transformers/src/transformers/models/musicgen_melody/convert_musicgen_melody_transformers.py": [
        [
          "convert_musicgen_melody_checkpoint",
          134,
          232,
          224,
          9,
          224,
          54,
          224,
          9,
          227,
          54
        ]
      ],
      "transformers/src/transformers/models/musicgen/convert_musicgen_transformers.py": [
        [
          "convert_musicgen_checkpoint",
          131,
          201,
          193,
          9,
          193,
          54,
          193,
          9,
          196,
          54
        ]
      ],
      "transformers/src/transformers/models/opt/convert_opt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_opt_checkpoint",
          80,
          96,
          95,
          5,
          95,
          55,
          91,
          13,
          96,
          51
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_movilevit_checkpoint",
          175,
          218,
          208,
          5,
          208,
          55,
          208,
          5,
          214,
          18
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_movilevit_checkpoint",
          253,
          320,
          310,
          5,
          310,
          55,
          310,
          5,
          316,
          18
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          434,
          5,
          434,
          55,
          434,
          5,
          436,
          51
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "convert_poolformer_checkpoint",
          93,
          195,
          192,
          5,
          192,
          55,
          188,
          5,
          195,
          61
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          155,
          254,
          246,
          9,
          246,
          59,
          246,
          9,
          249,
          59
        ]
      ],
      "transformers/src/transformers/models/pvt_v2/convert_pvt_v2_to_pytorch.py": [
        [
          "convert_pvt_v2_checkpoint",
          184,
          260,
          256,
          5,
          256,
          55,
          256,
          5,
          260,
          61
        ]
      ],
      "transformers/src/transformers/models/pvt/convert_pvt_to_pytorch.py": [
        [
          "convert_pvt_checkpoint",
          150,
          203,
          199,
          5,
          199,
          55,
          197,
          5,
          203,
          61
        ]
      ],
      "transformers/src/transformers/models/roberta/convert_roberta_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_roberta_checkpoint_to_pytorch",
          47,
          159,
          157,
          5,
          157,
          77,
          157,
          5,
          159,
          51
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "write_model_and_image_processor",
          221,
          345,
          325,
          9,
          325,
          45,
          325,
          9,
          329,
          51
        ]
      ],
      "transformers/src/transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": [
        [
          "convert_rt_detr_checkpoint",
          547,
          761,
          743,
          9,
          743,
          59,
          743,
          9,
          747,
          65
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "convert_segformer_checkpoint",
          120,
          368,
          366,
          5,
          366,
          55,
          362,
          9,
          368,
          61
        ],
        [
          "convert_segformer_checkpoint",
          120,
          368,
          366,
          5,
          366,
          55,
          360,
          12,
          368,
          61
        ]
      ],
      "transformers/src/transformers/models/bark/convert_suno_to_hf.py": [
        [
          "load_model",
          161,
          209,
          208,
          5,
          208,
          55,
          208,
          5,
          209,
          51
        ],
        [
          "load_whole_bark_model",
          212,
          250,
          249,
          5,
          249,
          55,
          213,
          5,
          250,
          86
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "convert_swiftformer_checkpoint",
          89,
          153,
          151,
          5,
          151,
          55,
          149,
          5,
          153,
          54
        ]
      ],
      "transformers/src/transformers/models/table_transformer/convert_table_transformer_to_hf.py": [
        [
          "convert_table_transformer_checkpoint",
          189,
          294,
          281,
          9,
          281,
          59,
          280,
          9,
          283,
          65
        ]
      ],
      "transformers/src/transformers/models/table_transformer/convert_table_transformer_to_hf_no_timm.py": [
        [
          "convert_table_transformer_checkpoint",
          302,
          411,
          398,
          9,
          398,
          59,
          397,
          9,
          400,
          65
        ]
      ],
      "transformers/src/transformers/models/trocr/convert_trocr_unilm_to_pytorch.py": [
        [
          "convert_tr_ocr_checkpoint",
          123,
          221,
          217,
          5,
          217,
          55,
          217,
          5,
          221,
          55
        ]
      ],
      "transformers/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py": [
        [
          "convert_vilt_checkpoint",
          168,
          282,
          279,
          5,
          279,
          55,
          272,
          9,
          282,
          55
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          279,
          5,
          279,
          55,
          262,
          9,
          282,
          55
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          279,
          5,
          279,
          55,
          279,
          5,
          282,
          55
        ]
      ],
      "transformers/src/transformers/models/visual_bert/convert_visual_bert_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_visual_bert_checkpoint",
          82,
          140,
          139,
          5,
          139,
          55,
          137,
          5,
          140,
          51
        ]
      ],
      "transformers/src/transformers/models/vit/convert_vit_timm_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          131,
          237,
          233,
          5,
          233,
          55,
          227,
          9,
          237,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          237,
          233,
          5,
          233,
          55,
          231,
          9,
          237,
          61
        ]
      ],
      "transformers/src/transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          165,
          262,
          253,
          9,
          253,
          59,
          253,
          9,
          257,
          59
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_to_hf.py": [
        [
          "convert_and_test_vjepa2_checkpoint",
          223,
          312,
          303,
          9,
          303,
          59,
          303,
          9,
          307,
          59
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta_xl/convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xlm_roberta_xl_checkpoint_to_pytorch",
          47,
          165,
          163,
          5,
          163,
          77,
          163,
          5,
          165,
          51
        ]
      ],
      "transformers/src/transformers/models/xmod/convert_xmod_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          192,
          5,
          192,
          69,
          192,
          5,
          194,
          51
        ]
      ],
      "transformers/src/transformers/models/zoedepth/convert_zoedepth_to_hf.py": [
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          385,
          9,
          385,
          59,
          384,
          9,
          387,
          65
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "convert_yolos_checkpoint",
          157,
          241,
          223,
          5,
          223,
          55,
          221,
          5,
          229,
          18
        ]
      ],
      "transformers/examples/legacy/seq2seq/download_wmt.py": [
        [
          "download_wmt_dataset",
          22,
          63,
          45,
          5,
          45,
          33,
          44,
          16,
          47,
          19
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/lightning_base.py": [
        [
          "generic_train",
          345,
          397,
          359,
          5,
          359,
          29,
          346,
          5,
          362,
          34
        ]
      ],
      "transformers/examples/legacy/seq2seq/minify_dataset.py": [
        [
          "minify",
          21,
          30,
          25,
          5,
          25,
          33,
          21,
          12,
          26,
          33
        ]
      ],
      "transformers/examples/legacy/seq2seq/pack_dataset.py": [
        [
          "pack_data_dir",
          58,
          72,
          60,
          5,
          60,
          34,
          58,
          19,
          61,
          26
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_distributed_eval.py": [
        [
          "run_generate",
          119,
          227,
          167,
          5,
          167,
          44,
          166,
          21,
          169,
          25
        ],
        [
          "run_generate",
          119,
          227,
          178,
          5,
          178,
          44,
          178,
          5,
          196,
          27
        ],
        [
          "run_generate",
          119,
          227,
          198,
          9,
          198,
          37,
          197,
          20,
          201,
          40
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "create_tmp_repo",
          251,
          275,
          258,
          5,
          258,
          32,
          258,
          5,
          271,
          37
        ]
      ]
    },
    "pathlib.Path.resolve": {
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "patch_transformer_repo_path",
          172,
          187,
          177,
          34,
          177,
          59,
          172,
          33,
          182,
          13
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "setUp",
          1957,
          1975,
          1963,
          16,
          1963,
          51,
          1957,
          15,
          1965,
          27
        ],
        [
          "get_auto_remove_tmp_dir",
          2045,
          2111,
          2080,
          20,
          2080,
          42,
          2080,
          20,
          2083,
          43
        ]
      ],
      "transformers/src/transformers/tokenization_mistral_common.py": [
        [
          "_maybe_adapt_message",
          1447,
          1492,
          1470,
          42,
          1470,
          67,
          1470,
          42,
          1470,
          38
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/modeling_deta.py": [
        [
          "load_cuda_kernels",
          56,
          83,
          61,
          12,
          61,
          35,
          57,
          10,
          71,
          33
        ]
      ],
      "transformers/src/transformers/models/mra/modeling_mra.py": [
        [
          "load_cuda_kernels",
          47,
          56,
          49,
          18,
          49,
          41,
          48,
          5,
          56,
          19
        ]
      ],
      "transformers/src/transformers/models/rwkv/modeling_rwkv.py": [
        [
          "load_wkv_cuda_kernel",
          46,
          75,
          51,
          21,
          51,
          44,
          46,
          26,
          55,
          35
        ]
      ],
      "transformers/src/transformers/models/yoso/modeling_yoso.py": [
        [
          "append_root",
          56,
          58,
          57,
          22,
          57,
          45,
          56,
          21,
          58,
          52
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_infer_model_from_relative_path",
          353,
          358,
          355,
          24,
          355,
          46,
          355,
          24,
          355,
          46
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "patch_transformer_repo_path",
          279,
          295,
          286,
          17,
          286,
          42,
          279,
          33,
          291,
          13
        ]
      ]
    },
    "os.path.isdir": {
      "transformers/tests/models/bert_japanese/test_tokenization_bert_japanese.py": [
        [
          "test_mecab_tokenizer_unidic",
          154,
          169,
          159,
          17,
          159,
          44,
          159,
          17,
          159,
          44
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "check_saved_checkpoints",
          624,
          637,
          635,
          29,
          635,
          53,
          633,
          13,
          636,
          37
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4975,
          20,
          4975,
          38,
          4972,
          13,
          4975,
          38
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "save_vocabulary",
          302,
          317,
          303,
          16,
          303,
          44,
          302,
          25,
          303,
          44
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert_fast.py": [
        [
          "save_vocabulary",
          158,
          175,
          165,
          16,
          165,
          44,
          165,
          16,
          165,
          44
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "save_vocabulary",
          282,
          309,
          283,
          16,
          283,
          44,
          282,
          25,
          283,
          44
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez.py": [
        [
          "save_vocabulary",
          273,
          288,
          274,
          16,
          274,
          44,
          273,
          25,
          274,
          44
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez_fast.py": [
        [
          "save_vocabulary",
          173,
          190,
          180,
          16,
          180,
          44,
          180,
          16,
          180,
          44
        ]
      ],
      "transformers/src/transformers/models/bartpho/tokenization_bartpho.py": [
        [
          "save_vocabulary",
          286,
          315,
          287,
          16,
          287,
          44,
          286,
          25,
          287,
          44
        ]
      ],
      "transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py": [
        [
          "save_vocabulary",
          159,
          174,
          160,
          16,
          160,
          44,
          159,
          25,
          160,
          44
        ]
      ],
      "transformers/src/transformers/models/bert/tokenization_bert.py": [
        [
          "save_vocabulary",
          239,
          257,
          241,
          12,
          241,
          40,
          239,
          25,
          241,
          40
        ]
      ],
      "transformers/src/transformers/models/bert_japanese/tokenization_bert_japanese.py": [
        [
          "save_vocabulary",
          312,
          342,
          313,
          12,
          313,
          40,
          312,
          25,
          313,
          40
        ],
        [
          "__init__",
          348,
          432,
          420,
          24,
          420,
          45,
          412,
          28,
          420,
          45
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "save_vocabulary",
          233,
          248,
          234,
          16,
          234,
          44,
          233,
          25,
          234,
          44
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "save_vocabulary",
          373,
          394,
          374,
          16,
          374,
          44,
          373,
          25,
          374,
          44
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird_fast.py": [
        [
          "save_vocabulary",
          178,
          195,
          185,
          16,
          185,
          44,
          185,
          16,
          185,
          44
        ]
      ],
      "transformers/src/transformers/models/biogpt/tokenization_biogpt.py": [
        [
          "save_vocabulary",
          284,
          310,
          285,
          16,
          285,
          44,
          284,
          25,
          285,
          44
        ]
      ],
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "save_vocabulary",
          192,
          219,
          193,
          16,
          193,
          44,
          192,
          25,
          193,
          44
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "save_vocabulary",
          305,
          332,
          306,
          16,
          306,
          44,
          305,
          25,
          306,
          44
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert.py": [
        [
          "save_vocabulary",
          229,
          244,
          230,
          16,
          230,
          44,
          229,
          25,
          230,
          44
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert_fast.py": [
        [
          "save_vocabulary",
          177,
          194,
          184,
          16,
          184,
          44,
          184,
          16,
          184,
          44
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "save_vocabulary",
          489,
          516,
          490,
          16,
          490,
          44,
          489,
          25,
          490,
          44
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "save_vocabulary",
          337,
          364,
          338,
          16,
          338,
          44,
          337,
          25,
          338,
          44
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama.py": [
        [
          "save_vocabulary",
          331,
          356,
          342,
          16,
          342,
          44,
          331,
          25,
          342,
          44
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "save_vocabulary",
          276,
          303,
          277,
          16,
          277,
          44,
          276,
          25,
          277,
          44
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama_fast.py": [
        [
          "save_vocabulary",
          326,
          343,
          333,
          16,
          333,
          44,
          333,
          16,
          333,
          44
        ]
      ],
      "transformers/src/transformers/models/convbert/tokenization_convbert.py": [
        [
          "save_vocabulary",
          242,
          260,
          244,
          12,
          244,
          40,
          242,
          25,
          244,
          40
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "save_vocabulary",
          327,
          342,
          328,
          16,
          328,
          44,
          327,
          25,
          328,
          44
        ]
      ],
      "transformers/src/transformers/models/cpmant/tokenization_cpmant.py": [
        [
          "save_vocabulary",
          198,
          223,
          199,
          12,
          199,
          40,
          198,
          25,
          199,
          40
        ]
      ],
      "transformers/src/transformers/models/ctrl/tokenization_ctrl.py": [
        [
          "save_vocabulary",
          215,
          242,
          216,
          16,
          216,
          44,
          215,
          25,
          216,
          44
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "save_vocabulary",
          330,
          357,
          331,
          16,
          331,
          44,
          330,
          25,
          331,
          44
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm_fast.py": [
        [
          "save_vocabulary",
          205,
          222,
          212,
          16,
          212,
          44,
          212,
          16,
          212,
          44
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          179,
          16,
          179,
          44,
          179,
          16,
          179,
          44
        ]
      ],
      "transformers/src/transformers/models/distilbert/tokenization_distilbert.py": [
        [
          "save_vocabulary",
          251,
          269,
          253,
          12,
          253,
          40,
          251,
          25,
          253,
          40
        ]
      ],
      "transformers/src/transformers/models/electra/tokenization_electra.py": [
        [
          "save_vocabulary",
          241,
          259,
          243,
          12,
          243,
          40,
          241,
          25,
          243,
          40
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": [
        [
          "save_vocabulary",
          146,
          167,
          157,
          16,
          157,
          44,
          146,
          25,
          157,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/ernie_m/tokenization_ernie_m.py": [
        [
          "save_vocabulary",
          382,
          406,
          384,
          12,
          384,
          40,
          382,
          25,
          384,
          40
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet_fast.py": [
        [
          "save_vocabulary",
          141,
          152,
          142,
          16,
          142,
          44,
          141,
          25,
          142,
          44
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "save_vocabulary",
          489,
          515,
          490,
          16,
          490,
          44,
          489,
          25,
          490,
          44
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "save_vocabulary",
          296,
          311,
          297,
          16,
          297,
          44,
          296,
          25,
          297,
          44
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "save_vocabulary",
          433,
          467,
          434,
          16,
          434,
          44,
          433,
          25,
          434,
          44
        ]
      ],
      "transformers/src/transformers/models/funnel/tokenization_funnel.py": [
        [
          "save_vocabulary",
          301,
          319,
          303,
          12,
          303,
          40,
          301,
          25,
          303,
          40
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma.py": [
        [
          "save_vocabulary",
          197,
          222,
          208,
          16,
          208,
          44,
          197,
          25,
          208,
          44
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "save_vocabulary",
          298,
          325,
          299,
          16,
          299,
          44,
          298,
          25,
          299,
          44
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma_fast.py": [
        [
          "save_vocabulary",
          163,
          180,
          170,
          16,
          170,
          44,
          170,
          16,
          170,
          44
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "save_vocabulary",
          236,
          251,
          237,
          16,
          237,
          44,
          236,
          25,
          237,
          44
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "save_vocabulary",
          165,
          193,
          167,
          12,
          167,
          40,
          165,
          25,
          167,
          40
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "save_vocabulary",
          240,
          268,
          242,
          12,
          242,
          40,
          240,
          25,
          242,
          40
        ]
      ],
      "transformers/src/transformers/models/layoutlm/tokenization_layoutlm.py": [
        [
          "save_vocabulary",
          242,
          260,
          244,
          12,
          244,
          40,
          242,
          25,
          244,
          40
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "save_vocabulary",
          568,
          594,
          569,
          16,
          569,
          44,
          568,
          25,
          569,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "save_vocabulary",
          336,
          370,
          348,
          16,
          348,
          44,
          336,
          25,
          348,
          44
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py": [
        [
          "save_vocabulary",
          360,
          378,
          362,
          12,
          362,
          40,
          360,
          25,
          362,
          40
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "save_vocabulary",
          411,
          438,
          412,
          16,
          412,
          44,
          411,
          25,
          412,
          44
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm.py": [
        [
          "save_vocabulary",
          421,
          436,
          422,
          16,
          422,
          44,
          421,
          25,
          422,
          44
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "save_vocabulary",
          295,
          322,
          296,
          16,
          296,
          44,
          295,
          25,
          296,
          44
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama_fast.py": [
        [
          "save_vocabulary",
          218,
          235,
          225,
          16,
          225,
          44,
          225,
          16,
          225,
          44
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "save_vocabulary",
          291,
          318,
          292,
          16,
          292,
          44,
          291,
          25,
          292,
          44
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py": [
        [
          "save_vocabulary",
          794,
          811,
          801,
          16,
          801,
          44,
          801,
          16,
          801,
          44
        ]
      ],
      "transformers/src/transformers/models/lxmert/tokenization_lxmert.py": [
        [
          "save_vocabulary",
          241,
          259,
          243,
          12,
          243,
          40,
          241,
          25,
          243,
          40
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama.py": [
        [
          "save_vocabulary",
          306,
          331,
          317,
          16,
          317,
          44,
          306,
          25,
          317,
          44
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "save_vocabulary",
          287,
          330,
          288,
          16,
          288,
          44,
          287,
          25,
          288,
          44
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "save_vocabulary",
          369,
          398,
          370,
          16,
          370,
          44,
          369,
          25,
          370,
          44
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "save_vocabulary",
          1691,
          1725,
          1692,
          16,
          1692,
          44,
          1691,
          25,
          1692,
          44
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart.py": [
        [
          "save_vocabulary",
          294,
          309,
          295,
          16,
          295,
          44,
          294,
          25,
          295,
          44
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50.py": [
        [
          "save_vocabulary",
          242,
          257,
          243,
          16,
          243,
          44,
          242,
          25,
          243,
          44
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50_fast.py": [
        [
          "save_vocabulary",
          238,
          255,
          245,
          16,
          245,
          44,
          245,
          16,
          245,
          44
        ]
      ],
      "transformers/src/transformers/models/mgp_str/tokenization_mgp_str.py": [
        [
          "save_vocabulary",
          90,
          101,
          91,
          16,
          91,
          44,
          90,
          25,
          91,
          44
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart_fast.py": [
        [
          "save_vocabulary",
          249,
          266,
          256,
          16,
          256,
          44,
          256,
          16,
          256,
          44
        ]
      ],
      "transformers/src/transformers/models/mobilebert/tokenization_mobilebert.py": [
        [
          "save_vocabulary",
          243,
          261,
          245,
          12,
          245,
          40,
          243,
          25,
          245,
          40
        ]
      ],
      "transformers/src/transformers/models/mpnet/tokenization_mpnet.py": [
        [
          "save_vocabulary",
          296,
          314,
          298,
          12,
          298,
          40,
          296,
          25,
          298,
          40
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "save_vocabulary",
          1530,
          1553,
          1531,
          16,
          1531,
          44,
          1530,
          25,
          1531,
          44
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "save_vocabulary",
          283,
          310,
          284,
          16,
          284,
          44,
          283,
          25,
          284,
          44
        ]
      ],
      "transformers/src/transformers/models/myt5/tokenization_myt5.py": [
        [
          "save_vocabulary",
          368,
          377,
          369,
          12,
          369,
          40,
          368,
          25,
          369,
          40
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb_fast.py": [
        [
          "save_vocabulary",
          307,
          324,
          314,
          16,
          314,
          44,
          314,
          16,
          314,
          44
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb.py": [
        [
          "save_vocabulary",
          332,
          347,
          333,
          16,
          333,
          44,
          332,
          25,
          333,
          44
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "save_vocabulary",
          366,
          393,
          367,
          16,
          367,
          44,
          366,
          25,
          367,
          44
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus_fast.py": [
        [
          "save_vocabulary",
          195,
          212,
          202,
          16,
          202,
          44,
          202,
          16,
          202,
          44
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus.py": [
        [
          "save_vocabulary",
          274,
          289,
          275,
          16,
          275,
          44,
          274,
          25,
          275,
          44
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "save_vocabulary",
          298,
          319,
          299,
          16,
          299,
          44,
          298,
          25,
          299,
          44
        ]
      ],
      "transformers/src/transformers/tokenization_mistral_common.py": [
        [
          "from_pretrained",
          1685,
          1809,
          1761,
          16,
          1761,
          59,
          1761,
          16,
          1761,
          59
        ]
      ],
      "transformers/src/transformers/models/pop2piano/tokenization_pop2piano.py": [
        [
          "save_vocabulary",
          344,
          365,
          354,
          16,
          354,
          44,
          344,
          25,
          354,
          44
        ]
      ],
      "transformers/src/transformers/models/plbart/tokenization_plbart.py": [
        [
          "save_vocabulary",
          370,
          385,
          371,
          16,
          371,
          44,
          370,
          25,
          371,
          44
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "save_vocabulary",
          308,
          335,
          309,
          16,
          309,
          44,
          308,
          25,
          309,
          44
        ]
      ],
      "transformers/src/transformers/models/prophetnet/tokenization_prophetnet.py": [
        [
          "save_vocabulary",
          435,
          453,
          437,
          12,
          437,
          40,
          435,
          25,
          437,
          40
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/tokenization_realm.py": [
        [
          "save_vocabulary",
          307,
          325,
          309,
          12,
          309,
          40,
          307,
          25,
          309,
          40
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer.py": [
        [
          "save_vocabulary",
          158,
          173,
          159,
          16,
          159,
          44,
          158,
          25,
          159,
          44
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer_fast.py": [
        [
          "save_vocabulary",
          94,
          111,
          101,
          16,
          101,
          44,
          101,
          16,
          101,
          44
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert_fast.py": [
        [
          "save_vocabulary",
          184,
          195,
          185,
          16,
          185,
          44,
          184,
          25,
          185,
          44
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert.py": [
        [
          "save_vocabulary",
          219,
          234,
          220,
          16,
          220,
          44,
          219,
          25,
          220,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/retribert/tokenization_retribert.py": [
        [
          "save_vocabulary",
          236,
          254,
          238,
          12,
          238,
          40,
          236,
          25,
          238,
          40
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "save_vocabulary",
          291,
          318,
          292,
          16,
          292,
          44,
          291,
          25,
          292,
          44
        ]
      ],
      "transformers/src/transformers/models/roformer/tokenization_roformer.py": [
        [
          "save_vocabulary",
          490,
          508,
          492,
          12,
          492,
          40,
          490,
          25,
          492,
          40
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "save_vocabulary",
          362,
          377,
          363,
          16,
          363,
          44,
          362,
          25,
          363,
          44
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t_fast.py": [
        [
          "save_vocabulary",
          320,
          337,
          327,
          16,
          327,
          44,
          327,
          16,
          327,
          44
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t.py": [
        [
          "save_vocabulary",
          497,
          512,
          498,
          16,
          498,
          44,
          497,
          25,
          498,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py": [
        [
          "save_vocabulary",
          220,
          249,
          221,
          16,
          221,
          44,
          220,
          25,
          221,
          44
        ]
      ],
      "transformers/src/transformers/models/splinter/tokenization_splinter.py": [
        [
          "save_vocabulary",
          280,
          298,
          282,
          12,
          282,
          40,
          280,
          25,
          282,
          40
        ]
      ],
      "transformers/src/transformers/models/speecht5/tokenization_speecht5.py": [
        [
          "save_vocabulary",
          205,
          220,
          206,
          16,
          206,
          44,
          205,
          25,
          206,
          44
        ]
      ],
      "transformers/src/transformers/models/squeezebert/tokenization_squeezebert.py": [
        [
          "save_vocabulary",
          242,
          260,
          244,
          12,
          244,
          40,
          242,
          25,
          244,
          40
        ]
      ],
      "transformers/src/transformers/models/roc_bert/tokenization_roc_bert.py": [
        [
          "save_vocabulary",
          827,
          869,
          829,
          12,
          829,
          40,
          827,
          25,
          829,
          40
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "save_vocabulary",
          430,
          445,
          431,
          16,
          431,
          44,
          430,
          25,
          431,
          44
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5_fast.py": [
        [
          "save_vocabulary",
          156,
          174,
          163,
          16,
          163,
          44,
          163,
          16,
          163,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "save_vocabulary",
          465,
          492,
          466,
          16,
          466,
          44,
          465,
          25,
          466,
          44
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "save_vocabulary",
          491,
          506,
          492,
          16,
          492,
          44,
          491,
          25,
          492,
          44
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "save_vocabulary",
          372,
          390,
          374,
          12,
          374,
          40,
          372,
          25,
          374,
          40
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "save_vocabulary",
          317,
          327,
          318,
          12,
          318,
          40,
          317,
          25,
          318,
          40
        ],
        [
          "from_pretrained",
          686,
          720,
          691,
          20,
          691,
          63,
          686,
          25,
          694,
          46
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop_fast.py": [
        [
          "save_vocabulary",
          1006,
          1023,
          1013,
          16,
          1013,
          44,
          1013,
          16,
          1013,
          44
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "save_vocabulary",
          231,
          243,
          232,
          16,
          232,
          44,
          231,
          25,
          232,
          44
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        [
          "save_vocabulary",
          558,
          569,
          559,
          16,
          559,
          44,
          558,
          25,
          559,
          44
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py": [
        [
          "save_vocabulary",
          624,
          635,
          625,
          16,
          625,
          44,
          624,
          25,
          625,
          44
        ],
        [
          "save_vocabulary",
          901,
          912,
          902,
          16,
          902,
          44,
          901,
          25,
          902,
          44
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "from_pretrained",
          1859,
          2128,
          1977,
          20,
          1977,
          63,
          1973,
          41,
          1979,
          56
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm.py": [
        [
          "save_vocabulary",
          284,
          299,
          285,
          16,
          285,
          44,
          284,
          25,
          285,
          44
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "save_vocabulary",
          801,
          837,
          802,
          16,
          802,
          44,
          801,
          25,
          802,
          44
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          179,
          16,
          179,
          44,
          179,
          16,
          179,
          44
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "save_vocabulary",
          532,
          558,
          533,
          16,
          533,
          44,
          532,
          25,
          533,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        [
          "save_vocabulary",
          279,
          294,
          280,
          16,
          280,
          44,
          279,
          25,
          280,
          44
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py": [
        [
          "save_vocabulary",
          174,
          191,
          181,
          16,
          181,
          44,
          181,
          16,
          181,
          44
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py": [
        [
          "save_vocabulary",
          283,
          298,
          284,
          16,
          284,
          44,
          283,
          25,
          284,
          44
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet_fast.py": [
        [
          "save_vocabulary",
          210,
          227,
          217,
          16,
          217,
          44,
          217,
          16,
          217,
          44
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "save_vocabulary",
          369,
          384,
          370,
          16,
          370,
          44,
          369,
          25,
          370,
          44
        ]
      ],
      "transformers/src/transformers/trainer_utils.py": [
        [
          "listcomp",
          204,
          205,
          207,
          56,
          207,
          96,
          207,
          56,
          207,
          96
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2767,
          24,
          2767,
          60,
          2760,
          23,
          2767,
          60
        ],
        [
          "genexpr",
          2770,
          2770,
          2772,
          20,
          2772,
          83,
          2771,
          21,
          2772,
          83
        ],
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2788,
          16,
          2788,
          52,
          2767,
          9,
          2788,
          52
        ],
        [
          "listcomp",
          2779,
          2780,
          2782,
          20,
          2782,
          83,
          2781,
          21,
          2782,
          83
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3357,
          21,
          3357,
          45,
          3357,
          21,
          3357,
          45
        ],
        [
          "genexpr",
          3359,
          3359,
          3361,
          28,
          3361,
          79,
          3360,
          29,
          3361,
          79
        ],
        [
          "listcomp",
          4188,
          4188,
          4188,
          96,
          4188,
          111,
          4188,
          40,
          4188,
          111
        ]
      ],
      "transformers/examples/pytorch/question-answering/utils_qa.py": [
        [
          "postprocess_qa_predictions",
          31,
          249,
          224,
          16,
          224,
          40,
          224,
          16,
          224,
          40
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          418,
          16,
          418,
          40,
          418,
          16,
          418,
          40
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "get_video_processor_dict",
          611,
          724,
          660,
          20,
          660,
          63,
          659,
          41,
          661,
          56
        ]
      ],
      "transformers/src/transformers/pipelines/__init__.py": [
        [
          "pipeline",
          514,
          1094,
          1009,
          28,
          1009,
          52,
          1009,
          42,
          1009,
          52
        ]
      ],
      "transformers/utils/check_doctest_list.py": [
        [
          "clean_doctest_list",
          44,
          76,
          60,
          45,
          60,
          63,
          60,
          45,
          60,
          63
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "check_model_list",
          442,
          470,
          455,
          12,
          455,
          35,
          454,
          21,
          455,
          35
        ],
        [
          "get_model_test_files",
          565,
          597,
          585,
          12,
          585,
          27,
          583,
          9,
          585,
          27
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1052,
          8,
          1052,
          62,
          1052,
          8,
          1052,
          62
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "_get_config_dict",
          669,
          760,
          698,
          20,
          698,
          63,
          696,
          41,
          699,
          81
        ]
      ],
      "transformers/src/transformers/models/align/convert_align_tf_to_hf.py": [
        [
          "convert_align_checkpoint",
          288,
          367,
          357,
          16,
          357,
          54,
          357,
          16,
          357,
          54
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "convert_convnextv2_checkpoint",
          144,
          262,
          223,
          16,
          223,
          54,
          221,
          9,
          223,
          54
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "convert_efficientnet_checkpoint",
          250,
          317,
          306,
          16,
          306,
          54,
          306,
          16,
          306,
          54
        ]
      ],
      "transformers/src/transformers/models/gemma2/convert_gemma2_weights_to_hf.py": [
        [
          "write_model",
          84,
          158,
          92,
          8,
          92,
          37,
          84,
          17,
          92,
          37
        ]
      ],
      "transformers/src/transformers/models/hubert/convert_hubert_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_hubert_checkpoint",
          183,
          246,
          205,
          20,
          205,
          58,
          196,
          27,
          205,
          58
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "extract_nemotron_tokenizer",
          298,
          327,
          313,
          14,
          313,
          37,
          313,
          14,
          313,
          37
        ]
      ],
      "transformers/src/transformers/models/owlv2/convert_owlv2_to_hf.py": [
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          367,
          16,
          367,
          54,
          365,
          9,
          367,
          54
        ]
      ],
      "transformers/src/transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          223,
          290,
          265,
          20,
          265,
          58,
          254,
          27,
          265,
          58
        ]
      ],
      "transformers/src/transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          235,
          302,
          277,
          20,
          277,
          58,
          266,
          27,
          277,
          58
        ]
      ],
      "transformers/src/transformers/models/superpoint/convert_superpoint_to_pytorch.py": [
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          141,
          16,
          141,
          54,
          139,
          9,
          141,
          54
        ]
      ],
      "transformers/src/transformers/models/unispeech/convert_unispeech_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_unispeech_checkpoint",
          190,
          258,
          212,
          20,
          212,
          58,
          203,
          27,
          212,
          58
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_conformer/convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_conformer_checkpoint",
          220,
          294,
          245,
          20,
          245,
          58,
          236,
          27,
          245,
          58
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          274,
          358,
          309,
          20,
          309,
          58,
          300,
          27,
          309,
          58
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "build_model",
          745,
          768,
          755,
          8,
          755,
          42,
          745,
          17,
          755,
          42
        ],
        [
          "build_composite_models",
          834,
          956,
          935,
          16,
          935,
          52,
          935,
          30,
          935,
          52
        ],
        [
          "build_composite_models",
          834,
          956,
          937,
          16,
          937,
          52,
          937,
          30,
          937,
          52
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "format_mrpc",
          57,
          106,
          60,
          12,
          60,
          34,
          57,
          17,
          60,
          34
        ],
        [
          "download_diagnostic",
          109,
          116,
          111,
          12,
          111,
          62,
          109,
          25,
          111,
          62
        ],
        [
          "main",
          132,
          156,
          146,
          12,
          146,
          39,
          132,
          10,
          146,
          39
        ]
      ],
      "transformers/utils/extract_warnings.py": [
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          43,
          20,
          43,
          43,
          41,
          13,
          43,
          43
        ],
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          53,
          28,
          53,
          50,
          53,
          42,
          53,
          50
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_cached_module_file",
          316,
          485,
          390,
          16,
          390,
          59,
          389,
          37,
          391,
          15
        ],
        [
          "resolve_trust_remote_code",
          694,
          776,
          724,
          14,
          724,
          38,
          724,
          14,
          724,
          38
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "get_feature_extractor_dict",
          417,
          529,
          463,
          20,
          463,
          63,
          462,
          41,
          464,
          55
        ],
        [
          "get_feature_extractor_dict",
          417,
          529,
          464,
          12,
          464,
          55,
          462,
          41,
          464,
          55
        ]
      ],
      "transformers/examples/legacy/seq2seq/finetune_trainer.py": [
        [
          "main",
          157,
          366,
          314,
          57,
          314,
          100,
          311,
          9,
          314,
          100
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "get_errors_from_single_artifact",
          112,
          156,
          120,
          20,
          120,
          42,
          119,
          13,
          120,
          42
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_last_daily_ci_reports",
          123,
          159,
          153,
          24,
          153,
          47,
          151,
          17,
          153,
          47
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          704,
          14,
          704,
          49,
          701,
          29,
          707,
          14
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "cached_files",
          319,
          579,
          420,
          12,
          420,
          41,
          419,
          9,
          420,
          41
        ],
        [
          "cached_files",
          319,
          579,
          433,
          8,
          433,
          37,
          433,
          8,
          433,
          37
        ],
        [
          "has_file",
          609,
          701,
          644,
          8,
          644,
          34,
          644,
          8,
          644,
          34
        ],
        [
          "listcomp",
          784,
          785,
          787,
          64,
          787,
          106,
          787,
          64,
          787,
          106
        ],
        [
          "_upload_modified_files",
          750,
          827,
          793,
          16,
          793,
          61,
          792,
          13,
          793,
          61
        ],
        [
          "push_to_hub",
          829,
          975,
          921,
          16,
          921,
          47,
          921,
          16,
          921,
          47
        ],
        [
          "push_to_hub",
          829,
          975,
          947,
          32,
          947,
          57,
          947,
          32,
          947,
          24
        ],
        [
          "get_checkpoint_shard_files",
          1011,
          1078,
          1058,
          8,
          1058,
          51,
          1049,
          10,
          1058,
          51
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "get_image_processor_dict",
          264,
          382,
          316,
          20,
          316,
          63,
          315,
          41,
          317,
          55
        ],
        [
          "get_image_processor_dict",
          264,
          382,
          317,
          12,
          317,
          55,
          315,
          41,
          317,
          55
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          187,
          226,
          194,
          12,
          194,
          34,
          187,
          18,
          194,
          43
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2178,
          35,
          2178,
          77,
          2178,
          35,
          2178,
          77
        ],
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2181,
          18,
          2181,
          58,
          2181,
          18,
          2181,
          58
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "save_pretrained",
          114,
          123,
          116,
          12,
          116,
          48,
          114,
          25,
          116,
          48
        ],
        [
          "from_pretrained",
          126,
          217,
          179,
          20,
          179,
          63,
          179,
          20,
          180,
          56
        ],
        [
          "from_trainer",
          540,
          615,
          574,
          21,
          574,
          69,
          574,
          21,
          574,
          69
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "_get_resolved_checkpoint_files",
          912,
          1178,
          937,
          20,
          937,
          63,
          936,
          41,
          938,
          19
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "listcomp",
          1560,
          1560,
          1560,
          68,
          1560,
          83,
          1560,
          47,
          1560,
          83
        ],
        [
          "listcomp",
          1561,
          1561,
          1561,
          75,
          1561,
          116,
          1561,
          44,
          1561,
          116
        ]
      ],
      "transformers/src/transformers/utils/peft_utils.py": [
        [
          "find_adapter_config_file",
          29,
          100,
          79,
          10,
          79,
          32,
          79,
          10,
          79,
          32
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py": [
        [
          "from_pretrained",
          121,
          189,
          155,
          12,
          155,
          55,
          121,
          25,
          155,
          55
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "get_processor_dict",
          899,
          1149,
          939,
          20,
          939,
          63,
          938,
          41,
          940,
          55
        ],
        [
          "get_processor_dict",
          899,
          1149,
          940,
          12,
          940,
          55,
          938,
          41,
          940,
          55
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/retrieval_realm.py": [
        [
          "from_pretrained",
          101,
          120,
          102,
          12,
          102,
          55,
          101,
          25,
          102,
          55
        ]
      ],
      "transformers/src/transformers/models/rag/retrieval_rag.py": [
        [
          "_resolve_path",
          115,
          131,
          116,
          20,
          116,
          44,
          115,
          23,
          119,
          47
        ]
      ],
      "transformers/examples/pytorch/audio-classification/run_audio_classification.py": [
        [
          "main",
          208,
          435,
          250,
          8,
          250,
          46,
          232,
          17,
          250,
          46
        ]
      ],
      "transformers/examples/pytorch/contrastive-image-text/run_clip.py": [
        [
          "main",
          236,
          533,
          276,
          8,
          276,
          46,
          261,
          17,
          276,
          46
        ],
        [
          "main",
          236,
          533,
          519,
          8,
          519,
          36,
          517,
          22,
          519,
          36
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          326,
          8,
          326,
          46,
          310,
          17,
          326,
          46
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm.py": [
        [
          "main",
          282,
          720,
          322,
          8,
          322,
          46,
          306,
          17,
          322,
          46
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim.py": [
        [
          "main",
          309,
          854,
          349,
          8,
          349,
          46,
          333,
          17,
          349,
          46
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          271,
          8,
          271,
          46,
          255,
          17,
          271,
          46
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "main",
          191,
          445,
          230,
          8,
          230,
          46,
          215,
          17,
          230,
          46
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          203,
          8,
          203,
          46,
          202,
          23,
          203,
          46
        ],
        [
          "main",
          188,
          529,
          464,
          14,
          464,
          57,
          464,
          14,
          464,
          57
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "main",
          197,
          364,
          334,
          62,
          334,
          105,
          334,
          62,
          334,
          105
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation.py": [
        [
          "find_last_checkpoint",
          331,
          350,
          337,
          10,
          337,
          48,
          337,
          10,
          337,
          48
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mae.py": [
        [
          "main",
          183,
          403,
          222,
          8,
          222,
          46,
          207,
          17,
          222,
          46
        ]
      ],
      "transformers/examples/legacy/multiple_choice/run_multiple_choice.py": [
        [
          "main",
          90,
          234,
          209,
          57,
          209,
          100,
          208,
          9,
          209,
          100
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim.py": [
        [
          "main",
          247,
          483,
          286,
          8,
          286,
          46,
          271,
          17,
          286,
          46
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm.py": [
        [
          "main",
          254,
          678,
          295,
          8,
          295,
          46,
          278,
          17,
          295,
          46
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          260,
          57,
          260,
          100,
          259,
          9,
          260,
          100
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          268,
          8,
          268,
          46,
          252,
          17,
          268,
          46
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection.py": [
        [
          "main",
          339,
          534,
          380,
          10,
          380,
          48,
          380,
          10,
          380,
          48
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_plm.py": [
        [
          "main",
          234,
          575,
          274,
          8,
          274,
          46,
          258,
          17,
          274,
          46
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa.py": [
        [
          "main",
          227,
          701,
          267,
          8,
          267,
          46,
          251,
          17,
          267,
          46
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search.py": [
        [
          "main",
          225,
          728,
          265,
          8,
          265,
          46,
          249,
          17,
          265,
          46
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          226,
          8,
          226,
          46,
          211,
          17,
          226,
          46
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          434,
          8,
          434,
          46,
          433,
          23,
          434,
          46
        ],
        [
          "main",
          419,
          839,
          786,
          14,
          786,
          57,
          786,
          14,
          786,
          57
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_seq2seq_qa.py": [
        [
          "main",
          272,
          729,
          312,
          8,
          312,
          46,
          296,
          17,
          312,
          46
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad_trainer.py": [
        [
          "main",
          65,
          176,
          170,
          57,
          170,
          100,
          169,
          9,
          170,
          100
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py": [
        [
          "main",
          302,
          657,
          345,
          8,
          345,
          46,
          341,
          5,
          345,
          46
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          411,
          8,
          411,
          46,
          410,
          23,
          411,
          46
        ],
        [
          "main",
          396,
          837,
          778,
          14,
          778,
          57,
          778,
          14,
          778,
          57
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag.py": [
        [
          "main",
          178,
          442,
          218,
          8,
          218,
          46,
          202,
          17,
          218,
          46
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          379,
          8,
          379,
          46,
          378,
          23,
          379,
          46
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          327,
          8,
          327,
          46,
          326,
          23,
          327,
          46
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_xnli.py": [
        [
          "main",
          194,
          461,
          229,
          8,
          229,
          46,
          213,
          17,
          229,
          46
        ]
      ],
      "transformers/tests/deepspeed/test_deepspeed.py": [
        [
          "check_saved_checkpoints_deepspeed",
          805,
          833,
          821,
          29,
          821,
          53,
          819,
          13,
          823,
          37
        ]
      ],
      "transformers/tests/fsdp/test_fsdp.py": [
        [
          "test_accelerate_fsdp2_integration",
          353,
          394,
          376,
          24,
          376,
          48,
          353,
          43,
          376,
          48
        ],
        [
          "test_training_and_can_resume_normally",
          297,
          329,
          311,
          24,
          311,
          48,
          297,
          47,
          311,
          48
        ],
        [
          "genexpr",
          314,
          314,
          316,
          20,
          316,
          71,
          315,
          21,
          316,
          71
        ],
        [
          "genexpr",
          379,
          379,
          381,
          20,
          381,
          71,
          380,
          21,
          381,
          71
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_cached_file",
          44,
          62,
          47,
          25,
          47,
          48,
          44,
          26,
          49,
          55
        ],
        [
          "test_cached_file",
          44,
          62,
          50,
          29,
          50,
          77,
          49,
          13,
          50,
          78
        ]
      ]
    },
    "pathlib.Path.open": {
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template_file_priority",
          1734,
          1747,
          1743,
          26,
          1743,
          76,
          1738,
          13,
          1747,
          78
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "get_char_lens",
          164,
          165,
          165,
          33,
          165,
          54,
          164,
          23,
          165,
          67
        ],
        [
          "write_txt_file",
          631,
          635,
          632,
          9,
          632,
          28,
          631,
          20,
          633,
          25
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "remap_model_yaml_config",
          88,
          101,
          89,
          10,
          89,
          59,
          88,
          29,
          97,
          66
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_hifigan.py": [
        [
          "remap_hifigan_yaml_config",
          62,
          89,
          63,
          10,
          63,
          59,
          62,
          31,
          68,
          42
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "fetch_test_set",
          322,
          333,
          326,
          11,
          326,
          28,
          322,
          20,
          330,
          52
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_seq2seq_examples.py": [
        [
          "_dump_articles",
          33,
          35,
          35,
          5,
          35,
          24,
          33,
          20,
          35,
          44
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_datasets.py": [
        [
          "_dump_articles",
          41,
          43,
          43,
          5,
          43,
          24,
          41,
          20,
          43,
          44
        ]
      ],
      "transformers/examples/legacy/seq2seq/pack_dataset.py": [
        [
          "pack_data_dir",
          58,
          72,
          67,
          9,
          67,
          53,
          61,
          9,
          68,
          82
        ],
        [
          "pack_data_dir",
          58,
          72,
          68,
          9,
          68,
          53,
          61,
          9,
          68,
          82
        ],
        [
          "pack_data_dir",
          58,
          72,
          63,
          41,
          63,
          61,
          61,
          9,
          68,
          82
        ],
        [
          "pack_data_dir",
          58,
          72,
          64,
          41,
          64,
          61,
          61,
          9,
          68,
          82
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval.py": [
        [
          "generate_summaries_or_translations",
          37,
          78,
          49,
          12,
          49,
          53,
          38,
          5,
          52,
          11
        ]
      ]
    },
    "shutil.move": {
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_local_versioning",
          211,
          236,
          230,
          13,
          230,
          118,
          211,
          31,
          236,
          77
        ]
      ],
      "transformers/tests/utils/test_configuration_utils.py": [
        [
          "test_local_versioning",
          237,
          257,
          255,
          13,
          255,
          112,
          237,
          31,
          257,
          64
        ]
      ]
    },
    "pathlib.Path.glob": {
      "transformers/tests/models/marian/test_tokenization_marian.py": [
        [
          "test_tokenizer_equivalence_en_de",
          91,
          102,
          100,
          37,
          100,
          60,
          91,
          42,
          102,
          49
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "check_checkpoint_deletion",
          4081,
          4088,
          4086,
          45,
          4086,
          95,
          4085,
          9,
          4088,
          55
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "from_pretrained",
          1859,
          2128,
          2052,
          50,
          2052,
          77,
          2052,
          50,
          2052,
          77
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_sorted_checkpoints",
          4183,
          4218,
          4188,
          45,
          4188,
          91,
          4184,
          9,
          4190,
          36
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "find_all_documented_objects",
          914,
          939,
          925,
          21,
          925,
          53,
          915,
          5,
          925,
          53
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "find_model_file",
          112,
          117,
          113,
          24,
          113,
          51,
          112,
          21,
          114,
          28
        ],
        [
          "find_vocab_file",
          384,
          385,
          385,
          17,
          385,
          44,
          384,
          21,
          385,
          48
        ],
        [
          "find_src_vocab_file",
          388,
          389,
          389,
          17,
          389,
          48,
          388,
          25,
          389,
          52
        ],
        [
          "find_tgt_vocab_file",
          392,
          393,
          393,
          17,
          393,
          48,
          392,
          25,
          393,
          52
        ]
      ],
      "transformers/src/transformers/models/mask2former/convert_mask2former_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "using_dirs",
          825,
          844,
          826,
          35,
          826,
          66,
          825,
          20,
          828,
          37
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "using_dirs",
          547,
          555,
          548,
          35,
          548,
          66,
          547,
          20,
          550,
          37
        ]
      ],
      "transformers/src/transformers/models/oneformer/convert_to_hf_oneformer.py": [
        [
          "using_dirs",
          925,
          933,
          926,
          35,
          926,
          66,
          925,
          20,
          928,
          37
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "_objective",
          318,
          354,
          339,
          40,
          339,
          93,
          336,
          39,
          340,
          88
        ],
        [
          "setup",
          822,
          946,
          934,
          30,
          934,
          53,
          926,
          45,
          934,
          53
        ],
        [
          "on_train_end",
          959,
          1001,
          997,
          26,
          997,
          49,
          989,
          21,
          997,
          49
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "get_processor_dict",
          899,
          1149,
          963,
          42,
          963,
          69,
          963,
          42,
          963,
          69
        ]
      ],
      "transformers/utils/release.py": [
        [
          "remove_conversion_scripts",
          135,
          143,
          142,
          35,
          142,
          66,
          136,
          5,
          142,
          67
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "discover_benchmarks",
          51,
          101,
          64,
          20,
          64,
          44,
          64,
          20,
          64,
          44
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_distributed_eval.py": [
        [
          "run_generate",
          119,
          227,
          168,
          31,
          168,
          63,
          166,
          21,
          169,
          25
        ],
        [
          "gather_results_from_each_node",
          240,
          256,
          246,
          27,
          246,
          54,
          246,
          22,
          247,
          41
        ]
      ]
    },
    "os.remove": {
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          95,
          13,
          95,
          31,
          93,
          13,
          99,
          43
        ],
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          95,
          13,
          95,
          31,
          95,
          13,
          95,
          31
        ],
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          111,
          13,
          111,
          39,
          111,
          13,
          111,
          39
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          714,
          9,
          714,
          31,
          712,
          22,
          727,
          60
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "remove_dummy_checkpoint",
          996,
          1001,
          1001,
          17,
          1001,
          31,
          1001,
          17,
          1001,
          31
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "fetch_test_set",
          322,
          333,
          332,
          5,
          332,
          20,
          332,
          5,
          333,
          31
        ],
        [
          "download_and_unzip",
          652,
          660,
          660,
          5,
          660,
          23,
          654,
          16,
          660,
          23
        ]
      ],
      "transformers/src/transformers/convert_slow_tokenizers_checkpoints_to_fast.py": [
        [
          "convert_slow_checkpoint_to_fast",
          37,
          98,
          97,
          21,
          97,
          40,
          97,
          21,
          98,
          59
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "download_and_extract",
          47,
          54,
          53,
          5,
          53,
          24,
          47,
          26,
          54,
          25
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "save_pretrained",
          3648,
          4088,
          4005,
          17,
          4005,
          40,
          4005,
          17,
          4005,
          40
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_seq2seq_examples.py": [
        [
          "test_run_eval_search",
          87,
          132,
          132,
          13,
          132,
          45,
          131,
          13,
          132,
          45
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          563,
          21,
          563,
          41,
          563,
          31,
          563,
          41
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          562,
          21,
          562,
          41,
          562,
          31,
          562,
          41
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "test_load_img_base64_prefix",
          741,
          756,
          754,
          13,
          754,
          31,
          751,
          17,
          756,
          52
        ],
        [
          "test_load_img_base64_prefix",
          741,
          756,
          754,
          13,
          754,
          31,
          754,
          13,
          754,
          31
        ],
        [
          "test_load_img_base64",
          758,
          773,
          771,
          13,
          771,
          31,
          768,
          17,
          773,
          52
        ],
        [
          "test_load_img_base64",
          758,
          773,
          771,
          13,
          771,
          31,
          771,
          13,
          771,
          31
        ],
        [
          "test_load_img_base64_encoded_bytes",
          775,
          790,
          788,
          13,
          788,
          31,
          785,
          17,
          790,
          54
        ],
        [
          "test_load_img_base64_encoded_bytes",
          775,
          790,
          788,
          13,
          788,
          31,
          788,
          13,
          788,
          31
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "run_distributed_test",
          238,
          274,
          274,
          9,
          274,
          27,
          238,
          30,
          274,
          27
        ]
      ]
    },
    "os.path.basename": {
      "transformers/tests/extended/test_trainer_ext.py": [
        [
          "setcomp",
          160,
          160,
          160,
          21,
          160,
          39,
          160,
          45,
          160,
          39
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_modified_cards",
          37,
          51,
          47,
          47,
          47,
          68,
          47,
          30,
          48,
          61
        ],
        [
          "get_paper_link",
          54,
          91,
          60,
          18,
          60,
          44,
          59,
          5,
          70,
          26
        ],
        [
          "replace_paper_links",
          139,
          177,
          145,
          18,
          145,
          44,
          139,
          25,
          155,
          31
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "get_generation_parameterization",
          477,
          503,
          487,
          28,
          487,
          67,
          486,
          27,
          488,
          33
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          98,
          23,
          98,
          52,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          120,
          17,
          120,
          50,
          92,
          5,
          137,
          22
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "listcomp",
          80,
          80,
          80,
          36,
          80,
          54,
          80,
          60,
          80,
          54
        ],
        [
          "listcomp",
          137,
          137,
          137,
          30,
          137,
          48,
          137,
          54,
          137,
          48
        ],
        [
          "listcomp",
          144,
          144,
          144,
          30,
          144,
          48,
          144,
          54,
          144,
          48
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_download",
          147,
          182,
          149,
          16,
          149,
          36,
          147,
          15,
          154,
          38
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_cached_module_file",
          316,
          485,
          392,
          43,
          392,
          89,
          392,
          21,
          402,
          42
        ],
        [
          "get_cached_module_file",
          316,
          485,
          428,
          43,
          428,
          89,
          402,
          9,
          428,
          90
        ],
        [
          "get_cached_module_file",
          316,
          485,
          428,
          43,
          428,
          89,
          422,
          22,
          428,
          90
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "push_index_to_hub",
          290,
          301,
          298,
          30,
          298,
          52,
          294,
          13,
          301,
          13
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "convert_modular_file",
          1686,
          1715,
          1707,
          61,
          1707,
          91,
          1702,
          33,
          1711,
          28
        ]
      ],
      "transformers/utils/process_test_artifacts.py": [
        [
          "process_artifacts",
          47,
          69,
          56,
          36,
          56,
          65,
          56,
          19,
          61,
          42
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          587,
          20,
          587,
          64,
          586,
          31,
          587,
          16
        ],
        [
          "main",
          268,
          722,
          594,
          20,
          594,
          52,
          590,
          37,
          594,
          16
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          532,
          20,
          532,
          64,
          531,
          31,
          532,
          16
        ],
        [
          "main",
          235,
          692,
          539,
          20,
          539,
          52,
          535,
          37,
          539,
          16
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          785,
          20,
          785,
          64,
          784,
          31,
          785,
          16
        ],
        [
          "main",
          328,
          911,
          792,
          20,
          792,
          52,
          788,
          37,
          792,
          16
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "main",
          234,
          650,
          500,
          20,
          500,
          64,
          499,
          31,
          500,
          16
        ],
        [
          "main",
          234,
          650,
          507,
          20,
          507,
          52,
          503,
          37,
          507,
          16
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "main",
          413,
          747,
          593,
          20,
          593,
          64,
          592,
          31,
          593,
          16
        ],
        [
          "main",
          413,
          747,
          600,
          20,
          600,
          52,
          596,
          37,
          600,
          16
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          675,
          20,
          675,
          64,
          674,
          31,
          675,
          16
        ],
        [
          "main",
          384,
          804,
          682,
          20,
          682,
          52,
          678,
          37,
          682,
          16
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          624,
          20,
          624,
          64,
          623,
          31,
          624,
          16
        ],
        [
          "main",
          275,
          760,
          631,
          20,
          631,
          52,
          627,
          37,
          631,
          16
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          684,
          20,
          684,
          64,
          683,
          31,
          684,
          16
        ],
        [
          "main",
          284,
          835,
          691,
          20,
          691,
          52,
          687,
          37,
          691,
          16
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection_no_trainer.py": [
        [
          "main",
          411,
          796,
          642,
          20,
          642,
          64,
          641,
          31,
          642,
          16
        ],
        [
          "main",
          411,
          796,
          649,
          20,
          649,
          52,
          645,
          37,
          649,
          16
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          826,
          20,
          826,
          64,
          825,
          31,
          826,
          16
        ],
        [
          "main",
          299,
          1057,
          833,
          20,
          833,
          52,
          829,
          37,
          833,
          16
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "main",
          253,
          637,
          471,
          20,
          471,
          64,
          470,
          31,
          471,
          16
        ],
        [
          "main",
          253,
          637,
          478,
          20,
          478,
          52,
          474,
          37,
          478,
          16
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "main",
          338,
          1035,
          843,
          20,
          843,
          64,
          842,
          31,
          843,
          16
        ],
        [
          "main",
          338,
          1035,
          850,
          20,
          850,
          52,
          846,
          37,
          850,
          16
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          522,
          20,
          522,
          64,
          521,
          31,
          522,
          16
        ],
        [
          "main",
          238,
          654,
          529,
          20,
          529,
          52,
          525,
          37,
          529,
          16
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          654,
          20,
          654,
          64,
          653,
          31,
          654,
          16
        ],
        [
          "main",
          339,
          809,
          661,
          20,
          661,
          52,
          657,
          37,
          661,
          16
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          631,
          20,
          631,
          64,
          630,
          31,
          631,
          16
        ],
        [
          "main",
          329,
          796,
          638,
          20,
          638,
          52,
          634,
          37,
          638,
          16
        ]
      ],
      "transformers/tests/models/encodec/test_modeling_encodec.py": [
        [
          "listcomp",
          1205,
          1206,
          1206,
          17,
          1206,
          42,
          1208,
          17,
          1206,
          95
        ],
        [
          "listcomp",
          1272,
          1273,
          1273,
          17,
          1273,
          42,
          1275,
          17,
          1273,
          95
        ]
      ]
    },
    "os.path.abspath": {
      "transformers/tests/trainer/test_trainer.py": [
        [
          "test_auto_batch_size_finder",
          3493,
          3524,
          3497,
          19,
          3499,
          9,
          3497,
          19,
          3524,
          27
        ],
        [
          "test_end_to_end_example",
          4443,
          4485,
          4445,
          23,
          4449,
          9,
          4443,
          33,
          4485,
          45
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "save_vocabulary",
          302,
          317,
          310,
          12,
          310,
          43,
          307,
          30,
          310,
          78
        ],
        [
          "save_vocabulary",
          302,
          317,
          310,
          48,
          310,
          78,
          307,
          30,
          310,
          78
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert_fast.py": [
        [
          "save_vocabulary",
          158,
          175,
          172,
          12,
          172,
          43,
          169,
          30,
          172,
          78
        ],
        [
          "save_vocabulary",
          158,
          175,
          172,
          48,
          172,
          78,
          169,
          30,
          172,
          78
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez.py": [
        [
          "save_vocabulary",
          273,
          288,
          281,
          12,
          281,
          43,
          278,
          30,
          281,
          78
        ],
        [
          "save_vocabulary",
          273,
          288,
          281,
          48,
          281,
          78,
          278,
          30,
          281,
          78
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez_fast.py": [
        [
          "save_vocabulary",
          173,
          190,
          187,
          12,
          187,
          43,
          184,
          30,
          187,
          78
        ],
        [
          "save_vocabulary",
          173,
          190,
          187,
          48,
          187,
          78,
          184,
          30,
          187,
          78
        ]
      ],
      "transformers/src/transformers/models/bartpho/tokenization_bartpho.py": [
        [
          "save_vocabulary",
          286,
          315,
          298,
          12,
          298,
          43,
          295,
          14,
          298,
          78
        ],
        [
          "save_vocabulary",
          286,
          315,
          298,
          48,
          298,
          78,
          295,
          14,
          298,
          78
        ],
        [
          "save_vocabulary",
          286,
          315,
          305,
          12,
          305,
          55,
          305,
          12,
          307,
          9
        ],
        [
          "save_vocabulary",
          286,
          315,
          305,
          60,
          307,
          9,
          305,
          12,
          307,
          9
        ]
      ],
      "transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py": [
        [
          "save_vocabulary",
          159,
          174,
          167,
          12,
          167,
          43,
          164,
          30,
          167,
          78
        ],
        [
          "save_vocabulary",
          159,
          174,
          167,
          48,
          167,
          78,
          164,
          30,
          167,
          78
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "get_tests_dir",
          1522,
          1542,
          1534,
          17,
          1534,
          64,
          1522,
          19,
          1534,
          13
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "save_vocabulary",
          233,
          248,
          241,
          12,
          241,
          43,
          238,
          30,
          241,
          78
        ],
        [
          "save_vocabulary",
          233,
          248,
          241,
          48,
          241,
          78,
          238,
          30,
          241,
          78
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "save_vocabulary",
          373,
          394,
          384,
          12,
          384,
          43,
          381,
          30,
          384,
          78
        ],
        [
          "save_vocabulary",
          373,
          394,
          384,
          48,
          384,
          78,
          381,
          30,
          384,
          78
        ],
        [
          "save_vocabulary",
          373,
          394,
          391,
          12,
          391,
          44,
          391,
          12,
          391,
          79
        ],
        [
          "save_vocabulary",
          373,
          394,
          391,
          49,
          391,
          79,
          391,
          12,
          391,
          79
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird_fast.py": [
        [
          "save_vocabulary",
          178,
          195,
          192,
          12,
          192,
          43,
          189,
          30,
          192,
          78
        ],
        [
          "save_vocabulary",
          178,
          195,
          192,
          48,
          192,
          78,
          189,
          30,
          192,
          78
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert.py": [
        [
          "save_vocabulary",
          229,
          244,
          237,
          12,
          237,
          43,
          234,
          30,
          237,
          78
        ],
        [
          "save_vocabulary",
          229,
          244,
          237,
          48,
          237,
          78,
          234,
          30,
          237,
          78
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert_fast.py": [
        [
          "save_vocabulary",
          177,
          194,
          191,
          12,
          191,
          43,
          188,
          30,
          191,
          78
        ],
        [
          "save_vocabulary",
          177,
          194,
          191,
          48,
          191,
          78,
          188,
          30,
          191,
          78
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama.py": [
        [
          "save_vocabulary",
          331,
          356,
          349,
          12,
          349,
          43,
          346,
          30,
          349,
          78
        ],
        [
          "save_vocabulary",
          331,
          356,
          349,
          48,
          349,
          78,
          346,
          30,
          349,
          78
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama_fast.py": [
        [
          "save_vocabulary",
          326,
          343,
          340,
          12,
          340,
          43,
          337,
          30,
          340,
          78
        ],
        [
          "save_vocabulary",
          326,
          343,
          340,
          48,
          340,
          78,
          337,
          30,
          340,
          78
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "save_vocabulary",
          327,
          342,
          335,
          12,
          335,
          43,
          332,
          30,
          335,
          78
        ],
        [
          "save_vocabulary",
          327,
          342,
          335,
          48,
          335,
          78,
          332,
          30,
          335,
          78
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm_fast.py": [
        [
          "save_vocabulary",
          205,
          222,
          219,
          12,
          219,
          43,
          216,
          30,
          219,
          78
        ],
        [
          "save_vocabulary",
          205,
          222,
          219,
          48,
          219,
          78,
          216,
          30,
          219,
          78
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          186,
          12,
          186,
          43,
          183,
          30,
          186,
          78
        ],
        [
          "save_vocabulary",
          172,
          189,
          186,
          48,
          186,
          78,
          183,
          30,
          186,
          78
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet_fast.py": [
        [
          "save_vocabulary",
          141,
          152,
          149,
          12,
          149,
          43,
          146,
          30,
          149,
          78
        ],
        [
          "save_vocabulary",
          141,
          152,
          149,
          48,
          149,
          78,
          146,
          30,
          149,
          78
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "save_vocabulary",
          296,
          311,
          304,
          12,
          304,
          43,
          301,
          30,
          304,
          78
        ],
        [
          "save_vocabulary",
          296,
          311,
          304,
          48,
          304,
          78,
          301,
          30,
          304,
          78
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma.py": [
        [
          "save_vocabulary",
          197,
          222,
          215,
          12,
          215,
          43,
          212,
          30,
          215,
          78
        ],
        [
          "save_vocabulary",
          197,
          222,
          215,
          48,
          215,
          78,
          212,
          30,
          215,
          78
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma_fast.py": [
        [
          "save_vocabulary",
          163,
          180,
          177,
          12,
          177,
          43,
          174,
          30,
          177,
          78
        ],
        [
          "save_vocabulary",
          163,
          180,
          177,
          48,
          177,
          78,
          174,
          30,
          177,
          78
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "save_vocabulary",
          236,
          251,
          244,
          12,
          244,
          43,
          241,
          30,
          244,
          78
        ],
        [
          "save_vocabulary",
          236,
          251,
          244,
          48,
          244,
          78,
          241,
          30,
          244,
          78
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm.py": [
        [
          "save_vocabulary",
          421,
          436,
          429,
          12,
          429,
          43,
          426,
          30,
          429,
          78
        ],
        [
          "save_vocabulary",
          421,
          436,
          429,
          48,
          429,
          78,
          426,
          30,
          429,
          78
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama_fast.py": [
        [
          "save_vocabulary",
          218,
          235,
          232,
          12,
          232,
          43,
          229,
          30,
          232,
          78
        ],
        [
          "save_vocabulary",
          218,
          235,
          232,
          48,
          232,
          78,
          229,
          30,
          232,
          78
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm_fast.py": [
        [
          "save_vocabulary",
          794,
          811,
          808,
          12,
          808,
          43,
          805,
          30,
          808,
          78
        ],
        [
          "save_vocabulary",
          794,
          811,
          808,
          48,
          808,
          78,
          805,
          30,
          808,
          78
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama.py": [
        [
          "save_vocabulary",
          306,
          331,
          324,
          12,
          324,
          43,
          321,
          30,
          324,
          78
        ],
        [
          "save_vocabulary",
          306,
          331,
          324,
          48,
          324,
          78,
          321,
          30,
          324,
          78
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "save_vocabulary",
          287,
          330,
          321,
          16,
          321,
          45,
          319,
          34,
          321,
          79
        ],
        [
          "save_vocabulary",
          287,
          330,
          321,
          50,
          321,
          79,
          319,
          34,
          321,
          79
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart.py": [
        [
          "save_vocabulary",
          294,
          309,
          302,
          12,
          302,
          43,
          299,
          30,
          302,
          78
        ],
        [
          "save_vocabulary",
          294,
          309,
          302,
          48,
          302,
          78,
          299,
          30,
          302,
          78
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50.py": [
        [
          "save_vocabulary",
          242,
          257,
          250,
          12,
          250,
          43,
          247,
          30,
          250,
          78
        ],
        [
          "save_vocabulary",
          242,
          257,
          250,
          48,
          250,
          78,
          247,
          30,
          250,
          78
        ]
      ],
      "transformers/src/transformers/models/m2m_100/tokenization_m2m_100.py": [
        [
          "save_vocabulary",
          295,
          315,
          308,
          12,
          308,
          41,
          303,
          14,
          308,
          75
        ],
        [
          "save_vocabulary",
          295,
          315,
          308,
          46,
          308,
          75,
          303,
          14,
          308,
          75
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50_fast.py": [
        [
          "save_vocabulary",
          238,
          255,
          252,
          12,
          252,
          43,
          249,
          30,
          252,
          78
        ],
        [
          "save_vocabulary",
          238,
          255,
          252,
          48,
          252,
          78,
          249,
          30,
          252,
          78
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart_fast.py": [
        [
          "save_vocabulary",
          249,
          266,
          263,
          12,
          263,
          43,
          260,
          30,
          263,
          78
        ],
        [
          "save_vocabulary",
          249,
          266,
          263,
          48,
          263,
          78,
          260,
          30,
          263,
          78
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "save_vocabulary",
          1530,
          1553,
          1539,
          12,
          1539,
          43,
          1536,
          30,
          1539,
          78
        ],
        [
          "save_vocabulary",
          1530,
          1553,
          1539,
          48,
          1539,
          78,
          1536,
          30,
          1539,
          78
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb_fast.py": [
        [
          "save_vocabulary",
          307,
          324,
          321,
          12,
          321,
          43,
          318,
          30,
          321,
          78
        ],
        [
          "save_vocabulary",
          307,
          324,
          321,
          48,
          321,
          78,
          318,
          30,
          321,
          78
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb.py": [
        [
          "save_vocabulary",
          332,
          347,
          340,
          12,
          340,
          43,
          337,
          30,
          340,
          78
        ],
        [
          "save_vocabulary",
          332,
          347,
          340,
          48,
          340,
          78,
          337,
          30,
          340,
          78
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus_fast.py": [
        [
          "save_vocabulary",
          195,
          212,
          209,
          12,
          209,
          43,
          206,
          30,
          209,
          78
        ],
        [
          "save_vocabulary",
          195,
          212,
          209,
          48,
          209,
          78,
          206,
          30,
          209,
          78
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus.py": [
        [
          "save_vocabulary",
          274,
          289,
          282,
          12,
          282,
          43,
          279,
          30,
          282,
          78
        ],
        [
          "save_vocabulary",
          274,
          289,
          282,
          48,
          282,
          78,
          279,
          30,
          282,
          78
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "save_vocabulary",
          298,
          319,
          309,
          12,
          309,
          43,
          306,
          30,
          309,
          78
        ],
        [
          "save_vocabulary",
          298,
          319,
          309,
          48,
          309,
          78,
          306,
          30,
          309,
          78
        ],
        [
          "save_vocabulary",
          298,
          319,
          316,
          12,
          316,
          44,
          316,
          12,
          316,
          79
        ],
        [
          "save_vocabulary",
          298,
          319,
          316,
          49,
          316,
          79,
          316,
          12,
          316,
          79
        ]
      ],
      "transformers/src/transformers/models/plbart/tokenization_plbart.py": [
        [
          "save_vocabulary",
          370,
          385,
          378,
          12,
          378,
          43,
          375,
          30,
          378,
          78
        ],
        [
          "save_vocabulary",
          370,
          385,
          378,
          48,
          378,
          78,
          375,
          30,
          378,
          78
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer.py": [
        [
          "save_vocabulary",
          158,
          173,
          166,
          12,
          166,
          43,
          163,
          30,
          166,
          78
        ],
        [
          "save_vocabulary",
          158,
          173,
          166,
          48,
          166,
          78,
          163,
          30,
          166,
          78
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer_fast.py": [
        [
          "save_vocabulary",
          94,
          111,
          108,
          12,
          108,
          43,
          105,
          30,
          108,
          78
        ],
        [
          "save_vocabulary",
          94,
          111,
          108,
          48,
          108,
          78,
          105,
          30,
          108,
          78
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert_fast.py": [
        [
          "save_vocabulary",
          184,
          195,
          192,
          12,
          192,
          43,
          189,
          30,
          192,
          78
        ],
        [
          "save_vocabulary",
          184,
          195,
          192,
          48,
          192,
          78,
          189,
          30,
          192,
          78
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert.py": [
        [
          "save_vocabulary",
          219,
          234,
          227,
          12,
          227,
          43,
          224,
          30,
          227,
          78
        ],
        [
          "save_vocabulary",
          219,
          234,
          227,
          48,
          227,
          78,
          224,
          30,
          227,
          78
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "save_vocabulary",
          362,
          377,
          370,
          12,
          370,
          43,
          367,
          30,
          370,
          78
        ],
        [
          "save_vocabulary",
          362,
          377,
          370,
          48,
          370,
          78,
          367,
          30,
          370,
          78
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t_fast.py": [
        [
          "save_vocabulary",
          320,
          337,
          334,
          12,
          334,
          43,
          331,
          30,
          334,
          78
        ],
        [
          "save_vocabulary",
          320,
          337,
          334,
          48,
          334,
          78,
          331,
          30,
          334,
          78
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t.py": [
        [
          "save_vocabulary",
          497,
          512,
          505,
          12,
          505,
          43,
          502,
          30,
          505,
          78
        ],
        [
          "save_vocabulary",
          497,
          512,
          505,
          48,
          505,
          78,
          502,
          30,
          505,
          78
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/tokenization_speech_to_text.py": [
        [
          "save_vocabulary",
          257,
          276,
          269,
          12,
          269,
          41,
          264,
          14,
          269,
          75
        ],
        [
          "save_vocabulary",
          257,
          276,
          269,
          46,
          269,
          75,
          264,
          14,
          269,
          75
        ]
      ],
      "transformers/src/transformers/models/speecht5/tokenization_speecht5.py": [
        [
          "save_vocabulary",
          205,
          220,
          213,
          12,
          213,
          43,
          210,
          30,
          213,
          78
        ],
        [
          "save_vocabulary",
          205,
          220,
          213,
          48,
          213,
          78,
          210,
          30,
          213,
          78
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "save_vocabulary",
          430,
          445,
          438,
          12,
          438,
          43,
          435,
          30,
          438,
          78
        ],
        [
          "save_vocabulary",
          430,
          445,
          438,
          48,
          438,
          78,
          435,
          30,
          438,
          78
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5_fast.py": [
        [
          "save_vocabulary",
          156,
          174,
          170,
          12,
          170,
          43,
          167,
          30,
          170,
          78
        ],
        [
          "save_vocabulary",
          156,
          174,
          170,
          48,
          170,
          78,
          167,
          30,
          170,
          78
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "save_vocabulary",
          491,
          506,
          499,
          12,
          499,
          43,
          496,
          30,
          499,
          78
        ],
        [
          "save_vocabulary",
          491,
          506,
          499,
          48,
          499,
          78,
          496,
          30,
          499,
          78
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop_fast.py": [
        [
          "save_vocabulary",
          1006,
          1023,
          1020,
          12,
          1020,
          43,
          1017,
          30,
          1020,
          78
        ],
        [
          "save_vocabulary",
          1006,
          1023,
          1020,
          48,
          1020,
          78,
          1017,
          30,
          1020,
          78
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm.py": [
        [
          "save_vocabulary",
          284,
          299,
          292,
          12,
          292,
          43,
          289,
          30,
          292,
          78
        ],
        [
          "save_vocabulary",
          284,
          299,
          292,
          48,
          292,
          78,
          289,
          30,
          292,
          78
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm_fast.py": [
        [
          "save_vocabulary",
          172,
          189,
          186,
          12,
          186,
          43,
          183,
          30,
          186,
          78
        ],
        [
          "save_vocabulary",
          172,
          189,
          186,
          48,
          186,
          78,
          183,
          30,
          186,
          78
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        [
          "save_vocabulary",
          279,
          294,
          287,
          12,
          287,
          43,
          284,
          30,
          287,
          78
        ],
        [
          "save_vocabulary",
          279,
          294,
          287,
          48,
          287,
          78,
          284,
          30,
          287,
          78
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py": [
        [
          "save_vocabulary",
          174,
          191,
          188,
          12,
          188,
          43,
          185,
          30,
          188,
          78
        ],
        [
          "save_vocabulary",
          174,
          191,
          188,
          48,
          188,
          78,
          185,
          30,
          188,
          78
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py": [
        [
          "save_vocabulary",
          283,
          298,
          291,
          12,
          291,
          43,
          288,
          30,
          291,
          78
        ],
        [
          "save_vocabulary",
          283,
          298,
          291,
          48,
          291,
          78,
          288,
          30,
          291,
          78
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet_fast.py": [
        [
          "save_vocabulary",
          210,
          227,
          224,
          12,
          224,
          43,
          221,
          30,
          224,
          78
        ],
        [
          "save_vocabulary",
          210,
          227,
          224,
          48,
          224,
          78,
          221,
          30,
          224,
          78
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "save_vocabulary",
          369,
          384,
          377,
          12,
          377,
          43,
          374,
          30,
          377,
          78
        ],
        [
          "save_vocabulary",
          369,
          384,
          377,
          48,
          377,
          78,
          374,
          30,
          377,
          78
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "__init__",
          421,
          442,
          437,
          23,
          437,
          47,
          437,
          16,
          437,
          48
        ],
        [
          "__init__",
          421,
          442,
          441,
          27,
          441,
          50,
          441,
          20,
          441,
          51
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "save_chat",
          395,
          411,
          411,
          16,
          411,
          40,
          408,
          9,
          411,
          40
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          620,
          21,
          620,
          92,
          608,
          54,
          621,
          37
        ]
      ],
      "transformers/src/transformers/models/bert/convert_bert_original_tf2_checkpoint_to_pytorch.py": [
        [
          "load_tf2_weights_in_bert",
          43,
          210,
          44,
          15,
          44,
          49,
          43,
          30,
          51,
          37
        ]
      ],
      "transformers/src/transformers/models/big_bird/convert_bigbird_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_big_bird",
          50,
          206,
          106,
          15,
          106,
          49,
          99,
          30,
          110,
          70
        ]
      ],
      "transformers/src/transformers/models/canine/convert_canine_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_canine",
          30,
          124,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/byt5/convert_byt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/convbert/convert_convbert_original_tf1_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_convbert",
          31,
          152,
          41,
          15,
          41,
          49,
          34,
          30,
          46,
          32
        ]
      ],
      "transformers/src/transformers/models/electra/convert_electra_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_electra",
          30,
          109,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_funnel",
          31,
          118,
          44,
          15,
          44,
          49,
          37,
          30,
          50,
          32
        ]
      ],
      "transformers/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_gpt2",
          30,
          83,
          42,
          15,
          42,
          51,
          35,
          30,
          48,
          32
        ]
      ],
      "transformers/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": [
        [
          "load_tf_weights_in_gpt_neo",
          32,
          109,
          44,
          15,
          44,
          54,
          37,
          30,
          50,
          32
        ]
      ],
      "transformers/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py": [
        [
          "load_tf_weights_in_imagegpt",
          30,
          138,
          44,
          15,
          44,
          55,
          37,
          30,
          51,
          32
        ]
      ],
      "transformers/src/transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_lxmert",
          30,
          106,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/mobilebert/convert_mobilebert_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_mobilebert",
          28,
          103,
          41,
          15,
          41,
          49,
          34,
          30,
          47,
          32
        ]
      ],
      "transformers/src/transformers/models/myt5/convert_myt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/rembert/convert_rembert_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_rembert",
          30,
          110,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/roformer/convert_roformer_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_roformer",
          30,
          100,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          43,
          15,
          43,
          49,
          36,
          30,
          49,
          32
        ]
      ],
      "transformers/src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_tapas",
          37,
          168,
          55,
          15,
          55,
          49,
          48,
          30,
          61,
          32
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          189,
          23,
          189,
          61,
          189,
          23,
          194,
          39
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          190,
          19,
          190,
          53,
          189,
          23,
          194,
          39
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          205,
          40,
          205,
          81,
          198,
          9,
          209,
          44
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          207,
          45,
          207,
          85,
          198,
          9,
          209,
          44
        ]
      ],
      "transformers/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          222,
          36,
          222,
          77,
          217,
          5,
          226,
          40
        ],
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          224,
          41,
          224,
          81,
          217,
          5,
          226,
          40
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "create_tiny_models",
          1321,
          1431,
          1332,
          18,
          1332,
          76,
          1322,
          5,
          1333,
          32
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "resolve_trust_remote_code",
          694,
          776,
          728,
          31,
          728,
          57,
          726,
          17,
          725,
          25
        ]
      ],
      "transformers/examples/legacy/seq2seq/finetune_trainer.py": [
        [
          "main",
          157,
          366,
          167,
          81,
          167,
          108,
          167,
          48,
          167,
          44
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "convert_modular_file",
          1686,
          1715,
          1703,
          59,
          1703,
          87,
          1702,
          33,
          1711,
          28
        ]
      ],
      "transformers/examples/pytorch/audio-classification/run_audio_classification.py": [
        [
          "main",
          208,
          435,
          217,
          81,
          217,
          108,
          217,
          48,
          217,
          44
        ]
      ],
      "transformers/examples/pytorch/contrastive-image-text/run_clip.py": [
        [
          "main",
          236,
          533,
          246,
          81,
          246,
          108,
          246,
          48,
          246,
          44
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          295,
          81,
          295,
          108,
          295,
          48,
          295,
          44
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm.py": [
        [
          "main",
          282,
          720,
          291,
          81,
          291,
          108,
          291,
          48,
          291,
          44
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim.py": [
        [
          "main",
          309,
          854,
          318,
          81,
          318,
          108,
          318,
          48,
          318,
          44
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          240,
          81,
          240,
          108,
          240,
          48,
          240,
          44
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "main",
          191,
          445,
          200,
          81,
          200,
          108,
          200,
          48,
          200,
          44
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          197,
          81,
          197,
          108,
          197,
          48,
          197,
          44
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation.py": [
        [
          "main",
          353,
          483,
          361,
          64,
          361,
          91,
          361,
          31,
          361,
          27
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mae.py": [
        [
          "main",
          183,
          403,
          192,
          81,
          192,
          108,
          192,
          48,
          192,
          44
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim.py": [
        [
          "main",
          247,
          483,
          256,
          81,
          256,
          108,
          256,
          48,
          256,
          44
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm.py": [
        [
          "main",
          254,
          678,
          263,
          81,
          263,
          108,
          263,
          48,
          263,
          44
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          110,
          81,
          110,
          108,
          110,
          48,
          110,
          44
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          237,
          81,
          237,
          108,
          237,
          48,
          237,
          44
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection.py": [
        [
          "main",
          339,
          534,
          348,
          81,
          348,
          108,
          348,
          48,
          348,
          44
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_plm.py": [
        [
          "main",
          234,
          575,
          243,
          81,
          243,
          108,
          243,
          48,
          243,
          44
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa.py": [
        [
          "main",
          227,
          701,
          236,
          81,
          236,
          108,
          236,
          48,
          236,
          44
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search.py": [
        [
          "main",
          225,
          728,
          234,
          81,
          234,
          108,
          234,
          48,
          234,
          44
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          196,
          81,
          196,
          108,
          196,
          48,
          196,
          44
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          428,
          81,
          428,
          108,
          428,
          48,
          428,
          44
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_seq2seq_qa.py": [
        [
          "main",
          272,
          729,
          281,
          81,
          281,
          108,
          281,
          48,
          281,
          44
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad_trainer.py": [
        [
          "main",
          65,
          176,
          75,
          81,
          75,
          108,
          75,
          48,
          75,
          44
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py": [
        [
          "main",
          302,
          657,
          312,
          81,
          312,
          108,
          312,
          48,
          312,
          44
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          405,
          81,
          405,
          108,
          405,
          48,
          405,
          44
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag.py": [
        [
          "main",
          178,
          442,
          187,
          81,
          187,
          108,
          187,
          48,
          187,
          44
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          336,
          81,
          336,
          108,
          336,
          48,
          336,
          44
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          284,
          81,
          284,
          108,
          284,
          48,
          284,
          44
        ]
      ]
    },
    "os.path.relpath": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "_get_test_info",
          3345,
          3459,
          3424,
          19,
          3424,
          56,
          3424,
          19,
          3459,
          5
        ]
      ]
    },
    "pathlib.Path.unlink": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "patch_testing_methods_to_collect_info",
          3741,
          3768,
          3749,
          5,
          3749,
          35,
          3742,
          5,
          3751,
          27
        ]
      ],
      "transformers/tests/models/dia/test_modeling_dia.py": [
        [
          "tearDown",
          570,
          573,
          572,
          9,
          572,
          55,
          570,
          18,
          573,
          46
        ],
        [
          "tearDown",
          570,
          573,
          571,
          9,
          571,
          55,
          570,
          18,
          573,
          46
        ]
      ]
    },
    "os.path.expanduser": {
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "ja_tokenize",
          293,
          312,
          299,
          31,
          299,
          53,
          299,
          50,
          299,
          53
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "ja_tokenize",
          409,
          428,
          415,
          31,
          415,
          53,
          415,
          50,
          415,
          53
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "ja_tokenize",
          294,
          313,
          300,
          31,
          300,
          53,
          300,
          50,
          300,
          53
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "__post_init__",
          1467,
          1917,
          1491,
          31,
          1491,
          65,
          1491,
          31,
          1491,
          27
        ],
        [
          "__post_init__",
          1467,
          1917,
          1495,
          32,
          1495,
          67,
          1495,
          32,
          1495,
          28
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          218,
          366,
          240,
          31,
          240,
          53,
          238,
          13,
          252,
          73
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t_v2/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          219,
          374,
          238,
          31,
          238,
          53,
          219,
          16,
          250,
          73
        ]
      ]
    },
    "io.open": {
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "from_json_file",
          1156,
          1168,
          1159,
          14,
          1159,
          56,
          1158,
          21,
          1163,
          30
        ]
      ]
    },
    "os.path.samefile": {
      "transformers/src/transformers/trainer.py": [
        [
          "_inner_training_loop",
          2252,
          2734,
          2720,
          24,
          2720,
          85,
          2719,
          17,
          2720,
          85
        ]
      ]
    },
    "pathlib.Path.touch": {
      "transformers/src/transformers/trainer.py": [
        [
          "save_model",
          4003,
          4055,
          4021,
          13,
          4021,
          69,
          4021,
          13,
          4021,
          69
        ]
      ]
    },
    "os.path.splitext": {
      "transformers/utils/add_dates.py": [
        [
          "get_modified_cards",
          37,
          51,
          47,
          30,
          47,
          69,
          47,
          30,
          48,
          61
        ],
        [
          "get_all_model_cards",
          253,
          263,
          260,
          26,
          260,
          47,
          260,
          26,
          261,
          57
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "save_binary",
          458,
          474,
          468,
          19,
          468,
          52,
          458,
          21,
          474,
          26
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "get_model_test_files",
          565,
          597,
          593,
          52,
          593,
          77,
          593,
          52,
          593,
          101
        ]
      ],
      "transformers/utils/process_test_artifacts.py": [
        [
          "process_artifacts",
          47,
          69,
          56,
          19,
          56,
          66,
          56,
          19,
          61,
          42
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          599,
          31,
          599,
          52,
          596,
          9,
          601,
          41
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          544,
          31,
          544,
          52,
          541,
          9,
          546,
          41
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          797,
          31,
          797,
          52,
          794,
          9,
          799,
          41
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "main",
          234,
          650,
          512,
          31,
          512,
          52,
          509,
          9,
          514,
          41
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "main",
          413,
          747,
          605,
          31,
          605,
          52,
          602,
          9,
          607,
          41
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          687,
          31,
          687,
          52,
          684,
          9,
          689,
          41
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          636,
          31,
          636,
          52,
          633,
          9,
          638,
          41
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          696,
          31,
          696,
          52,
          693,
          9,
          698,
          41
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection_no_trainer.py": [
        [
          "main",
          411,
          796,
          654,
          31,
          654,
          52,
          651,
          9,
          656,
          41
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          838,
          31,
          838,
          52,
          835,
          9,
          840,
          41
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "main",
          253,
          637,
          483,
          31,
          483,
          52,
          480,
          9,
          485,
          41
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "main",
          338,
          1035,
          855,
          31,
          855,
          52,
          852,
          9,
          857,
          41
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          534,
          31,
          534,
          52,
          531,
          9,
          536,
          41
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          666,
          31,
          666,
          52,
          663,
          9,
          668,
          41
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          643,
          31,
          643,
          52,
          640,
          9,
          645,
          41
        ]
      ]
    },
    "os.walk": {
      "transformers/utils/check_inits.py": [
        [
          "get_transformers_submodules",
          282,
          306,
          287,
          37,
          287,
          65,
          283,
          5,
          287,
          65
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "extract_nemo_archive",
          57,
          147,
          75,
          30,
          75,
          49,
          57,
          26,
          75,
          49
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          84,
          30,
          84,
          49,
          80,
          5,
          84,
          49
        ]
      ],
      "transformers/utils/custom_init_isort.py": [
        [
          "sort_imports_in_all_inits",
          308,
          322,
          316,
          27,
          316,
          55,
          308,
          31,
          316,
          55
        ]
      ],
      "transformers/utils/release.py": [
        [
          "update_version_in_examples",
          99,
          119,
          107,
          40,
          107,
          64,
          99,
          32,
          107,
          64
        ]
      ]
    },
    "os.path.split": {
      "transformers/utils/check_repo.py": [
        [
          "get_model_test_files",
          565,
          597,
          592,
          28,
          592,
          46,
          592,
          28,
          593,
          46
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_text_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          61,
          62,
          61,
          100,
          56,
          5,
          78,
          26
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          335,
          418,
          356,
          31,
          356,
          54,
          353,
          38,
          382,
          51
        ],
        [
          "__init__",
          41,
          100,
          60,
          31,
          60,
          54,
          58,
          22,
          62,
          46
        ]
      ]
    },
    "os.mkdir": {
      "transformers/src/transformers/models/align/convert_align_tf_to_hf.py": [
        [
          "convert_align_checkpoint",
          288,
          367,
          358,
          13,
          358,
          46,
          358,
          13,
          358,
          46
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "convert_convnextv2_checkpoint",
          144,
          262,
          224,
          13,
          224,
          46,
          224,
          13,
          224,
          46
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "convert_efficientnet_checkpoint",
          250,
          317,
          307,
          13,
          307,
          46,
          307,
          13,
          307,
          46
        ]
      ],
      "transformers/src/transformers/models/owlv2/convert_owlv2_to_hf.py": [
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          368,
          13,
          368,
          46,
          368,
          13,
          368,
          46
        ]
      ],
      "transformers/src/transformers/models/superpoint/convert_superpoint_to_pytorch.py": [
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          142,
          13,
          142,
          46,
          142,
          13,
          142,
          46
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "format_mrpc",
          57,
          106,
          61,
          9,
          61,
          26,
          61,
          9,
          61,
          26
        ],
        [
          "download_diagnostic",
          109,
          116,
          112,
          9,
          112,
          54,
          112,
          9,
          112,
          54
        ],
        [
          "main",
          132,
          156,
          147,
          9,
          147,
          31,
          147,
          9,
          147,
          31
        ]
      ],
      "transformers/tests/utils/test_hf_argparser.py": [
        [
          "test_12_parse_yaml",
          397,
          413,
          408,
          13,
          408,
          37,
          397,
          28,
          413,
          43
        ],
        [
          "test_11_parse_json",
          378,
          395,
          389,
          13,
          389,
          37,
          378,
          28,
          395,
          43
        ]
      ]
    },
    "os.rename": {
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "shard_on_the_fly",
          70,
          149,
          136,
          9,
          136,
          69,
          131,
          9,
          138,
          24
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          114,
          9,
          114,
          69,
          111,
          9,
          115,
          24
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "extract_nemotron_tokenizer",
          298,
          327,
          312,
          13,
          312,
          75,
          306,
          20,
          312,
          75
        ]
      ]
    },
    "pathlib.Path.read_text": {
      "transformers/src/transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_cvt_checkpoint",
          278,
          330,
          286,
          27,
          286,
          106,
          278,
          28,
          294,
          48
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          112,
          27,
          112,
          99,
          104,
          37,
          130,
          32
        ],
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          112,
          27,
          112,
          99,
          105,
          23,
          130,
          32
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "get_deta_config",
          36,
          71,
          66,
          27,
          66,
          99,
          65,
          25,
          71,
          17
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "get_deta_config",
          36,
          56,
          51,
          27,
          51,
          99,
          37,
          14,
          56,
          17
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_to_pytorch.py": [
        [
          "get_dpt_config",
          34,
          58,
          52,
          31,
          52,
          103,
          47,
          52,
          56,
          22
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "get_dpt_config",
          34,
          70,
          64,
          31,
          64,
          103,
          57,
          52,
          68,
          22
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_seer_10b_to_pytorch.py": [
        [
          "convert_weights_and_push",
          162,
          272,
          167,
          27,
          167,
          99,
          162,
          30,
          204,
          58
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_to_pytorch.py": [
        [
          "convert_weights_and_push",
          221,
          422,
          227,
          27,
          227,
          99,
          221,
          30,
          403,
          17
        ]
      ],
      "transformers/src/transformers/hf_argparser.py": [
        [
          "parse_yaml_file",
          410,
          430,
          429,
          50,
          429,
          76,
          411,
          9,
          430,
          29
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_extract_definitions",
          305,
          351,
          327,
          18,
          327,
          54,
          306,
          9,
          330,
          46
        ]
      ],
      "transformers/utils/release.py": [
        [
          "update_version_in_examples",
          99,
          119,
          113,
          40,
          113,
          70,
          113,
          20,
          113,
          70
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_debugger_outputs",
          52,
          63,
          61,
          35,
          61,
          53,
          60,
          17,
          63,
          49
        ]
      ]
    },
    "pathlib.Path.iterdir": {
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "merge_tp_weights",
          250,
          625,
          252,
          17,
          252,
          42,
          250,
          22,
          252,
          42
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "make_registry",
          281,
          295,
          288,
          14,
          288,
          38,
          287,
          15,
          288,
          38
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "list_repo_templates",
          148,
          190,
          190,
          37,
          190,
          59,
          190,
          37,
          190,
          113
        ]
      ],
      "transformers/examples/legacy/seq2seq/minify_dataset.py": [
        [
          "minify",
          21,
          30,
          26,
          17,
          26,
          33,
          21,
          12,
          26,
          33
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_datasets.py": [
        [
          "test_pack_dataset",
          127,
          142,
          134,
          39,
          134,
          55,
          127,
          27,
          139,
          56
        ],
        [
          "test_pack_dataset",
          127,
          142,
          135,
          38,
          135,
          55,
          127,
          27,
          139,
          56
        ]
      ]
    },
    "zipfile.ZipFile.extractall": {
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "unzip",
          693,
          695,
          695,
          9,
          695,
          35,
          693,
          11,
          695,
          35
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "download_and_extract",
          47,
          54,
          52,
          9,
          52,
          36,
          47,
          26,
          54,
          25
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_last_daily_ci_reports",
          123,
          159,
          147,
          17,
          147,
          40,
          145,
          26,
          151,
          36
        ]
      ]
    },
    "zipfile.ZipFile.open": {
      "transformers/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py": [
        [
          "main",
          275,
          326,
          296,
          18,
          296,
          73,
          295,
          14,
          297,
          32
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py": [
        [
          "main",
          312,
          422,
          337,
          18,
          337,
          73,
          336,
          14,
          338,
          32
        ]
      ],
      "transformers/utils/extract_warnings.py": [
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          57,
          30,
          57,
          45,
          57,
          37,
          57,
          45
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "get_errors_from_single_artifact",
          112,
          156,
          123,
          26,
          123,
          41,
          123,
          26,
          124,
          37
        ]
      ]
    },
    "tarfile.open": {
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "extract_nemo_archive",
          57,
          147,
          70,
          10,
          70,
          60,
          57,
          26,
          75,
          49
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "extract_nemotron_tokenizer",
          298,
          327,
          308,
          23,
          308,
          50,
          306,
          20,
          312,
          75
        ]
      ]
    },
    "shutil.copytree": {
      "transformers/utils/create_dummy_models.py": [
        [
          "build_model",
          745,
          768,
          756,
          9,
          756,
          81,
          756,
          9,
          756,
          81
        ],
        [
          "upload_model",
          784,
          831,
          811,
          9,
          811,
          62,
          808,
          10,
          813,
          21
        ],
        [
          "build_composite_models",
          834,
          956,
          936,
          17,
          936,
          87,
          936,
          33,
          936,
          87
        ],
        [
          "build_composite_models",
          834,
          956,
          938,
          17,
          938,
          87,
          938,
          33,
          938,
          87
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "_log_model_checkpoint",
          1773,
          1795,
          1782,
          17,
          1782,
          57,
          1782,
          33,
          1782,
          57
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "setUpClass",
          35,
          76,
          46,
          9,
          46,
          79,
          35,
          20,
          56,
          35
        ],
        [
          "setUpClass",
          35,
          76,
          58,
          13,
          58,
          83,
          56,
          13,
          63,
          30
        ],
        [
          "setUpClass",
          35,
          76,
          61,
          13,
          61,
          81,
          56,
          13,
          63,
          30
        ]
      ]
    },
    "zipfile.ZipFile.namelist": {
      "transformers/utils/extract_warnings.py": [
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          52,
          33,
          52,
          44,
          52,
          33,
          52,
          44
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "get_errors_from_single_artifact",
          112,
          156,
          119,
          25,
          119,
          36,
          112,
          37,
          119,
          36
        ]
      ]
    },
    "os.path.normpath": {
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_class_in_module",
          268,
          313,
          287,
          12,
          287,
          40,
          269,
          5,
          292,
          23
        ]
      ]
    },
    "pathlib.Path.relative_to": {
      "transformers/utils/get_test_reports.py": [
        [
          "run_pytest",
          48,
          79,
          61,
          21,
          61,
          53,
          49,
          5,
          66,
          20
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_extract_definitions",
          305,
          351,
          339,
          28,
          339,
          61,
          339,
          25,
          339,
          75
        ]
      ]
    },
    "tempfile.mkstemp": {
      "transformers/src/transformers/utils/hub.py": [
        [
          "download_url",
          582,
          606,
          603,
          24,
          603,
          41,
          582,
          18,
          606,
          19
        ]
      ]
    },
    "zipfile.is_zipfile": {
      "transformers/src/transformers/modeling_utils.py": [
        [
          "load_state_dict",
          469,
          536,
          513,
          76,
          513,
          102,
          513,
          87,
          513,
          102
        ]
      ]
    },
    "logging.FileHandler": {
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "setup_logging",
          33,
          48,
          42,
          25,
          42,
          108,
          42,
          9,
          42,
          109
        ]
      ]
    },
    "pathlib.Path.rglob": {
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "upload_results_to_hf_dataset",
          193,
          275,
          247,
          26,
          247,
          47,
          247,
          44,
          247,
          47
        ]
      ],
      "transformers/utils/scan_skipped_tests.py": [
        [
          "get_models_and_test_files",
          45,
          50,
          48,
          37,
          48,
          74,
          48,
          30,
          50,
          34
        ]
      ]
    },
    "os.scandir": {
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          590,
          37,
          590,
          59,
          590,
          37,
          594,
          16
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          535,
          37,
          535,
          59,
          535,
          37,
          539,
          16
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          788,
          37,
          788,
          59,
          788,
          37,
          792,
          16
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "main",
          234,
          650,
          503,
          37,
          503,
          59,
          503,
          37,
          507,
          16
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "main",
          413,
          747,
          596,
          37,
          596,
          59,
          596,
          37,
          600,
          16
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          678,
          37,
          678,
          59,
          678,
          37,
          682,
          16
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          627,
          37,
          627,
          59,
          627,
          37,
          631,
          16
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          687,
          37,
          687,
          59,
          687,
          37,
          691,
          16
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection_no_trainer.py": [
        [
          "main",
          411,
          796,
          645,
          37,
          645,
          59,
          645,
          37,
          649,
          16
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          829,
          37,
          829,
          59,
          829,
          37,
          833,
          16
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "main",
          253,
          637,
          474,
          37,
          474,
          59,
          474,
          37,
          478,
          16
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "main",
          338,
          1035,
          846,
          37,
          846,
          59,
          846,
          37,
          850,
          16
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          525,
          37,
          525,
          59,
          525,
          37,
          529,
          16
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          657,
          37,
          657,
          59,
          657,
          37,
          661,
          16
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          634,
          37,
          634,
          59,
          634,
          37,
          638,
          16
        ]
      ]
    },
    "pathlib.Path.write_text": {
      "transformers/utils/scan_skipped_tests.py": [
        [
          "save_json",
          89,
          91,
          91,
          5,
          91,
          71,
          89,
          15,
          91,
          71
        ]
      ]
    },
    "pathlib.Path.expanduser": {
      "transformers/utils/scan_skipped_tests.py": [
        [
          "main",
          162,
          195,
          177,
          18,
          177,
          51,
          163,
          14,
          181,
          23
        ]
      ]
    }
  },
  "CWE-078": {
    "subprocess.run": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_loading_is_fast_on_gpu",
          1904,
          1956,
          1954,
          21,
          1954,
          115,
          1954,
          62,
          1954,
          115
        ]
      ],
      "transformers/tests/sagemaker/test_multi_node_data_parallel.py": [
        [
          "setUp",
          40,
          46,
          41,
          9,
          45,
          9,
          40,
          15,
          46,
          35
        ]
      ],
      "transformers/tests/utils/test_offline.py": [
        [
          "_execute_with_env",
          197,
          220,
          211,
          18,
          211,
          83,
          197,
          27,
          214,
          22
        ]
      ],
      "transformers/tests/sagemaker/test_multi_node_model_parallel.py": [
        [
          "setUp",
          40,
          46,
          41,
          9,
          45,
          9,
          40,
          15,
          46,
          35
        ]
      ],
      "transformers/tests/sagemaker/test_single_node_gpu.py": [
        [
          "setUp",
          34,
          40,
          35,
          9,
          39,
          9,
          34,
          15,
          40,
          35
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "wrapper",
          2747,
          2792,
          2773,
          17,
          2773,
          81,
          2773,
          32,
          2773,
          81
        ],
        [
          "torchrun",
          3771,
          3788,
          3786,
          17,
          3786,
          88,
          3786,
          32,
          3786,
          88
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "get_commit_history",
          5361,
          5370,
          5362,
          23,
          5368,
          9,
          5361,
          28,
          5370,
          53
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "create_new_model_like",
          477,
          571,
          553,
          5,
          557,
          5,
          552,
          23,
          571,
          5
        ],
        [
          "create_new_model_like",
          477,
          571,
          558,
          5,
          562,
          5,
          552,
          23,
          571,
          5
        ],
        [
          "create_new_model_like",
          477,
          571,
          563,
          5,
          565,
          5,
          552,
          23,
          571,
          5
        ],
        [
          "create_new_model_like",
          477,
          571,
          566,
          5,
          566,
          103,
          552,
          23,
          571,
          5
        ],
        [
          "create_new_model_like",
          477,
          571,
          569,
          5,
          571,
          5,
          552,
          23,
          571,
          5
        ]
      ],
      "transformers/src/transformers/pipelines/audio_utils.py": [
        [
          "_get_microphone_name",
          280,
          297,
          287,
          26,
          287,
          101,
          287,
          61,
          287,
          101
        ]
      ],
      "transformers/examples/legacy/seq2seq/test_data/fsmt/build-eval-data.py": [
        [
          "get_all_data",
          17,
          26,
          22,
          21,
          22,
          63,
          19,
          9,
          25,
          18
        ],
        [
          "get_all_data",
          17,
          26,
          24,
          21,
          24,
          63,
          19,
          9,
          25,
          18
        ]
      ],
      "transformers/utils/check_bad_commit.py": [
        [
          "find_bad_commit",
          72,
          133,
          98,
          14,
          103,
          5,
          87,
          5,
          106,
          50
        ]
      ],
      "transformers/utils/check_self_hosted_runner.py": [
        [
          "get_runner_status",
          6,
          34,
          18,
          14,
          18,
          81,
          6,
          23,
          23,
          25
        ]
      ],
      "transformers/utils/get_test_reports.py": [
        [
          "run_pytest",
          48,
          79,
          79,
          13,
          79,
          53,
          79,
          13,
          79,
          53
        ]
      ],
      "transformers/benchmark/optimum_benchmark_wrapper.py": [
        [
          "main",
          5,
          10,
          6,
          5,
          10,
          5,
          5,
          10,
          10,
          5
        ]
      ],
      "transformers/utils/patch_helper.py": [
        [
          "checkout_branch",
          63,
          70,
          66,
          9,
          66,
          63,
          66,
          25,
          66,
          63
        ],
        [
          "get_prs_by_label",
          73,
          95,
          88,
          14,
          88,
          77,
          73,
          22,
          91,
          17
        ],
        [
          "get_commit_timestamp",
          98,
          104,
          100,
          14,
          102,
          5,
          98,
          26,
          104,
          37
        ],
        [
          "cherry_pick_commit",
          107,
          113,
          110,
          9,
          110,
          63,
          110,
          25,
          110,
          63
        ],
        [
          "commit_in_history",
          116,
          124,
          118,
          14,
          123,
          5,
          116,
          23,
          124,
          33
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_ddp.py": [
        [
          "main",
          21,
          48,
          46,
          9,
          46,
          39,
          46,
          24,
          46,
          39
        ]
      ],
      "transformers/tests/fsdp/test_fsdp.py": [
        [
          "test_fsdp_cpu_offloading",
          334,
          346,
          340,
          13,
          344,
          13,
          341,
          17,
          344,
          13
        ],
        [
          "test_fsdp2_cpu_offloading",
          402,
          414,
          408,
          13,
          412,
          13,
          409,
          17,
          412,
          13
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "_is_old_model_by_commit_date",
          647,
          674,
          656,
          26,
          661,
          17,
          660,
          21,
          661,
          17
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "run_distributed_test",
          238,
          274,
          271,
          9,
          271,
          39,
          238,
          30,
          274,
          27
        ]
      ]
    },
    "subprocess.check_output": {
      "transformers/tests/pipelines/test_pipelines_automatic_speech_recognition.py": [
        [
          "require_ffmpeg",
          1801,
          1814,
          1811,
          9,
          1811,
          76,
          1811,
          51,
          1811,
          76
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "run_command",
          2524,
          2538,
          2530,
          18,
          2530,
          75,
          2530,
          51,
          2530,
          75
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_modified_cards",
          37,
          51,
          40,
          14,
          40,
          96,
          38,
          5,
          43,
          42
        ],
        [
          "get_first_commit_date",
          94,
          121,
          110,
          19,
          112,
          5,
          110,
          19,
          113,
          22
        ],
        [
          "get_first_commit_date",
          94,
          121,
          118,
          22,
          120,
          9,
          118,
          22,
          118,
          18
        ]
      ],
      "transformers/utils/check_modular_conversion.py": [
        [
          "get_models_in_diff",
          79,
          99,
          86,
          22,
          86,
          80,
          80,
          5,
          96,
          44
        ],
        [
          "get_models_in_diff",
          79,
          99,
          88,
          9,
          88,
          97,
          80,
          5,
          96,
          44
        ]
      ],
      "transformers/utils/collated_reports.py": [
        [
          "get_commit_hash",
          73,
          82,
          77,
          27,
          77,
          79,
          77,
          52,
          77,
          79
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "is_ninja_available",
          780,
          790,
          786,
          9,
          786,
          55,
          786,
          34,
          786,
          55
        ]
      ]
    },
    "shutil.which": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "cmd_exists",
          1441,
          1442,
          1442,
          12,
          1442,
          28,
          1441,
          16,
          1442,
          40
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "is_jumanpp_available",
          1128,
          1129,
          1129,
          48,
          1129,
          70,
          1129,
          48,
          1129,
          82
        ]
      ]
    },
    "shlex.split": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "python_one_liner_max_rss",
          2113,
          2144,
          2139,
          15,
          2139,
          77,
          2139,
          15,
          2144,
          22
        ]
      ]
    },
    "asyncio.create_subprocess_exec": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "_stream_subprocess",
          2384,
          2422,
          2388,
          15,
          2395,
          5,
          2388,
          15,
          2422,
          47
        ]
      ]
    },
    "subprocess.Popen": {
      "transformers/src/transformers/pipelines/audio_utils.py": [
        [
          "ffmpeg_read",
          10,
          46,
          34,
          14,
          34,
          92,
          34,
          70,
          34,
          92
        ],
        [
          "_ffmpeg_stream",
          264,
          277,
          270,
          14,
          270,
          86,
          270,
          47,
          270,
          86
        ]
      ],
      "transformers/src/transformers/pipelines/audio_classification.py": [
        [
          "ffmpeg_read",
          30,
          63,
          54,
          26,
          54,
          104,
          54,
          82,
          54,
          104
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "run_ruff",
          556,
          563,
          561,
          15,
          561,
          110,
          561,
          15,
          563,
          26
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "run_ruff",
          1676,
          1683,
          1681,
          15,
          1681,
          110,
          1681,
          15,
          1683,
          26
        ]
      ]
    },
    "subprocess.check_call": {
      "transformers/tests/deepspeed/test_model_zoo.py": [
        [
          "test_zero_to_fp32",
          352,
          370,
          369,
          9,
          369,
          46,
          352,
          27,
          370,
          51
        ]
      ]
    }
  },
  "CWE-079": {
    "html.unescape": {
      "transformers/src/transformers/models/markuplm/feature_extraction_markuplm.py": [
        [
          "get_three_from_single",
          62,
          89,
          74,
          36,
          74,
          57,
          74,
          36,
          75,
          39
        ]
      ]
    }
  },
  "CWE-095": {
    "json.loads": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          816,
          29,
          816,
          48,
          815,
          22,
          824,
          77
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          1999,
          26,
          1999,
          45,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2025,
          26,
          2025,
          45,
          2006,
          66,
          2030,
          85
        ]
      ],
      "transformers/tests/models/csm/test_processing_csm.py": [
        [
          "test_chat_template_is_saved",
          57,
          66,
          59,
          33,
          59,
          77,
          57,
          37,
          66,
          100
        ]
      ],
      "transformers/tests/test_processing_common.py": [
        [
          "test_processor_to_json_string",
          186,
          200,
          188,
          15,
          188,
          52,
          186,
          39,
          189,
          63
        ]
      ],
      "transformers/tests/models/llava/test_processing_llava.py": [
        [
          "test_chat_template_is_saved",
          76,
          85,
          78,
          33,
          78,
          77,
          76,
          37,
          85,
          100
        ]
      ],
      "transformers/tests/models/llava_next/test_processing_llava_next.py": [
        [
          "test_chat_template_is_saved",
          83,
          92,
          85,
          33,
          85,
          77,
          83,
          37,
          92,
          100
        ]
      ],
      "transformers/tests/models/llava_next_video/test_processing_llava_next_video.py": [
        [
          "test_chat_template_is_saved",
          92,
          101,
          94,
          33,
          94,
          77,
          92,
          37,
          101,
          100
        ]
      ],
      "transformers/tests/models/llava_onevision/test_processing_llava_onevision.py": [
        [
          "test_chat_template_is_saved",
          96,
          105,
          98,
          33,
          98,
          77,
          96,
          37,
          105,
          100
        ]
      ],
      "transformers/tests/models/mllama/test_processing_mllama.py": [
        [
          "test_chat_template_is_saved",
          70,
          79,
          72,
          33,
          72,
          77,
          70,
          37,
          79,
          100
        ]
      ],
      "transformers/tests/models/perception_lm/test_processing_perception_lm.py": [
        [
          "test_chat_template_is_saved",
          82,
          91,
          84,
          33,
          84,
          77,
          82,
          37,
          91,
          100
        ]
      ],
      "transformers/tests/models/ovis2/test_processor_ovis2.py": [
        [
          "test_processor_to_json_string",
          60,
          67,
          62,
          15,
          62,
          52,
          60,
          39,
          63,
          63
        ],
        [
          "test_chat_template_is_saved",
          69,
          78,
          71,
          33,
          71,
          77,
          69,
          37,
          78,
          100
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_local_versioning",
          211,
          236,
          213,
          26,
          213,
          66,
          211,
          31,
          236,
          77
        ],
        [
          "test_local_versioning",
          211,
          236,
          225,
          30,
          225,
          74,
          211,
          31,
          236,
          77
        ],
        [
          "test_local_versioning",
          211,
          236,
          235,
          30,
          235,
          74,
          211,
          31,
          236,
          77
        ],
        [
          "test_repo_versioning",
          238,
          255,
          245,
          26,
          245,
          66,
          238,
          30,
          255,
          73
        ],
        [
          "test_repo_versioning",
          238,
          255,
          254,
          26,
          254,
          70,
          238,
          30,
          255,
          73
        ]
      ],
      "transformers/tests/models/longformer/test_tokenization_longformer.py": [
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          209,
          221,
          215,
          35,
          215,
          104,
          210,
          13,
          221,
          80
        ],
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          209,
          221,
          216,
          36,
          216,
          106,
          210,
          13,
          221,
          80
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template",
          1114,
          1174,
          1165,
          35,
          1165,
          104,
          1123,
          13,
          1174,
          103
        ]
      ],
      "transformers/tests/models/roberta/test_tokenization_roberta.py": [
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          207,
          219,
          213,
          35,
          213,
          104,
          208,
          13,
          219,
          80
        ],
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          207,
          219,
          214,
          36,
          214,
          106,
          208,
          13,
          219,
          80
        ]
      ],
      "transformers/tests/models/auto/test_video_processing_auto.py": [
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          111,
          29,
          111,
          63,
          82,
          63,
          114,
          67
        ]
      ],
      "transformers/tests/test_video_processing_common.py": [
        [
          "test_video_processor_to_json_string",
          114,
          119,
          117,
          19,
          117,
          62,
          115,
          13,
          118,
          63
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          277,
          23,
          277,
          45,
          268,
          9,
          287,
          30
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          278,
          23,
          278,
          45,
          268,
          9,
          287,
          30
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart_fast.py": [
        [
          "__init__",
          120,
          185,
          164,
          21,
          164,
          75,
          164,
          21,
          167,
          29
        ]
      ],
      "transformers/src/transformers/models/bert/tokenization_bert_fast.py": [
        [
          "__init__",
          75,
          115,
          103,
          28,
          103,
          87,
          76,
          9,
          105,
          77
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot_fast.py": [
        [
          "__init__",
          124,
          187,
          166,
          21,
          166,
          75,
          166,
          21,
          169,
          29
        ]
      ],
      "transformers/src/transformers/models/convbert/tokenization_convbert_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/models/distilbert/tokenization_distilbert_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/models/electra/tokenization_electra_fast.py": [
        [
          "__init__",
          72,
          112,
          100,
          28,
          100,
          87,
          73,
          9,
          102,
          77
        ]
      ],
      "transformers/src/transformers/models/funnel/tokenization_funnel_fast.py": [
        [
          "__init__",
          93,
          141,
          129,
          28,
          129,
          87,
          94,
          9,
          131,
          77
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "load_vocab_and_emoji",
          35,
          52,
          38,
          17,
          38,
          36,
          35,
          26,
          46,
          34
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "load_vocab_and_emoji",
          43,
          60,
          46,
          17,
          46,
          36,
          43,
          26,
          54,
          34
        ]
      ],
      "transformers/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py": [
        [
          "__init__",
          98,
          153,
          136,
          25,
          136,
          84,
          99,
          9,
          138,
          74
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py": [
        [
          "__init__",
          121,
          196,
          168,
          21,
          168,
          75,
          168,
          21,
          171,
          29
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led_fast.py": [
        [
          "__init__",
          120,
          185,
          164,
          21,
          164,
          75,
          164,
          21,
          167,
          29
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer_fast.py": [
        [
          "__init__",
          119,
          182,
          161,
          21,
          161,
          75,
          161,
          21,
          164,
          29
        ]
      ],
      "transformers/src/transformers/models/lxmert/tokenization_lxmert_fast.py": [
        [
          "__init__",
          72,
          112,
          100,
          28,
          100,
          87,
          73,
          9,
          102,
          77
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm_fast.py": [
        [
          "__init__",
          144,
          241,
          213,
          21,
          213,
          75,
          213,
          21,
          216,
          29
        ]
      ],
      "transformers/src/transformers/models/mobilebert/tokenization_mobilebert_fast.py": [
        [
          "__init__",
          77,
          117,
          105,
          28,
          105,
          87,
          78,
          9,
          107,
          77
        ]
      ],
      "transformers/src/transformers/models/mpnet/tokenization_mpnet_fast.py": [
        [
          "__init__",
          93,
          145,
          135,
          25,
          135,
          84,
          117,
          22,
          137,
          74
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp_fast.py": [
        [
          "__init__",
          120,
          188,
          167,
          21,
          167,
          75,
          167,
          21,
          170,
          29
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/tokenization_realm_fast.py": [
        [
          "__init__",
          79,
          119,
          107,
          28,
          107,
          87,
          80,
          9,
          109,
          77
        ]
      ],
      "transformers/src/transformers/models/deprecated/retribert/tokenization_retribert_fast.py": [
        [
          "__init__",
          79,
          119,
          107,
          28,
          107,
          87,
          80,
          9,
          109,
          77
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta_fast.py": [
        [
          "__init__",
          118,
          181,
          160,
          21,
          160,
          75,
          160,
          21,
          163,
          29
        ]
      ],
      "transformers/src/transformers/models/roformer/tokenization_roformer_fast.py": [
        [
          "__init__",
          57,
          99,
          85,
          28,
          85,
          87,
          58,
          9,
          87,
          77
        ]
      ],
      "transformers/src/transformers/models/splinter/tokenization_splinter_fast.py": [
        [
          "__init__",
          77,
          117,
          107,
          25,
          107,
          84,
          78,
          9,
          109,
          74
        ]
      ],
      "transformers/src/transformers/models/squeezebert/tokenization_squeezebert_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "__init__",
          98,
          220,
          211,
          29,
          211,
          91,
          211,
          29,
          211,
          91
        ],
        [
          "train_new_from_iterator",
          744,
          922,
          778,
          26,
          778,
          61,
          745,
          9,
          786,
          51
        ],
        [
          "train_new_from_iterator",
          744,
          922,
          860,
          38,
          860,
          67,
          860,
          38,
          862,
          49
        ]
      ],
      "transformers/src/transformers/trainer_callback.py": [
        [
          "load_from_json",
          151,
          155,
          155,
          22,
          155,
          37,
          151,
          24,
          155,
          38
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "_create_examples",
          347,
          409,
          367,
          24,
          367,
          51,
          366,
          13,
          368,
          56
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "__post_init__",
          1467,
          1917,
          1482,
          31,
          1482,
          54,
          1482,
          31,
          1485,
          49
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "get_video_processor_dict",
          611,
          724,
          710,
          36,
          710,
          51,
          710,
          47,
          710,
          51
        ],
        [
          "from_json_file",
          821,
          837,
          836,
          32,
          836,
          47,
          821,
          24,
          837,
          42
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4881,
          29,
          4881,
          48,
          4879,
          17,
          4883,
          50
        ]
      ],
      "transformers/src/transformers/utils/chat_template_utils.py": [
        [
          "get_json_schema",
          237,
          371,
          364,
          50,
          364,
          82,
          364,
          50,
          365,
          16
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "parse_generate_flags",
          424,
          475,
          468,
          40,
          468,
          72,
          468,
          51,
          468,
          72
        ]
      ],
      "transformers/utils/check_self_hosted_runner.py": [
        [
          "get_runner_status",
          6,
          34,
          20,
          14,
          20,
          26,
          6,
          23,
          23,
          25
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "_dict_from_json_file",
          948,
          951,
          951,
          16,
          951,
          31,
          948,
          30,
          951,
          31
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "_dict_from_json_file",
          853,
          856,
          856,
          16,
          856,
          31,
          853,
          30,
          856,
          31
        ]
      ],
      "transformers/src/transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_cvt_checkpoint",
          278,
          330,
          286,
          16,
          286,
          107,
          278,
          28,
          294,
          48
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          112,
          16,
          112,
          100,
          104,
          37,
          130,
          32
        ],
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          112,
          16,
          112,
          100,
          105,
          23,
          130,
          32
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "get_deta_config",
          36,
          71,
          66,
          16,
          66,
          100,
          65,
          25,
          71,
          17
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "get_deta_config",
          36,
          56,
          51,
          16,
          51,
          100,
          37,
          14,
          56,
          17
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_to_pytorch.py": [
        [
          "get_dpt_config",
          34,
          58,
          52,
          20,
          52,
          104,
          47,
          52,
          56,
          22
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "get_dpt_config",
          34,
          70,
          64,
          20,
          64,
          104,
          57,
          52,
          68,
          22
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/convert_gptsan_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_gptsan_to_pt",
          28,
          171,
          30,
          14,
          30,
          52,
          28,
          29,
          31,
          17
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "main",
          700,
          805,
          783,
          32,
          783,
          77,
          743,
          28,
          797,
          82
        ],
        [
          "main",
          700,
          805,
          784,
          30,
          784,
          73,
          743,
          28,
          797,
          82
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_model",
          146,
          284,
          157,
          23,
          157,
          85,
          154,
          20,
          179,
          49
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "listcomp",
          189,
          189,
          189,
          13,
          189,
          28,
          189,
          34,
          189,
          28
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "write_model",
          272,
          398,
          285,
          20,
          285,
          54,
          273,
          5,
          299,
          59
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          312,
          19,
          312,
          34,
          292,
          9,
          315,
          20
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_seer_10b_to_pytorch.py": [
        [
          "convert_weights_and_push",
          162,
          272,
          167,
          16,
          167,
          100,
          162,
          30,
          204,
          58
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_to_pytorch.py": [
        [
          "convert_weights_and_push",
          221,
          422,
          227,
          16,
          227,
          100,
          221,
          30,
          403,
          17
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "prepare_config",
          43,
          113,
          44,
          19,
          44,
          64,
          43,
          20,
          47,
          31
        ],
        [
          "convert_textnet_checkpoint",
          116,
          181,
          120,
          19,
          120,
          38,
          116,
          32,
          124,
          62
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "get_feature_extractor_dict",
          417,
          529,
          514,
          38,
          514,
          53,
          514,
          49,
          514,
          53
        ],
        [
          "from_json_file",
          584,
          600,
          599,
          34,
          599,
          49,
          584,
          24,
          600,
          44
        ]
      ],
      "transformers/src/transformers/hf_argparser.py": [
        [
          "parse_json_file",
          386,
          408,
          406,
          20,
          406,
          52,
          387,
          9,
          408,
          29
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "define_sagemaker_information",
          198,
          221,
          207,
          24,
          207,
          73,
          207,
          24,
          209,
          96
        ],
        [
          "get_checkpoint_shard_files",
          1011,
          1078,
          1050,
          17,
          1050,
          36,
          1049,
          10,
          1058,
          51
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "get_image_processor_dict",
          264,
          382,
          367,
          36,
          367,
          51,
          367,
          47,
          367,
          51
        ],
        [
          "from_json_file",
          442,
          458,
          457,
          32,
          457,
          47,
          442,
          24,
          458,
          42
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "listcomp",
          160,
          160,
          160,
          20,
          160,
          35,
          160,
          20,
          160,
          35
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "is_sagemaker_dp_enabled",
          1282,
          1293,
          1287,
          28,
          1287,
          55,
          1287,
          39,
          1287,
          55
        ],
        [
          "is_sagemaker_mp_enabled",
          1296,
          1317,
          1301,
          23,
          1301,
          45,
          1301,
          34,
          1301,
          45
        ],
        [
          "is_sagemaker_mp_enabled",
          1296,
          1317,
          1311,
          23,
          1311,
          45,
          1311,
          34,
          1311,
          45
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "log_model_debug_trace",
          228,
          268,
          264,
          17,
          264,
          56,
          238,
          5,
          268,
          41
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "setup",
          1371,
          1476,
          1474,
          31,
          1474,
          53,
          1474,
          31,
          1475,
          51
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "from_json_file",
          225,
          230,
          229,
          20,
          229,
          35,
          225,
          24,
          230,
          30
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "error_out",
          184,
          207,
          201,
          37,
          201,
          55,
          187,
          17,
          207,
          9
        ],
        [
          "post",
          209,
          219,
          211,
          37,
          211,
          60,
          209,
          14,
          213,
          92
        ]
      ],
      "transformers/utils/patch_helper.py": [
        [
          "get_prs_by_label",
          73,
          95,
          90,
          11,
          90,
          35,
          73,
          22,
          91,
          17
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "error_out",
          701,
          760,
          715,
          35,
          715,
          52,
          715,
          35,
          715,
          31
        ],
        [
          "post",
          762,
          773,
          765,
          37,
          765,
          55,
          762,
          14,
          767,
          92
        ],
        [
          "get_new_model_failure_blocks",
          817,
          892,
          837,
          34,
          839,
          13,
          837,
          34,
          841,
          47
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "get_processor_dict",
          899,
          1149,
          1073,
          38,
          1073,
          62,
          1072,
          18,
          1075,
          58
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1108,
          34,
          1108,
          49,
          1108,
          45,
          1108,
          49
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1135,
          40,
          1135,
          71,
          1133,
          26,
          1135,
          36
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_ddp.py": [
        [
          "main",
          21,
          48,
          25,
          13,
          25,
          46,
          22,
          12,
          31,
          20
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "create_generation_config_from_req",
          233,
          289,
          257,
          48,
          257,
          83,
          257,
          29,
          257,
          25
        ]
      ],
      "transformers/tests/test_configuration_common.py": [
        [
          "create_and_test_config_to_json_string",
          79,
          83,
          81,
          15,
          81,
          49,
          79,
          47,
          82,
          50
        ]
      ],
      "transformers/tests/models/auto/test_feature_extraction_auto.py": [
        [
          "test_feature_extractor_from_local_directory_from_config",
          57,
          77,
          74,
          29,
          74,
          63,
          57,
          65,
          77,
          63
        ]
      ],
      "transformers/tests/test_feature_extraction_common.py": [
        [
          "test_feat_extract_to_json_string",
          26,
          30,
          28,
          15,
          28,
          55,
          26,
          42,
          29,
          56
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_get_file_from_repo_distant",
          114,
          156,
          155,
          18,
          155,
          55,
          114,
          41,
          156,
          52
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          118,
          29,
          118,
          63,
          92,
          63,
          121,
          57
        ]
      ],
      "transformers/tests/models/conditional_detr/test_image_processing_conditional_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          170,
          212,
          174,
          22,
          174,
          41,
          170,
          59,
          178,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          215,
          263,
          219,
          22,
          219,
          41,
          215,
          58,
          225,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          383,
          272,
          22,
          272,
          41,
          267,
          49,
          280,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          386,
          507,
          392,
          22,
          392,
          41,
          386,
          48,
          399,
          58
        ]
      ],
      "transformers/tests/models/deformable_detr/test_image_processing_deformable_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          175,
          217,
          179,
          22,
          179,
          41,
          175,
          59,
          183,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          220,
          268,
          224,
          22,
          224,
          41,
          220,
          58,
          230,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          272,
          388,
          277,
          22,
          277,
          41,
          272,
          49,
          285,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          391,
          512,
          397,
          22,
          397,
          41,
          391,
          48,
          404,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          618,
          671,
          622,
          22,
          622,
          41,
          618,
          84,
          671,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          676,
          740,
          680,
          22,
          680,
          41,
          676,
          83,
          740,
          114
        ]
      ],
      "transformers/tests/models/detr/test_image_processing_detr.py": [
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          283,
          331,
          287,
          22,
          287,
          41,
          283,
          58,
          293,
          63
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          734,
          796,
          738,
          22,
          738,
          41,
          734,
          83,
          796,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          678,
          729,
          682,
          22,
          682,
          41,
          678,
          84,
          729,
          114
        ],
        [
          "test_should_raise_if_annotation_format_invalid",
          178,
          199,
          182,
          32,
          182,
          51,
          178,
          56,
          193,
          63
        ],
        [
          "test_valid_coco_detection_annotations",
          201,
          235,
          205,
          22,
          205,
          41,
          201,
          47,
          209,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          238,
          280,
          242,
          22,
          242,
          41,
          238,
          59,
          246,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          334,
          450,
          339,
          22,
          339,
          41,
          334,
          49,
          347,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          452,
          573,
          458,
          22,
          458,
          41,
          452,
          48,
          465,
          58
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_image_processor_to_json_string",
          259,
          264,
          262,
          19,
          262,
          62,
          260,
          13,
          263,
          63
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          707,
          32,
          707,
          51,
          702,
          57,
          754,
          51
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          718,
          31,
          718,
          50,
          702,
          57,
          754,
          51
        ]
      ],
      "transformers/tests/models/imagegpt/test_image_processing_imagegpt.py": [
        [
          "test_image_processor_to_json_string",
          136,
          144,
          139,
          19,
          139,
          62,
          137,
          13,
          140,
          63
        ]
      ],
      "transformers/tests/models/grounding_dino/test_image_processing_grounding_dino.py": [
        [
          "test_batched_coco_detection_annotations",
          253,
          369,
          258,
          22,
          258,
          41,
          253,
          49,
          266,
          57
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          207,
          249,
          211,
          22,
          211,
          41,
          207,
          59,
          215,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          373,
          421,
          377,
          22,
          377,
          41,
          373,
          58,
          383,
          63
        ],
        [
          "test_batched_coco_panoptic_annotations",
          425,
          546,
          431,
          22,
          431,
          41,
          425,
          48,
          438,
          58
        ]
      ],
      "transformers/tests/models/rt_detr/test_image_processing_rt_detr.py": [
        [
          "test_valid_coco_detection_annotations",
          125,
          159,
          129,
          22,
          129,
          41,
          125,
          47,
          133,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          379,
          272,
          22,
          272,
          41,
          267,
          49,
          280,
          57
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          162,
          204,
          166,
          22,
          166,
          41,
          162,
          59,
          170,
          63
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          385,
          436,
          389,
          22,
          389,
          41,
          385,
          84,
          436,
          114
        ]
      ],
      "transformers/tests/models/yolos/test_image_processing_yolos.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          226,
          268,
          230,
          22,
          230,
          41,
          226,
          59,
          234,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          271,
          319,
          275,
          22,
          275,
          41,
          271,
          58,
          281,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          323,
          439,
          328,
          22,
          328,
          41,
          323,
          49,
          336,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          442,
          564,
          448,
          22,
          448,
          41,
          442,
          48,
          455,
          58
        ]
      ],
      "transformers/tests/utils/test_model_card.py": [
        [
          "test_model_card_to_json_string",
          60,
          64,
          62,
          15,
          62,
          52,
          60,
          40,
          63,
          50
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_debugger_outputs",
          52,
          63,
          61,
          24,
          61,
          54,
          60,
          17,
          63,
          49
        ]
      ]
    },
    "input": {
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "get_user_input",
          634,
          742,
          643,
          26,
          645,
          9,
          643,
          26,
          646,
          40
        ],
        [
          "get_user_field",
          574,
          620,
          605,
          18,
          605,
          32,
          605,
          18,
          606,
          57
        ],
        [
          "get_user_field",
          574,
          620,
          605,
          18,
          605,
          32,
          605,
          18,
          608,
          33
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "resolve_trust_remote_code",
          694,
          776,
          746,
          30,
          750,
          21,
          746,
          30,
          750,
          21
        ]
      ],
      "transformers/utils/release.py": [
        [
          "pre_release_work",
          163,
          193,
          185,
          15,
          185,
          76,
          185,
          15,
          186,
          24
        ],
        [
          "post_release_work",
          196,
          214,
          209,
          15,
          209,
          76,
          197,
          5,
          210,
          24
        ]
      ],
      "transformers/examples/pytorch/text-generation/run_generation.py": [
        [
          "prepare_xlm_input",
          110,
          133,
          122,
          28,
          122,
          109,
          122,
          28,
          122,
          24
        ],
        [
          "main",
          289,
          445,
          370,
          51,
          370,
          76,
          370,
          51,
          370,
          76
        ]
      ]
    },
    "yaml.safe_load": {
      "transformers/src/transformers/commands/chat.py": [
        [
          "_inner_run",
          667,
          752,
          696,
          28,
          696,
          44,
          695,
          18,
          696,
          24
        ]
      ],
      "transformers/utils/check_doc_toc.py": [
        [
          "check_model_doc",
          79,
          125,
          89,
          19,
          89,
          42,
          79,
          21,
          92,
          11
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          353,
          21,
          353,
          50,
          341,
          10,
          355,
          42
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "remap_model_yaml_config",
          88,
          101,
          90,
          16,
          90,
          32,
          88,
          29,
          97,
          66
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_hifigan.py": [
        [
          "remap_hifigan_yaml_config",
          62,
          89,
          64,
          16,
          64,
          32,
          62,
          31,
          68,
          42
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "parse_metadata",
          290,
          318,
          305,
          24,
          305,
          56,
          302,
          68,
          306,
          79
        ],
        [
          "parse_metadata",
          290,
          318,
          313,
          24,
          313,
          57,
          308,
          32,
          314,
          80
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "write_model",
          68,
          216,
          82,
          20,
          82,
          58,
          69,
          5,
          84,
          58
        ],
        [
          "_write_tokenizer",
          219,
          248,
          231,
          28,
          231,
          66,
          230,
          23,
          234,
          57
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "write_model",
          65,
          183,
          71,
          19,
          71,
          57,
          65,
          17,
          83,
          54
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "write_model",
          91,
          215,
          97,
          20,
          97,
          58,
          91,
          17,
          99,
          23
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "convert_checkpoint",
          185,
          261,
          188,
          24,
          188,
          40,
          185,
          24,
          205,
          38
        ]
      ],
      "transformers/src/transformers/hf_argparser.py": [
        [
          "parse_yaml_file",
          410,
          430,
          429,
          35,
          429,
          77,
          411,
          9,
          430,
          29
        ]
      ]
    },
    "eval": {
      "transformers/src/transformers/models/hubert/convert_distilhubert_original_s3prl_checkpoint_to_pytorch.py": [
        [
          "convert_config",
          154,
          184,
          162,
          19,
          162,
          63,
          154,
          20,
          167,
          82
        ]
      ],
      "transformers/src/transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_config",
          173,
          219,
          181,
          19,
          181,
          53,
          176,
          21,
          186,
          82
        ],
        [
          "convert_config",
          173,
          219,
          181,
          19,
          181,
          53,
          178,
          21,
          186,
          82
        ]
      ],
      "transformers/src/transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_config",
          177,
          231,
          185,
          19,
          185,
          53,
          180,
          21,
          190,
          82
        ],
        [
          "convert_config",
          177,
          231,
          185,
          19,
          185,
          53,
          182,
          21,
          190,
          82
        ]
      ],
      "transformers/examples/legacy/benchmarking/run_benchmark.py": [
        [
          "main",
          21,
          43,
          29,
          28,
          29,
          54,
          25,
          5,
          31,
          35
        ]
      ]
    }
  },
  "CWE-113": {
    "urllib.parse.urlparse": {
      "transformers/src/transformers/video_utils.py": [
        [
          "load_video",
          618,
          714,
          675,
          8,
          675,
          22,
          675,
          8,
          675,
          67
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "is_remote_url",
          193,
          195,
          194,
          14,
          194,
          38,
          193,
          19,
          195,
          45
        ]
      ],
      "transformers/src/transformers/models/idefics/processing_idefics.py": [
        [
          "is_url",
          129,
          135,
          134,
          14,
          134,
          29,
          134,
          14,
          135,
          46
        ]
      ]
    }
  },
  "CWE-117": {
    "print": {
      "transformers/tests/models/sam/test_modeling_sam.py": [
        [
          "test_attention_outputs",
          570,
          623,
          589,
          13,
          589,
          61,
          581,
          13,
          623,
          13
        ]
      ],
      "transformers/tests/models/sam2_video/test_modeling_sam2_video.py": [
        [
          "test_inference_mask_generation_video_batched_bb",
          396,
          435,
          418,
          13,
          418,
          40,
          410,
          13,
          419,
          42
        ],
        [
          "test_inference_mask_generation_video_batched_bb",
          396,
          435,
          422,
          9,
          422,
          27,
          420,
          18,
          435,
          9
        ],
        [
          "test_inference_mask_generation_video_batched_bb",
          396,
          435,
          423,
          9,
          423,
          39,
          420,
          18,
          435,
          9
        ]
      ],
      "transformers/tests/models/vilt/test_modeling_vilt.py": [
        [
          "test_training",
          271,
          293,
          291,
          17,
          291,
          33,
          290,
          17,
          291,
          33
        ],
        [
          "test_hidden_states_output",
          446,
          492,
          484,
          13,
          484,
          46,
          483,
          13,
          492,
          72
        ]
      ],
      "transformers/tests/models/vit_msn/test_modeling_vit_msn.py": [
        [
          "create_and_check_for_image_classification",
          123,
          141,
          129,
          9,
          129,
          77,
          123,
          51,
          141,
          102
        ],
        [
          "create_and_check_for_image_classification",
          123,
          141,
          130,
          9,
          130,
          33,
          123,
          51,
          141,
          102
        ]
      ],
      "transformers/tests/models/vitmatte/test_modeling_vitmatte.py": [
        [
          "test_hidden_states_output",
          203,
          236,
          234,
          13,
          234,
          37,
          226,
          13,
          236,
          72
        ]
      ],
      "transformers/tests/models/vitpose/test_modeling_vitpose.py": [
        [
          "test_batched_inference",
          288,
          333,
          317,
          9,
          317,
          27,
          314,
          9,
          333,
          113
        ]
      ],
      "transformers/tests/models/x_clip/test_modeling_x_clip.py": [
        [
          "test_gradient_checkpointing_backward_compatibility",
          220,
          231,
          227,
          13,
          227,
          46,
          227,
          13,
          231,
          60
        ],
        [
          "test_multi_gpu_data_parallel_forward",
          289,
          311,
          308,
          25,
          308,
          41,
          308,
          25,
          308,
          41
        ],
        [
          "test_multi_gpu_data_parallel_forward",
          289,
          311,
          310,
          25,
          310,
          35,
          310,
          25,
          310,
          35
        ]
      ],
      "transformers/tests/generation/test_paged_attention.py": [
        [
          "test_generate_batch_with_sampling",
          98,
          149,
          125,
          9,
          127,
          9,
          98,
          43,
          135,
          49
        ],
        [
          "test_generate_batch_consistency",
          53,
          88,
          76,
          9,
          78,
          9,
          53,
          41,
          80,
          49
        ]
      ],
      "transformers/tests/models/aria/test_processing_aria.py": [
        [
          "test_apply_chat_template",
          195,
          231,
          221,
          9,
          221,
          23,
          195,
          34,
          231,
          53
        ]
      ],
      "transformers/tests/models/csm/test_processing_csm.py": [
        [
          "_test_apply_chat_template",
          69,
          174,
          154,
          9,
          154,
          76,
          145,
          20,
          162,
          25
        ],
        [
          "_test_apply_chat_template",
          69,
          174,
          155,
          9,
          155,
          44,
          145,
          20,
          162,
          25
        ]
      ],
      "transformers/tests/models/flaubert/test_tokenization_flaubert.py": [
        [
          "test_sequence_builders",
          63,
          75,
          72,
          9,
          72,
          31,
          63,
          32,
          74,
          51
        ],
        [
          "test_sequence_builders",
          63,
          75,
          71,
          9,
          71,
          31,
          63,
          32,
          74,
          51
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_fast_special_tokens",
          376,
          408,
          387,
          9,
          387,
          43,
          384,
          9,
          389,
          46
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_encode_decode_fast_slow_all_tokens",
          2135,
          2179,
          2148,
          17,
          2148,
          99,
          2137,
          31,
          2150,
          80
        ],
        [
          "test_encode_decode_fast_slow_all_tokens",
          2135,
          2179,
          2163,
          17,
          2163,
          93,
          2163,
          17,
          2164,
          75
        ]
      ],
      "transformers/tests/models/phobert/test_tokenization_phobert.py": [
        [
          "test_full_tokenizer",
          58,
          69,
          63,
          9,
          63,
          21,
          58,
          29,
          69,
          93
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "get_modified_python_files",
          358,
          385,
          378,
          13,
          378,
          48,
          377,
          13,
          378,
          48
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          253,
          9,
          253,
          55,
          252,
          9,
          256,
          29
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          252,
          9,
          252,
          52,
          252,
          9,
          256,
          29
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          257,
          13,
          257,
          48,
          256,
          13,
          257,
          48
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          259,
          9,
          259,
          47,
          259,
          9,
          261,
          29
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          262,
          13,
          262,
          45,
          261,
          13,
          262,
          45
        ],
        [
          "get_diff",
          316,
          355,
          333,
          5,
          333,
          29,
          316,
          14,
          335,
          25
        ],
        [
          "get_diff",
          316,
          355,
          351,
          25,
          351,
          112,
          351,
          25,
          351,
          112
        ],
        [
          "get_modified_python_files",
          358,
          385,
          373,
          9,
          373,
          52,
          373,
          9,
          377,
          39
        ],
        [
          "get_modified_python_files",
          358,
          385,
          374,
          9,
          374,
          55,
          373,
          9,
          377,
          39
        ],
        [
          "get_modified_python_files",
          358,
          385,
          381,
          9,
          381,
          47,
          381,
          9,
          383,
          36
        ],
        [
          "get_modified_python_files",
          358,
          385,
          384,
          13,
          384,
          45,
          383,
          13,
          384,
          45
        ],
        [
          "get_diff_for_doctesting",
          388,
          426,
          404,
          5,
          404,
          29,
          388,
          29,
          406,
          25
        ],
        [
          "get_diff_for_doctesting",
          388,
          426,
          424,
          25,
          424,
          107,
          424,
          25,
          424,
          107
        ],
        [
          "get_doctest_files",
          489,
          534,
          504,
          9,
          504,
          52,
          504,
          9,
          508,
          39
        ],
        [
          "get_doctest_files",
          489,
          534,
          505,
          9,
          505,
          55,
          504,
          9,
          508,
          39
        ],
        [
          "get_doctest_files",
          489,
          534,
          509,
          13,
          509,
          48,
          508,
          13,
          509,
          48
        ],
        [
          "get_doctest_files",
          489,
          534,
          512,
          9,
          512,
          47,
          512,
          9,
          514,
          36
        ],
        [
          "get_doctest_files",
          489,
          534,
          515,
          13,
          515,
          45,
          514,
          13,
          515,
          45
        ],
        [
          "print_tree_deps_of",
          765,
          795,
          795,
          9,
          795,
          22,
          793,
          9,
          795,
          22
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          982,
          9,
          982,
          64,
          981,
          43,
          982,
          64
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          983,
          5,
          983,
          69,
          983,
          5,
          987,
          27
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          993,
          5,
          993,
          69,
          992,
          22,
          998,
          93
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          1007,
          13,
          1009,
          13,
          1007,
          13,
          1009,
          13
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          1028,
          5,
          1028,
          69,
          1028,
          5,
          1035,
          28
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          1034,
          5,
          1034,
          67,
          1028,
          5,
          1035,
          28
        ],
        [
          "filter_tests",
          1041,
          1065,
          1050,
          9,
          1050,
          36,
          1050,
          9,
          1051,
          14
        ],
        [
          "filter_tests",
          1041,
          1065,
          1056,
          9,
          1056,
          36,
          1056,
          9,
          1057,
          14
        ],
        [
          "create_test_list_from_filter",
          1109,
          1121,
          1118,
          9,
          1118,
          34,
          1118,
          9,
          1119,
          33
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "_stream_subprocess",
          2384,
          2422,
          2386,
          9,
          2386,
          43,
          2386,
          9,
          2386,
          43
        ],
        [
          "tee",
          2408,
          2412,
          2412,
          13,
          2412,
          41,
          2412,
          13,
          2412,
          41
        ],
        [
          "_get_call_arguments",
          3462,
          3519,
          3517,
          9,
          3517,
          36,
          3516,
          5,
          3517,
          36
        ]
      ],
      "transformers/scripts/distributed/torch-distributed-gpu-test.py": [
        [
          "printflock",
          53,
          60,
          58,
          13,
          58,
          24,
          58,
          13,
          58,
          24
        ]
      ],
      "transformers/src/transformers/trainer_callback.py": [
        [
          "on_log",
          706,
          709,
          709,
          13,
          709,
          23,
          709,
          13,
          709,
          23
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "log_metrics",
          794,
          881,
          876,
          5,
          876,
          41,
          876,
          5,
          880,
          47
        ],
        [
          "log_metrics",
          794,
          881,
          881,
          9,
          881,
          75,
          880,
          9,
          881,
          75
        ]
      ],
      "transformers/utils/update_metadata.py": [
        [
          "update_metadata",
          232,
          312,
          295,
          13,
          295,
          75,
          295,
          13,
          296,
          18
        ]
      ],
      "transformers/.github/scripts/assign_reviewers.py": [
        [
          "main",
          74,
          117,
          117,
          9,
          117,
          64,
          116,
          5,
          117,
          64
        ],
        [
          "main",
          74,
          117,
          89,
          9,
          89,
          82,
          89,
          9,
          90,
          14
        ],
        [
          "main",
          74,
          117,
          94,
          9,
          94,
          81,
          94,
          9,
          95,
          14
        ],
        [
          "main",
          74,
          117,
          100,
          9,
          100,
          64,
          100,
          9,
          101,
          14
        ],
        [
          "main",
          74,
          117,
          112,
          5,
          112,
          35,
          110,
          5,
          115,
          32
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_release_date",
          124,
          136,
          132,
          13,
          132,
          105,
          131,
          9,
          132,
          105
        ],
        [
          "insert_dates",
          180,
          250,
          250,
          13,
          250,
          66,
          244,
          28,
          250,
          66
        ],
        [
          "get_paper_link",
          54,
          91,
          85,
          13,
          85,
          108,
          85,
          13,
          86,
          41
        ],
        [
          "get_paper_link",
          54,
          91,
          87,
          17,
          87,
          36,
          86,
          17,
          87,
          36
        ],
        [
          "get_release_date",
          124,
          136,
          135,
          9,
          135,
          118,
          135,
          9,
          136,
          32
        ],
        [
          "replace_paper_links",
          139,
          177,
          165,
          13,
          165,
          57,
          165,
          13,
          165,
          57
        ],
        [
          "replace_paper_links",
          139,
          177,
          169,
          13,
          169,
          111,
          167,
          9,
          170,
          20
        ],
        [
          "insert_dates",
          180,
          250,
          195,
          13,
          195,
          57,
          195,
          13,
          195,
          57
        ],
        [
          "insert_dates",
          180,
          250,
          206,
          13,
          206,
          94,
          206,
          13,
          212,
          19
        ],
        [
          "main",
          266,
          280,
          269,
          9,
          269,
          83,
          268,
          23,
          269,
          83
        ],
        [
          "main",
          266,
          280,
          273,
          13,
          273,
          51,
          273,
          13,
          274,
          18
        ],
        [
          "main",
          266,
          280,
          275,
          9,
          275,
          64,
          275,
          9,
          275,
          64
        ],
        [
          "main",
          266,
          280,
          278,
          9,
          278,
          65,
          277,
          23,
          278,
          65
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_file",
          342,
          446,
          370,
          9,
          370,
          62,
          367,
          9,
          373,
          9
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          350,
          9,
          350,
          79,
          350,
          9,
          351,
          14
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          356,
          9,
          356,
          113,
          356,
          9,
          360,
          9
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          357,
          9,
          357,
          62,
          356,
          9,
          360,
          9
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          367,
          9,
          369,
          9,
          367,
          9,
          373,
          9
        ],
        [
          "add_fast_image_processor",
          449,
          507,
          480,
          5,
          480,
          87,
          476,
          28,
          507,
          5
        ]
      ],
      "transformers/src/transformers/utils/attention_visualizer.py": [
        [
          "visualize_attention_mask",
          177,
          251,
          232,
          9,
          232,
          39,
          228,
          29,
          251,
          37
        ],
        [
          "visualize_attention_mask",
          177,
          251,
          233,
          9,
          240,
          9,
          228,
          29,
          251,
          37
        ],
        [
          "visualize_attention_mask",
          177,
          251,
          241,
          9,
          241,
          37,
          228,
          29,
          251,
          37
        ],
        [
          "visualize_attention_mask",
          177,
          251,
          250,
          9,
          250,
          23,
          228,
          29,
          251,
          37
        ],
        [
          "visualize_attention_mask",
          177,
          251,
          251,
          9,
          251,
          37,
          228,
          29,
          251,
          37
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "get_user_field",
          574,
          620,
          618,
          13,
          618,
          35,
          618,
          13,
          618,
          35
        ],
        [
          "get_user_input",
          634,
          742,
          649,
          13,
          649,
          65,
          649,
          13,
          651,
          37
        ],
        [
          "get_user_input",
          634,
          742,
          654,
          17,
          654,
          54,
          654,
          17,
          654,
          54
        ]
      ],
      "transformers/src/transformers/pipelines/audio_utils.py": [
        [
          "_get_microphone_name",
          280,
          297,
          292,
          13,
          292,
          57,
          292,
          13,
          292,
          57
        ],
        [
          "_get_microphone_name",
          280,
          297,
          295,
          9,
          295,
          96,
          294,
          5,
          295,
          96
        ]
      ],
      "transformers/src/transformers/utils/auto_docstring.py": [
        [
          "get_model_name",
          1104,
          1121,
          1120,
          5,
          1120,
          86,
          1120,
          5,
          1121,
          18
        ],
        [
          "_get_model_info",
          1225,
          1270,
          1266,
          17,
          1268,
          17,
          1265,
          32,
          1268,
          17
        ],
        [
          "_process_kwargs_parameters",
          1448,
          1537,
          1517,
          25,
          1519,
          25,
          1517,
          25,
          1520,
          64
        ],
        [
          "_process_parameters_section",
          1540,
          1581,
          1579,
          9,
          1579,
          49,
          1579,
          9,
          1579,
          49
        ],
        [
          "_process_example_section",
          1619,
          1705,
          1685,
          17,
          1687,
          17,
          1685,
          17,
          1687,
          17
        ],
        [
          "auto_class_docstring",
          1767,
          1881,
          1859,
          25,
          1859,
          118,
          1859,
          25,
          1860,
          64
        ],
        [
          "auto_class_docstring",
          1767,
          1881,
          1875,
          9,
          1877,
          9,
          1809,
          50,
          1877,
          9
        ],
        [
          "auto_class_docstring",
          1767,
          1881,
          1875,
          9,
          1877,
          9,
          1875,
          9,
          1877,
          9
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          132,
          21,
          132,
          51,
          131,
          21,
          132,
          51
        ],
        [
          "summarize",
          60,
          146,
          123,
          9,
          123,
          32,
          123,
          9,
          126,
          34
        ],
        [
          "summarize",
          60,
          146,
          124,
          9,
          124,
          34,
          123,
          9,
          126,
          34
        ],
        [
          "summarize",
          60,
          146,
          125,
          9,
          125,
          42,
          123,
          9,
          126,
          34
        ],
        [
          "summarize",
          60,
          146,
          127,
          13,
          127,
          29,
          127,
          13,
          128,
          29
        ],
        [
          "summarize",
          60,
          146,
          129,
          17,
          129,
          37,
          129,
          17,
          129,
          37
        ],
        [
          "summarize",
          60,
          146,
          133,
          9,
          133,
          23,
          133,
          9,
          144,
          44
        ],
        [
          "combine_summaries",
          149,
          195,
          193,
          5,
          193,
          41,
          190,
          10,
          195,
          19
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "save",
          627,
          634,
          634,
          9,
          634,
          19,
          627,
          14,
          634,
          19
        ]
      ],
      "transformers/utils/check_bad_commit.py": [
        [
          "find_bad_commit",
          72,
          133,
          104,
          5,
          104,
          24,
          87,
          5,
          106,
          50
        ],
        [
          "find_bad_commit",
          72,
          133,
          130,
          5,
          130,
          81,
          130,
          5,
          133,
          21
        ],
        [
          "find_bad_commit",
          72,
          133,
          131,
          5,
          131,
          40,
          130,
          5,
          133,
          21
        ]
      ],
      "transformers/utils/check_dummies.py": [
        [
          "check_dummies",
          186,
          248,
          217,
          17,
          220,
          17,
          217,
          17,
          222,
          49
        ],
        [
          "check_dummies",
          186,
          248,
          236,
          21,
          236,
          94,
          236,
          21,
          237,
          28
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "is_copy_consistent",
          635,
          826,
          823,
          9,
          823,
          57,
          823,
          9,
          825,
          31
        ]
      ],
      "transformers/utils/check_pipeline_typing.py": [
        [
          "main",
          30,
          78,
          64,
          9,
          64,
          50,
          64,
          9,
          71,
          31
        ]
      ],
      "transformers/scripts/check_tokenizers.py": [
        [
          "check_details",
          59,
          119,
          110,
          9,
          110,
          80,
          110,
          9,
          110,
          80
        ],
        [
          "check_details",
          59,
          119,
          118,
          5,
          118,
          16,
          114,
          5,
          119,
          16
        ],
        [
          "check_details",
          59,
          119,
          108,
          5,
          108,
          76,
          108,
          5,
          110,
          76
        ],
        [
          "check_details",
          59,
          119,
          117,
          5,
          117,
          11,
          114,
          5,
          119,
          16
        ],
        [
          "test_string",
          122,
          151,
          144,
          9,
          144,
          89,
          144,
          9,
          144,
          89
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "check_auto_docstrings",
          1335,
          1376,
          1367,
          17,
          1369,
          17,
          1367,
          17,
          1369,
          17
        ],
        [
          "fix_docstring",
          798,
          870,
          868,
          5,
          868,
          67,
          856,
          16,
          870,
          33
        ],
        [
          "find_matching_model_files",
          903,
          940,
          938,
          5,
          938,
          112,
          934,
          12,
          940,
          25
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1359,
          17,
          1361,
          17,
          1359,
          17,
          1361,
          17
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1362,
          13,
          1362,
          90,
          1362,
          13,
          1363,
          58
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1364,
          17,
          1364,
          30,
          1363,
          17,
          1364,
          30
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1370,
          13,
          1370,
          92,
          1370,
          13,
          1371,
          60
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1372,
          17,
          1372,
          30,
          1371,
          17,
          1372,
          30
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1374,
          13,
          1374,
          101,
          1374,
          13,
          1375,
          55
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1376,
          17,
          1376,
          30,
          1375,
          17,
          1376,
          30
        ],
        [
          "check_docstrings",
          1379,
          1473,
          1404,
          9,
          1404,
          114,
          1404,
          9,
          1404,
          114
        ],
        [
          "check_docstrings",
          1379,
          1473,
          1437,
          13,
          1437,
          20,
          1436,
          9,
          1439,
          20
        ]
      ],
      "transformers/utils/collated_reports.py": [
        [
          "get_gpu_name",
          56,
          70,
          64,
          13,
          64,
          53,
          63,
          9,
          65,
          20
        ],
        [
          "get_commit_hash",
          73,
          82,
          79,
          13,
          79,
          56,
          78,
          9,
          80,
          23
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "check_repo_quality",
          1199,
          1220,
          1201,
          5,
          1201,
          36,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1202,
          5,
          1202,
          52,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1204,
          5,
          1204,
          50,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1206,
          5,
          1206,
          50,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1209,
          5,
          1209,
          59,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1211,
          5,
          1211,
          70,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1213,
          5,
          1213,
          72,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1215,
          5,
          1215,
          97,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1217,
          5,
          1217,
          64,
          1200,
          5,
          1220,
          45
        ],
        [
          "check_repo_quality",
          1199,
          1220,
          1219,
          5,
          1219,
          73,
          1200,
          5,
          1220,
          45
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "recursive_print",
          172,
          197,
          195,
          9,
          195,
          35,
          195,
          9,
          195,
          35
        ],
        [
          "recursive_print",
          172,
          197,
          191,
          13,
          191,
          22,
          191,
          13,
          191,
          22
        ],
        [
          "recursive_print",
          172,
          197,
          197,
          9,
          197,
          28,
          197,
          9,
          197,
          28
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          343,
          5,
          343,
          84,
          343,
          5,
          347,
          28
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          372,
          5,
          372,
          21,
          368,
          9,
          443,
          33
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          409,
          5,
          409,
          23,
          368,
          9,
          443,
          33
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          412,
          5,
          412,
          34,
          368,
          9,
          443,
          33
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          435,
          5,
          435,
          42,
          368,
          9,
          443,
          33
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          445,
          13,
          445,
          65,
          445,
          13,
          446,
          26
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          540,
          5,
          540,
          39,
          540,
          5,
          553,
          38
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          546,
          5,
          546,
          31,
          540,
          5,
          553,
          38
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          550,
          5,
          550,
          65,
          540,
          5,
          553,
          38
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          569,
          5,
          569,
          26,
          564,
          17,
          573,
          38
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          574,
          9,
          574,
          58,
          574,
          9,
          575,
          49
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          594,
          9,
          594,
          85,
          594,
          9,
          594,
          85
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          601,
          9,
          605,
          9,
          596,
          27,
          605,
          9
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          634,
          9,
          634,
          111,
          634,
          9,
          635,
          15
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          729,
          5,
          729,
          23,
          729,
          5,
          731,
          58
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          735,
          5,
          735,
          39,
          735,
          5,
          742,
          42
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          766,
          5,
          766,
          42,
          766,
          5,
          767,
          79
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          904,
          17,
          907,
          17,
          904,
          17,
          908,
          65
        ]
      ],
      "transformers/src/transformers/models/albert/convert_albert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          28,
          39,
          31,
          5,
          31,
          65,
          28,
          38,
          39,
          53
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          28,
          39,
          38,
          5,
          38,
          55,
          28,
          38,
          39,
          53
        ]
      ],
      "transformers/examples/pytorch/continuous_batching.py": [
        [
          "batch_generate",
          94,
          178,
          140,
          17,
          140,
          56,
          139,
          17,
          141,
          57
        ],
        [
          "batch_generate",
          94,
          178,
          132,
          13,
          132,
          64,
          131,
          9,
          134,
          20
        ],
        [
          "batch_generate",
          94,
          178,
          115,
          9,
          115,
          44,
          106,
          9,
          120,
          46
        ],
        [
          "setup_metrics",
          64,
          91,
          91,
          9,
          91,
          47,
          90,
          5,
          91,
          47
        ],
        [
          "batch_generate",
          94,
          178,
          106,
          9,
          106,
          54,
          106,
          9,
          120,
          46
        ],
        [
          "batch_generate",
          94,
          178,
          139,
          17,
          139,
          31,
          139,
          17,
          141,
          57
        ],
        [
          "batch_generate",
          94,
          178,
          141,
          17,
          141,
          57,
          139,
          17,
          141,
          57
        ],
        [
          "batch_generate",
          94,
          178,
          143,
          17,
          143,
          56,
          143,
          17,
          145,
          53
        ],
        [
          "batch_generate",
          94,
          178,
          144,
          17,
          144,
          31,
          143,
          17,
          145,
          53
        ],
        [
          "batch_generate",
          94,
          178,
          145,
          17,
          145,
          53,
          143,
          17,
          145,
          53
        ],
        [
          "batch_generate",
          94,
          178,
          154,
          13,
          154,
          88,
          154,
          19,
          154,
          88
        ],
        [
          "batch_generate",
          94,
          178,
          160,
          9,
          160,
          23,
          157,
          16,
          174,
          30
        ],
        [
          "batch_generate",
          94,
          178,
          161,
          9,
          161,
          57,
          157,
          16,
          174,
          30
        ],
        [
          "batch_generate",
          94,
          178,
          162,
          9,
          162,
          109,
          157,
          16,
          174,
          30
        ]
      ],
      "transformers/src/transformers/models/aimv2/convert_aimv2_original_pytorch_to_hf.py": [
        [
          "write_model",
          146,
          212,
          179,
          5,
          179,
          32,
          177,
          27,
          185,
          23
        ],
        [
          "write_model",
          146,
          212,
          199,
          5,
          199,
          65,
          199,
          5,
          212,
          16
        ],
        [
          "write_model",
          146,
          212,
          202,
          5,
          202,
          44,
          199,
          5,
          212,
          16
        ],
        [
          "write_model",
          146,
          212,
          204,
          5,
          204,
          30,
          199,
          5,
          212,
          16
        ],
        [
          "write_model",
          146,
          212,
          209,
          5,
          209,
          66,
          199,
          5,
          212,
          16
        ],
        [
          "write_model",
          146,
          212,
          211,
          5,
          211,
          41,
          199,
          5,
          212,
          16
        ],
        [
          "main",
          224,
          265,
          263,
          9,
          263,
          34,
          263,
          9,
          265,
          53
        ]
      ],
      "transformers/src/transformers/models/aria/convert_aria_weights_to_hf.py": [
        [
          "convert_aria_llama_to_hf",
          86,
          129,
          127,
          5,
          127,
          27,
          86,
          30,
          129,
          58
        ]
      ],
      "transformers/src/transformers/models/align/convert_align_tf_to_hf.py": [
        [
          "convert_align_checkpoint",
          288,
          367,
          312,
          5,
          312,
          37,
          304,
          22,
          349,
          68
        ],
        [
          "convert_align_checkpoint",
          288,
          367,
          353,
          5,
          353,
          33,
          353,
          5,
          355,
          17
        ],
        [
          "convert_align_checkpoint",
          288,
          367,
          365,
          9,
          365,
          54,
          365,
          9,
          367,
          42
        ]
      ],
      "transformers/src/transformers/models/audio_spectrogram_transformer/convert_audio_spectrogram_transformer_original_to_pytorch.py": [
        [
          "convert_audio_spectrogram_transformer_checkpoint",
          153,
          259,
          253,
          9,
          253,
          72,
          250,
          9,
          254,
          67
        ],
        [
          "convert_audio_spectrogram_transformer_checkpoint",
          153,
          259,
          247,
          5,
          247,
          22,
          247,
          5,
          249,
          43
        ],
        [
          "convert_audio_spectrogram_transformer_checkpoint",
          153,
          259,
          251,
          9,
          251,
          73,
          250,
          9,
          254,
          67
        ],
        [
          "convert_audio_spectrogram_transformer_checkpoint",
          153,
          259,
          257,
          9,
          257,
          66,
          257,
          9,
          259,
          58
        ]
      ],
      "transformers/src/transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          28,
          39,
          31,
          5,
          31,
          65,
          28,
          38,
          39,
          53
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          28,
          39,
          38,
          5,
          38,
          55,
          28,
          38,
          39,
          53
        ]
      ],
      "transformers/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py": [
        [
          "convert_beit_checkpoint",
          170,
          357,
          346,
          13,
          346,
          67,
          346,
          13,
          348,
          76
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          354,
          5,
          354,
          56,
          341,
          12,
          357,
          61
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          354,
          5,
          354,
          56,
          353,
          5,
          357,
          61
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          356,
          5,
          356,
          66,
          341,
          12,
          357,
          61
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          356,
          5,
          356,
          66,
          353,
          5,
          357,
          61
        ]
      ],
      "transformers/src/transformers/models/bert/convert_bert_token_dropping_original_tf2_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint_to_pytorch",
          42,
          167,
          80,
          5,
          80,
          65,
          42,
          35,
          85,
          57
        ],
        [
          "convert_checkpoint_to_pytorch",
          42,
          167,
          165,
          5,
          165,
          27,
          139,
          61,
          167,
          52
        ],
        [
          "convert_checkpoint_to_pytorch",
          42,
          167,
          167,
          5,
          167,
          52,
          139,
          61,
          167,
          52
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "sanity_check",
          180,
          194,
          194,
          5,
          194,
          35,
          181,
          10,
          194,
          35
        ]
      ],
      "transformers/src/transformers/models/big_bird/convert_bigbird_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          209,
          224,
          212,
          5,
          212,
          65,
          209,
          38,
          214,
          19
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          209,
          224,
          223,
          5,
          223,
          55,
          220,
          5,
          224,
          44
        ]
      ],
      "transformers/src/transformers/models/bit/convert_bit_to_pytorch.py": [
        [
          "convert_bit_checkpoint",
          83,
          155,
          153,
          9,
          153,
          69,
          153,
          9,
          155,
          55
        ],
        [
          "convert_bit_checkpoint",
          83,
          155,
          139,
          5,
          139,
          35,
          132,
          5,
          142,
          52
        ],
        [
          "convert_bit_checkpoint",
          83,
          155,
          140,
          5,
          140,
          78,
          132,
          5,
          142,
          52
        ],
        [
          "convert_bit_checkpoint",
          83,
          155,
          144,
          5,
          144,
          22,
          143,
          5,
          146,
          43
        ],
        [
          "convert_bit_checkpoint",
          83,
          155,
          148,
          9,
          148,
          87,
          147,
          9,
          150,
          59
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          164,
          5,
          164,
          59,
          163,
          5,
          169,
          42
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          183,
          5,
          183,
          69,
          179,
          16,
          189,
          40
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          223,
          5,
          223,
          51,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          240,
          5,
          240,
          55,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          269,
          5,
          269,
          52,
          261,
          14,
          272,
          32
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          272,
          5,
          272,
          32,
          261,
          14,
          272,
          32
        ]
      ],
      "transformers/src/transformers/models/blip_2/convert_blip_2_original_to_pytorch.py": [
        [
          "convert_blip2_checkpoint",
          144,
          347,
          259,
          9,
          259,
          73,
          258,
          9,
          265,
          99
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          260,
          9,
          260,
          75,
          258,
          9,
          265,
          99
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          284,
          9,
          284,
          73,
          283,
          9,
          290,
          99
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          184,
          5,
          184,
          38,
          170,
          9,
          194,
          32
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          189,
          5,
          189,
          18,
          170,
          9,
          194,
          32
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          270,
          9,
          270,
          26,
          269,
          9,
          283,
          69
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          285,
          9,
          285,
          75,
          283,
          9,
          290,
          99
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          291,
          9,
          291,
          26,
          290,
          9,
          291,
          26
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          308,
          9,
          308,
          77,
          307,
          9,
          312,
          83
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          309,
          9,
          309,
          62,
          307,
          9,
          312,
          83
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          313,
          9,
          313,
          26,
          312,
          9,
          339,
          44
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          315,
          9,
          315,
          40,
          312,
          9,
          339,
          44
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          338,
          9,
          338,
          55,
          312,
          9,
          339,
          44
        ],
        [
          "convert_blip2_checkpoint",
          144,
          347,
          339,
          9,
          339,
          44,
          312,
          9,
          339,
          44
        ]
      ],
      "transformers/src/transformers/models/blip/convert_blip_original_pytorch_to_hf.py": [
        [
          "convert_blip_checkpoint",
          82,
          182,
          144,
          5,
          144,
          38,
          136,
          20,
          146,
          57
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          205,
          9,
          205,
          93,
          199,
          9,
          206,
          35
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          101,
          13,
          101,
          45,
          100,
          13,
          104,
          42
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          209,
          9,
          209,
          71,
          208,
          9,
          211,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/bort/convert_bort_original_gluonnlp_checkpoint_to_pytorch.py": [
        [
          "convert_bort_checkpoint_to_pytorch",
          54,
          305,
          304,
          9,
          304,
          64,
          304,
          9,
          305,
          59
        ],
        [
          "convert_bort_checkpoint_to_pytorch",
          54,
          305,
          305,
          9,
          305,
          59,
          304,
          9,
          305,
          59
        ],
        [
          "convert_bort_checkpoint_to_pytorch",
          54,
          305,
          302,
          9,
          302,
          57,
          302,
          9,
          302,
          57
        ]
      ],
      "transformers/src/transformers/models/bros/convert_bros_to_pytorch.py": [
        [
          "convert_bros_checkpoint",
          68,
          117,
          111,
          9,
          111,
          74,
          111,
          9,
          113,
          59
        ]
      ],
      "transformers/src/transformers/models/canine/convert_canine_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          127,
          145,
          133,
          5,
          133,
          65,
          127,
          38,
          145,
          48
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          127,
          145,
          139,
          5,
          139,
          55,
          127,
          38,
          145,
          48
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          127,
          145,
          144,
          5,
          144,
          57,
          127,
          38,
          145,
          48
        ]
      ],
      "transformers/src/transformers/models/byt5/convert_byt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          135,
          146,
          138,
          5,
          138,
          65,
          135,
          38,
          146,
          44
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          135,
          146,
          145,
          5,
          145,
          55,
          135,
          38,
          146,
          44
        ]
      ],
      "transformers/src/transformers/models/colqwen2/convert_colqwen2_weights_to_hf.py": [
        [
          "convert_colqwen2_weights_to_hf",
          96,
          158,
          154,
          9,
          154,
          59,
          153,
          9,
          154,
          59
        ],
        [
          "convert_colqwen2_weights_to_hf",
          96,
          158,
          128,
          5,
          128,
          75,
          113,
          27,
          136,
          35
        ],
        [
          "convert_colqwen2_weights_to_hf",
          96,
          158,
          138,
          5,
          138,
          67,
          138,
          5,
          148,
          20
        ],
        [
          "convert_colqwen2_weights_to_hf",
          96,
          158,
          142,
          5,
          142,
          42,
          138,
          5,
          148,
          20
        ],
        [
          "convert_colqwen2_weights_to_hf",
          96,
          158,
          158,
          9,
          158,
          47,
          156,
          9,
          158,
          47
        ]
      ],
      "transformers/src/transformers/models/colpali/convert_colpali_weights_to_hf.py": [
        [
          "convert_colpali_weights_to_hf",
          97,
          163,
          163,
          9,
          163,
          47,
          161,
          9,
          163,
          47
        ],
        [
          "convert_colpali_weights_to_hf",
          97,
          163,
          159,
          9,
          159,
          59,
          158,
          9,
          159,
          59
        ],
        [
          "convert_colpali_weights_to_hf",
          97,
          163,
          129,
          5,
          129,
          75,
          114,
          27,
          137,
          35
        ],
        [
          "convert_colpali_weights_to_hf",
          97,
          163,
          139,
          5,
          139,
          67,
          139,
          5,
          146,
          62
        ],
        [
          "convert_colpali_weights_to_hf",
          97,
          163,
          143,
          5,
          143,
          42,
          139,
          5,
          146,
          62
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          124,
          5,
          124,
          80,
          124,
          5,
          126,
          22
        ],
        [
          "write_model",
          84,
          436,
          400,
          5,
          400,
          59,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          401,
          5,
          401,
          20,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          419,
          5,
          419,
          59,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          420,
          5,
          420,
          20,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          436,
          5,
          436,
          58,
          357,
          13,
          436,
          58
        ]
      ],
      "transformers/src/transformers/models/clipseg/convert_clipseg_original_pytorch_to_hf.py": [
        [
          "convert_clipseg_checkpoint",
          167,
          231,
          229,
          9,
          229,
          73,
          229,
          9,
          231,
          52
        ],
        [
          "convert_clipseg_checkpoint",
          167,
          231,
          221,
          5,
          221,
          22,
          220,
          5,
          223,
          43
        ],
        [
          "convert_clipseg_checkpoint",
          167,
          231,
          224,
          9,
          224,
          74,
          224,
          9,
          226,
          59
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_convnext_upernet_to_pytorch.py": [
        [
          "convert_upernet_checkpoint",
          121,
          193,
          180,
          5,
          180,
          50,
          180,
          5,
          181,
          82
        ],
        [
          "convert_upernet_checkpoint",
          121,
          193,
          182,
          5,
          182,
          22,
          181,
          5,
          184,
          43
        ],
        [
          "convert_upernet_checkpoint",
          121,
          193,
          185,
          9,
          185,
          73,
          185,
          9,
          188,
          59
        ],
        [
          "convert_upernet_checkpoint",
          121,
          193,
          187,
          9,
          187,
          64,
          185,
          9,
          188,
          59
        ],
        [
          "convert_upernet_checkpoint",
          121,
          193,
          191,
          9,
          191,
          69,
          191,
          9,
          193,
          56
        ]
      ],
      "transformers/src/transformers/models/convnext/convert_convnext_to_pytorch.py": [
        [
          "convert_convnext_checkpoint",
          121,
          221,
          191,
          5,
          191,
          56,
          188,
          5,
          198,
          31
        ],
        [
          "convert_convnext_checkpoint",
          121,
          221,
          193,
          5,
          193,
          66,
          188,
          5,
          198,
          31
        ],
        [
          "convert_convnext_checkpoint",
          121,
          221,
          196,
          5,
          196,
          40,
          188,
          5,
          198,
          31
        ]
      ],
      "transformers/src/transformers/models/csm/convert_csm.py": [
        [
          "write_model",
          79,
          232,
          86,
          5,
          86,
          34,
          80,
          5,
          173,
          36
        ],
        [
          "write_model",
          79,
          232,
          159,
          5,
          159,
          76,
          80,
          5,
          173,
          36
        ],
        [
          "write_model",
          79,
          232,
          162,
          5,
          162,
          32,
          80,
          5,
          173,
          36
        ],
        [
          "write_model",
          79,
          232,
          207,
          5,
          207,
          51,
          197,
          61,
          232,
          41
        ],
        [
          "write_model",
          79,
          232,
          211,
          5,
          211,
          44,
          197,
          61,
          232,
          41
        ],
        [
          "write_model",
          79,
          232,
          224,
          5,
          224,
          30,
          197,
          61,
          232,
          41
        ],
        [
          "write_model",
          79,
          232,
          230,
          5,
          230,
          66,
          197,
          61,
          232,
          41
        ],
        [
          "write_model",
          79,
          232,
          232,
          5,
          232,
          41,
          197,
          61,
          232,
          41
        ],
        [
          "write_tokenizer",
          235,
          278,
          266,
          5,
          268,
          5,
          235,
          21,
          278,
          8
        ],
        [
          "write_tokenizer",
          235,
          278,
          269,
          5,
          278,
          8,
          235,
          21,
          278,
          8
        ],
        [
          "write_processor",
          281,
          293,
          293,
          5,
          293,
          42,
          281,
          21,
          293,
          42
        ]
      ],
      "transformers/src/transformers/models/clvp/convert_clvp_to_hf.py": [
        [
          "convert_clvp_weights",
          194,
          217,
          200,
          13,
          200,
          92,
          200,
          13,
          201,
          63
        ],
        [
          "convert_clvp_weights",
          194,
          217,
          217,
          5,
          217,
          56,
          209,
          5,
          217,
          56
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "convert_convnextv2_checkpoint",
          144,
          262,
          221,
          9,
          221,
          41,
          221,
          9,
          223,
          54
        ],
        [
          "convert_convnextv2_checkpoint",
          144,
          262,
          148,
          5,
          148,
          58,
          144,
          35,
          156,
          32
        ],
        [
          "convert_convnextv2_checkpoint",
          144,
          262,
          154,
          5,
          154,
          43,
          144,
          35,
          156,
          32
        ],
        [
          "convert_convnextv2_checkpoint",
          144,
          262,
          218,
          5,
          218,
          54,
          217,
          5,
          220,
          17
        ],
        [
          "convert_convnextv2_checkpoint",
          144,
          262,
          260,
          9,
          260,
          52,
          260,
          9,
          262,
          44
        ]
      ],
      "transformers/src/transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_cvt_checkpoint",
          278,
          330,
          324,
          9,
          324,
          17,
          323,
          9,
          324,
          17
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_text_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          80,
          5,
          80,
          37,
          79,
          29,
          95,
          44
        ],
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          80,
          5,
          80,
          37,
          80,
          5,
          95,
          44
        ],
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          179,
          5,
          179,
          47,
          157,
          8,
          183,
          67
        ],
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          181,
          5,
          181,
          53,
          157,
          8,
          183,
          67
        ],
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          183,
          5,
          183,
          77,
          183,
          54,
          184,
          18
        ],
        [
          "convert_data2vec_checkpoint_to_pytorch",
          55,
          189,
          188,
          5,
          188,
          56,
          187,
          5,
          189,
          51
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "load_beit_model",
          150,
          246,
          223,
          5,
          223,
          51,
          216,
          9,
          225,
          39
        ],
        [
          "load_state_dict",
          151,
          196,
          188,
          13,
          188,
          113,
          188,
          13,
          188,
          113
        ],
        [
          "load_state_dict",
          151,
          196,
          190,
          13,
          190,
          109,
          190,
          13,
          190,
          109
        ],
        [
          "load_state_dict",
          151,
          196,
          192,
          13,
          194,
          13,
          192,
          13,
          194,
          13
        ],
        [
          "load_state_dict",
          151,
          196,
          196,
          13,
          196,
          40,
          196,
          13,
          196,
          40
        ],
        [
          "load_beit_model",
          150,
          246,
          228,
          13,
          228,
          64,
          227,
          32,
          229,
          17
        ],
        [
          "main",
          249,
          351,
          330,
          5,
          330,
          37,
          328,
          5,
          344,
          67
        ],
        [
          "main",
          249,
          351,
          331,
          5,
          331,
          48,
          328,
          5,
          344,
          67
        ],
        [
          "main",
          249,
          351,
          342,
          5,
          342,
          53,
          328,
          5,
          344,
          67
        ],
        [
          "main",
          249,
          351,
          344,
          5,
          344,
          77,
          344,
          54,
          345,
          18
        ],
        [
          "main",
          249,
          351,
          349,
          5,
          349,
          49,
          349,
          5,
          351,
          60
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          194,
          270,
          250,
          9,
          250,
          74,
          242,
          24,
          250,
          74
        ],
        [
          "convert_wav2vec2_checkpoint",
          194,
          270,
          257,
          5,
          257,
          47,
          257,
          5,
          261,
          67
        ],
        [
          "convert_wav2vec2_checkpoint",
          194,
          270,
          259,
          5,
          259,
          53,
          257,
          5,
          261,
          67
        ],
        [
          "convert_wav2vec2_checkpoint",
          194,
          270,
          261,
          5,
          261,
          77,
          261,
          54,
          262,
          18
        ]
      ],
      "transformers/src/transformers/models/dac/convert_dac_checkpoint.py": [
        [
          "recursively_load_weights",
          143,
          187,
          185,
          5,
          185,
          36,
          185,
          5,
          187,
          55
        ],
        [
          "convert_checkpoint",
          223,
          261,
          259,
          9,
          259,
          38,
          259,
          9,
          261,
          34
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "load_model_state_dict",
          203,
          233,
          229,
          9,
          229,
          45,
          229,
          9,
          230,
          56
        ],
        [
          "convert_model",
          236,
          360,
          347,
          9,
          347,
          49,
          342,
          5,
          360,
          51
        ],
        [
          "load_model_state_dict",
          203,
          233,
          212,
          9,
          212,
          41,
          212,
          9,
          219,
          44
        ],
        [
          "load_model_state_dict",
          203,
          233,
          220,
          13,
          220,
          51,
          219,
          13,
          223,
          41
        ],
        [
          "convert_model",
          236,
          360,
          287,
          9,
          287,
          51,
          255,
          14,
          318,
          22
        ],
        [
          "convert_model",
          236,
          360,
          316,
          9,
          316,
          53,
          255,
          14,
          318,
          22
        ],
        [
          "convert_model",
          236,
          360,
          319,
          9,
          319,
          66,
          319,
          9,
          338,
          33
        ],
        [
          "convert_model",
          236,
          360,
          326,
          5,
          326,
          36,
          326,
          5,
          338,
          33
        ],
        [
          "convert_model",
          236,
          360,
          326,
          5,
          326,
          36,
          319,
          9,
          338,
          33
        ],
        [
          "convert_model",
          236,
          360,
          331,
          5,
          331,
          34,
          326,
          5,
          338,
          33
        ],
        [
          "convert_model",
          236,
          360,
          331,
          5,
          331,
          34,
          319,
          9,
          338,
          33
        ],
        [
          "convert_model",
          236,
          360,
          336,
          5,
          336,
          52,
          326,
          5,
          338,
          33
        ],
        [
          "convert_model",
          236,
          360,
          336,
          5,
          336,
          52,
          319,
          9,
          338,
          33
        ],
        [
          "convert_model",
          236,
          360,
          342,
          5,
          342,
          29,
          342,
          5,
          360,
          51
        ],
        [
          "convert_model",
          236,
          360,
          342,
          5,
          342,
          29,
          342,
          5,
          357,
          17
        ],
        [
          "convert_model",
          236,
          360,
          350,
          9,
          350,
          62,
          342,
          5,
          360,
          51
        ],
        [
          "convert_model",
          236,
          360,
          350,
          9,
          350,
          62,
          342,
          5,
          357,
          17
        ],
        [
          "convert_model",
          236,
          360,
          358,
          9,
          358,
          78,
          342,
          5,
          360,
          51
        ],
        [
          "convert_model",
          236,
          360,
          360,
          9,
          360,
          51,
          342,
          5,
          360,
          51
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          180,
          5,
          180,
          47,
          174,
          8,
          182,
          91
        ],
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          180,
          5,
          180,
          47,
          180,
          5,
          182,
          91
        ],
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          185,
          5,
          185,
          27,
          183,
          5,
          194,
          18
        ],
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          200,
          9,
          200,
          40,
          199,
          23,
          201,
          106
        ]
      ],
      "transformers/src/transformers/models/deit/convert_deit_timm_to_pytorch.py": [
        [
          "convert_deit_checkpoint",
          131,
          201,
          198,
          5,
          198,
          68,
          195,
          5,
          201,
          61
        ],
        [
          "convert_deit_checkpoint",
          131,
          201,
          200,
          5,
          200,
          66,
          195,
          5,
          201,
          61
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "load_model_state_dict",
          176,
          206,
          202,
          9,
          202,
          45,
          202,
          9,
          203,
          56
        ],
        [
          "convert_model",
          209,
          322,
          309,
          9,
          309,
          49,
          304,
          5,
          322,
          51
        ],
        [
          "load_model_state_dict",
          176,
          206,
          193,
          13,
          193,
          51,
          192,
          13,
          196,
          41
        ],
        [
          "load_model_state_dict",
          176,
          206,
          185,
          9,
          185,
          41,
          185,
          9,
          192,
          44
        ],
        [
          "convert_model",
          209,
          322,
          252,
          9,
          252,
          51,
          228,
          14,
          280,
          22
        ],
        [
          "convert_model",
          209,
          322,
          278,
          9,
          278,
          53,
          228,
          14,
          280,
          22
        ],
        [
          "convert_model",
          209,
          322,
          281,
          9,
          281,
          66,
          281,
          9,
          300,
          33
        ],
        [
          "convert_model",
          209,
          322,
          288,
          5,
          288,
          36,
          288,
          5,
          300,
          33
        ],
        [
          "convert_model",
          209,
          322,
          288,
          5,
          288,
          36,
          281,
          9,
          300,
          33
        ],
        [
          "convert_model",
          209,
          322,
          293,
          5,
          293,
          34,
          288,
          5,
          300,
          33
        ],
        [
          "convert_model",
          209,
          322,
          293,
          5,
          293,
          34,
          281,
          9,
          300,
          33
        ],
        [
          "convert_model",
          209,
          322,
          298,
          5,
          298,
          52,
          288,
          5,
          300,
          33
        ],
        [
          "convert_model",
          209,
          322,
          298,
          5,
          298,
          52,
          281,
          9,
          300,
          33
        ],
        [
          "convert_model",
          209,
          322,
          304,
          5,
          304,
          29,
          304,
          5,
          322,
          51
        ],
        [
          "convert_model",
          209,
          322,
          304,
          5,
          304,
          29,
          304,
          5,
          319,
          17
        ],
        [
          "convert_model",
          209,
          322,
          312,
          9,
          312,
          62,
          304,
          5,
          322,
          51
        ],
        [
          "convert_model",
          209,
          322,
          312,
          9,
          312,
          62,
          304,
          5,
          319,
          17
        ],
        [
          "convert_model",
          209,
          322,
          320,
          9,
          320,
          78,
          304,
          5,
          322,
          51
        ],
        [
          "convert_model",
          209,
          322,
          322,
          9,
          322,
          51,
          304,
          5,
          322,
          51
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "convert_d_fine_checkpoint",
          389,
          668,
          649,
          9,
          649,
          73,
          648,
          9,
          652,
          65
        ],
        [
          "convert_d_fine_checkpoint",
          389,
          668,
          651,
          9,
          651,
          70,
          648,
          9,
          652,
          65
        ]
      ],
      "transformers/src/transformers/models/depth_pro/convert_depth_pro_weights_to_hf.py": [
        [
          "main",
          211,
          251,
          249,
          9,
          249,
          34,
          249,
          9,
          251,
          53
        ],
        [
          "write_model",
          132,
          202,
          188,
          5,
          188,
          56,
          188,
          5,
          202,
          16
        ],
        [
          "write_model",
          132,
          202,
          163,
          5,
          163,
          47,
          133,
          5,
          178,
          23
        ],
        [
          "write_model",
          132,
          202,
          173,
          5,
          173,
          32,
          133,
          5,
          178,
          23
        ],
        [
          "write_model",
          132,
          202,
          191,
          5,
          191,
          44,
          188,
          5,
          202,
          16
        ],
        [
          "write_model",
          132,
          202,
          193,
          5,
          193,
          30,
          188,
          5,
          202,
          16
        ],
        [
          "write_model",
          132,
          202,
          199,
          5,
          199,
          66,
          188,
          5,
          202,
          16
        ],
        [
          "write_model",
          132,
          202,
          201,
          5,
          201,
          41,
          188,
          5,
          202,
          16
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          201,
          336,
          325,
          9,
          325,
          26,
          324,
          9,
          325,
          26
        ],
        [
          "convert_dpt_checkpoint",
          201,
          336,
          267,
          5,
          267,
          54,
          238,
          5,
          270,
          20
        ],
        [
          "convert_dpt_checkpoint",
          201,
          336,
          266,
          5,
          266,
          61,
          238,
          5,
          270,
          20
        ],
        [
          "convert_dpt_checkpoint",
          201,
          336,
          329,
          9,
          329,
          74,
          328,
          9,
          331,
          59
        ],
        [
          "convert_dpt_checkpoint",
          201,
          336,
          334,
          9,
          334,
          54,
          334,
          9,
          336,
          65
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_to_pytorch.py": [
        [
          "convert_detr_checkpoint",
          288,
          367,
          354,
          5,
          354,
          22,
          354,
          5,
          356,
          43
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "convert_deta_checkpoint",
          217,
          303,
          237,
          9,
          237,
          32,
          236,
          9,
          237,
          32
        ],
        [
          "convert_deta_checkpoint",
          217,
          303,
          276,
          5,
          276,
          47,
          263,
          14,
          278,
          38
        ],
        [
          "convert_deta_checkpoint",
          217,
          303,
          277,
          5,
          277,
          50,
          263,
          14,
          278,
          38
        ],
        [
          "convert_deta_checkpoint",
          217,
          303,
          290,
          5,
          290,
          27,
          289,
          5,
          292,
          31
        ],
        [
          "convert_deta_checkpoint",
          217,
          303,
          301,
          9,
          301,
          54,
          301,
          9,
          303,
          56
        ]
      ],
      "transformers/src/transformers/models/dia/convert_dia_to_hf.py": [
        [
          "convert_dia_model_to_hf",
          78,
          155,
          89,
          5,
          89,
          76,
          78,
          29,
          99,
          21
        ],
        [
          "convert_dia_model_to_hf",
          78,
          155,
          139,
          25,
          139,
          97,
          139,
          25,
          139,
          97
        ],
        [
          "convert_dia_model_to_hf",
          78,
          155,
          141,
          21,
          141,
          67,
          140,
          17,
          141,
          67
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "convert_deta_checkpoint",
          216,
          296,
          294,
          9,
          294,
          54,
          294,
          9,
          296,
          56
        ],
        [
          "convert_deta_checkpoint",
          216,
          296,
          283,
          5,
          283,
          27,
          282,
          5,
          285,
          31
        ]
      ],
      "transformers/src/transformers/models/vit/convert_dino_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          131,
          195,
          192,
          5,
          192,
          69,
          189,
          9,
          195,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          195,
          192,
          5,
          192,
          69,
          185,
          9,
          195,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          195,
          194,
          5,
          194,
          66,
          189,
          9,
          195,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          195,
          194,
          5,
          194,
          66,
          185,
          9,
          195,
          61
        ]
      ],
      "transformers/src/transformers/models/dinov2_with_registers/convert_dinov2_with_registers_to_hf.py": [
        [
          "convert_dinov2_with_registers_checkpoint",
          152,
          261,
          232,
          9,
          232,
          33,
          224,
          5,
          240,
          43
        ],
        [
          "convert_dinov2_with_registers_checkpoint",
          152,
          261,
          234,
          9,
          234,
          47,
          224,
          5,
          240,
          43
        ],
        [
          "convert_dinov2_with_registers_checkpoint",
          152,
          261,
          238,
          5,
          238,
          22,
          224,
          5,
          240,
          43
        ],
        [
          "convert_dinov2_with_registers_checkpoint",
          152,
          261,
          238,
          5,
          238,
          22,
          237,
          9,
          240,
          43
        ],
        [
          "convert_dinov2_with_registers_checkpoint",
          152,
          261,
          242,
          9,
          242,
          73,
          241,
          9,
          245,
          59
        ],
        [
          "convert_dinov2_with_registers_checkpoint",
          152,
          261,
          244,
          9,
          244,
          70,
          241,
          9,
          245,
          59
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dinov2_depth_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          243,
          351,
          349,
          9,
          349,
          54,
          349,
          9,
          351,
          63
        ],
        [
          "convert_dpt_checkpoint",
          243,
          351,
          344,
          9,
          344,
          74,
          343,
          9,
          346,
          59
        ],
        [
          "convert_dpt_checkpoint",
          243,
          351,
          253,
          5,
          253,
          33,
          243,
          28,
          257,
          32
        ],
        [
          "convert_dpt_checkpoint",
          243,
          351,
          296,
          5,
          296,
          40,
          291,
          21,
          301,
          5
        ],
        [
          "convert_dpt_checkpoint",
          243,
          351,
          297,
          5,
          297,
          46,
          291,
          21,
          301,
          5
        ],
        [
          "convert_dpt_checkpoint",
          243,
          351,
          327,
          5,
          327,
          61,
          319,
          5,
          331,
          20
        ],
        [
          "convert_dpt_checkpoint",
          243,
          351,
          328,
          5,
          328,
          73,
          319,
          5,
          331,
          20
        ],
        [
          "convert_dpt_checkpoint",
          243,
          351,
          340,
          9,
          340,
          26,
          339,
          9,
          340,
          26
        ]
      ],
      "transformers/src/transformers/models/dinov2/convert_dinov2_to_hf.py": [
        [
          "convert_dinov2_checkpoint",
          146,
          255,
          226,
          9,
          226,
          33,
          218,
          5,
          234,
          43
        ],
        [
          "convert_dinov2_checkpoint",
          146,
          255,
          228,
          9,
          228,
          47,
          218,
          5,
          234,
          43
        ],
        [
          "convert_dinov2_checkpoint",
          146,
          255,
          232,
          5,
          232,
          22,
          218,
          5,
          234,
          43
        ],
        [
          "convert_dinov2_checkpoint",
          146,
          255,
          232,
          5,
          232,
          22,
          231,
          9,
          234,
          43
        ],
        [
          "convert_dinov2_checkpoint",
          146,
          255,
          236,
          9,
          236,
          73,
          235,
          9,
          239,
          59
        ],
        [
          "convert_dinov2_checkpoint",
          146,
          255,
          238,
          9,
          238,
          70,
          235,
          9,
          239,
          59
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          190,
          5,
          190,
          63,
          156,
          5,
          206,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          168,
          5,
          168,
          36,
          156,
          5,
          206,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          180,
          5,
          180,
          82,
          156,
          5,
          206,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          181,
          5,
          181,
          61,
          156,
          5,
          206,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          189,
          5,
          189,
          84,
          156,
          5,
          206,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          198,
          5,
          198,
          35,
          156,
          5,
          206,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          204,
          5,
          204,
          39,
          156,
          5,
          206,
          23
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          147,
          215,
          180,
          5,
          180,
          61,
          147,
          28,
          183,
          20
        ],
        [
          "convert_dpt_checkpoint",
          147,
          215,
          181,
          5,
          181,
          54,
          147,
          28,
          183,
          20
        ],
        [
          "convert_dpt_checkpoint",
          147,
          215,
          184,
          9,
          184,
          36,
          184,
          9,
          187,
          50
        ],
        [
          "convert_dpt_checkpoint",
          147,
          215,
          204,
          9,
          204,
          26,
          203,
          9,
          204,
          26
        ],
        [
          "convert_dpt_checkpoint",
          147,
          215,
          208,
          9,
          208,
          74,
          207,
          9,
          210,
          59
        ],
        [
          "convert_dpt_checkpoint",
          147,
          215,
          213,
          9,
          213,
          54,
          213,
          9,
          215,
          65
        ]
      ],
      "transformers/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py": [
        [
          "convert_dit_checkpoint",
          133,
          210,
          189,
          5,
          189,
          56,
          186,
          5,
          194,
          18
        ],
        [
          "convert_dit_checkpoint",
          133,
          210,
          191,
          5,
          191,
          66,
          186,
          5,
          194,
          18
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          265,
          5,
          265,
          36,
          253,
          5,
          300,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          277,
          5,
          277,
          82,
          253,
          5,
          300,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          278,
          5,
          278,
          61,
          253,
          5,
          300,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          292,
          5,
          292,
          35,
          253,
          5,
          300,
          23
        ],
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          298,
          5,
          298,
          39,
          253,
          5,
          300,
          23
        ]
      ],
      "transformers/src/transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py": [
        [
          "load_states_from_checkpoint",
          30,
          35,
          31,
          5,
          31,
          51,
          30,
          33,
          35,
          40
        ],
        [
          "load_dpr_model",
          58,
          72,
          60,
          9,
          60,
          60,
          58,
          24,
          65,
          56
        ],
        [
          "load_dpr_model",
          76,
          90,
          78,
          9,
          78,
          60,
          76,
          24,
          83,
          56
        ],
        [
          "load_dpr_model",
          94,
          107,
          96,
          9,
          96,
          57,
          94,
          24,
          102,
          56
        ]
      ],
      "transformers/src/transformers/models/donut/convert_donut_to_pytorch.py": [
        [
          "convert_donut_checkpoint",
          135,
          207,
          198,
          5,
          198,
          22,
          197,
          5,
          200,
          43
        ],
        [
          "convert_donut_checkpoint",
          135,
          207,
          201,
          9,
          201,
          74,
          201,
          9,
          203,
          59
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_beit_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          174,
          279,
          202,
          5,
          202,
          40,
          197,
          5,
          204,
          29
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          203,
          5,
          203,
          46,
          197,
          5,
          204,
          29
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          217,
          5,
          217,
          70,
          204,
          5,
          247,
          41
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          218,
          5,
          218,
          62,
          204,
          5,
          247,
          41
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          219,
          5,
          219,
          55,
          204,
          5,
          247,
          41
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          242,
          5,
          242,
          61,
          204,
          5,
          247,
          41
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          243,
          5,
          243,
          73,
          204,
          5,
          247,
          41
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          268,
          5,
          268,
          22,
          267,
          5,
          270,
          43
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          272,
          9,
          272,
          74,
          271,
          9,
          274,
          59
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          277,
          9,
          277,
          54,
          277,
          9,
          279,
          61
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_to_pytorch.py": [
        [
          "convert_dpt_checkpoint",
          188,
          253,
          237,
          9,
          237,
          70,
          234,
          9,
          238,
          65
        ],
        [
          "convert_dpt_checkpoint",
          188,
          253,
          231,
          5,
          231,
          22,
          226,
          5,
          233,
          43
        ],
        [
          "convert_dpt_checkpoint",
          188,
          253,
          235,
          9,
          235,
          60,
          234,
          9,
          238,
          65
        ],
        [
          "convert_dpt_checkpoint",
          188,
          253,
          241,
          9,
          241,
          40,
          241,
          9,
          253,
          9
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_swinv2_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          186,
          290,
          216,
          5,
          216,
          40,
          213,
          5,
          226,
          20
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          217,
          5,
          217,
          46,
          213,
          5,
          226,
          20
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          246,
          9,
          246,
          65,
          227,
          14,
          250,
          46
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          247,
          9,
          247,
          77,
          227,
          14,
          250,
          46
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          279,
          9,
          279,
          26,
          278,
          9,
          279,
          26
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          283,
          9,
          283,
          74,
          282,
          9,
          285,
          59
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          288,
          9,
          288,
          54,
          288,
          9,
          290,
          60
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "convert_dpt_checkpoint",
          220,
          278,
          271,
          9,
          271,
          60,
          270,
          9,
          274,
          65
        ],
        [
          "convert_dpt_checkpoint",
          220,
          278,
          273,
          9,
          273,
          70,
          270,
          9,
          274,
          65
        ]
      ],
      "transformers/src/transformers/models/edgetam_video/convert_edgetam_video_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          235,
          278,
          251,
          5,
          251,
          40,
          247,
          14,
          254,
          23
        ],
        [
          "convert_edgetam_checkpoint",
          235,
          278,
          252,
          5,
          252,
          46,
          247,
          14,
          254,
          23
        ]
      ],
      "transformers/src/transformers/models/edgetam/convert_edgetam_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          192,
          238,
          210,
          9,
          210,
          44,
          210,
          9,
          212,
          72
        ],
        [
          "convert_edgetam_checkpoint",
          192,
          238,
          211,
          9,
          211,
          50,
          210,
          9,
          212,
          72
        ]
      ],
      "transformers/src/transformers/models/electra/convert_electra_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_electra",
          30,
          109,
          104,
          13,
          104,
          69,
          104,
          56,
          104,
          69
        ],
        [
          "load_tf_weights_in_electra",
          30,
          109,
          107,
          13,
          107,
          55,
          106,
          9,
          108,
          20
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          112,
          131,
          115,
          5,
          115,
          65,
          112,
          38,
          117,
          52
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          112,
          131,
          130,
          5,
          130,
          55,
          125,
          5,
          131,
          53
        ]
      ],
      "transformers/src/transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_efficientformer_checkpoint",
          123,
          213,
          199,
          5,
          199,
          65,
          195,
          5,
          201,
          18
        ],
        [
          "convert_efficientformer_checkpoint",
          123,
          213,
          197,
          5,
          197,
          83,
          195,
          5,
          201,
          18
        ],
        [
          "convert_efficientformer_checkpoint",
          123,
          213,
          202,
          9,
          202,
          44,
          202,
          9,
          213,
          9
        ]
      ],
      "transformers/src/transformers/models/efficientloftr/convert_efficientloftr_to_hf.py": [
        [
          "write_model",
          128,
          199,
          187,
          9,
          187,
          46,
          187,
          9,
          188,
          43
        ],
        [
          "write_image_processor",
          202,
          211,
          207,
          9,
          207,
          54,
          207,
          9,
          211,
          9
        ],
        [
          "write_model",
          128,
          199,
          144,
          5,
          144,
          47,
          129,
          5,
          159,
          23
        ],
        [
          "write_model",
          128,
          199,
          150,
          5,
          150,
          88,
          129,
          5,
          159,
          23
        ],
        [
          "write_model",
          128,
          199,
          154,
          5,
          154,
          32,
          129,
          5,
          159,
          23
        ],
        [
          "write_model",
          128,
          199,
          166,
          5,
          166,
          64,
          163,
          9,
          168,
          48
        ],
        [
          "write_model",
          128,
          199,
          172,
          5,
          172,
          46,
          168,
          14,
          186,
          39
        ],
        [
          "write_model",
          128,
          199,
          175,
          5,
          175,
          32,
          168,
          14,
          186,
          39
        ],
        [
          "write_model",
          128,
          199,
          181,
          5,
          181,
          66,
          168,
          14,
          186,
          39
        ],
        [
          "write_model",
          128,
          199,
          183,
          5,
          183,
          41,
          168,
          14,
          186,
          39
        ],
        [
          "write_model",
          128,
          199,
          189,
          5,
          189,
          49,
          189,
          5,
          191,
          18
        ],
        [
          "write_model",
          128,
          199,
          192,
          9,
          192,
          44,
          192,
          9,
          197,
          95
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "convert_efficientnet_checkpoint",
          250,
          317,
          278,
          5,
          278,
          37,
          270,
          22,
          301,
          61
        ],
        [
          "convert_efficientnet_checkpoint",
          250,
          317,
          302,
          5,
          302,
          33,
          301,
          5,
          304,
          17
        ],
        [
          "convert_efficientnet_checkpoint",
          250,
          317,
          314,
          9,
          314,
          62,
          314,
          9,
          317,
          40
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "ensure_model_downloaded",
          120,
          155,
          152,
          9,
          152,
          58,
          150,
          5,
          155,
          27
        ],
        [
          "convert_model",
          191,
          286,
          276,
          9,
          276,
          62,
          254,
          9,
          283,
          17
        ],
        [
          "convert_model",
          191,
          286,
          276,
          9,
          276,
          62,
          275,
          8,
          283,
          17
        ],
        [
          "load_model_state_dict",
          158,
          188,
          184,
          9,
          184,
          45,
          184,
          9,
          185,
          63
        ],
        [
          "load_model_state_dict",
          158,
          188,
          175,
          13,
          175,
          51,
          174,
          13,
          178,
          41
        ],
        [
          "load_model_state_dict",
          158,
          188,
          167,
          9,
          167,
          41,
          167,
          9,
          174,
          44
        ],
        [
          "ensure_model_downloaded",
          120,
          155,
          134,
          13,
          134,
          65,
          134,
          13,
          134,
          65
        ],
        [
          "ensure_model_downloaded",
          120,
          155,
          138,
          13,
          138,
          58,
          137,
          13,
          138,
          58
        ],
        [
          "ensure_model_downloaded",
          120,
          155,
          143,
          5,
          143,
          84,
          143,
          64,
          147,
          40
        ],
        [
          "ensure_model_downloaded",
          120,
          155,
          148,
          9,
          148,
          61,
          148,
          9,
          148,
          61
        ],
        [
          "ensure_model_downloaded",
          120,
          155,
          154,
          9,
          154,
          58,
          150,
          5,
          155,
          27
        ],
        [
          "convert_model",
          191,
          286,
          209,
          9,
          209,
          65,
          208,
          9,
          209,
          65
        ],
        [
          "convert_model",
          191,
          286,
          258,
          5,
          258,
          36,
          254,
          9,
          283,
          17
        ],
        [
          "convert_model",
          191,
          286,
          258,
          5,
          258,
          36,
          258,
          5,
          283,
          17
        ],
        [
          "convert_model",
          191,
          286,
          258,
          5,
          258,
          36,
          254,
          9,
          272,
          17
        ],
        [
          "convert_model",
          191,
          286,
          258,
          5,
          258,
          36,
          258,
          5,
          272,
          17
        ],
        [
          "convert_model",
          191,
          286,
          263,
          5,
          263,
          34,
          254,
          9,
          283,
          17
        ],
        [
          "convert_model",
          191,
          286,
          263,
          5,
          263,
          34,
          258,
          5,
          283,
          17
        ],
        [
          "convert_model",
          191,
          286,
          263,
          5,
          263,
          34,
          254,
          9,
          272,
          17
        ],
        [
          "convert_model",
          191,
          286,
          263,
          5,
          263,
          34,
          258,
          5,
          272,
          17
        ],
        [
          "convert_model",
          191,
          286,
          268,
          5,
          268,
          52,
          254,
          9,
          283,
          17
        ],
        [
          "convert_model",
          191,
          286,
          268,
          5,
          268,
          52,
          258,
          5,
          283,
          17
        ],
        [
          "convert_model",
          191,
          286,
          268,
          5,
          268,
          52,
          254,
          9,
          272,
          17
        ],
        [
          "convert_model",
          191,
          286,
          268,
          5,
          268,
          52,
          258,
          5,
          272,
          17
        ],
        [
          "convert_model",
          191,
          286,
          273,
          9,
          273,
          49,
          273,
          9,
          274,
          80
        ],
        [
          "convert_model",
          191,
          286,
          284,
          9,
          284,
          78,
          284,
          9,
          286,
          51
        ],
        [
          "convert_model",
          191,
          286,
          286,
          9,
          286,
          51,
          284,
          9,
          286,
          51
        ]
      ],
      "transformers/src/transformers/models/encodec/convert_encodec_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint",
          279,
          338,
          336,
          9,
          336,
          38,
          336,
          9,
          338,
          34
        ]
      ],
      "transformers/src/transformers/models/esm/convert_esm.py": [
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          350,
          9,
          350,
          57,
          323,
          10,
          351,
          71
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          350,
          9,
          350,
          57,
          343,
          12,
          351,
          71
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          365,
          13,
          365,
          85,
          365,
          62,
          367,
          26
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          363,
          13,
          363,
          48,
          356,
          16,
          365,
          75
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          351,
          9,
          351,
          81,
          351,
          58,
          353,
          22
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          181,
          5,
          181,
          36,
          181,
          5,
          183,
          34
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          319,
          5,
          319,
          87,
          319,
          64,
          320,
          18
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          364,
          13,
          364,
          61,
          356,
          16,
          365,
          75
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          371,
          9,
          371,
          60,
          356,
          16,
          379,
          19
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          371,
          9,
          371,
          60,
          370,
          9,
          379,
          19
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          376,
          5,
          376,
          60,
          356,
          16,
          379,
          19
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          376,
          5,
          376,
          60,
          370,
          9,
          379,
          19
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_model",
          255,
          408,
          347,
          9,
          347,
          63,
          314,
          9,
          348,
          24
        ],
        [
          "convert_model",
          255,
          408,
          314,
          9,
          314,
          58,
          314,
          9,
          348,
          24
        ],
        [
          "convert_model",
          255,
          408,
          315,
          9,
          315,
          24,
          314,
          9,
          348,
          24
        ],
        [
          "convert_model",
          255,
          408,
          348,
          9,
          348,
          24,
          314,
          9,
          348,
          24
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          218,
          366,
          353,
          5,
          353,
          41,
          258,
          111,
          366,
          12
        ],
        [
          "load_model",
          218,
          366,
          358,
          5,
          358,
          85,
          258,
          111,
          366,
          12
        ],
        [
          "load_model",
          218,
          366,
          359,
          5,
          359,
          94,
          258,
          111,
          366,
          12
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t_v2/convert_fairseq2_to_hf.py": [
        [
          "load_model",
          219,
          374,
          361,
          5,
          361,
          41,
          256,
          111,
          374,
          12
        ],
        [
          "load_model",
          219,
          374,
          366,
          5,
          366,
          85,
          256,
          111,
          374,
          12
        ],
        [
          "load_model",
          219,
          374,
          367,
          5,
          367,
          94,
          256,
          111,
          374,
          12
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_FastSpeech2ConformerModel_checkpoint",
          155,
          188,
          186,
          9,
          186,
          38,
          186,
          9,
          188,
          38
        ]
      ],
      "transformers/src/transformers/models/fnet/convert_fnet_original_flax_checkpoint_to_pytorch.py": [
        [
          "convert_flax_checkpoint_to_pytorch",
          29,
          135,
          32,
          5,
          32,
          65,
          29,
          40,
          68,
          48
        ],
        [
          "convert_flax_checkpoint_to_pytorch",
          29,
          135,
          134,
          5,
          134,
          52,
          98,
          50,
          135,
          53
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          94,
          5,
          94,
          59,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          109,
          5,
          109,
          48,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          130,
          5,
          130,
          83,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          146,
          5,
          146,
          83,
          142,
          16,
          152,
          34
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          159,
          5,
          159,
          38,
          156,
          10,
          168,
          35
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          209,
          5,
          209,
          49,
          209,
          5,
          243,
          24
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          222,
          5,
          222,
          53,
          209,
          5,
          243,
          24
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          254,
          5,
          254,
          52,
          246,
          14,
          260,
          45
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          257,
          5,
          257,
          32,
          246,
          14,
          260,
          45
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          258,
          5,
          258,
          53,
          246,
          14,
          260,
          45
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          259,
          5,
          259,
          28,
          246,
          14,
          260,
          45
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          260,
          5,
          260,
          45,
          246,
          14,
          260,
          45
        ]
      ],
      "transformers/src/transformers/models/focalnet/convert_focalnet_to_hf_format.py": [
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          140,
          5,
          140,
          45,
          123,
          33,
          144,
          32
        ],
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          188,
          5,
          188,
          73,
          183,
          5,
          192,
          36
        ],
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          190,
          5,
          190,
          59,
          183,
          5,
          192,
          36
        ],
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          205,
          5,
          205,
          22,
          204,
          5,
          207,
          43
        ],
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          208,
          9,
          208,
          90,
          208,
          9,
          210,
          59
        ],
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          213,
          9,
          213,
          75,
          213,
          9,
          215,
          46
        ]
      ],
      "transformers/src/transformers/models/gemma2/convert_gemma2_weights_to_hf.py": [
        [
          "write_model",
          84,
          158,
          103,
          9,
          103,
          50,
          103,
          9,
          105,
          41
        ],
        [
          "write_model",
          84,
          158,
          90,
          5,
          90,
          80,
          84,
          17,
          92,
          37
        ],
        [
          "write_model",
          84,
          158,
          93,
          9,
          93,
          36,
          93,
          9,
          98,
          25
        ],
        [
          "write_model",
          84,
          158,
          99,
          13,
          99,
          23,
          98,
          13,
          101,
          54
        ],
        [
          "write_model",
          84,
          158,
          145,
          5,
          145,
          54,
          143,
          5,
          154,
          18
        ],
        [
          "write_model",
          84,
          158,
          152,
          5,
          152,
          47,
          143,
          5,
          154,
          18
        ],
        [
          "write_model",
          84,
          158,
          155,
          9,
          155,
          50,
          155,
          9,
          156,
          89
        ],
        [
          "write_tokenizer",
          161,
          169,
          164,
          5,
          164,
          65,
          163,
          23,
          166,
          18
        ]
      ],
      "transformers/src/transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_funnel",
          31,
          118,
          108,
          21,
          108,
          68,
          107,
          17,
          110,
          25
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          121,
          132,
          124,
          5,
          124,
          65,
          121,
          38,
          125,
          49
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          121,
          132,
          131,
          5,
          131,
          55,
          125,
          13,
          132,
          53
        ]
      ],
      "transformers/src/transformers/models/gemma/convert_gemma_weights_to_hf.py": [
        [
          "write_model",
          68,
          125,
          74,
          5,
          74,
          80,
          68,
          17,
          79,
          40
        ],
        [
          "write_model",
          68,
          125,
          112,
          5,
          112,
          53,
          110,
          5,
          121,
          18
        ],
        [
          "write_model",
          68,
          125,
          119,
          5,
          119,
          47,
          110,
          5,
          121,
          18
        ],
        [
          "write_model",
          68,
          125,
          122,
          9,
          122,
          50,
          122,
          9,
          123,
          89
        ],
        [
          "write_tokenizer",
          128,
          136,
          131,
          5,
          131,
          65,
          130,
          23,
          133,
          18
        ]
      ],
      "transformers/src/transformers/models/git/convert_git_to_pytorch.py": [
        [
          "convert_git_checkpoint",
          254,
          423,
          318,
          5,
          318,
          40,
          311,
          5,
          321,
          116
        ],
        [
          "convert_git_checkpoint",
          254,
          423,
          319,
          5,
          319,
          46,
          311,
          5,
          321,
          116
        ],
        [
          "convert_git_checkpoint",
          254,
          423,
          360,
          5,
          360,
          39,
          357,
          17,
          362,
          31
        ],
        [
          "convert_git_checkpoint",
          254,
          423,
          398,
          5,
          398,
          22,
          397,
          5,
          401,
          30
        ],
        [
          "convert_git_checkpoint",
          254,
          423,
          410,
          5,
          410,
          34,
          407,
          17,
          414,
          43
        ],
        [
          "convert_git_checkpoint",
          254,
          423,
          412,
          5,
          412,
          96,
          407,
          17,
          414,
          43
        ],
        [
          "convert_git_checkpoint",
          254,
          423,
          416,
          9,
          416,
          90,
          415,
          9,
          418,
          59
        ],
        [
          "convert_git_checkpoint",
          254,
          423,
          421,
          9,
          421,
          75,
          421,
          9,
          423,
          56
        ]
      ],
      "transformers/src/transformers/models/got_ocr2/convert_got_ocr2_weights_to_hf.py": [
        [
          "write_model",
          98,
          157,
          108,
          5,
          108,
          47,
          99,
          5,
          120,
          23
        ],
        [
          "write_model",
          98,
          157,
          114,
          5,
          114,
          81,
          99,
          5,
          120,
          23
        ],
        [
          "write_model",
          98,
          157,
          116,
          5,
          116,
          32,
          99,
          5,
          120,
          23
        ],
        [
          "write_model",
          98,
          157,
          127,
          5,
          127,
          79,
          124,
          9,
          137,
          18
        ],
        [
          "write_model",
          98,
          157,
          131,
          5,
          131,
          38,
          124,
          9,
          137,
          18
        ],
        [
          "write_model",
          98,
          157,
          132,
          5,
          132,
          40,
          124,
          9,
          137,
          18
        ],
        [
          "write_model",
          98,
          157,
          133,
          5,
          133,
          46,
          124,
          9,
          137,
          18
        ],
        [
          "write_model",
          98,
          157,
          135,
          5,
          135,
          30,
          124,
          9,
          137,
          18
        ],
        [
          "write_model",
          98,
          157,
          143,
          5,
          143,
          66,
          139,
          9,
          155,
          44
        ],
        [
          "write_model",
          98,
          157,
          154,
          5,
          154,
          44,
          139,
          9,
          155,
          44
        ],
        [
          "write_model",
          98,
          157,
          156,
          5,
          156,
          41,
          155,
          5,
          157,
          13
        ]
      ],
      "transformers/src/transformers/models/glpn/convert_glpn_to_pytorch.py": [
        [
          "convert_glpn_checkpoint",
          125,
          193,
          177,
          9,
          177,
          26,
          176,
          9,
          177,
          26
        ]
      ],
      "transformers/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_gpt2_checkpoint_to_pytorch",
          86,
          104,
          100,
          5,
          100,
          63,
          92,
          13,
          104,
          40
        ],
        [
          "convert_gpt2_checkpoint_to_pytorch",
          86,
          104,
          102,
          5,
          102,
          67,
          92,
          13,
          104,
          40
        ]
      ],
      "transformers/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": [
        [
          "load_tf_weights_in_gpt_neo",
          32,
          109,
          101,
          9,
          101,
          50,
          101,
          9,
          102,
          20
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          112,
          133,
          125,
          5,
          125,
          65,
          112,
          38,
          133,
          44
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          112,
          133,
          132,
          5,
          132,
          55,
          112,
          38,
          133,
          44
        ]
      ],
      "transformers/src/transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py": [
        [
          "convert_groupvit_checkpoint",
          157,
          195,
          190,
          5,
          190,
          80,
          186,
          5,
          192,
          18
        ],
        [
          "convert_groupvit_checkpoint",
          157,
          195,
          193,
          9,
          193,
          38,
          193,
          9,
          195,
          60
        ]
      ],
      "transformers/src/transformers/models/grounding_dino/convert_grounding_dino_to_hf.py": [
        [
          "convert_grounding_dino_checkpoint",
          395,
          467,
          414,
          9,
          414,
          32,
          413,
          9,
          414,
          32
        ],
        [
          "convert_grounding_dino_checkpoint",
          395,
          467,
          430,
          5,
          430,
          40,
          422,
          5,
          445,
          80
        ],
        [
          "convert_grounding_dino_checkpoint",
          395,
          467,
          431,
          5,
          431,
          46,
          422,
          5,
          445,
          80
        ],
        [
          "convert_grounding_dino_checkpoint",
          395,
          467,
          452,
          9,
          452,
          40,
          449,
          14,
          458,
          83
        ],
        [
          "convert_grounding_dino_checkpoint",
          395,
          467,
          459,
          9,
          459,
          26,
          458,
          9,
          459,
          26
        ]
      ],
      "transformers/src/transformers/models/hiera/convert_hiera_to_hf.py": [
        [
          "convert_hiera_checkpoint",
          206,
          327,
          298,
          9,
          298,
          57,
          296,
          9,
          311,
          43
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          308,
          9,
          308,
          77,
          307,
          9,
          309,
          42
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          252,
          5,
          252,
          40,
          242,
          8,
          277,
          80
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          252,
          5,
          252,
          40,
          249,
          5,
          277,
          80
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          253,
          5,
          253,
          46,
          242,
          8,
          277,
          80
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          253,
          5,
          253,
          46,
          249,
          5,
          277,
          80
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          325,
          9,
          325,
          82,
          317,
          20,
          327,
          44
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          325,
          9,
          325,
          82,
          324,
          19,
          327,
          44
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          278,
          5,
          278,
          36,
          277,
          5,
          288,
          46
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          279,
          5,
          279,
          51,
          277,
          5,
          288,
          46
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          297,
          9,
          297,
          86,
          296,
          9,
          311,
          43
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          304,
          9,
          304,
          78,
          303,
          9,
          304,
          78
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          309,
          9,
          309,
          42,
          307,
          9,
          309,
          42
        ],
        [
          "convert_hiera_checkpoint",
          206,
          327,
          312,
          9,
          312,
          91,
          312,
          9,
          314,
          65
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_model",
          146,
          284,
          247,
          9,
          247,
          33,
          240,
          9,
          249,
          29
        ],
        [
          "write_model",
          146,
          284,
          193,
          9,
          193,
          52,
          193,
          9,
          194,
          41
        ],
        [
          "write_model",
          146,
          284,
          177,
          5,
          177,
          81,
          154,
          20,
          179,
          49
        ],
        [
          "write_model",
          146,
          284,
          183,
          5,
          183,
          26,
          183,
          5,
          188,
          23
        ],
        [
          "write_model",
          146,
          284,
          240,
          9,
          240,
          77,
          240,
          9,
          249,
          29
        ],
        [
          "write_model",
          146,
          284,
          244,
          9,
          244,
          48,
          240,
          9,
          249,
          29
        ],
        [
          "write_model",
          146,
          284,
          252,
          9,
          252,
          54,
          252,
          9,
          266,
          22
        ],
        [
          "write_model",
          146,
          284,
          269,
          5,
          269,
          66,
          268,
          5,
          274,
          15
        ],
        [
          "write_model",
          146,
          284,
          271,
          5,
          271,
          41,
          268,
          5,
          274,
          15
        ],
        [
          "write_model",
          146,
          284,
          275,
          9,
          275,
          44,
          275,
          9,
          284,
          53
        ],
        [
          "write_tokenizer",
          426,
          772,
          769,
          9,
          769,
          40,
          769,
          9,
          772,
          68
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "merge_tp_weights",
          250,
          625,
          275,
          5,
          278,
          5,
          265,
          5,
          281,
          33
        ],
        [
          "save_sharded_model",
          174,
          247,
          239,
          9,
          239,
          69,
          238,
          9,
          241,
          47
        ],
        [
          "save_sharded_model",
          174,
          247,
          240,
          9,
          240,
          110,
          238,
          9,
          241,
          47
        ],
        [
          "save_sharded_model",
          174,
          247,
          241,
          9,
          241,
          47,
          238,
          9,
          241,
          47
        ],
        [
          "merge_tp_weights",
          250,
          625,
          259,
          5,
          259,
          58,
          259,
          5,
          261,
          19
        ],
        [
          "merge_tp_weights",
          250,
          625,
          262,
          9,
          262,
          59,
          262,
          9,
          263,
          14
        ],
        [
          "merge_tp_weights",
          250,
          625,
          265,
          5,
          265,
          65,
          265,
          5,
          281,
          33
        ],
        [
          "merge_tp_weights",
          250,
          625,
          282,
          9,
          282,
          47,
          281,
          9,
          286,
          32
        ],
        [
          "merge_tp_weights",
          250,
          625,
          298,
          5,
          298,
          47,
          298,
          5,
          327,
          32
        ],
        [
          "merge_tp_weights",
          250,
          625,
          302,
          5,
          302,
          107,
          298,
          5,
          327,
          32
        ],
        [
          "merge_tp_weights",
          250,
          625,
          553,
          5,
          553,
          66,
          553,
          5,
          555,
          49
        ],
        [
          "merge_tp_weights",
          250,
          625,
          558,
          5,
          558,
          46,
          558,
          5,
          599,
          38
        ],
        [
          "merge_tp_weights",
          250,
          625,
          625,
          5,
          625,
          63,
          621,
          19,
          625,
          63
        ]
      ],
      "transformers/src/transformers/models/speecht5/convert_hifigan.py": [
        [
          "convert_hifigan_checkpoint",
          59,
          86,
          85,
          9,
          85,
          38,
          85,
          9,
          86,
          34
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_hifigan.py": [
        [
          "convert_hifigan_checkpoint",
          93,
          114,
          113,
          9,
          113,
          38,
          113,
          9,
          114,
          34
        ]
      ],
      "transformers/src/transformers/models/idefics3/convert_idefics3_weights_to_hf.py": [
        [
          "merge_weights",
          90,
          115,
          96,
          13,
          96,
          34,
          95,
          13,
          97,
          48
        ],
        [
          "convert_idefics3_hub_to_hf",
          156,
          188,
          176,
          5,
          176,
          17,
          156,
          32,
          186,
          18
        ]
      ],
      "transformers/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py": [
        [
          "convert_imagegpt_checkpoint_to_pytorch",
          141,
          158,
          154,
          5,
          154,
          63,
          141,
          44,
          158,
          40
        ],
        [
          "convert_imagegpt_checkpoint_to_pytorch",
          141,
          158,
          156,
          5,
          156,
          67,
          141,
          44,
          158,
          40
        ]
      ],
      "transformers/src/transformers/models/instructblip/convert_instructblip_original_to_pytorch.py": [
        [
          "convert_blip2_checkpoint",
          131,
          276,
          165,
          5,
          165,
          38,
          139,
          21,
          166,
          59
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          165,
          5,
          165,
          38,
          152,
          26,
          166,
          59
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          172,
          5,
          172,
          18,
          167,
          20,
          177,
          32
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          236,
          5,
          236,
          73,
          229,
          31,
          240,
          48
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          236,
          5,
          236,
          73,
          226,
          31,
          240,
          48
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          237,
          5,
          237,
          58,
          229,
          31,
          240,
          48
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          237,
          5,
          237,
          58,
          226,
          31,
          240,
          48
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          243,
          5,
          243,
          22,
          242,
          5,
          261,
          29
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          245,
          5,
          245,
          46,
          242,
          5,
          261,
          29
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          249,
          5,
          249,
          40,
          242,
          5,
          261,
          29
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          265,
          5,
          265,
          51,
          265,
          5,
          270,
          43
        ],
        [
          "convert_blip2_checkpoint",
          131,
          276,
          268,
          5,
          268,
          40,
          265,
          5,
          270,
          43
        ]
      ],
      "transformers/src/transformers/models/ijepa/convert_ijepa_to_hf.py": [
        [
          "write_model",
          150,
          226,
          226,
          9,
          226,
          45,
          221,
          8,
          226,
          45
        ],
        [
          "write_model",
          150,
          226,
          224,
          9,
          224,
          70,
          221,
          8,
          226,
          45
        ],
        [
          "write_model",
          150,
          226,
          213,
          9,
          213,
          59,
          212,
          9,
          217,
          18
        ]
      ],
      "transformers/src/transformers/models/instructblipvideo/convert_instructblipvideo_original_to_pytorch.py": [
        [
          "convert_blip2_checkpoint",
          133,
          278,
          251,
          5,
          251,
          40,
          244,
          5,
          263,
          29
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          167,
          5,
          167,
          38,
          141,
          21,
          168,
          59
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          167,
          5,
          167,
          38,
          154,
          26,
          168,
          59
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          174,
          5,
          174,
          18,
          169,
          20,
          179,
          32
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          238,
          5,
          238,
          73,
          228,
          31,
          242,
          48
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          238,
          5,
          238,
          73,
          231,
          31,
          242,
          48
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          239,
          5,
          239,
          58,
          228,
          31,
          242,
          48
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          239,
          5,
          239,
          58,
          231,
          31,
          242,
          48
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          245,
          5,
          245,
          22,
          244,
          5,
          263,
          29
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          247,
          5,
          247,
          46,
          244,
          5,
          263,
          29
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          267,
          5,
          267,
          51,
          267,
          5,
          272,
          43
        ],
        [
          "convert_blip2_checkpoint",
          133,
          278,
          270,
          5,
          270,
          40,
          267,
          5,
          272,
          43
        ]
      ],
      "transformers/src/transformers/models/internvl/convert_internvl_weights_to_hf.py": [
        [
          "write_model",
          235,
          342,
          248,
          5,
          248,
          47,
          247,
          9,
          262,
          23
        ],
        [
          "write_model",
          235,
          342,
          248,
          5,
          248,
          47,
          248,
          5,
          262,
          23
        ],
        [
          "write_model",
          235,
          342,
          254,
          5,
          254,
          81,
          247,
          9,
          262,
          23
        ],
        [
          "write_model",
          235,
          342,
          254,
          5,
          254,
          81,
          248,
          5,
          262,
          23
        ],
        [
          "write_model",
          235,
          342,
          256,
          5,
          256,
          32,
          247,
          9,
          262,
          23
        ],
        [
          "write_model",
          235,
          342,
          256,
          5,
          256,
          32,
          248,
          5,
          262,
          23
        ],
        [
          "write_model",
          235,
          342,
          297,
          5,
          297,
          80,
          294,
          9,
          324,
          46
        ],
        [
          "write_model",
          235,
          342,
          301,
          5,
          301,
          38,
          294,
          9,
          324,
          46
        ],
        [
          "write_model",
          235,
          342,
          302,
          5,
          302,
          40,
          294,
          9,
          324,
          46
        ],
        [
          "write_model",
          235,
          342,
          303,
          5,
          303,
          46,
          294,
          9,
          324,
          46
        ],
        [
          "write_model",
          235,
          342,
          305,
          5,
          305,
          30,
          294,
          9,
          324,
          46
        ],
        [
          "write_model",
          235,
          342,
          325,
          9,
          325,
          44,
          325,
          9,
          333,
          69
        ],
        [
          "write_model",
          235,
          342,
          325,
          9,
          325,
          44,
          325,
          9,
          332,
          22
        ],
        [
          "write_model",
          235,
          342,
          339,
          5,
          339,
          66,
          338,
          5,
          342,
          13
        ],
        [
          "write_model",
          235,
          342,
          341,
          5,
          341,
          41,
          338,
          5,
          342,
          13
        ]
      ],
      "transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py": [
        [
          "convert_weight_and_push",
          36,
          80,
          80,
          9,
          80,
          42,
          76,
          9,
          80,
          42
        ],
        [
          "convert_weight_and_push",
          36,
          80,
          39,
          5,
          39,
          34,
          37,
          5,
          42,
          30
        ],
        [
          "convert_weight_and_push",
          36,
          80,
          61,
          9,
          61,
          42,
          47,
          12,
          62,
          36
        ],
        [
          "convert_weight_and_push",
          36,
          80,
          61,
          9,
          61,
          42,
          54,
          9,
          62,
          36
        ],
        [
          "convert_weight_and_push",
          36,
          80,
          61,
          9,
          61,
          42,
          48,
          26,
          62,
          36
        ],
        [
          "convert_weight_and_push",
          36,
          80,
          73,
          5,
          73,
          26,
          70,
          5,
          75,
          18
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "convert_model",
          242,
          447,
          436,
          9,
          436,
          62,
          416,
          65,
          443,
          17
        ],
        [
          "convert_model",
          242,
          447,
          436,
          9,
          436,
          62,
          435,
          8,
          443,
          17
        ],
        [
          "ensure_model_downloaded",
          171,
          206,
          205,
          9,
          205,
          58,
          201,
          5,
          206,
          27
        ],
        [
          "load_model_state_dict",
          209,
          239,
          235,
          9,
          235,
          45,
          235,
          9,
          236,
          63
        ],
        [
          "ensure_model_downloaded",
          171,
          206,
          185,
          13,
          185,
          65,
          185,
          13,
          185,
          65
        ],
        [
          "ensure_model_downloaded",
          171,
          206,
          189,
          13,
          189,
          58,
          188,
          13,
          189,
          58
        ],
        [
          "ensure_model_downloaded",
          171,
          206,
          194,
          5,
          194,
          84,
          194,
          64,
          198,
          40
        ],
        [
          "ensure_model_downloaded",
          171,
          206,
          199,
          9,
          199,
          61,
          199,
          9,
          199,
          61
        ],
        [
          "ensure_model_downloaded",
          171,
          206,
          203,
          9,
          203,
          58,
          201,
          5,
          206,
          27
        ],
        [
          "load_model_state_dict",
          209,
          239,
          218,
          9,
          218,
          41,
          218,
          9,
          225,
          44
        ],
        [
          "load_model_state_dict",
          209,
          239,
          226,
          13,
          226,
          51,
          225,
          13,
          229,
          41
        ],
        [
          "convert_model",
          242,
          447,
          261,
          9,
          261,
          65,
          260,
          9,
          261,
          65
        ],
        [
          "convert_model",
          242,
          447,
          336,
          9,
          336,
          53,
          336,
          9,
          337,
          45
        ],
        [
          "convert_model",
          242,
          447,
          339,
          9,
          339,
          66,
          339,
          9,
          354,
          5
        ],
        [
          "convert_model",
          242,
          447,
          406,
          5,
          406,
          36,
          381,
          21,
          414,
          64
        ],
        [
          "convert_model",
          242,
          447,
          406,
          5,
          406,
          36,
          402,
          8,
          414,
          64
        ],
        [
          "convert_model",
          242,
          447,
          419,
          5,
          419,
          34,
          416,
          65,
          443,
          17
        ],
        [
          "convert_model",
          242,
          447,
          419,
          5,
          419,
          34,
          416,
          65,
          432,
          17
        ],
        [
          "convert_model",
          242,
          447,
          424,
          5,
          424,
          52,
          416,
          65,
          443,
          17
        ],
        [
          "convert_model",
          242,
          447,
          424,
          5,
          424,
          52,
          416,
          65,
          432,
          17
        ],
        [
          "convert_model",
          242,
          447,
          428,
          5,
          428,
          29,
          416,
          65,
          443,
          17
        ],
        [
          "convert_model",
          242,
          447,
          428,
          5,
          428,
          29,
          416,
          65,
          432,
          17
        ],
        [
          "convert_model",
          242,
          447,
          433,
          9,
          433,
          49,
          433,
          9,
          434,
          80
        ],
        [
          "convert_model",
          242,
          447,
          444,
          9,
          444,
          78,
          444,
          9,
          447,
          51
        ],
        [
          "convert_model",
          242,
          447,
          447,
          9,
          447,
          51,
          444,
          9,
          447,
          51
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "fix_jukebox_keys",
          96,
          209,
          198,
          13,
          198,
          79,
          198,
          13,
          198,
          79
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          203,
          13,
          203,
          98,
          202,
          19,
          204,
          15
        ],
        [
          "convert_openai_checkpoint",
          213,
          260,
          257,
          5,
          257,
          69,
          253,
          5,
          260,
          22
        ]
      ],
      "transformers/src/transformers/models/kyutai_speech_to_text/convert_kyutai_speech_to_text_to_hf.py": [
        [
          "write_model",
          181,
          263,
          190,
          5,
          190,
          34,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          214,
          5,
          214,
          76,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          217,
          5,
          217,
          76,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          220,
          5,
          220,
          32,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          230,
          5,
          230,
          57,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          242,
          5,
          242,
          44,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          255,
          5,
          255,
          30,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          261,
          5,
          261,
          66,
          182,
          5,
          263,
          41
        ],
        [
          "write_model",
          181,
          263,
          263,
          5,
          263,
          41,
          182,
          5,
          263,
          41
        ],
        [
          "write_processor",
          266,
          300,
          300,
          5,
          300,
          58,
          267,
          5,
          300,
          58
        ]
      ],
      "transformers/src/transformers/models/lightglue/convert_lightglue_to_hf.py": [
        [
          "write_image_processor",
          229,
          241,
          237,
          9,
          237,
          54,
          237,
          9,
          241,
          9
        ],
        [
          "write_model",
          149,
          226,
          214,
          9,
          214,
          46,
          214,
          9,
          215,
          43
        ],
        [
          "write_model",
          149,
          226,
          169,
          5,
          169,
          47,
          150,
          5,
          183,
          23
        ],
        [
          "write_model",
          149,
          226,
          175,
          5,
          175,
          80,
          150,
          5,
          183,
          23
        ],
        [
          "write_model",
          149,
          226,
          178,
          5,
          178,
          32,
          150,
          5,
          183,
          23
        ],
        [
          "write_model",
          149,
          226,
          192,
          5,
          192,
          59,
          187,
          9,
          211,
          37
        ],
        [
          "write_model",
          149,
          226,
          197,
          5,
          197,
          46,
          187,
          9,
          211,
          37
        ],
        [
          "write_model",
          149,
          226,
          200,
          5,
          200,
          32,
          187,
          9,
          211,
          37
        ],
        [
          "write_model",
          149,
          226,
          206,
          5,
          206,
          66,
          187,
          9,
          211,
          37
        ],
        [
          "write_model",
          149,
          226,
          208,
          5,
          208,
          41,
          187,
          9,
          211,
          37
        ],
        [
          "write_model",
          149,
          226,
          216,
          5,
          216,
          49,
          216,
          5,
          218,
          18
        ],
        [
          "write_model",
          149,
          226,
          219,
          9,
          219,
          44,
          219,
          9,
          224,
          95
        ]
      ],
      "transformers/src/transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          153,
          248,
          246,
          9,
          246,
          54,
          245,
          19,
          248,
          55
        ],
        [
          "convert_llava_to_hf",
          153,
          248,
          158,
          9,
          158,
          19,
          153,
          25,
          160,
          53
        ],
        [
          "convert_llava_to_hf",
          153,
          248,
          239,
          9,
          239,
          89,
          239,
          9,
          242,
          59
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "write_model",
          213,
          554,
          519,
          9,
          519,
          45,
          513,
          13,
          525,
          20
        ],
        [
          "write_model",
          213,
          554,
          332,
          5,
          332,
          47,
          284,
          20,
          338,
          26
        ],
        [
          "write_model",
          213,
          554,
          339,
          9,
          339,
          85,
          339,
          9,
          340,
          26
        ],
        [
          "write_model",
          213,
          554,
          363,
          17,
          363,
          62,
          362,
          13,
          363,
          62
        ],
        [
          "write_model",
          213,
          554,
          364,
          9,
          364,
          44,
          364,
          9,
          373,
          86
        ],
        [
          "write_model",
          213,
          554,
          368,
          9,
          368,
          36,
          364,
          9,
          373,
          86
        ],
        [
          "write_model",
          213,
          554,
          375,
          13,
          375,
          31,
          373,
          13,
          381,
          102
        ],
        [
          "write_model",
          213,
          554,
          375,
          13,
          375,
          31,
          373,
          13,
          376,
          29
        ],
        [
          "write_model",
          213,
          554,
          379,
          17,
          379,
          78,
          373,
          13,
          381,
          102
        ],
        [
          "write_model",
          213,
          554,
          379,
          17,
          379,
          78,
          379,
          17,
          381,
          102
        ],
        [
          "write_model",
          213,
          554,
          516,
          9,
          516,
          58,
          513,
          13,
          525,
          20
        ],
        [
          "write_model",
          213,
          554,
          520,
          9,
          520,
          34,
          513,
          13,
          525,
          20
        ],
        [
          "write_model",
          213,
          554,
          526,
          5,
          526,
          66,
          526,
          5,
          544,
          15
        ],
        [
          "write_model",
          213,
          554,
          535,
          9,
          535,
          45,
          526,
          5,
          544,
          15
        ],
        [
          "write_model",
          213,
          554,
          542,
          9,
          542,
          42,
          526,
          5,
          544,
          15
        ],
        [
          "write_model",
          213,
          554,
          545,
          9,
          545,
          44,
          545,
          9,
          554,
          53
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          101,
          9,
          101,
          19,
          95,
          25,
          103,
          53
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          187,
          5,
          187,
          85,
          187,
          5,
          204,
          53
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          243,
          5,
          243,
          32,
          240,
          5,
          250,
          57
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          247,
          9,
          247,
          55,
          240,
          5,
          250,
          57
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          248,
          9,
          248,
          67,
          240,
          5,
          250,
          57
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          298,
          9,
          298,
          31,
          297,
          9,
          311,
          53
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          309,
          5,
          309,
          50,
          297,
          9,
          311,
          53
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          329,
          5,
          329,
          34,
          328,
          5,
          343,
          30
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          332,
          5,
          332,
          34,
          328,
          5,
          343,
          30
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          344,
          9,
          344,
          25,
          343,
          9,
          344,
          25
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          346,
          5,
          346,
          45,
          346,
          5,
          362,
          18
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          352,
          5,
          352,
          34,
          346,
          5,
          362,
          18
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          360,
          5,
          360,
          18,
          346,
          5,
          362,
          18
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          364,
          9,
          364,
          63,
          363,
          27,
          366,
          63
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          98,
          357,
          220,
          5,
          220,
          32,
          217,
          5,
          227,
          63
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          187,
          5,
          187,
          85,
          121,
          23,
          214,
          76
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          104,
          9,
          104,
          19,
          98,
          25,
          106,
          103
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          224,
          9,
          224,
          55,
          217,
          5,
          227,
          63
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          225,
          9,
          225,
          67,
          217,
          5,
          227,
          63
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          287,
          9,
          287,
          31,
          286,
          9,
          300,
          59
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          298,
          5,
          298,
          50,
          286,
          9,
          300,
          59
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          320,
          5,
          320,
          34,
          319,
          5,
          334,
          30
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          323,
          5,
          323,
          34,
          319,
          5,
          334,
          30
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          335,
          9,
          335,
          25,
          334,
          9,
          335,
          25
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          337,
          5,
          337,
          45,
          337,
          5,
          353,
          18
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          343,
          5,
          343,
          34,
          337,
          5,
          353,
          18
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          351,
          5,
          351,
          18,
          337,
          5,
          353,
          18
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          355,
          9,
          355,
          63,
          354,
          27,
          357,
          63
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "write_model",
          184,
          433,
          236,
          13,
          236,
          55,
          235,
          31,
          237,
          18
        ],
        [
          "write_model",
          184,
          433,
          225,
          9,
          225,
          83,
          221,
          34,
          227,
          26
        ],
        [
          "write_model",
          184,
          433,
          195,
          5,
          195,
          34,
          185,
          5,
          197,
          61
        ],
        [
          "write_model",
          184,
          433,
          420,
          9,
          420,
          57,
          388,
          18,
          428,
          22
        ],
        [
          "write_model",
          184,
          433,
          427,
          9,
          427,
          51,
          388,
          18,
          428,
          22
        ],
        [
          "write_model",
          184,
          433,
          429,
          13,
          429,
          40,
          429,
          13,
          430,
          113
        ],
        [
          "write_model",
          184,
          433,
          432,
          13,
          432,
          36,
          432,
          13,
          433,
          84
        ],
        [
          "write_tokenizer",
          492,
          518,
          495,
          5,
          495,
          38,
          493,
          5,
          496,
          66
        ],
        [
          "write_tokenizer",
          492,
          518,
          513,
          9,
          513,
          90,
          513,
          9,
          514,
          78
        ],
        [
          "write_tokenizer",
          492,
          518,
          516,
          9,
          516,
          74,
          516,
          9,
          517,
          49
        ]
      ],
      "transformers/src/transformers/models/longformer/convert_longformer_original_pytorch_lightning_to_pytorch.py": [
        [
          "convert_longformer_qa_checkpoint_to_pytorch",
          38,
          59,
          59,
          5,
          59,
          81,
          39,
          5,
          59,
          81
        ]
      ],
      "transformers/src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          28,
          131,
          48,
          5,
          48,
          60,
          28,
          29,
          62,
          54
        ],
        [
          "convert_luke_checkpoint",
          28,
          131,
          130,
          5,
          130,
          64,
          130,
          5,
          131,
          51
        ]
      ],
      "transformers/src/transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          109,
          120,
          112,
          5,
          112,
          65,
          109,
          38,
          120,
          53
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          109,
          120,
          119,
          5,
          119,
          55,
          109,
          38,
          120,
          53
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          302,
          9,
          302,
          64,
          302,
          9,
          304,
          59
        ],
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          262,
          9,
          262,
          32,
          261,
          9,
          262,
          32
        ],
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          286,
          5,
          286,
          61,
          274,
          24,
          288,
          47
        ],
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          286,
          5,
          286,
          61,
          279,
          24,
          288,
          47
        ],
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          293,
          5,
          293,
          22,
          292,
          5,
          295,
          43
        ],
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          296,
          9,
          296,
          80,
          296,
          9,
          299,
          65
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "load_marian_model",
          595,
          649,
          632,
          13,
          632,
          41,
          632,
          13,
          637,
          34
        ],
        [
          "write_model_card",
          210,
          278,
          257,
          5,
          257,
          19,
          231,
          49,
          269,
          14
        ],
        [
          "add_special_tokens_to_vocab",
          396,
          414,
          412,
          9,
          412,
          51,
          409,
          17,
          414,
          40
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "convert_models",
          74,
          89,
          81,
          17,
          81,
          100,
          81,
          17,
          82,
          24
        ],
        [
          "get_tags",
          97,
          107,
          106,
          13,
          106,
          59,
          106,
          13,
          107,
          25
        ],
        [
          "write_model_card",
          129,
          275,
          262,
          13,
          262,
          29,
          262,
          13,
          266,
          18
        ],
        [
          "write_model_card",
          129,
          275,
          263,
          13,
          263,
          26,
          262,
          13,
          266,
          18
        ],
        [
          "write_model_card",
          129,
          275,
          264,
          13,
          264,
          30,
          262,
          13,
          266,
          18
        ],
        [
          "write_model_card",
          129,
          275,
          265,
          13,
          265,
          27,
          262,
          13,
          266,
          18
        ]
      ],
      "transformers/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py": [
        [
          "recursive_print",
          48,
          65,
          65,
          9,
          65,
          28,
          65,
          9,
          65,
          28
        ],
        [
          "recursive_print",
          48,
          65,
          59,
          13,
          59,
          22,
          59,
          13,
          59,
          22
        ],
        [
          "recursive_print",
          48,
          65,
          63,
          9,
          63,
          35,
          63,
          9,
          63,
          35
        ],
        [
          "main",
          275,
          326,
          293,
          5,
          293,
          82,
          277,
          14,
          294,
          47
        ],
        [
          "main",
          275,
          326,
          312,
          5,
          312,
          23,
          312,
          5,
          316,
          38
        ],
        [
          "main",
          275,
          326,
          320,
          5,
          320,
          26,
          320,
          5,
          326,
          57
        ],
        [
          "main",
          275,
          326,
          325,
          5,
          325,
          61,
          320,
          5,
          326,
          57
        ]
      ],
      "transformers/src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          258,
          5,
          258,
          53,
          235,
          5,
          263,
          14
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          132,
          5,
          139,
          5,
          124,
          39,
          191,
          42
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          140,
          5,
          147,
          5,
          124,
          39,
          191,
          42
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          227,
          9,
          227,
          60,
          227,
          9,
          227,
          60
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          229,
          9,
          229,
          53,
          229,
          9,
          229,
          53
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          235,
          5,
          235,
          86,
          235,
          5,
          263,
          14
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          238,
          5,
          245,
          5,
          235,
          5,
          263,
          14
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          259,
          5,
          259,
          41,
          235,
          5,
          263,
          14
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          260,
          5,
          260,
          61,
          235,
          5,
          263,
          14
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          264,
          9,
          264,
          21,
          264,
          9,
          269,
          25
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          270,
          9,
          270,
          39,
          270,
          9,
          272,
          46
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "convert_maskformer_checkpoint",
          261,
          350,
          339,
          5,
          339,
          22,
          338,
          5,
          341,
          43
        ],
        [
          "convert_maskformer_checkpoint",
          261,
          350,
          342,
          9,
          342,
          96,
          342,
          9,
          345,
          65
        ],
        [
          "convert_maskformer_checkpoint",
          261,
          350,
          348,
          9,
          348,
          81,
          348,
          9,
          350,
          61
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py": [
        [
          "convert_megatron_checkpoint",
          94,
          306,
          300,
          9,
          300,
          66,
          300,
          9,
          300,
          66
        ],
        [
          "recursive_print",
          48,
          65,
          65,
          9,
          65,
          28,
          65,
          9,
          65,
          28
        ],
        [
          "recursive_print",
          48,
          65,
          59,
          13,
          59,
          22,
          59,
          13,
          59,
          22
        ],
        [
          "recursive_print",
          48,
          65,
          63,
          9,
          63,
          35,
          63,
          9,
          63,
          35
        ],
        [
          "convert_megatron_checkpoint",
          94,
          306,
          283,
          13,
          285,
          13,
          283,
          13,
          285,
          13
        ],
        [
          "main",
          312,
          422,
          334,
          5,
          334,
          80,
          314,
          14,
          335,
          47
        ],
        [
          "main",
          312,
          422,
          387,
          5,
          387,
          23,
          384,
          29,
          391,
          38
        ],
        [
          "main",
          312,
          422,
          412,
          5,
          412,
          26,
          407,
          17,
          422,
          57
        ],
        [
          "main",
          312,
          422,
          416,
          5,
          416,
          54,
          407,
          17,
          422,
          57
        ],
        [
          "main",
          312,
          422,
          421,
          5,
          421,
          61,
          407,
          17,
          422,
          57
        ]
      ],
      "transformers/src/transformers/models/mimi/convert_mimi_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint",
          142,
          178,
          176,
          9,
          176,
          38,
          176,
          9,
          178,
          34
        ]
      ],
      "transformers/src/transformers/models/metaclip_2/convert_metaclip_2_to_hf.py": [
        [
          "push_to_hub",
          361,
          370,
          370,
          9,
          370,
          46,
          369,
          5,
          370,
          46
        ],
        [
          "load_metaclip2_checkpoint",
          39,
          52,
          41,
          5,
          41,
          52,
          39,
          31,
          45,
          40
        ],
        [
          "load_metaclip2_checkpoint",
          39,
          52,
          47,
          9,
          47,
          62,
          46,
          33,
          47,
          62
        ],
        [
          "create_hf_config",
          55,
          167,
          60,
          5,
          60,
          44,
          55,
          22,
          167,
          29
        ],
        [
          "convert_state_dict",
          170,
          292,
          172,
          5,
          172,
          37,
          170,
          24,
          176,
          49
        ],
        [
          "verify_conversion",
          295,
          358,
          299,
          5,
          299,
          36,
          296,
          5,
          302,
          22
        ],
        [
          "verify_conversion",
          295,
          358,
          311,
          5,
          311,
          55,
          309,
          23,
          313,
          56
        ],
        [
          "verify_conversion",
          295,
          358,
          312,
          5,
          312,
          61,
          309,
          23,
          313,
          56
        ],
        [
          "verify_conversion",
          295,
          358,
          320,
          5,
          320,
          53,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          321,
          5,
          321,
          60,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          333,
          9,
          333,
          78,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          334,
          9,
          334,
          80,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          341,
          9,
          341,
          76,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          342,
          9,
          342,
          78,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          343,
          9,
          343,
          83,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          346,
          5,
          346,
          44,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          347,
          5,
          347,
          36,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          348,
          5,
          348,
          114,
          313,
          5,
          351,
          43
        ],
        [
          "verify_conversion",
          295,
          358,
          352,
          9,
          352,
          54,
          352,
          9,
          353,
          19
        ],
        [
          "verify_conversion",
          295,
          358,
          355,
          9,
          355,
          58,
          355,
          9,
          356,
          34
        ],
        [
          "verify_conversion",
          295,
          358,
          357,
          13,
          357,
          77,
          357,
          13,
          357,
          77
        ],
        [
          "push_to_hub",
          361,
          370,
          363,
          5,
          363,
          41,
          361,
          17,
          366,
          28
        ],
        [
          "push_to_hub",
          361,
          370,
          368,
          9,
          368,
          54,
          368,
          9,
          368,
          54
        ],
        [
          "main",
          373,
          423,
          405,
          9,
          405,
          32,
          404,
          9,
          405,
          32
        ],
        [
          "main",
          373,
          423,
          412,
          9,
          412,
          83,
          412,
          9,
          413,
          14
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/convert_megatron_to_pytorch.py": [
        [
          "recursive_print",
          25,
          42,
          36,
          13,
          36,
          22,
          36,
          13,
          36,
          22
        ],
        [
          "recursive_print",
          25,
          42,
          40,
          9,
          40,
          35,
          40,
          9,
          40,
          35
        ],
        [
          "recursive_print",
          25,
          42,
          42,
          9,
          42,
          28,
          42,
          9,
          42,
          28
        ],
        [
          "main",
          147,
          183,
          148,
          5,
          148,
          15,
          147,
          10,
          152,
          30
        ],
        [
          "main",
          147,
          183,
          167,
          5,
          167,
          23,
          156,
          18,
          171,
          38
        ],
        [
          "main",
          147,
          183,
          177,
          5,
          177,
          26,
          174,
          33,
          183,
          45
        ],
        [
          "main",
          147,
          183,
          182,
          5,
          182,
          61,
          174,
          33,
          183,
          45
        ]
      ],
      "transformers/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py": [
        [
          "write_model",
          61,
          217,
          94,
          5,
          94,
          79,
          91,
          28,
          102,
          28
        ],
        [
          "write_model",
          61,
          217,
          204,
          5,
          204,
          55,
          182,
          5,
          214,
          40
        ],
        [
          "write_model",
          61,
          217,
          210,
          5,
          210,
          47,
          182,
          5,
          214,
          40
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "load_orig_config_file",
          41,
          64,
          42,
          5,
          42,
          35,
          41,
          27,
          57,
          22
        ],
        [
          "convert_mobilevitv2_checkpoint",
          235,
          281,
          271,
          9,
          271,
          77,
          269,
          18,
          272,
          49
        ],
        [
          "convert_mobilevitv2_checkpoint",
          235,
          281,
          278,
          5,
          278,
          68,
          277,
          5,
          281,
          61
        ],
        [
          "convert_mobilevitv2_checkpoint",
          235,
          281,
          280,
          5,
          280,
          66,
          277,
          5,
          281,
          61
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          29,
          183,
          52,
          5,
          52,
          60,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          182,
          5,
          182,
          64,
          179,
          5,
          183,
          51
        ]
      ],
      "transformers/src/transformers/models/mobilebert/convert_mobilebert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          106,
          115,
          114,
          5,
          114,
          55,
          106,
          38,
          115,
          53
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          106,
          115,
          109,
          5,
          109,
          65,
          106,
          38,
          115,
          53
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          295,
          9,
          295,
          50,
          292,
          19,
          296,
          48
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          282,
          9,
          282,
          59,
          282,
          9,
          288,
          109
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          277,
          5,
          277,
          34,
          272,
          5,
          281,
          26
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          249,
          5,
          249,
          58,
          246,
          5,
          255,
          43
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          253,
          5,
          253,
          44,
          246,
          5,
          255,
          43
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          262,
          5,
          262,
          49,
          257,
          18,
          266,
          37
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          272,
          5,
          272,
          41,
          272,
          5,
          281,
          26
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          293,
          9,
          293,
          59,
          292,
          19,
          296,
          48
        ],
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          299,
          9,
          299,
          88,
          299,
          9,
          301,
          79
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "convert_movilevit_checkpoint",
          195,
          283,
          265,
          5,
          265,
          73,
          264,
          5,
          270,
          18
        ],
        [
          "convert_movilevit_checkpoint",
          195,
          283,
          267,
          5,
          267,
          66,
          264,
          5,
          270,
          18
        ],
        [
          "convert_movilevit_checkpoint",
          195,
          283,
          280,
          9,
          280,
          38,
          272,
          13,
          283,
          59
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_model_with_hifigan.py": [
        [
          "convert_FastSpeech2ConformerWithHifiGan_checkpoint",
          42,
          75,
          74,
          9,
          74,
          38,
          74,
          9,
          75,
          47
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_model",
          209,
          471,
          462,
          9,
          462,
          44,
          462,
          9,
          471,
          53
        ],
        [
          "write_model",
          209,
          471,
          333,
          5,
          333,
          47,
          270,
          20,
          340,
          22
        ],
        [
          "write_model",
          209,
          471,
          339,
          5,
          339,
          81,
          270,
          20,
          340,
          22
        ],
        [
          "write_model",
          209,
          471,
          357,
          5,
          357,
          32,
          357,
          5,
          362,
          23
        ],
        [
          "write_model",
          209,
          471,
          443,
          5,
          443,
          54,
          433,
          62,
          461,
          15
        ],
        [
          "write_model",
          209,
          471,
          447,
          5,
          447,
          44,
          433,
          62,
          461,
          15
        ],
        [
          "write_model",
          209,
          471,
          450,
          5,
          450,
          30,
          433,
          62,
          461,
          15
        ],
        [
          "write_model",
          209,
          471,
          456,
          5,
          456,
          66,
          433,
          62,
          461,
          15
        ],
        [
          "write_model",
          209,
          471,
          458,
          5,
          458,
          41,
          433,
          62,
          461,
          15
        ],
        [
          "write_tokenizer",
          497,
          565,
          562,
          9,
          562,
          40,
          562,
          9,
          565,
          68
        ]
      ],
      "transformers/src/transformers/models/moshi/convert_moshi_transformers.py": [
        [
          "convert_checkpoint",
          199,
          256,
          255,
          9,
          255,
          38,
          255,
          9,
          256,
          34
        ]
      ],
      "transformers/src/transformers/models/mra/convert_mra_pytorch_to_pytorch.py": [
        [
          "convert_mra_checkpoint",
          79,
          90,
          86,
          5,
          86,
          48,
          79,
          28,
          90,
          83
        ],
        [
          "convert_mra_checkpoint",
          79,
          90,
          90,
          5,
          90,
          83,
          79,
          28,
          90,
          83
        ]
      ],
      "transformers/src/transformers/models/vit_msn/convert_msn_to_pytorch.py": [
        [
          "convert_vit_msn_checkpoint",
          148,
          228,
          224,
          5,
          224,
          56,
          222,
          5,
          228,
          61
        ],
        [
          "convert_vit_msn_checkpoint",
          148,
          228,
          227,
          5,
          227,
          66,
          222,
          5,
          228,
          61
        ]
      ],
      "transformers/src/transformers/models/myt5/convert_myt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          136,
          147,
          139,
          5,
          139,
          65,
          136,
          38,
          147,
          44
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          136,
          147,
          146,
          5,
          146,
          55,
          136,
          38,
          147,
          44
        ]
      ],
      "transformers/src/transformers/models/mm_grounding_dino/convert_mm_grounding_dino_to_hf.py": [
        [
          "convert_mm_grounding_dino_checkpoint",
          430,
          477,
          438,
          5,
          438,
          55,
          431,
          5,
          451,
          21
        ],
        [
          "convert_mm_grounding_dino_checkpoint",
          430,
          477,
          443,
          5,
          443,
          30,
          431,
          5,
          451,
          21
        ],
        [
          "convert_mm_grounding_dino_checkpoint",
          430,
          477,
          452,
          9,
          452,
          55,
          452,
          9,
          465,
          27
        ],
        [
          "convert_mm_grounding_dino_checkpoint",
          430,
          477,
          463,
          9,
          463,
          21,
          452,
          9,
          465,
          27
        ],
        [
          "convert_mm_grounding_dino_checkpoint",
          430,
          477,
          467,
          9,
          467,
          31,
          467,
          9,
          467,
          31
        ],
        [
          "convert_mm_grounding_dino_checkpoint",
          430,
          477,
          471,
          9,
          471,
          34,
          471,
          9,
          475,
          58
        ],
        [
          "convert_mm_grounding_dino_checkpoint",
          430,
          477,
          475,
          9,
          475,
          58,
          471,
          9,
          475,
          58
        ]
      ],
      "transformers/src/transformers/models/nystromformer/convert_nystromformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_nystromformer_checkpoint",
          80,
          91,
          91,
          5,
          91,
          83,
          80,
          38,
          91,
          83
        ]
      ],
      "transformers/src/transformers/models/nougat/convert_nougat_to_hf.py": [
        [
          "convert_nougat_checkpoint",
          142,
          254,
          242,
          5,
          242,
          22,
          241,
          5,
          244,
          43
        ],
        [
          "convert_nougat_checkpoint",
          142,
          254,
          245,
          9,
          245,
          74,
          245,
          9,
          247,
          59
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "extract_nemo_archive",
          57,
          147,
          126,
          21,
          126,
          64,
          125,
          59,
          126,
          64
        ],
        [
          "write_model",
          206,
          284,
          281,
          9,
          281,
          45,
          275,
          13,
          281,
          45
        ],
        [
          "write_model",
          206,
          284,
          269,
          9,
          269,
          34,
          259,
          24,
          272,
          26
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          80,
          5,
          80,
          77,
          80,
          5,
          84,
          49
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          68,
          5,
          68,
          55,
          57,
          26,
          75,
          49
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          102,
          17,
          102,
          53,
          101,
          48,
          102,
          53
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          112,
          21,
          112,
          55,
          111,
          51,
          112,
          55
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          128,
          21,
          128,
          87,
          128,
          21,
          128,
          87
        ],
        [
          "extract_nemo_archive",
          57,
          147,
          130,
          5,
          130,
          59,
          130,
          5,
          133,
          41
        ],
        [
          "write_model",
          206,
          284,
          253,
          13,
          253,
          58,
          253,
          13,
          254,
          20
        ],
        [
          "write_model",
          206,
          284,
          262,
          9,
          262,
          64,
          259,
          24,
          272,
          26
        ],
        [
          "write_model",
          206,
          284,
          266,
          9,
          266,
          48,
          259,
          24,
          272,
          26
        ],
        [
          "write_model",
          206,
          284,
          279,
          9,
          279,
          70,
          275,
          13,
          281,
          45
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "write_model",
          68,
          216,
          106,
          5,
          106,
          79,
          106,
          5,
          114,
          34
        ],
        [
          "write_model",
          68,
          216,
          179,
          9,
          179,
          55,
          179,
          9,
          180,
          36
        ],
        [
          "write_model",
          68,
          216,
          207,
          5,
          207,
          53,
          207,
          5,
          213,
          18
        ],
        [
          "write_model",
          68,
          216,
          211,
          5,
          211,
          47,
          207,
          5,
          213,
          18
        ],
        [
          "_write_tokenizer",
          219,
          248,
          225,
          5,
          225,
          69,
          220,
          5,
          227,
          39
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "write_model",
          65,
          183,
          90,
          5,
          90,
          79,
          90,
          5,
          98,
          34
        ],
        [
          "write_model",
          65,
          183,
          177,
          5,
          177,
          52,
          177,
          5,
          183,
          33
        ],
        [
          "write_model",
          65,
          183,
          181,
          5,
          181,
          47,
          177,
          5,
          183,
          33
        ],
        [
          "_write_tokenizer",
          186,
          209,
          189,
          5,
          189,
          72,
          187,
          5,
          193,
          73
        ],
        [
          "_write_tokenizer",
          186,
          209,
          198,
          9,
          198,
          55,
          198,
          9,
          199,
          20
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "write_model",
          91,
          215,
          119,
          5,
          119,
          79,
          119,
          5,
          126,
          34
        ],
        [
          "write_model",
          91,
          215,
          209,
          5,
          209,
          53,
          209,
          5,
          215,
          33
        ],
        [
          "write_model",
          91,
          215,
          213,
          5,
          213,
          47,
          209,
          5,
          215,
          33
        ],
        [
          "_write_tokenizer",
          218,
          241,
          221,
          5,
          221,
          72,
          219,
          5,
          225,
          73
        ],
        [
          "_write_tokenizer",
          218,
          241,
          230,
          9,
          230,
          55,
          230,
          9,
          231,
          20
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "convert",
          134,
          295,
          194,
          9,
          194,
          38,
          193,
          9,
          234,
          62
        ],
        [
          "convert",
          134,
          295,
          277,
          9,
          277,
          32,
          277,
          9,
          277,
          32
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "write_model",
          272,
          398,
          304,
          5,
          304,
          79,
          304,
          5,
          314,
          34
        ],
        [
          "write_model",
          272,
          398,
          309,
          5,
          309,
          24,
          304,
          5,
          314,
          34
        ],
        [
          "write_model",
          272,
          398,
          387,
          5,
          387,
          54,
          387,
          5,
          395,
          18
        ],
        [
          "write_model",
          272,
          398,
          389,
          5,
          389,
          65,
          387,
          5,
          395,
          18
        ],
        [
          "write_model",
          272,
          398,
          393,
          5,
          393,
          47,
          387,
          5,
          395,
          18
        ],
        [
          "_write_tokenizer",
          401,
          408,
          405,
          5,
          405,
          50,
          402,
          5,
          408,
          42
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_openai_checkpoint_to_pytorch",
          109,
          127,
          123,
          5,
          123,
          63,
          115,
          13,
          127,
          40
        ],
        [
          "convert_openai_checkpoint_to_pytorch",
          109,
          127,
          125,
          5,
          125,
          67,
          115,
          13,
          127,
          40
        ]
      ],
      "transformers/src/transformers/models/omdet_turbo/convert_omdet_turbo_to_hf.py": [
        [
          "run_test",
          237,
          255,
          251,
          5,
          251,
          26,
          237,
          14,
          254,
          69
        ],
        [
          "run_test",
          237,
          255,
          255,
          5,
          255,
          22,
          254,
          5,
          255,
          22
        ],
        [
          "convert_omdet_turbo_checkpoint",
          259,
          325,
          303,
          5,
          303,
          40,
          293,
          5,
          319,
          43
        ],
        [
          "convert_omdet_turbo_checkpoint",
          259,
          325,
          304,
          5,
          304,
          46,
          293,
          5,
          319,
          43
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "rename_keys",
          126,
          137,
          134,
          9,
          134,
          36,
          134,
          9,
          136,
          23
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_movilevit_checkpoint",
          175,
          218,
          209,
          5,
          209,
          69,
          208,
          5,
          214,
          18
        ],
        [
          "convert_movilevit_checkpoint",
          175,
          218,
          211,
          5,
          211,
          66,
          208,
          5,
          214,
          18
        ],
        [
          "convert_movilevit_checkpoint",
          175,
          218,
          215,
          9,
          215,
          38,
          215,
          9,
          218,
          34
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_movilevit_checkpoint",
          253,
          320,
          311,
          5,
          311,
          69,
          310,
          5,
          316,
          18
        ],
        [
          "convert_movilevit_checkpoint",
          253,
          320,
          313,
          5,
          313,
          66,
          310,
          5,
          316,
          18
        ],
        [
          "convert_movilevit_checkpoint",
          253,
          320,
          317,
          9,
          317,
          38,
          317,
          9,
          320,
          34
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          358,
          9,
          358,
          38,
          358,
          9,
          360,
          34
        ]
      ],
      "transformers/src/transformers/models/owlv2/convert_owlv2_to_hf.py": [
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          355,
          9,
          355,
          51,
          353,
          9,
          357,
          76
        ],
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          365,
          9,
          365,
          54,
          365,
          9,
          367,
          54
        ],
        [
          "rename_and_reshape_key",
          216,
          233,
          225,
          9,
          225,
          54,
          225,
          9,
          226,
          11
        ],
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          353,
          9,
          353,
          62,
          353,
          9,
          357,
          76
        ],
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          354,
          9,
          354,
          43,
          353,
          9,
          357,
          76
        ],
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          360,
          9,
          360,
          26,
          359,
          9,
          360,
          26
        ],
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          362,
          9,
          362,
          57,
          362,
          9,
          362,
          57
        ],
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          374,
          9,
          374,
          52,
          374,
          9,
          376,
          53
        ]
      ],
      "transformers/src/transformers/models/ovis2/convert_ovis2_weights_to_hf.py": [
        [
          "main",
          309,
          400,
          334,
          5,
          334,
          80,
          310,
          5,
          337,
          38
        ],
        [
          "convert_model",
          277,
          306,
          302,
          9,
          302,
          46,
          302,
          9,
          302,
          46
        ],
        [
          "convert_model",
          277,
          306,
          304,
          9,
          304,
          52,
          304,
          9,
          304,
          52
        ],
        [
          "main",
          309,
          400,
          386,
          5,
          386,
          19,
          365,
          9,
          400,
          26
        ],
        [
          "main",
          309,
          400,
          400,
          9,
          400,
          26,
          365,
          9,
          400,
          26
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "write_model",
          195,
          436,
          312,
          9,
          312,
          34,
          311,
          9,
          317,
          40
        ],
        [
          "write_weights",
          186,
          192,
          191,
          5,
          191,
          30,
          190,
          5,
          192,
          22
        ],
        [
          "write_model",
          195,
          436,
          205,
          5,
          205,
          34,
          196,
          5,
          219,
          55
        ],
        [
          "write_model",
          195,
          436,
          231,
          9,
          231,
          83,
          227,
          34,
          255,
          38
        ],
        [
          "write_model",
          195,
          436,
          294,
          13,
          294,
          38,
          293,
          13,
          294,
          38
        ],
        [
          "write_model",
          195,
          436,
          349,
          9,
          349,
          34,
          348,
          9,
          361,
          26
        ],
        [
          "write_model",
          195,
          436,
          412,
          9,
          412,
          64,
          372,
          23,
          426,
          22
        ],
        [
          "write_model",
          195,
          436,
          425,
          9,
          425,
          51,
          372,
          23,
          426,
          22
        ],
        [
          "write_model",
          195,
          436,
          427,
          13,
          427,
          40,
          427,
          13,
          433,
          13
        ],
        [
          "write_model",
          195,
          436,
          435,
          13,
          435,
          36,
          435,
          13,
          436,
          84
        ],
        [
          "write_tokenizer",
          493,
          550,
          500,
          5,
          500,
          38,
          494,
          5,
          501,
          66
        ],
        [
          "write_tokenizer",
          493,
          550,
          545,
          9,
          545,
          90,
          545,
          9,
          546,
          78
        ],
        [
          "write_tokenizer",
          493,
          550,
          548,
          9,
          548,
          74,
          548,
          9,
          549,
          49
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          424,
          9,
          424,
          36,
          423,
          9,
          428,
          58
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          427,
          9,
          427,
          34,
          423,
          9,
          428,
          58
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          411,
          9,
          411,
          47,
          411,
          9,
          411,
          47
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          414,
          13,
          414,
          62,
          413,
          13,
          414,
          62
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          425,
          9,
          425,
          40,
          423,
          9,
          428,
          58
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          426,
          9,
          426,
          15,
          423,
          9,
          428,
          58
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          428,
          9,
          428,
          58,
          423,
          9,
          428,
          58
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          431,
          9,
          431,
          82,
          431,
          9,
          431,
          82
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          435,
          5,
          435,
          56,
          434,
          5,
          436,
          51
        ]
      ],
      "transformers/src/transformers/models/phi/convert_phi_weights_to_hf.py": [
        [
          "convert_phi_weights",
          105,
          164,
          118,
          17,
          118,
          86,
          118,
          17,
          119,
          62
        ],
        [
          "convert_phi_weights",
          105,
          164,
          148,
          13,
          148,
          65,
          146,
          33,
          148,
          65
        ],
        [
          "convert_phi_weights",
          105,
          164,
          155,
          13,
          155,
          55,
          151,
          21,
          158,
          29
        ]
      ],
      "transformers/src/transformers/models/pix2struct/convert_pix2struct_original_pytorch_to_hf.py": [
        [
          "convert_pix2struct_original_pytorch_checkpoint_to_hf",
          105,
          142,
          142,
          5,
          142,
          55,
          111,
          26,
          142,
          55
        ],
        [
          "convert_pix2struct_original_pytorch_checkpoint_to_hf",
          105,
          142,
          142,
          5,
          142,
          55,
          114,
          26,
          142,
          55
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "convert_poolformer_checkpoint",
          93,
          195,
          194,
          5,
          194,
          66,
          188,
          5,
          195,
          61
        ]
      ],
      "transformers/src/transformers/models/prophetnet/convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_prophetnet_checkpoint_to_pytorch",
          37,
          144,
          143,
          5,
          143,
          56,
          143,
          5,
          144,
          53
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          155,
          254,
          252,
          9,
          252,
          54,
          252,
          9,
          254,
          65
        ],
        [
          "convert_dpt_checkpoint",
          155,
          254,
          221,
          5,
          221,
          61,
          192,
          13,
          225,
          20
        ],
        [
          "convert_dpt_checkpoint",
          155,
          254,
          222,
          5,
          222,
          54,
          192,
          13,
          225,
          20
        ],
        [
          "convert_dpt_checkpoint",
          155,
          254,
          243,
          9,
          243,
          26,
          242,
          9,
          243,
          26
        ],
        [
          "convert_dpt_checkpoint",
          155,
          254,
          247,
          9,
          247,
          74,
          246,
          9,
          249,
          59
        ]
      ],
      "transformers/src/transformers/models/pvt_v2/convert_pvt_v2_to_pytorch.py": [
        [
          "convert_pvt_v2_checkpoint",
          184,
          260,
          224,
          9,
          224,
          71,
          224,
          9,
          230,
          30
        ],
        [
          "convert_pvt_v2_checkpoint",
          184,
          260,
          254,
          9,
          254,
          66,
          250,
          9,
          254,
          66
        ],
        [
          "convert_pvt_v2_checkpoint",
          184,
          260,
          257,
          5,
          257,
          74,
          256,
          5,
          260,
          61
        ],
        [
          "convert_pvt_v2_checkpoint",
          184,
          260,
          259,
          5,
          259,
          66,
          256,
          5,
          260,
          61
        ]
      ],
      "transformers/src/transformers/models/recurrent_gemma/convert_recurrent_gemma_to_hf.py": [
        [
          "write_model",
          72,
          141,
          139,
          9,
          139,
          50,
          139,
          9,
          139,
          50
        ],
        [
          "write_model",
          72,
          141,
          129,
          5,
          129,
          53,
          127,
          5,
          138,
          18
        ],
        [
          "write_model",
          72,
          141,
          73,
          5,
          73,
          80,
          72,
          17,
          101,
          40
        ],
        [
          "write_model",
          72,
          141,
          136,
          5,
          136,
          47,
          127,
          5,
          138,
          18
        ],
        [
          "write_tokenizer",
          144,
          152,
          147,
          5,
          147,
          65,
          146,
          23,
          149,
          18
        ]
      ],
      "transformers/src/transformers/models/rembert/convert_rembert_tf_checkpoint_to_pytorch.py": [
        [
          "convert_rembert_tf_checkpoint_to_pytorch",
          113,
          124,
          116,
          5,
          116,
          70,
          113,
          46,
          124,
          53
        ],
        [
          "convert_rembert_tf_checkpoint_to_pytorch",
          113,
          124,
          123,
          5,
          123,
          55,
          113,
          46,
          124,
          53
        ]
      ],
      "transformers/src/transformers/models/pvt/convert_pvt_to_pytorch.py": [
        [
          "convert_pvt_checkpoint",
          150,
          203,
          200,
          5,
          200,
          74,
          197,
          5,
          203,
          61
        ],
        [
          "convert_pvt_checkpoint",
          150,
          203,
          202,
          5,
          202,
          66,
          197,
          5,
          203,
          61
        ]
      ],
      "transformers/src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py": [
        [
          "convert_trax_checkpoint_to_pytorch",
          185,
          198,
          197,
          5,
          197,
          55,
          185,
          40,
          198,
          53
        ],
        [
          "convert_trax_checkpoint_to_pytorch",
          185,
          198,
          188,
          5,
          188,
          65,
          185,
          40,
          198,
          53
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_to_pytorch.py": [
        [
          "manually_copy_vissl_head",
          157,
          161,
          160,
          9,
          160,
          51,
          158,
          9,
          160,
          51
        ],
        [
          "__call__",
          73,
          93,
          93,
          17,
          93,
          62,
          93,
          17,
          93,
          62
        ],
        [
          "convert_weight_and_push",
          164,
          218,
          172,
          5,
          172,
          34,
          165,
          5,
          180,
          34
        ],
        [
          "convert_weight_and_push",
          164,
          218,
          218,
          9,
          218,
          31,
          209,
          16,
          218,
          31
        ]
      ],
      "transformers/src/transformers/models/roberta/convert_roberta_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_roberta_checkpoint_to_pytorch",
          47,
          159,
          68,
          5,
          68,
          37,
          67,
          29,
          83,
          44
        ],
        [
          "convert_roberta_checkpoint_to_pytorch",
          47,
          159,
          68,
          5,
          68,
          37,
          68,
          5,
          83,
          44
        ],
        [
          "convert_roberta_checkpoint_to_pytorch",
          47,
          159,
          149,
          5,
          149,
          47,
          127,
          8,
          153,
          67
        ],
        [
          "convert_roberta_checkpoint_to_pytorch",
          47,
          159,
          151,
          5,
          151,
          53,
          127,
          8,
          153,
          67
        ],
        [
          "convert_roberta_checkpoint_to_pytorch",
          47,
          159,
          153,
          5,
          153,
          77,
          153,
          54,
          154,
          18
        ],
        [
          "convert_roberta_checkpoint_to_pytorch",
          47,
          159,
          158,
          5,
          158,
          56,
          157,
          5,
          159,
          51
        ]
      ],
      "transformers/src/transformers/models/roformer/convert_roformer_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          103,
          114,
          113,
          5,
          113,
          55,
          103,
          38,
          114,
          91
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          103,
          114,
          106,
          5,
          106,
          65,
          103,
          38,
          114,
          91
        ]
      ],
      "transformers/src/transformers/models/resnet/convert_resnet_to_pytorch.py": [
        [
          "__call__",
          70,
          90,
          90,
          17,
          90,
          62,
          90,
          17,
          90,
          62
        ],
        [
          "convert_weight_and_push",
          93,
          122,
          94,
          5,
          94,
          34,
          93,
          29,
          102,
          61
        ],
        [
          "convert_weight_and_push",
          93,
          122,
          105,
          5,
          105,
          26,
          102,
          5,
          107,
          18
        ],
        [
          "convert_weight_and_push",
          93,
          122,
          122,
          9,
          122,
          42,
          108,
          9,
          122,
          42
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          140,
          9,
          142,
          9,
          133,
          27,
          149,
          37
        ],
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          85,
          9,
          85,
          83,
          85,
          9,
          87,
          17
        ]
      ],
      "transformers/src/transformers/models/sam2/convert_sam2_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          218,
          280,
          236,
          9,
          236,
          44,
          236,
          9,
          238,
          72
        ],
        [
          "convert_sam2_checkpoint",
          218,
          280,
          237,
          9,
          237,
          50,
          236,
          9,
          238,
          72
        ]
      ],
      "transformers/src/transformers/models/sam2_video/convert_sam2_video_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          227,
          286,
          243,
          5,
          243,
          40,
          239,
          14,
          260,
          40
        ],
        [
          "convert_sam2_checkpoint",
          227,
          286,
          244,
          5,
          244,
          46,
          239,
          14,
          260,
          40
        ]
      ],
      "transformers/src/transformers/models/seggpt/convert_seggpt_to_hf.py": [
        [
          "convert_seggpt_checkpoint",
          111,
          195,
          188,
          9,
          188,
          91,
          188,
          9,
          190,
          65
        ],
        [
          "convert_seggpt_checkpoint",
          111,
          195,
          172,
          5,
          172,
          18,
          168,
          5,
          174,
          20
        ],
        [
          "convert_seggpt_checkpoint",
          111,
          195,
          135,
          5,
          135,
          40,
          132,
          13,
          166,
          94
        ],
        [
          "convert_seggpt_checkpoint",
          111,
          195,
          136,
          5,
          136,
          46,
          132,
          13,
          166,
          94
        ],
        [
          "convert_seggpt_checkpoint",
          111,
          195,
          183,
          9,
          183,
          28,
          182,
          9,
          183,
          28
        ],
        [
          "convert_seggpt_checkpoint",
          111,
          195,
          185,
          9,
          185,
          51,
          185,
          9,
          185,
          51
        ],
        [
          "convert_seggpt_checkpoint",
          111,
          195,
          193,
          9,
          193,
          69,
          193,
          9,
          195,
          67
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "write_model_and_image_processor",
          221,
          345,
          326,
          9,
          326,
          59,
          325,
          9,
          329,
          51
        ],
        [
          "write_model_and_image_processor",
          221,
          345,
          328,
          9,
          328,
          56,
          325,
          9,
          329,
          51
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "convert_segformer_checkpoint",
          120,
          368,
          357,
          9,
          357,
          77,
          356,
          31,
          357,
          77
        ]
      ],
      "transformers/src/transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": [
        [
          "convert_rt_detr_checkpoint",
          547,
          761,
          744,
          9,
          744,
          73,
          743,
          9,
          747,
          65
        ],
        [
          "convert_rt_detr_checkpoint",
          547,
          761,
          746,
          9,
          746,
          70,
          743,
          9,
          747,
          65
        ]
      ],
      "transformers/src/transformers/models/shieldgemma2/convert_shieldgemma2_weights_orbax_to_hf.py": [
        [
          "convert_siglip_weight",
          135,
          221,
          220,
          9,
          220,
          30,
          220,
          9,
          220,
          30
        ]
      ],
      "transformers/src/transformers/models/siglip2/convert_siglip2_to_hf.py": [
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          346,
          5,
          346,
          53,
          346,
          5,
          359,
          37
        ],
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          353,
          5,
          353,
          49,
          346,
          5,
          359,
          37
        ],
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          379,
          5,
          379,
          41,
          379,
          5,
          391,
          20
        ],
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          384,
          5,
          384,
          34,
          379,
          5,
          391,
          20
        ],
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          392,
          9,
          392,
          54,
          392,
          9,
          396,
          111
        ],
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          401,
          9,
          401,
          59,
          400,
          19,
          404,
          42
        ],
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          403,
          9,
          403,
          50,
          400,
          19,
          404,
          42
        ],
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          407,
          9,
          407,
          88,
          407,
          9,
          409,
          70
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "convert_siglip_checkpoint",
          380,
          506,
          450,
          9,
          450,
          77,
          448,
          13,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          450,
          9,
          450,
          77,
          450,
          9,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          451,
          9,
          451,
          70,
          448,
          13,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          451,
          9,
          451,
          70,
          450,
          9,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          456,
          9,
          456,
          47,
          448,
          13,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          456,
          9,
          456,
          47,
          450,
          9,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          459,
          9,
          459,
          64,
          448,
          13,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          459,
          9,
          459,
          64,
          450,
          9,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          460,
          9,
          460,
          64,
          448,
          13,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          460,
          9,
          460,
          64,
          450,
          9,
          462,
          50
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          494,
          9,
          494,
          26,
          493,
          9,
          494,
          26
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          499,
          9,
          499,
          73,
          497,
          36,
          502,
          59
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          501,
          9,
          501,
          64,
          497,
          36,
          502,
          59
        ]
      ],
      "transformers/src/transformers/models/superglue/convert_superglue_to_hf.py": [
        [
          "write_model",
          223,
          300,
          272,
          5,
          272,
          32,
          265,
          27,
          283,
          48
        ],
        [
          "write_model",
          223,
          300,
          244,
          5,
          244,
          47,
          224,
          5,
          265,
          61
        ],
        [
          "write_model",
          223,
          300,
          250,
          5,
          250,
          80,
          224,
          5,
          265,
          61
        ],
        [
          "write_model",
          223,
          300,
          253,
          5,
          253,
          32,
          224,
          5,
          265,
          61
        ],
        [
          "write_model",
          223,
          300,
          264,
          5,
          264,
          59,
          224,
          5,
          265,
          61
        ],
        [
          "write_model",
          223,
          300,
          269,
          5,
          269,
          46,
          265,
          27,
          283,
          48
        ],
        [
          "write_model",
          223,
          300,
          278,
          5,
          278,
          66,
          265,
          27,
          283,
          48
        ],
        [
          "write_model",
          223,
          300,
          280,
          5,
          280,
          41,
          265,
          27,
          283,
          48
        ],
        [
          "write_model",
          223,
          300,
          288,
          5,
          288,
          42,
          288,
          5,
          293,
          18
        ],
        [
          "write_model",
          223,
          300,
          290,
          5,
          290,
          49,
          288,
          5,
          293,
          18
        ],
        [
          "write_model",
          223,
          300,
          294,
          9,
          294,
          44,
          294,
          9,
          298,
          9
        ],
        [
          "write_image_processor",
          303,
          312,
          308,
          9,
          308,
          54,
          308,
          9,
          312,
          9
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "convert_swiftformer_checkpoint",
          89,
          153,
          152,
          5,
          152,
          75,
          149,
          5,
          153,
          54
        ]
      ],
      "transformers/src/transformers/models/superpoint/convert_superpoint_to_pytorch.py": [
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          139,
          9,
          139,
          41,
          139,
          9,
          141,
          54
        ],
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          112,
          5,
          112,
          53,
          109,
          13,
          120,
          16
        ],
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          95,
          5,
          95,
          58,
          90,
          35,
          105,
          32
        ],
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          101,
          5,
          101,
          43,
          90,
          35,
          105,
          32
        ],
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          136,
          9,
          136,
          58,
          135,
          9,
          136,
          58
        ],
        [
          "convert_superpoint_checkpoint",
          90,
          151,
          149,
          13,
          149,
          56,
          149,
          13,
          149,
          56
        ]
      ],
      "transformers/src/transformers/models/swin2sr/convert_swin2sr_original_to_pytorch.py": [
        [
          "convert_swin2sr_checkpoint",
          163,
          260,
          255,
          9,
          255,
          70,
          253,
          9,
          256,
          59
        ],
        [
          "convert_swin2sr_checkpoint",
          163,
          260,
          231,
          5,
          231,
          22,
          230,
          5,
          252,
          43
        ],
        [
          "convert_swin2sr_checkpoint",
          163,
          260,
          253,
          9,
          253,
          73,
          253,
          9,
          256,
          59
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_simmim_to_pytorch.py": [
        [
          "convert_swin_checkpoint",
          123,
          155,
          149,
          9,
          149,
          70,
          146,
          9,
          150,
          65
        ],
        [
          "convert_swin_checkpoint",
          123,
          155,
          142,
          5,
          142,
          25,
          123,
          29,
          145,
          43
        ],
        [
          "convert_swin_checkpoint",
          123,
          155,
          143,
          5,
          143,
          22,
          123,
          29,
          145,
          43
        ],
        [
          "convert_swin_checkpoint",
          123,
          155,
          146,
          9,
          146,
          73,
          146,
          9,
          150,
          65
        ],
        [
          "convert_swin_checkpoint",
          123,
          155,
          153,
          9,
          153,
          75,
          153,
          9,
          155,
          62
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_timm_to_pytorch.py": [
        [
          "convert_swin_checkpoint",
          130,
          156,
          152,
          5,
          152,
          68,
          150,
          5,
          156,
          61
        ],
        [
          "convert_swin_checkpoint",
          130,
          156,
          155,
          5,
          155,
          66,
          150,
          5,
          156,
          61
        ]
      ],
      "transformers/src/transformers/models/speecht5/convert_speecht5_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_speecht5_checkpoint",
          320,
          372,
          370,
          9,
          370,
          38,
          370,
          9,
          372,
          34
        ]
      ],
      "transformers/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py": [
        [
          "convert_swinv2_checkpoint",
          170,
          202,
          192,
          5,
          192,
          70,
          190,
          5,
          202,
          5
        ],
        [
          "convert_swinv2_checkpoint",
          170,
          202,
          195,
          5,
          195,
          66,
          190,
          5,
          202,
          5
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_swin_upernet_to_pytorch.py": [
        [
          "convert_upernet_checkpoint",
          191,
          276,
          204,
          9,
          204,
          32,
          203,
          9,
          204,
          32
        ],
        [
          "convert_upernet_checkpoint",
          191,
          276,
          244,
          5,
          244,
          23,
          231,
          5,
          247,
          40
        ],
        [
          "convert_upernet_checkpoint",
          191,
          276,
          245,
          5,
          245,
          58,
          231,
          5,
          247,
          40
        ],
        [
          "convert_upernet_checkpoint",
          191,
          276,
          263,
          5,
          263,
          50,
          263,
          5,
          264,
          82
        ],
        [
          "convert_upernet_checkpoint",
          191,
          276,
          265,
          5,
          265,
          22,
          264,
          5,
          267,
          43
        ],
        [
          "convert_upernet_checkpoint",
          191,
          276,
          268,
          9,
          268,
          73,
          268,
          9,
          271,
          59
        ],
        [
          "convert_upernet_checkpoint",
          191,
          276,
          270,
          9,
          270,
          64,
          268,
          9,
          271,
          59
        ],
        [
          "convert_upernet_checkpoint",
          191,
          276,
          274,
          9,
          274,
          69,
          274,
          9,
          276,
          56
        ]
      ],
      "transformers/src/transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          135,
          146,
          138,
          5,
          138,
          65,
          135,
          38,
          146,
          44
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          135,
          146,
          145,
          5,
          145,
          55,
          135,
          38,
          146,
          44
        ]
      ],
      "transformers/src/transformers/models/t5/convert_t5x_checkpoint_to_pytorch.py": [
        [
          "make_state_dict",
          157,
          174,
          171,
          13,
          171,
          61,
          171,
          13,
          172,
          40
        ],
        [
          "convert_t5x_checkpoint_to_pytorch",
          190,
          213,
          208,
          5,
          208,
          55,
          205,
          5,
          213,
          17
        ],
        [
          "convert_t5x_to_pytorch",
          72,
          154,
          79,
          5,
          79,
          37,
          72,
          28,
          87,
          30
        ],
        [
          "convert_t5x_checkpoint_to_pytorch",
          190,
          213,
          196,
          5,
          196,
          65,
          191,
          5,
          199,
          22
        ],
        [
          "convert_t5x_checkpoint_to_pytorch",
          190,
          213,
          213,
          5,
          213,
          17,
          205,
          5,
          213,
          17
        ]
      ],
      "transformers/src/transformers/models/table_transformer/convert_table_transformer_to_hf.py": [
        [
          "convert_table_transformer_checkpoint",
          189,
          294,
          276,
          5,
          276,
          22,
          275,
          5,
          278,
          43
        ]
      ],
      "transformers/src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          171,
          236,
          223,
          5,
          223,
          65,
          223,
          5,
          236,
          91
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          171,
          236,
          228,
          5,
          228,
          55,
          223,
          5,
          236,
          91
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          171,
          236,
          232,
          5,
          232,
          57,
          223,
          5,
          236,
          91
        ],
        [
          "convert_tf_checkpoint_to_pytorch",
          171,
          236,
          236,
          5,
          236,
          91,
          223,
          5,
          236,
          91
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": [
        [
          "rename_keys",
          197,
          247,
          243,
          17,
          243,
          85,
          241,
          17,
          243,
          85
        ],
        [
          "rename_keys",
          197,
          247,
          224,
          9,
          224,
          36,
          224,
          9,
          225,
          23
        ],
        [
          "convert_flax_checkpoint_to_pytorch",
          285,
          309,
          290,
          5,
          290,
          64,
          286,
          5,
          293,
          27
        ],
        [
          "convert_flax_checkpoint_to_pytorch",
          285,
          309,
          308,
          5,
          308,
          55,
          298,
          16,
          309,
          47
        ]
      ],
      "transformers/src/transformers/models/timesformer/convert_timesformer_to_pytorch.py": [
        [
          "convert_timesformer_checkpoint",
          138,
          224,
          218,
          9,
          218,
          80,
          218,
          9,
          220,
          55
        ],
        [
          "convert_timesformer_checkpoint",
          138,
          224,
          215,
          5,
          215,
          23,
          214,
          5,
          217,
          43
        ],
        [
          "convert_timesformer_checkpoint",
          138,
          224,
          223,
          9,
          223,
          38,
          223,
          9,
          224,
          50
        ]
      ],
      "transformers/src/transformers/models/table_transformer/convert_table_transformer_to_hf_no_timm.py": [
        [
          "convert_table_transformer_checkpoint",
          302,
          411,
          393,
          5,
          393,
          22,
          392,
          5,
          395,
          43
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          177,
          9,
          177,
          62,
          173,
          14,
          185,
          67
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          184,
          9,
          184,
          61,
          173,
          14,
          185,
          67
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          192,
          9,
          192,
          99,
          189,
          23,
          194,
          39
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          198,
          9,
          198,
          69,
          198,
          9,
          209,
          44
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          205,
          9,
          205,
          84,
          198,
          9,
          209,
          44
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          207,
          9,
          207,
          88,
          198,
          9,
          209,
          44
        ]
      ],
      "transformers/src/transformers/models/timesfm/convert_timesfm_orignal_to_hf.py": [
        [
          "main",
          244,
          273,
          266,
          9,
          266,
          81,
          266,
          9,
          266,
          81
        ],
        [
          "write_model",
          36,
          147,
          111,
          13,
          111,
          71,
          110,
          9,
          111,
          71
        ],
        [
          "write_model",
          36,
          147,
          144,
          17,
          144,
          75,
          143,
          13,
          144,
          75
        ],
        [
          "check_outputs",
          150,
          241,
          152,
          5,
          152,
          40,
          150,
          19,
          157,
          55
        ],
        [
          "check_outputs",
          150,
          241,
          217,
          5,
          217,
          33,
          199,
          9,
          227,
          39
        ],
        [
          "check_outputs",
          150,
          241,
          218,
          5,
          218,
          67,
          199,
          9,
          227,
          39
        ],
        [
          "check_outputs",
          150,
          241,
          219,
          5,
          219,
          69,
          199,
          9,
          227,
          39
        ],
        [
          "check_outputs",
          150,
          241,
          220,
          5,
          220,
          73,
          199,
          9,
          227,
          39
        ],
        [
          "check_outputs",
          150,
          241,
          221,
          5,
          221,
          75,
          199,
          9,
          227,
          39
        ],
        [
          "check_outputs",
          150,
          241,
          234,
          5,
          234,
          63,
          234,
          5,
          241,
          73
        ],
        [
          "check_outputs",
          150,
          241,
          237,
          5,
          237,
          29,
          234,
          5,
          241,
          73
        ],
        [
          "check_outputs",
          150,
          241,
          238,
          5,
          238,
          66,
          234,
          5,
          241,
          73
        ],
        [
          "check_outputs",
          150,
          241,
          239,
          5,
          239,
          67,
          234,
          5,
          241,
          73
        ],
        [
          "check_outputs",
          150,
          241,
          240,
          5,
          240,
          72,
          234,
          5,
          241,
          73
        ],
        [
          "check_outputs",
          150,
          241,
          241,
          5,
          241,
          73,
          234,
          5,
          241,
          73
        ]
      ],
      "transformers/src/transformers/models/umt5/convert_umt5_checkpoint_to_pytorch.py": [
        [
          "make_state_dict",
          182,
          199,
          196,
          13,
          196,
          61,
          196,
          13,
          197,
          40
        ],
        [
          "convert_t5x_to_pytorch",
          82,
          179,
          91,
          5,
          91,
          37,
          83,
          5,
          99,
          30
        ],
        [
          "convert_t5x_checkpoint_to_pytorch",
          212,
          239,
          222,
          5,
          222,
          65,
          213,
          5,
          225,
          22
        ],
        [
          "convert_t5x_checkpoint_to_pytorch",
          212,
          239,
          234,
          5,
          234,
          55,
          231,
          5,
          239,
          17
        ],
        [
          "convert_t5x_checkpoint_to_pytorch",
          212,
          239,
          239,
          5,
          239,
          17,
          231,
          5,
          239,
          17
        ]
      ],
      "transformers/src/transformers/models/trocr/convert_trocr_unilm_to_pytorch.py": [
        [
          "convert_tr_ocr_checkpoint",
          123,
          221,
          218,
          5,
          218,
          56,
          217,
          5,
          221,
          55
        ],
        [
          "convert_tr_ocr_checkpoint",
          123,
          221,
          220,
          5,
          220,
          60,
          217,
          5,
          221,
          55
        ]
      ],
      "transformers/src/transformers/models/deprecated/van/convert_van_to_pytorch.py": [
        [
          "convert_weight_and_push",
          121,
          163,
          163,
          9,
          163,
          42,
          149,
          9,
          163,
          42
        ],
        [
          "__call__",
          74,
          94,
          94,
          17,
          94,
          62,
          94,
          17,
          94,
          62
        ],
        [
          "convert_weight_and_push",
          121,
          163,
          129,
          5,
          129,
          47,
          122,
          5,
          142,
          61
        ],
        [
          "convert_weight_and_push",
          121,
          163,
          131,
          5,
          131,
          34,
          122,
          5,
          142,
          61
        ],
        [
          "convert_weight_and_push",
          121,
          163,
          146,
          5,
          146,
          26,
          145,
          23,
          148,
          18
        ]
      ],
      "transformers/src/transformers/models/univnet/convert_univnet.py": [
        [
          "convert_univnet_checkpoint",
          102,
          133,
          132,
          9,
          132,
          38,
          132,
          9,
          133,
          34
        ]
      ],
      "transformers/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py": [
        [
          "convert_vilt_checkpoint",
          168,
          282,
          280,
          5,
          280,
          70,
          272,
          9,
          282,
          55
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          280,
          5,
          280,
          70,
          262,
          9,
          282,
          55
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          280,
          5,
          280,
          70,
          279,
          5,
          282,
          55
        ]
      ],
      "transformers/src/transformers/models/vitmatte/convert_vitmatte_to_hf.py": [
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          142,
          9,
          142,
          69,
          142,
          9,
          144,
          53
        ],
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          137,
          9,
          137,
          90,
          137,
          9,
          139,
          59
        ],
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          134,
          5,
          134,
          22,
          133,
          5,
          136,
          43
        ]
      ],
      "transformers/src/transformers/models/udop/convert_udop_to_hf.py": [
        [
          "prepare_dummy_inputs",
          56,
          88,
          86,
          5,
          86,
          33,
          85,
          5,
          88,
          102
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          103,
          5,
          103,
          46,
          91,
          29,
          106,
          43
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          116,
          5,
          116,
          40,
          106,
          18,
          118,
          99
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          116,
          5,
          116,
          40,
          106,
          50,
          118,
          99
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          117,
          5,
          117,
          46,
          106,
          18,
          118,
          99
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          117,
          5,
          117,
          46,
          106,
          50,
          118,
          99
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          151,
          9,
          151,
          62,
          150,
          5,
          152,
          37
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          155,
          5,
          155,
          42,
          155,
          5,
          165,
          20
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          159,
          9,
          159,
          55,
          155,
          5,
          165,
          20
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          160,
          9,
          160,
          67,
          155,
          5,
          165,
          20
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          166,
          9,
          166,
          26,
          165,
          9,
          166,
          26
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          168,
          9,
          168,
          57,
          167,
          5,
          168,
          57
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          171,
          5,
          171,
          34,
          171,
          5,
          183,
          77
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          175,
          5,
          175,
          82,
          171,
          5,
          183,
          77
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          178,
          5,
          178,
          55,
          171,
          5,
          183,
          77
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          187,
          5,
          187,
          89,
          183,
          29,
          195,
          43
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          188,
          5,
          188,
          36,
          183,
          29,
          195,
          43
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          193,
          5,
          193,
          39,
          183,
          29,
          195,
          43
        ]
      ],
      "transformers/src/transformers/models/vit_mae/convert_vit_mae_to_pytorch.py": [
        [
          "convert_vit_mae_checkpoint",
          105,
          161,
          157,
          5,
          157,
          56,
          155,
          5,
          161,
          61
        ],
        [
          "convert_vit_mae_checkpoint",
          105,
          161,
          160,
          5,
          160,
          66,
          155,
          5,
          161,
          61
        ]
      ],
      "transformers/src/transformers/models/vit/convert_vit_timm_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          131,
          237,
          194,
          9,
          194,
          82,
          194,
          9,
          204,
          32
        ],
        [
          "convert_vit_checkpoint",
          131,
          237,
          234,
          5,
          234,
          67,
          227,
          9,
          237,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          237,
          234,
          5,
          234,
          67,
          231,
          9,
          237,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          237,
          236,
          5,
          236,
          66,
          227,
          9,
          237,
          61
        ],
        [
          "convert_vit_checkpoint",
          131,
          237,
          236,
          5,
          236,
          66,
          231,
          9,
          237,
          61
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_classifier_to_hf.py": [
        [
          "main",
          142,
          208,
          197,
          9,
          197,
          36,
          197,
          9,
          197,
          36
        ]
      ],
      "transformers/src/transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          165,
          262,
          256,
          9,
          256,
          64,
          253,
          9,
          257,
          59
        ],
        [
          "convert_vit_checkpoint",
          165,
          262,
          260,
          9,
          260,
          67,
          260,
          9,
          262,
          53
        ],
        [
          "convert_vit_checkpoint",
          165,
          262,
          241,
          5,
          241,
          55,
          234,
          5,
          248,
          56
        ],
        [
          "convert_vit_checkpoint",
          165,
          262,
          250,
          5,
          250,
          22,
          249,
          9,
          252,
          43
        ],
        [
          "convert_vit_checkpoint",
          165,
          262,
          254,
          9,
          254,
          71,
          253,
          9,
          257,
          59
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "write_model",
          190,
          396,
          282,
          9,
          282,
          64,
          270,
          5,
          300,
          19
        ],
        [
          "write_model",
          190,
          396,
          253,
          5,
          253,
          55,
          253,
          5,
          270,
          73
        ],
        [
          "write_model",
          190,
          396,
          204,
          5,
          204,
          74,
          190,
          17,
          218,
          23
        ],
        [
          "write_model",
          190,
          396,
          210,
          5,
          210,
          32,
          190,
          17,
          218,
          23
        ],
        [
          "write_model",
          190,
          396,
          257,
          5,
          257,
          44,
          253,
          5,
          270,
          73
        ],
        [
          "write_model",
          190,
          396,
          275,
          9,
          275,
          78,
          270,
          5,
          300,
          19
        ],
        [
          "write_model",
          190,
          396,
          276,
          9,
          276,
          93,
          270,
          5,
          300,
          19
        ],
        [
          "write_model",
          190,
          396,
          283,
          9,
          283,
          61,
          270,
          5,
          300,
          19
        ],
        [
          "write_model",
          190,
          396,
          384,
          5,
          384,
          42,
          384,
          5,
          386,
          29
        ],
        [
          "write_model",
          190,
          396,
          392,
          9,
          392,
          75,
          392,
          9,
          396,
          67
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_to_hf.py": [
        [
          "upload_original_ckpts",
          204,
          219,
          207,
          5,
          207,
          90,
          204,
          27,
          219,
          35
        ],
        [
          "upload_original_ckpts",
          204,
          219,
          219,
          9,
          219,
          35,
          204,
          27,
          219,
          35
        ],
        [
          "convert_and_test_vjepa2_checkpoint",
          223,
          312,
          254,
          5,
          254,
          39,
          223,
          40,
          262,
          93
        ],
        [
          "convert_and_test_vjepa2_checkpoint",
          223,
          312,
          300,
          5,
          300,
          22,
          298,
          9,
          302,
          43
        ],
        [
          "convert_and_test_vjepa2_checkpoint",
          223,
          312,
          304,
          9,
          304,
          73,
          303,
          9,
          307,
          59
        ],
        [
          "convert_and_test_vjepa2_checkpoint",
          223,
          312,
          306,
          9,
          306,
          70,
          303,
          9,
          307,
          59
        ]
      ],
      "transformers/src/transformers/models/videomae/convert_videomae_to_pytorch.py": [
        [
          "convert_videomae_checkpoint",
          179,
          297,
          280,
          9,
          280,
          43,
          280,
          9,
          281,
          75
        ],
        [
          "convert_videomae_checkpoint",
          179,
          297,
          282,
          5,
          282,
          23,
          282,
          5,
          285,
          42
        ],
        [
          "convert_videomae_checkpoint",
          179,
          297,
          288,
          9,
          288,
          25,
          287,
          9,
          288,
          25
        ],
        [
          "convert_videomae_checkpoint",
          179,
          297,
          291,
          9,
          291,
          80,
          291,
          9,
          293,
          55
        ],
        [
          "convert_videomae_checkpoint",
          179,
          297,
          296,
          9,
          296,
          38,
          296,
          9,
          297,
          60
        ]
      ],
      "transformers/src/transformers/models/voxtral/convert_voxtral_weights_to_hf.py": [
        [
          "write_processor",
          237,
          248,
          248,
          5,
          248,
          42,
          237,
          21,
          248,
          42
        ],
        [
          "write_model",
          174,
          234,
          181,
          5,
          181,
          34,
          175,
          5,
          234,
          41
        ],
        [
          "write_model",
          174,
          234,
          200,
          5,
          200,
          76,
          175,
          5,
          234,
          41
        ],
        [
          "write_model",
          174,
          234,
          202,
          5,
          202,
          32,
          175,
          5,
          234,
          41
        ],
        [
          "write_model",
          174,
          234,
          216,
          5,
          216,
          55,
          175,
          5,
          234,
          41
        ],
        [
          "write_model",
          174,
          234,
          220,
          5,
          220,
          44,
          175,
          5,
          234,
          41
        ],
        [
          "write_model",
          174,
          234,
          226,
          5,
          226,
          30,
          175,
          5,
          234,
          41
        ],
        [
          "write_model",
          174,
          234,
          232,
          5,
          232,
          66,
          175,
          5,
          234,
          41
        ],
        [
          "write_model",
          174,
          234,
          234,
          5,
          234,
          41,
          175,
          5,
          234,
          41
        ],
        [
          "write_processor",
          237,
          248,
          241,
          5,
          241,
          38,
          237,
          21,
          248,
          42
        ]
      ],
      "transformers/src/transformers/models/xglm/convert_xglm_original_ckpt_to_trfms.py": [
        [
          "convert_fairseq_xglm_checkpoint_from_disk",
          28,
          58,
          55,
          5,
          55,
          18,
          28,
          47,
          58,
          16
        ]
      ],
      "transformers/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          55,
          5,
          55,
          63,
          44,
          14,
          64,
          51
        ],
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          58,
          5,
          58,
          67,
          44,
          14,
          64,
          51
        ],
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          62,
          5,
          62,
          59,
          44,
          14,
          64,
          51
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta_xl/convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xlm_roberta_xl_checkpoint_to_pytorch",
          47,
          165,
          69,
          5,
          69,
          40,
          67,
          29,
          85,
          44
        ],
        [
          "convert_xlm_roberta_xl_checkpoint_to_pytorch",
          47,
          165,
          69,
          5,
          69,
          40,
          69,
          5,
          85,
          44
        ],
        [
          "convert_xlm_roberta_xl_checkpoint_to_pytorch",
          47,
          165,
          155,
          5,
          155,
          47,
          133,
          8,
          159,
          67
        ],
        [
          "convert_xlm_roberta_xl_checkpoint_to_pytorch",
          47,
          165,
          157,
          5,
          157,
          53,
          133,
          8,
          159,
          67
        ],
        [
          "convert_xlm_roberta_xl_checkpoint_to_pytorch",
          47,
          165,
          159,
          5,
          159,
          77,
          159,
          54,
          160,
          18
        ],
        [
          "convert_xlm_roberta_xl_checkpoint_to_pytorch",
          47,
          165,
          164,
          5,
          164,
          56,
          163,
          5,
          165,
          51
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "convert_checkpoint",
          185,
          261,
          259,
          9,
          259,
          38,
          259,
          9,
          261,
          38
        ]
      ],
      "transformers/src/transformers/models/xmod/convert_xmod_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          186,
          5,
          186,
          53,
          161,
          8,
          188,
          67
        ],
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          57,
          5,
          57,
          15,
          42,
          5,
          76,
          26
        ],
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          79,
          5,
          79,
          38,
          77,
          29,
          95,
          44
        ],
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          79,
          5,
          79,
          38,
          79,
          5,
          95,
          44
        ],
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          184,
          5,
          184,
          47,
          161,
          8,
          188,
          67
        ],
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          188,
          5,
          188,
          77,
          188,
          54,
          189,
          18
        ],
        [
          "convert_xmod_checkpoint_to_pytorch",
          41,
          194,
          193,
          5,
          193,
          56,
          192,
          5,
          194,
          51
        ]
      ],
      "transformers/src/transformers/models/yoso/convert_yoso_pytorch_to_pytorch.py": [
        [
          "convert_yoso_checkpoint",
          77,
          88,
          84,
          5,
          84,
          48,
          77,
          29,
          88,
          83
        ],
        [
          "convert_yoso_checkpoint",
          77,
          88,
          88,
          5,
          88,
          83,
          77,
          29,
          88,
          83
        ]
      ],
      "transformers/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          206,
          9,
          206,
          100,
          206,
          9,
          209,
          13
        ],
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          222,
          5,
          222,
          80,
          217,
          5,
          226,
          40
        ],
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          224,
          5,
          224,
          84,
          217,
          5,
          226,
          40
        ]
      ],
      "transformers/src/transformers/models/x_clip/convert_x_clip_original_pytorch_to_hf.py": [
        [
          "convert_xclip_checkpoint",
          218,
          366,
          304,
          5,
          304,
          62,
          293,
          12,
          314,
          41
        ],
        [
          "convert_xclip_checkpoint",
          218,
          366,
          304,
          5,
          304,
          62,
          293,
          70,
          314,
          41
        ],
        [
          "convert_xclip_checkpoint",
          218,
          366,
          312,
          5,
          312,
          26,
          293,
          12,
          314,
          41
        ],
        [
          "convert_xclip_checkpoint",
          218,
          366,
          312,
          5,
          312,
          26,
          293,
          70,
          314,
          41
        ],
        [
          "convert_xclip_checkpoint",
          218,
          366,
          356,
          5,
          356,
          22,
          355,
          5,
          358,
          43
        ],
        [
          "convert_xclip_checkpoint",
          218,
          366,
          359,
          9,
          359,
          73,
          359,
          9,
          360,
          55
        ],
        [
          "convert_xclip_checkpoint",
          218,
          366,
          363,
          9,
          363,
          80,
          363,
          9,
          366,
          69
        ]
      ],
      "transformers/src/transformers/models/zoedepth/convert_zoedepth_to_hf.py": [
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          321,
          5,
          321,
          33,
          306,
          33,
          322,
          41
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          323,
          9,
          323,
          32,
          322,
          9,
          323,
          32
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          376,
          5,
          376,
          41,
          376,
          5,
          379,
          52
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          377,
          5,
          377,
          56,
          376,
          5,
          379,
          52
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          381,
          5,
          381,
          22,
          380,
          5,
          383,
          43
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          384,
          9,
          384,
          74,
          384,
          9,
          387,
          65
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          396,
          9,
          396,
          58,
          391,
          13,
          400,
          55
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "convert_yolos_checkpoint",
          157,
          241,
          224,
          5,
          224,
          69,
          221,
          5,
          229,
          18
        ],
        [
          "convert_yolos_checkpoint",
          157,
          241,
          226,
          5,
          226,
          66,
          221,
          5,
          229,
          18
        ],
        [
          "convert_yolos_checkpoint",
          157,
          241,
          238,
          9,
          238,
          38,
          231,
          13,
          241,
          60
        ]
      ],
      "transformers/.circleci/create_circleci_config.py": [
        [
          "__post_init__",
          98,
          129,
          107,
          13,
          107,
          55,
          107,
          13,
          108,
          77
        ],
        [
          "__post_init__",
          98,
          129,
          110,
          13,
          110,
          60,
          110,
          13,
          110,
          60
        ],
        [
          "__post_init__",
          98,
          129,
          121,
          13,
          121,
          44,
          120,
          25,
          122,
          40
        ],
        [
          "__post_init__",
          98,
          129,
          126,
          17,
          126,
          47,
          123,
          22,
          126,
          47
        ],
        [
          "__post_init__",
          98,
          129,
          129,
          17,
          129,
          34,
          128,
          37,
          129,
          34
        ],
        [
          "create_circleci_config",
          354,
          393,
          359,
          5,
          359,
          50,
          357,
          42,
          361,
          21
        ],
        [
          "create_circleci_config",
          354,
          393,
          364,
          9,
          364,
          120,
          364,
          9,
          368,
          12
        ]
      ],
      "transformers/utils/custom_init_isort.py": [
        [
          "sort_imports",
          235,
          305,
          303,
          13,
          303,
          41,
          303,
          13,
          305,
          47
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "get_tiny_config",
          354,
          445,
          373,
          9,
          373,
          65,
          373,
          9,
          373,
          65
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1364,
          13,
          1364,
          56,
          1363,
          13,
          1367,
          27
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1367,
          13,
          1367,
          27,
          1363,
          13,
          1367,
          27
        ]
      ],
      "transformers/src/transformers/debug_utils.py": [
        [
          "trace_frames",
          171,
          173,
          172,
          9,
          172,
          37,
          171,
          22,
          173,
          19
        ],
        [
          "dump_saved_frames",
          178,
          184,
          179,
          9,
          179,
          76,
          178,
          27,
          184,
          19
        ],
        [
          "dump_saved_frames",
          178,
          184,
          180,
          9,
          180,
          57,
          178,
          27,
          184,
          19
        ],
        [
          "dump_saved_frames",
          178,
          184,
          181,
          9,
          181,
          54,
          178,
          27,
          184,
          19
        ],
        [
          "dump_saved_frames",
          178,
          184,
          182,
          9,
          182,
          37,
          178,
          27,
          184,
          19
        ],
        [
          "dump_saved_frames",
          178,
          184,
          183,
          9,
          183,
          21,
          178,
          27,
          184,
          19
        ],
        [
          "detect_overflow",
          298,
          341,
          318,
          9,
          318,
          32,
          317,
          20,
          318,
          32
        ],
        [
          "detect_overflow",
          298,
          341,
          321,
          9,
          321,
          32,
          320,
          20,
          321,
          32
        ]
      ],
      "transformers/examples/training/distributed_training.py": [
        [
          "run",
          18,
          31,
          28,
          13,
          28,
          64,
          26,
          13,
          28,
          64
        ],
        [
          "run",
          18,
          31,
          31,
          9,
          31,
          71,
          30,
          9,
          31,
          71
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "extract_model_info",
          93,
          109,
          105,
          9,
          105,
          55,
          105,
          9,
          106,
          19
        ],
        [
          "deprecate_models",
          303,
          371,
          322,
          13,
          322,
          69,
          321,
          13,
          322,
          69
        ],
        [
          "extract_model_info",
          93,
          109,
          99,
          9,
          99,
          59,
          99,
          9,
          100,
          19
        ],
        [
          "deprecate_models",
          303,
          371,
          328,
          9,
          328,
          101,
          328,
          9,
          328,
          101
        ],
        [
          "deprecate_models",
          303,
          371,
          329,
          5,
          329,
          43,
          329,
          5,
          337,
          48
        ],
        [
          "deprecate_models",
          303,
          371,
          332,
          5,
          332,
          61,
          329,
          5,
          337,
          48
        ],
        [
          "deprecate_models",
          303,
          371,
          338,
          9,
          338,
          43,
          337,
          9,
          353,
          33
        ],
        [
          "deprecate_models",
          303,
          371,
          340,
          9,
          340,
          53,
          337,
          9,
          353,
          33
        ],
        [
          "deprecate_models",
          303,
          371,
          344,
          9,
          344,
          68,
          337,
          9,
          353,
          33
        ],
        [
          "deprecate_models",
          303,
          371,
          348,
          9,
          348,
          59,
          337,
          9,
          353,
          33
        ],
        [
          "deprecate_models",
          303,
          371,
          352,
          9,
          352,
          37,
          337,
          9,
          353,
          33
        ],
        [
          "deprecate_models",
          303,
          371,
          356,
          5,
          356,
          72,
          356,
          5,
          371,
          58
        ],
        [
          "deprecate_models",
          303,
          371,
          360,
          5,
          360,
          55,
          356,
          5,
          371,
          58
        ],
        [
          "deprecate_models",
          303,
          371,
          370,
          5,
          370,
          72,
          356,
          5,
          371,
          58
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "download_diagnostic",
          109,
          116,
          115,
          5,
          115,
          25,
          113,
          17,
          116,
          10
        ],
        [
          "download_and_extract",
          47,
          54,
          48,
          5,
          48,
          50,
          47,
          26,
          54,
          25
        ],
        [
          "download_and_extract",
          47,
          54,
          54,
          5,
          54,
          25,
          47,
          26,
          54,
          25
        ],
        [
          "format_mrpc",
          57,
          106,
          58,
          5,
          58,
          31,
          57,
          17,
          60,
          34
        ],
        [
          "format_mrpc",
          57,
          106,
          66,
          9,
          66,
          85,
          66,
          9,
          70,
          61
        ],
        [
          "format_mrpc",
          57,
          106,
          106,
          5,
          106,
          25,
          106,
          5,
          106,
          25
        ],
        [
          "download_diagnostic",
          109,
          116,
          110,
          5,
          110,
          53,
          109,
          25,
          111,
          62
        ]
      ],
      "transformers/examples/legacy/seq2seq/download_wmt.py": [
        [
          "download_wmt_dataset",
          22,
          63,
          48,
          9,
          48,
          69,
          47,
          9,
          51,
          43
        ],
        [
          "download_wmt_dataset",
          22,
          63,
          40,
          5,
          40,
          41,
          36,
          16,
          42,
          23
        ],
        [
          "download_wmt_dataset",
          22,
          63,
          63,
          5,
          63,
          51,
          63,
          5,
          63,
          51
        ]
      ],
      "transformers/src/transformers/commands/env.py": [
        [
          "run",
          59,
          140,
          137,
          9,
          137,
          105,
          137,
          9,
          140,
          19
        ],
        [
          "run",
          59,
          140,
          138,
          9,
          138,
          37,
          137,
          9,
          140,
          19
        ]
      ],
      "transformers/utils/get_github_job_time.py": [
        [
          "get_job_time",
          29,
          52,
          50,
          9,
          50,
          81,
          49,
          5,
          52,
          13
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "get_artifacts_links",
          65,
          90,
          88,
          9,
          88,
          81,
          87,
          5,
          90,
          13
        ],
        [
          "get_jobs",
          13,
          36,
          34,
          9,
          34,
          81,
          33,
          5,
          36,
          13
        ],
        [
          "get_job_links",
          39,
          62,
          60,
          9,
          60,
          81,
          59,
          5,
          62,
          13
        ]
      ],
      "transformers/utils/get_test_reports.py": [
        [
          "handle_suite",
          82,
          135,
          113,
          9,
          113,
          57,
          113,
          9,
          114,
          14
        ],
        [
          "run_pytest",
          48,
          79,
          63,
          5,
          63,
          58,
          49,
          5,
          66,
          20
        ],
        [
          "run_pytest",
          48,
          79,
          75,
          13,
          75,
          67,
          73,
          44,
          75,
          67
        ],
        [
          "run_pytest",
          48,
          79,
          77,
          9,
          77,
          40,
          77,
          9,
          78,
          22
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "save_model_architecture_to_file",
          754,
          761,
          757,
          13,
          757,
          32,
          757,
          13,
          757,
          32
        ],
        [
          "save_model_architecture_to_file",
          754,
          761,
          761,
          13,
          761,
          32,
          761,
          13,
          761,
          32
        ]
      ],
      "transformers/examples/legacy/seq2seq/minify_dataset.py": [
        [
          "minify",
          21,
          30,
          29,
          9,
          29,
          24,
          26,
          9,
          30,
          49
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "_repr_to_list",
          162,
          176,
          174,
          9,
          174,
          20,
          162,
          19,
          176,
          52
        ]
      ],
      "transformers/src/transformers/models/ctrl/modeling_ctrl.py": [
        [
          "prepare_inputs_for_generation",
          541,
          567,
          564,
          17,
          564,
          67,
          564,
          17,
          565,
          33
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/modeling_deta.py": [
        [
          "forward",
          1581,
          1828,
          1747,
          25,
          1750,
          25,
          1747,
          25,
          1751,
          33
        ]
      ],
      "transformers/src/transformers/models/falcon_h1/modeling_falcon_h1.py": [
        [
          "_init_weights",
          1169,
          1183,
          1183,
          21,
          1183,
          72,
          1182,
          17,
          1183,
          72
        ]
      ],
      "transformers/src/transformers/models/deprecated/nezha/modeling_nezha.py": [
        [
          "forward",
          1322,
          1382,
          1361,
          9,
          1361,
          34,
          1345,
          13,
          1369,
          29
        ],
        [
          "forward",
          1322,
          1382,
          1364,
          9,
          1364,
          27,
          1345,
          13,
          1369,
          29
        ],
        [
          "forward",
          1322,
          1382,
          1365,
          9,
          1365,
          26,
          1345,
          13,
          1369,
          29
        ]
      ],
      "transformers/src/transformers/models/reformer/modeling_reformer.py": [
        [
          "prepare_inputs_for_generation",
          2305,
          2329,
          2326,
          17,
          2326,
          67,
          2326,
          17,
          2327,
          33
        ]
      ],
      "transformers/utils/models_to_deprecate.py": [
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          195,
          9,
          195,
          61,
          195,
          9,
          197,
          65
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          256,
          13,
          256,
          113,
          255,
          13,
          257,
          47
        ],
        [
          "__iter__",
          140,
          145,
          144,
          13,
          144,
          32,
          143,
          9,
          145,
          18
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          253,
          9,
          253,
          98,
          249,
          44,
          255,
          68
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          276,
          5,
          276,
          43,
          276,
          5,
          279,
          42
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          284,
          13,
          284,
          38,
          282,
          13,
          286,
          59
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          285,
          13,
          285,
          46,
          282,
          13,
          286,
          59
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          286,
          13,
          286,
          59,
          282,
          13,
          286,
          59
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          291,
          5,
          291,
          99,
          289,
          27,
          293,
          118
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          292,
          5,
          292,
          70,
          289,
          27,
          293,
          118
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          293,
          5,
          293,
          118,
          289,
          27,
          293,
          118
        ]
      ],
      "transformers/src/transformers/models/falcon_h1/modular_falcon_h1.py": [
        [
          "_init_weights",
          935,
          949,
          949,
          21,
          949,
          72,
          948,
          17,
          949,
          72
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "convert_modular_file",
          1686,
          1715,
          1714,
          9,
          1714,
          70,
          1714,
          9,
          1715,
          17
        ],
        [
          "run_converter",
          1730,
          1734,
          1732,
          5,
          1732,
          76,
          1730,
          19,
          1734,
          54
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "post",
          209,
          219,
          210,
          9,
          210,
          46,
          209,
          14,
          213,
          92
        ],
        [
          "error_out",
          184,
          207,
          201,
          9,
          201,
          58,
          187,
          17,
          207,
          9
        ],
        [
          "error_out",
          184,
          207,
          200,
          9,
          200,
          46,
          187,
          17,
          207,
          9
        ],
        [
          "post",
          209,
          219,
          211,
          9,
          211,
          63,
          209,
          14,
          213,
          92
        ],
        [
          "post_reply",
          252,
          273,
          263,
          17,
          263,
          52,
          259,
          24,
          273,
          29
        ],
        [
          "post_reply",
          252,
          273,
          264,
          17,
          264,
          53,
          259,
          24,
          273,
          29
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_fsmt_bleu_score.py": [
        [
          "test_bleu_scores",
          50,
          70,
          69,
          9,
          69,
          21,
          50,
          26,
          70,
          63
        ]
      ],
      "transformers/examples/legacy/seq2seq/pack_dataset.py": [
        [
          "pack_data_dir",
          58,
          72,
          66,
          9,
          66,
          90,
          61,
          9,
          68,
          82
        ]
      ],
      "transformers/.circleci/parse_test_outputs.py": [
        [
          "parse_pytest_errors_output",
          35,
          50,
          47,
          9,
          47,
          67,
          46,
          9,
          47,
          67
        ],
        [
          "parse_pytest_output",
          5,
          17,
          16,
          9,
          16,
          49,
          15,
          9,
          16,
          49
        ],
        [
          "parse_pytest_output",
          5,
          17,
          17,
          5,
          17,
          52,
          17,
          5,
          17,
          52
        ],
        [
          "parse_pytest_failure_output",
          19,
          33,
          30,
          9,
          30,
          59,
          29,
          9,
          30,
          59
        ],
        [
          "parse_pytest_failure_output",
          19,
          33,
          31,
          5,
          31,
          50,
          31,
          5,
          32,
          21
        ],
        [
          "parse_pytest_errors_output",
          35,
          50,
          36,
          5,
          36,
          20,
          35,
          32,
          40,
          24
        ],
        [
          "parse_pytest_errors_output",
          35,
          50,
          48,
          5,
          48,
          43,
          48,
          5,
          49,
          20
        ]
      ],
      "transformers/utils/patch_helper.py": [
        [
          "checkout_branch",
          63,
          70,
          67,
          9,
          67,
          48,
          67,
          9,
          67,
          48
        ],
        [
          "main",
          127,
          152,
          140,
          13,
          140,
          34,
          137,
          13,
          140,
          34
        ],
        [
          "checkout_branch",
          63,
          70,
          69,
          9,
          69,
          71,
          68,
          5,
          70,
          15
        ],
        [
          "cherry_pick_commit",
          107,
          113,
          111,
          9,
          111,
          46,
          111,
          9,
          111,
          46
        ],
        [
          "cherry_pick_commit",
          107,
          113,
          113,
          9,
          113,
          79,
          112,
          5,
          113,
          79
        ],
        [
          "main",
          127,
          152,
          137,
          13,
          137,
          34,
          137,
          13,
          140,
          34
        ],
        [
          "main",
          127,
          152,
          138,
          13,
          138,
          77,
          137,
          13,
          140,
          34
        ],
        [
          "main",
          127,
          152,
          139,
          13,
          139,
          82,
          137,
          13,
          140,
          34
        ],
        [
          "main",
          127,
          152,
          149,
          21,
          149,
          96,
          149,
          21,
          149,
          96
        ],
        [
          "main",
          127,
          152,
          151,
          17,
          151,
          96,
          151,
          17,
          152,
          39
        ]
      ],
      "transformers/utils/pr_slow_ci_models.py": [
        [
          "get_new_python_files",
          66,
          95,
          83,
          9,
          83,
          42,
          83,
          9,
          87,
          29
        ],
        [
          "get_new_python_files",
          66,
          95,
          84,
          9,
          84,
          55,
          83,
          9,
          87,
          29
        ],
        [
          "get_new_python_files",
          66,
          95,
          88,
          13,
          88,
          48,
          87,
          13,
          88,
          48
        ],
        [
          "get_new_python_files",
          66,
          95,
          90,
          9,
          90,
          42,
          90,
          9,
          92,
          29
        ],
        [
          "get_new_python_files",
          66,
          95,
          93,
          13,
          93,
          45,
          92,
          13,
          93,
          45
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "error_out",
          701,
          760,
          753,
          9,
          753,
          46,
          735,
          9,
          760,
          9
        ],
        [
          "error_out",
          701,
          760,
          754,
          9,
          754,
          45,
          735,
          9,
          760,
          9
        ],
        [
          "post",
          762,
          773,
          764,
          9,
          764,
          46,
          762,
          14,
          767,
          92
        ],
        [
          "post",
          762,
          773,
          765,
          9,
          765,
          58,
          762,
          14,
          767,
          92
        ],
        [
          "post_reply",
          894,
          941,
          908,
          21,
          908,
          56,
          901,
          21,
          918,
          33
        ],
        [
          "post_reply",
          894,
          941,
          909,
          21,
          909,
          57,
          901,
          21,
          918,
          33
        ],
        [
          "post_reply",
          894,
          941,
          931,
          21,
          931,
          56,
          922,
          21,
          941,
          33
        ],
        [
          "post_reply",
          894,
          941,
          932,
          21,
          932,
          57,
          922,
          21,
          941,
          33
        ]
      ],
      "transformers/utils/release.py": [
        [
          "post_release_work",
          196,
          214,
          213,
          5,
          213,
          44,
          213,
          5,
          214,
          34
        ],
        [
          "pre_release_work",
          163,
          193,
          189,
          5,
          189,
          44,
          189,
          5,
          193,
          27
        ],
        [
          "pre_release_work",
          163,
          193,
          191,
          5,
          191,
          60,
          189,
          5,
          193,
          27
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_distributed_eval.py": [
        [
          "run_generate",
          119,
          227,
          165,
          9,
          165,
          73,
          165,
          9,
          165,
          73
        ],
        [
          "run_generate",
          119,
          227,
          203,
          13,
          203,
          96,
          202,
          25,
          205,
          18
        ],
        [
          "run_generate",
          119,
          227,
          222,
          9,
          222,
          22,
          213,
          23,
          224,
          21
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval.py": [
        [
          "run_generate",
          85,
          178,
          132,
          9,
          132,
          69,
          132,
          9,
          132,
          69
        ],
        [
          "run_generate",
          85,
          178,
          173,
          9,
          173,
          21,
          173,
          9,
          173,
          21
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval_search.py": [
        [
          "run_search",
          44,
          145,
          130,
          5,
          130,
          72,
          129,
          22,
          132,
          29
        ],
        [
          "run_search",
          44,
          145,
          131,
          5,
          131,
          72,
          129,
          22,
          132,
          29
        ],
        [
          "run_search",
          44,
          145,
          133,
          9,
          133,
          81,
          132,
          9,
          133,
          81
        ],
        [
          "run_search",
          44,
          145,
          141,
          9,
          141,
          37,
          141,
          9,
          141,
          37
        ],
        [
          "run_search",
          44,
          145,
          142,
          5,
          142,
          31,
          142,
          5,
          145,
          25
        ],
        [
          "run_search",
          44,
          145,
          143,
          5,
          143,
          53,
          142,
          5,
          145,
          25
        ]
      ],
      "transformers/examples/pytorch/text-generation/run_generation.py": [
        [
          "main",
          289,
          445,
          428,
          9,
          428,
          73,
          427,
          9,
          435,
          67
        ],
        [
          "main",
          289,
          445,
          443,
          9,
          443,
          29,
          435,
          23,
          443,
          29
        ]
      ],
      "transformers/examples/legacy/run_openai_gpt.py": [
        [
          "main",
          104,
          315,
          148,
          5,
          148,
          15,
          105,
          14,
          150,
          21
        ],
        [
          "main",
          104,
          315,
          154,
          9,
          154,
          44,
          152,
          16,
          156,
          31
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "main",
          470,
          835,
          697,
          9,
          697,
          44,
          695,
          16,
          699,
          31
        ]
      ],
      "transformers/examples/legacy/run_transfo_xl.py": [
        [
          "main",
          39,
          139,
          63,
          9,
          63,
          44,
          61,
          16,
          65,
          31
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "main",
          473,
          717,
          604,
          9,
          604,
          44,
          602,
          16,
          606,
          31
        ]
      ],
      "transformers/utils/scan_skipped_tests.py": [
        [
          "summarize_single_test",
          94,
          125,
          113,
          5,
          113,
          55,
          110,
          21,
          115,
          49
        ],
        [
          "summarize_single_test",
          94,
          125,
          112,
          5,
          112,
          33,
          110,
          21,
          115,
          49
        ],
        [
          "summarize_single_test",
          94,
          125,
          114,
          5,
          114,
          82,
          110,
          21,
          115,
          49
        ],
        [
          "summarize_single_test",
          94,
          125,
          116,
          9,
          116,
          35,
          115,
          9,
          116,
          35
        ],
        [
          "summarize_single_test",
          94,
          125,
          118,
          9,
          118,
          23,
          118,
          9,
          118,
          23
        ],
        [
          "summarize_all_tests",
          128,
          159,
          138,
          5,
          138,
          54,
          129,
          5,
          139,
          50
        ],
        [
          "summarize_all_tests",
          128,
          159,
          140,
          9,
          140,
          67,
          139,
          9,
          142,
          37
        ],
        [
          "summarize_all_tests",
          128,
          159,
          158,
          5,
          158,
          31,
          158,
          5,
          159,
          18
        ],
        [
          "main",
          162,
          195,
          185,
          5,
          185,
          77,
          182,
          30,
          195,
          53
        ],
        [
          "main",
          162,
          195,
          185,
          5,
          185,
          77,
          184,
          37,
          195,
          53
        ],
        [
          "main",
          162,
          195,
          195,
          5,
          195,
          53,
          182,
          30,
          195,
          53
        ],
        [
          "main",
          162,
          195,
          195,
          5,
          195,
          53,
          184,
          37,
          195,
          53
        ]
      ],
      "transformers/scripts/stale.py": [
        [
          "main",
          36,
          72,
          72,
          17,
          72,
          58,
          71,
          13,
          72,
          58
        ],
        [
          "main",
          36,
          72,
          42,
          9,
          42,
          23,
          41,
          9,
          44,
          55
        ],
        [
          "main",
          36,
          72,
          56,
          17,
          56,
          59,
          55,
          13,
          56,
          59
        ]
      ],
      "transformers/setup.py": [
        [
          "run",
          238,
          252,
          250,
          9,
          250,
          35,
          238,
          13,
          252,
          39
        ]
      ],
      "transformers/src/transformers/data/metrics/squad_metrics.py": [
        [
          "get_raw_scores",
          82,
          105,
          98,
          13,
          98,
          53,
          98,
          13,
          99,
          20
        ]
      ],
      "transformers/src/transformers/generation/streamers.py": [
        [
          "on_finalized_text",
          133,
          135,
          135,
          9,
          135,
          67,
          135,
          37,
          135,
          67
        ]
      ],
      "transformers/src/transformers/integrations/tensor_parallel.py": [
        [
          "add_tensor_parallel_hooks_to_module",
          987,
          1008,
          1003,
          13,
          1005,
          13,
          1002,
          9,
          1005,
          13
        ],
        [
          "shard_and_distribute_module",
          1011,
          1058,
          1046,
          13,
          1048,
          13,
          1045,
          9,
          1048,
          13
        ]
      ],
      "transformers/src/transformers/models/esm/openfold_utils/tensor_utils.py": [
        [
          "tree_map",
          125,
          136,
          135,
          9,
          135,
          25,
          135,
          9,
          136,
          40
        ]
      ],
      "transformers/tests/utils/test_attention_visualizer.py": [
        [
          "_print",
          48,
          50,
          50,
          13,
          50,
          39,
          48,
          21,
          50,
          39
        ],
        [
          "_print",
          96,
          98,
          98,
          13,
          98,
          39,
          96,
          21,
          98,
          39
        ]
      ],
      "transformers/tests/quantization/autoawq/test_awq.py": [
        [
          "test_quantized_model_ipex",
          535,
          555,
          550,
          9,
          550,
          68,
          535,
          35,
          555,
          93
        ]
      ],
      "transformers/tests/utils/test_doc_samples.py": [
        [
          "analyze_directory",
          32,
          82,
          69,
          13,
          69,
          34,
          67,
          13,
          71,
          27
        ]
      ],
      "transformers/tests/models/phi4_multimodal/test_feature_extraction_phi4_multimodal.py": [
        [
          "test_torch_integration_batch",
          257,
          288,
          287,
          9,
          287,
          40,
          257,
          38,
          288,
          108
        ]
      ],
      "transformers/tests/utils/test_file_utils.py": [
        [
          "test_context_managers_one_context",
          79,
          83,
          81,
          13,
          81,
          46,
          79,
          43,
          83,
          95
        ],
        [
          "context_en",
          50,
          53,
          53,
          5,
          53,
          17,
          51,
          5,
          53,
          17
        ],
        [
          "context_en",
          50,
          53,
          51,
          5,
          51,
          21,
          51,
          5,
          53,
          17
        ],
        [
          "context_fr",
          57,
          60,
          58,
          5,
          58,
          21,
          58,
          5,
          60,
          23
        ],
        [
          "context_fr",
          57,
          60,
          60,
          5,
          60,
          23,
          58,
          5,
          60,
          23
        ],
        [
          "test_context_managers_no_context",
          72,
          76,
          74,
          13,
          74,
          46,
          72,
          42,
          76,
          79
        ],
        [
          "test_context_managers_two_context",
          86,
          90,
          88,
          13,
          88,
          46,
          86,
          43,
          90,
          117
        ]
      ],
      "transformers/tests/generation/test_flash_attention_parity.py": [
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          141,
          9,
          141,
          20,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          136,
          9,
          136,
          41,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          138,
          9,
          138,
          60,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          132,
          9,
          132,
          76,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          133,
          9,
          133,
          36,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          134,
          9,
          134,
          66,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          135,
          9,
          135,
          66,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          137,
          9,
          137,
          77,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          139,
          9,
          139,
          60,
          127,
          14,
          141,
          20
        ],
        [
          "test_flash_attention_2_3_parity",
          82,
          141,
          140,
          9,
          140,
          50,
          127,
          14,
          141,
          20
        ]
      ],
      "transformers/tests/models/idefics/test_image_processing_idefics.py": [
        [
          "test_torchvision_numpy_transforms_equivalency",
          154,
          191,
          161,
          9,
          161,
          27,
          154,
          55,
          191,
          119
        ]
      ],
      "transformers/tests/models/aimv2/test_modeling_aimv2.py": [
        [
          "test_model",
          405,
          408,
          407,
          9,
          407,
          32,
          405,
          20,
          408,
          68
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "test_inference_interpolate_pos_encoding",
          577,
          615,
          603,
          9,
          603,
          24,
          577,
          49,
          615,
          9
        ],
        [
          "test_inference_interpolate_pos_encoding",
          577,
          615,
          604,
          9,
          604,
          66,
          577,
          49,
          615,
          9
        ],
        [
          "test_inference_interpolate_pos_encoding",
          577,
          615,
          605,
          9,
          605,
          71,
          577,
          49,
          615,
          9
        ]
      ],
      "transformers/tests/models/canine/test_modeling_canine.py": [
        [
          "test_model_outputs_equivalence",
          380,
          447,
          414,
          13,
          414,
          30,
          413,
          13,
          447,
          13
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "test_training",
          579,
          599,
          597,
          17,
          597,
          33,
          596,
          17,
          597,
          33
        ],
        [
          "test_training",
          579,
          599,
          590,
          13,
          590,
          46,
          590,
          13,
          596,
          38
        ]
      ],
      "transformers/tests/models/dab_detr/test_modeling_dab_detr.py": [
        [
          "set_nan_tensor_to_zero",
          266,
          269,
          267,
          13,
          267,
          20,
          266,
          36,
          269,
          20
        ]
      ],
      "transformers/tests/models/csm/test_modeling_csm.py": [
        [
          "test_1b_model_integration_generate_no_audio",
          385,
          442,
          402,
          9,
          402,
          28,
          385,
          53,
          442,
          79
        ]
      ],
      "transformers/tests/models/deformable_detr/test_modeling_deformable_detr.py": [
        [
          "test_model_outputs_equivalence",
          372,
          444,
          411,
          13,
          411,
          46,
          410,
          13,
          444,
          13
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "check_training_gradient_checkpointing",
          1144,
          1193,
          1186,
          33,
          1188,
          33,
          1186,
          33,
          1188,
          33
        ]
      ],
      "transformers/tests/models/edgetam_video/test_modeling_edgetam_video.py": [
        [
          "test_inference_mask_generation_video_one_point_propagate_in_video_directly",
          134,
          172,
          160,
          9,
          160,
          91,
          158,
          18,
          172,
          9
        ],
        [
          "test_inference_propagate_on_streamed_video",
          464,
          507,
          495,
          9,
          495,
          109,
          490,
          27,
          507,
          9
        ]
      ],
      "transformers/tests/models/evolla/test_modeling_evolla.py": [
        [
          "test_protein_encoder_output",
          271,
          285,
          285,
          13,
          285,
          55,
          281,
          21,
          285,
          55
        ],
        [
          "test_saprot_output",
          255,
          269,
          269,
          13,
          269,
          55,
          265,
          21,
          269,
          55
        ],
        [
          "test_single_forward",
          287,
          300,
          300,
          13,
          300,
          26,
          291,
          13,
          300,
          26
        ]
      ],
      "transformers/tests/models/falcon_mamba/test_modeling_falcon_mamba.py": [
        [
          "test_generation_torch_compile",
          451,
          462,
          457,
          9,
          457,
          77,
          451,
          39,
          462,
          9
        ]
      ],
      "transformers/tests/models/fsmt/test_modeling_fsmt.py": [
        [
          "translation_setup",
          500,
          520,
          508,
          9,
          508,
          40,
          500,
          27,
          515,
          37
        ]
      ],
      "transformers/tests/models/gemma3/test_modeling_gemma3.py": [
        [
          "test_model_4b_crops",
          478,
          519,
          518,
          9,
          518,
          47,
          478,
          29,
          519,
          52
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "test_model_matches_original_20b",
          429,
          492,
          484,
          17,
          486,
          17,
          471,
          17,
          489,
          17
        ],
        [
          "test_model_matches_original_120b",
          494,
          558,
          550,
          17,
          552,
          17,
          537,
          17,
          555,
          17
        ],
        [
          "distributed_worker",
          110,
          193,
          189,
          17,
          189,
          68,
          189,
          17,
          189,
          68
        ],
        [
          "distributed_worker",
          110,
          193,
          191,
          17,
          191,
          85,
          191,
          17,
          191,
          85
        ],
        [
          "distributed_worker",
          110,
          193,
          193,
          13,
          193,
          68,
          193,
          13,
          193,
          68
        ],
        [
          "test_model_outputs",
          319,
          374,
          371,
          17,
          371,
          85,
          371,
          17,
          371,
          85
        ]
      ],
      "transformers/tests/models/idefics/test_modeling_idefics.py": [
        [
          "test_generate_continue_from_inputs_embeds",
          728,
          784,
          733,
          13,
          733,
          25,
          731,
          13,
          762,
          41
        ],
        [
          "test_inference_natural_language_visual_reasoning",
          857,
          900,
          897,
          13,
          897,
          33,
          895,
          13,
          897,
          33
        ]
      ],
      "transformers/tests/models/llama4/test_modeling_llama4.py": [
        [
          "test_model_17b_16e_fp32",
          89,
          105,
          104,
          9,
          104,
          26,
          89,
          33,
          105,
          52
        ]
      ],
      "transformers/tests/models/markuplm/test_modeling_markuplm.py": [
        [
          "create_and_check_model",
          158,
          177,
          172,
          9,
          172,
          76,
          159,
          9,
          177,
          96
        ]
      ],
      "transformers/tests/models/moshi/test_modeling_moshi.py": [
        [
          "test_generate_without_input_ids",
          716,
          727,
          726,
          13,
          726,
          38,
          719,
          13,
          727,
          53
        ]
      ],
      "transformers/tests/models/patchtsmixer/test_modeling_patchtsmixer.py": [
        [
          "test_prediction_generation",
          505,
          525,
          508,
          9,
          508,
          35,
          505,
          36,
          525,
          107
        ],
        [
          "test_model_outputs_equivalence",
          319,
          390,
          362,
          13,
          362,
          30,
          361,
          13,
          390,
          13
        ],
        [
          "check_module",
          683,
          754,
          720,
          13,
          720,
          33,
          720,
          13,
          720,
          33
        ]
      ],
      "transformers/tests/models/qwen2/test_modeling_qwen2.py": [
        [
          "test_model_450m_logits",
          87,
          103,
          98,
          9,
          98,
          29,
          87,
          32,
          103,
          20
        ]
      ],
      "transformers/tests/models/recurrent_gemma/test_modeling_recurrent_gemma.py": [
        [
          "test_long_context",
          219,
          228,
          227,
          9,
          227,
          26,
          219,
          27,
          228,
          58
        ]
      ]
    },
    "json.dumps": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_device_map_works_with_unexpected_keys_sharded",
          2109,
          2147,
          2134,
          23,
          2134,
          65,
          2109,
          60,
          2139,
          54
        ]
      ],
      "transformers/tests/models/clipseg/test_processing_clipseg.py": [
        [
          "setUp",
          39,
          65,
          50,
          22,
          50,
          45,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "setUpClass",
          49,
          67,
          59,
          22,
          59,
          52,
          49,
          20,
          67,
          49
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_processing_layoutlmv2.py": [
        [
          "setUp",
          42,
          73,
          73,
          22,
          73,
          52,
          42,
          15,
          73,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_processing_layoutlmv3.py": [
        [
          "setUp",
          42,
          86,
          74,
          22,
          74,
          45,
          42,
          15,
          86,
          60
        ],
        [
          "setUp",
          42,
          86,
          86,
          22,
          86,
          52,
          42,
          15,
          86,
          60
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "setUp",
          50,
          70,
          59,
          22,
          59,
          45,
          50,
          15,
          70,
          46
        ]
      ],
      "transformers/tests/models/markuplm/test_processing_markuplm.py": [
        [
          "setUp",
          47,
          70,
          61,
          22,
          61,
          45,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          65,
          22,
          65,
          62,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          70,
          22,
          70,
          54,
          47,
          15,
          70,
          62
        ]
      ],
      "transformers/tests/models/owlvit/test_processing_owlvit.py": [
        [
          "setUp",
          39,
          65,
          50,
          22,
          50,
          45,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "setUpClass",
          41,
          65,
          65,
          22,
          65,
          54,
          41,
          20,
          65,
          62
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "setUpClass",
          35,
          63,
          57,
          22,
          57,
          45,
          35,
          20,
          63,
          49
        ],
        [
          "setUpClass",
          35,
          63,
          60,
          22,
          60,
          54,
          35,
          20,
          63,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "setUpClass",
          36,
          64,
          58,
          22,
          58,
          45,
          36,
          20,
          64,
          49
        ],
        [
          "setUpClass",
          36,
          64,
          61,
          22,
          61,
          54,
          36,
          20,
          64,
          49
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          173,
          29,
          173,
          51,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          119,
          25,
          119,
          47,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          142,
          29,
          142,
          51,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          150,
          25,
          150,
          47,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          181,
          25,
          181,
          47,
          176,
          18,
          185,
          59
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "setUp",
          50,
          77,
          71,
          22,
          71,
          45,
          50,
          15,
          77,
          25
        ],
        [
          "setUp",
          50,
          77,
          74,
          22,
          74,
          54,
          50,
          15,
          77,
          25
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "setUp",
          43,
          105,
          103,
          22,
          103,
          45,
          43,
          15,
          105,
          39
        ]
      ],
      "transformers/tests/models/bart/test_tokenization_bart.py": [
        [
          "setUpClass",
          36,
          70,
          68,
          22,
          68,
          45,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/models/biogpt/test_tokenization_biogpt.py": [
        [
          "setUpClass",
          33,
          68,
          66,
          22,
          66,
          45,
          33,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/blenderbot_small/test_tokenization_blenderbot_small.py": [
        [
          "setUpClass",
          35,
          49,
          47,
          22,
          47,
          45,
          35,
          20,
          49,
          39
        ]
      ],
      "transformers/tests/models/clip/test_tokenization_clip.py": [
        [
          "setUpClass",
          37,
          50,
          48,
          22,
          48,
          45,
          37,
          20,
          50,
          39
        ]
      ],
      "transformers/tests/models/clvp/test_tokenization_clvp.py": [
        [
          "setUpClass",
          34,
          71,
          69,
          22,
          69,
          45,
          34,
          20,
          71,
          39
        ]
      ],
      "transformers/tests/models/ctrl/test_tokenization_ctrl.py": [
        [
          "setUpClass",
          31,
          45,
          43,
          22,
          43,
          45,
          31,
          20,
          45,
          39
        ]
      ],
      "transformers/tests/models/deberta/test_tokenization_deberta.py": [
        [
          "setUpClass",
          34,
          69,
          67,
          22,
          67,
          45,
          34,
          20,
          69,
          39
        ]
      ],
      "transformers/tests/models/codegen/test_tokenization_codegen.py": [
        [
          "setUpClass",
          38,
          74,
          72,
          22,
          72,
          45,
          38,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/flaubert/test_tokenization_flaubert.py": [
        [
          "setUpClass",
          33,
          47,
          45,
          22,
          45,
          45,
          33,
          20,
          47,
          39
        ]
      ],
      "transformers/tests/models/gpt_neox_japanese/test_tokenization_gpt_neox_japanese.py": [
        [
          "setUpClass",
          37,
          72,
          72,
          32,
          72,
          55,
          37,
          20,
          72,
          56
        ]
      ],
      "transformers/tests/models/gpt2/test_tokenization_gpt2.py": [
        [
          "setUpClass",
          37,
          73,
          71,
          22,
          71,
          45,
          37,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/herbert/test_tokenization_herbert.py": [
        [
          "setUpClass",
          36,
          77,
          75,
          22,
          75,
          45,
          36,
          20,
          77,
          39
        ]
      ],
      "transformers/tests/models/fsmt/test_tokenization_fsmt.py": [
        [
          "setUpClass",
          37,
          85,
          79,
          22,
          79,
          45,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          81,
          22,
          81,
          45,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          85,
          22,
          85,
          39,
          37,
          20,
          85,
          40
        ]
      ],
      "transformers/tests/models/led/test_tokenization_led.py": [
        [
          "setUpClass",
          34,
          68,
          66,
          22,
          66,
          45,
          34,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/longformer/test_tokenization_longformer.py": [
        [
          "setUpClass",
          39,
          74,
          72,
          22,
          72,
          45,
          39,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "setUpClass",
          128,
          163,
          161,
          22,
          161,
          45,
          128,
          20,
          163,
          39
        ]
      ],
      "transformers/tests/models/mgp_str/test_tokenization_mgp_str.py": [
        [
          "setUpClass",
          36,
          44,
          44,
          22,
          44,
          45,
          36,
          20,
          44,
          53
        ]
      ],
      "transformers/tests/models/mvp/test_tokenization_mvp.py": [
        [
          "setUpClass",
          36,
          70,
          68,
          22,
          68,
          45,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/models/openai/test_tokenization_openai.py": [
        [
          "setUpClass",
          38,
          73,
          71,
          22,
          71,
          45,
          38,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "setUpClass",
          52,
          71,
          67,
          22,
          67,
          45,
          52,
          20,
          71,
          62
        ],
        [
          "setUpClass",
          52,
          71,
          71,
          22,
          71,
          61,
          52,
          20,
          71,
          62
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "setUp",
          38,
          100,
          98,
          22,
          98,
          45,
          38,
          15,
          100,
          39
        ]
      ],
      "transformers/tests/models/qwen2/test_tokenization_qwen2.py": [
        [
          "setUpClass",
          40,
          92,
          90,
          22,
          90,
          45,
          40,
          20,
          92,
          39
        ]
      ],
      "transformers/tests/models/roberta/test_tokenization_roberta.py": [
        [
          "setUpClass",
          37,
          72,
          70,
          22,
          70,
          45,
          37,
          20,
          72,
          39
        ]
      ],
      "transformers/tests/models/vits/test_tokenization_vits.py": [
        [
          "setUpClass",
          35,
          52,
          52,
          22,
          52,
          45,
          35,
          20,
          52,
          53
        ]
      ],
      "transformers/tests/models/wav2vec2_phoneme/test_tokenization_wav2vec2_phoneme.py": [
        [
          "setUpClass",
          35,
          59,
          59,
          22,
          59,
          45,
          35,
          20,
          59,
          53
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "setUpClass",
          60,
          71,
          71,
          22,
          71,
          45,
          60,
          20,
          71,
          53
        ],
        [
          "setUpClass",
          379,
          390,
          390,
          22,
          390,
          45,
          379,
          20,
          390,
          53
        ]
      ],
      "transformers/tests/models/xlm/test_tokenization_xlm.py": [
        [
          "setUpClass",
          32,
          67,
          65,
          22,
          65,
          45,
          32,
          20,
          67,
          39
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          724,
          23,
          724,
          65,
          712,
          22,
          727,
          60
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "save_vocabulary",
          282,
          309,
          294,
          21,
          294,
          90,
          290,
          30,
          299,
          95
        ]
      ],
      "transformers/src/transformers/models/biogpt/tokenization_biogpt.py": [
        [
          "save_vocabulary",
          284,
          310,
          296,
          21,
          296,
          90,
          292,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "save_vocabulary",
          192,
          219,
          204,
          21,
          204,
          90,
          200,
          30,
          209,
          95
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "save_vocabulary",
          305,
          332,
          317,
          21,
          317,
          90,
          313,
          30,
          322,
          95
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "save_vocabulary",
          489,
          516,
          501,
          21,
          501,
          90,
          497,
          30,
          506,
          95
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "save_vocabulary",
          337,
          364,
          349,
          21,
          349,
          90,
          345,
          30,
          354,
          95
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "save_vocabulary",
          276,
          303,
          288,
          21,
          288,
          90,
          284,
          30,
          293,
          95
        ]
      ],
      "transformers/src/transformers/models/ctrl/tokenization_ctrl.py": [
        [
          "save_vocabulary",
          215,
          242,
          227,
          21,
          227,
          90,
          223,
          30,
          232,
          95
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "save_vocabulary",
          330,
          357,
          342,
          21,
          342,
          90,
          338,
          30,
          347,
          95
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": [
        [
          "save_vocabulary",
          146,
          167,
          165,
          21,
          165,
          68,
          161,
          30,
          167,
          28
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "save_vocabulary",
          489,
          515,
          501,
          21,
          501,
          90,
          497,
          30,
          505,
          95
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "save_vocabulary",
          433,
          467,
          449,
          21,
          449,
          90,
          445,
          30,
          457,
          95
        ],
        [
          "save_vocabulary",
          433,
          467,
          453,
          21,
          453,
          87,
          445,
          30,
          457,
          95
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "save_vocabulary",
          298,
          325,
          310,
          21,
          310,
          90,
          306,
          30,
          315,
          95
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "save_vocabulary",
          568,
          594,
          580,
          21,
          580,
          90,
          576,
          30,
          584,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "save_vocabulary",
          336,
          370,
          356,
          21,
          356,
          72,
          353,
          30,
          359,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          362,
          21,
          362,
          71,
          359,
          30,
          365,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          368,
          21,
          368,
          71,
          365,
          30,
          370,
          55
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "save_vocabulary",
          411,
          438,
          423,
          21,
          423,
          90,
          419,
          30,
          428,
          95
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "save_vocabulary",
          295,
          322,
          307,
          21,
          307,
          90,
          303,
          30,
          312,
          95
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "save_vocabulary",
          291,
          318,
          303,
          21,
          303,
          90,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/mgp_str/tokenization_mgp_str.py": [
        [
          "save_vocabulary",
          90,
          101,
          99,
          21,
          99,
          88,
          95,
          30,
          101,
          28
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "save_vocabulary",
          369,
          398,
          382,
          21,
          382,
          90,
          377,
          30,
          388,
          95
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "save_vocabulary",
          1691,
          1725,
          1703,
          21,
          1703,
          90,
          1699,
          30,
          1708,
          95
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1723,
          21,
          1723,
          95,
          1719,
          30,
          1725,
          56
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "save_vocabulary",
          1530,
          1553,
          1551,
          21,
          1551,
          95,
          1547,
          30,
          1553,
          48
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "save_vocabulary",
          283,
          310,
          295,
          21,
          295,
          90,
          291,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/myt5/tokenization_myt5.py": [
        [
          "save_vocabulary",
          368,
          377,
          376,
          26,
          376,
          81,
          375,
          14,
          377,
          28
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "save_vocabulary",
          366,
          393,
          378,
          21,
          378,
          90,
          374,
          30,
          383,
          95
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "save_vocabulary",
          308,
          335,
          320,
          21,
          320,
          90,
          316,
          30,
          325,
          95
        ]
      ],
      "transformers/src/transformers/models/pop2piano/tokenization_pop2piano.py": [
        [
          "save_vocabulary",
          344,
          365,
          363,
          24,
          363,
          47,
          360,
          30,
          365,
          32
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "save_vocabulary",
          291,
          318,
          303,
          21,
          303,
          90,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py": [
        [
          "save_vocabulary",
          220,
          249,
          232,
          21,
          232,
          90,
          228,
          30,
          235,
          33
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "save_vocabulary",
          465,
          492,
          477,
          21,
          477,
          90,
          473,
          30,
          482,
          95
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "save_vocabulary",
          231,
          243,
          241,
          21,
          241,
          90,
          237,
          30,
          243,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        [
          "save_vocabulary",
          558,
          569,
          567,
          21,
          567,
          90,
          563,
          30,
          569,
          28
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "_save_pretrained",
          695,
          742,
          729,
          31,
          729,
          99,
          728,
          22,
          730,
          36
        ],
        [
          "train_new_from_iterator",
          744,
          922,
          812,
          44,
          812,
          69,
          812,
          21,
          816,
          39
        ],
        [
          "train_new_from_iterator",
          744,
          922,
          890,
          48,
          890,
          81,
          889,
          56,
          890,
          21
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py": [
        [
          "save_vocabulary",
          624,
          635,
          633,
          21,
          633,
          88,
          629,
          30,
          635,
          28
        ],
        [
          "save_vocabulary",
          901,
          912,
          910,
          21,
          910,
          90,
          906,
          30,
          912,
          28
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "save_vocabulary",
          439,
          452,
          449,
          21,
          449,
          110,
          447,
          18,
          450,
          17
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "save_pretrained",
          2471,
          2638,
          2607,
          23,
          2607,
          96,
          2606,
          14,
          2638,
          25
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2616,
          23,
          2616,
          90,
          2606,
          14,
          2638,
          25
        ],
        [
          "_save_pretrained",
          2640,
          2673,
          2667,
          27,
          2667,
          95,
          2666,
          18,
          2669,
          78
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "save_vocabulary",
          532,
          558,
          544,
          21,
          544,
          90,
          540,
          30,
          548,
          95
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "save_vocabulary",
          801,
          837,
          816,
          21,
          816,
          90,
          812,
          30,
          821,
          95
        ],
        [
          "save_vocabulary",
          801,
          837,
          834,
          21,
          834,
          110,
          832,
          18,
          835,
          17
        ]
      ],
      "transformers/src/transformers/trainer_callback.py": [
        [
          "save_to_json",
          144,
          148,
          146,
          23,
          146,
          84,
          144,
          22,
          148,
          32
        ]
      ],
      "transformers/src/transformers/data/processors/utils.py": [
        [
          "to_json_string",
          49,
          51,
          51,
          16,
          51,
          61,
          49,
          24,
          51,
          68
        ],
        [
          "to_json_string",
          75,
          77,
          77,
          16,
          77,
          51,
          75,
          24,
          77,
          58
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "to_json_string",
          2324,
          2328,
          2328,
          16,
          2328,
          51,
          2324,
          24,
          2328,
          51
        ]
      ],
      "transformers/examples/pytorch/question-answering/utils_qa.py": [
        [
          "postprocess_qa_predictions",
          31,
          249,
          240,
          26,
          240,
          62,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          240,
          26,
          240,
          62,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          240,
          26,
          240,
          62,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          240,
          26,
          240,
          62,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          243,
          26,
          243,
          61,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          243,
          26,
          243,
          61,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          243,
          26,
          243,
          61,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          243,
          26,
          243,
          61,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          247,
          30,
          247,
          67,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          247,
          30,
          247,
          67,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          434,
          26,
          434,
          62,
          432,
          9,
          438,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          434,
          26,
          434,
          62,
          428,
          30,
          441,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          437,
          26,
          437,
          61,
          432,
          9,
          438,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          437,
          26,
          437,
          61,
          428,
          30,
          441,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          441,
          30,
          441,
          67,
          428,
          30,
          441,
          75
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "to_json_string",
          785,
          804,
          804,
          16,
          804,
          63,
          804,
          16,
          804,
          70
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "combine_summaries",
          149,
          195,
          193,
          11,
          193,
          40,
          190,
          10,
          195,
          19
        ]
      ],
      "transformers/benchmark/benchmarks_entrypoint.py": [
        [
          "initialise_benchmark",
          103,
          144,
          129,
          37,
          129,
          56,
          121,
          23,
          134,
          30
        ]
      ],
      "transformers/src/transformers/utils/chat_template_utils.py": [
        [
          "tojson",
          449,
          452,
          452,
          16,
          452,
          114,
          449,
          16,
          452,
          114
        ]
      ],
      "transformers/utils/check_self_hosted_runner.py": [
        [
          "get_runner_status",
          6,
          34,
          30,
          18,
          30,
          44,
          29,
          10,
          32,
          31
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          599,
          23,
          599,
          65,
          596,
          27,
          605,
          9
        ]
      ],
      "transformers/src/transformers/distributed/configuration_utils.py": [
        [
          "to_json_file",
          52,
          66,
          64,
          27,
          64,
          75,
          52,
          22,
          66,
          37
        ],
        [
          "to_json_string",
          85,
          91,
          91,
          16,
          91,
          50,
          85,
          24,
          91,
          57
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "to_json_string",
          1045,
          1087,
          1087,
          16,
          1087,
          64,
          1068,
          9,
          1087,
          71
        ],
        [
          "to_json_file",
          1199,
          1210,
          1208,
          27,
          1208,
          75,
          1199,
          22,
          1210,
          37
        ],
        [
          "to_json_string",
          1229,
          1236,
          1236,
          16,
          1236,
          50,
          1229,
          24,
          1236,
          57
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "to_json_string",
          961,
          977,
          977,
          16,
          977,
          64,
          977,
          16,
          977,
          71
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "shard_on_the_fly",
          70,
          149,
          146,
          19,
          146,
          61,
          142,
          17,
          149,
          26
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          185,
          17,
          185,
          77,
          179,
          16,
          189,
          40
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          225,
          17,
          225,
          78,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          242,
          17,
          242,
          82,
          192,
          19,
          251,
          24
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          153,
          27,
          153,
          74,
          147,
          18,
          154,
          32
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          132,
          17,
          132,
          77,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          148,
          17,
          148,
          77,
          142,
          16,
          152,
          34
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          211,
          17,
          211,
          78,
          209,
          5,
          243,
          24
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          224,
          17,
          224,
          82,
          209,
          5,
          243,
          24
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "main",
          700,
          805,
          787,
          22,
          787,
          78,
          743,
          28,
          797,
          82
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "save_sharded_safetensors",
          143,
          167,
          161,
          19,
          161,
          61,
          144,
          5,
          165,
          50
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          123,
          19,
          123,
          61,
          119,
          17,
          126,
          26
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "convert_tiktoken_to_hf",
          291,
          327,
          316,
          21,
          316,
          83,
          295,
          43,
          320,
          36
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          340,
          21,
          340,
          90,
          338,
          10,
          357,
          14
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          136,
          23,
          136,
          65,
          133,
          27,
          149,
          37
        ]
      ],
      "transformers/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          60,
          17,
          60,
          44,
          44,
          14,
          64,
          51
        ],
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          64,
          17,
          64,
          43,
          44,
          14,
          64,
          51
        ]
      ],
      "transformers/examples/quantization/custom_quantization.py": [
        [
          "__repr__",
          23,
          25,
          25,
          45,
          25,
          93,
          23,
          18,
          25,
          97
        ]
      ],
      "transformers/examples/quantization/custom_quantization_int8_example.py": [
        [
          "__repr__",
          119,
          121,
          121,
          45,
          121,
          93,
          119,
          18,
          121,
          97
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "to_json_string",
          602,
          621,
          621,
          16,
          621,
          63,
          621,
          16,
          621,
          70
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "to_json_string",
          460,
          479,
          479,
          16,
          479,
          63,
          479,
          16,
          479,
          70
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "log_model_debug_trace",
          228,
          268,
          264,
          28,
          264,
          55,
          238,
          5,
          268,
          41
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "to_json_string",
          243,
          245,
          245,
          16,
          245,
          67,
          243,
          24,
          245,
          74
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "save_pretrained",
          3648,
          4088,
          4064,
          27,
          4064,
          69,
          4060,
          31,
          4070,
          13
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "post",
          209,
          219,
          211,
          15,
          211,
          62,
          209,
          14,
          213,
          92
        ],
        [
          "payload",
          169,
          181,
          181,
          16,
          181,
          33,
          181,
          16,
          181,
          33
        ],
        [
          "error_out",
          184,
          207,
          201,
          15,
          201,
          57,
          187,
          17,
          207,
          9
        ],
        [
          "post_reply",
          252,
          273,
          264,
          23,
          264,
          52,
          259,
          24,
          273,
          29
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "payload",
          556,
          698,
          698,
          16,
          698,
          33,
          698,
          16,
          698,
          33
        ],
        [
          "error_out",
          701,
          760,
          751,
          19,
          751,
          36,
          735,
          9,
          760,
          9
        ],
        [
          "error_out",
          701,
          760,
          754,
          15,
          754,
          44,
          735,
          9,
          760,
          9
        ],
        [
          "post",
          762,
          773,
          765,
          15,
          765,
          57,
          762,
          14,
          767,
          92
        ],
        [
          "post_reply",
          894,
          941,
          909,
          27,
          909,
          56,
          901,
          21,
          918,
          33
        ],
        [
          "post_reply",
          894,
          941,
          932,
          27,
          932,
          56,
          922,
          21,
          941,
          33
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "to_json_string",
          696,
          705,
          705,
          16,
          705,
          63,
          696,
          24,
          705,
          70
        ],
        [
          "save_pretrained",
          723,
          896,
          840,
          21,
          840,
          95,
          840,
          21,
          844,
          89
        ],
        [
          "save_pretrained",
          723,
          896,
          875,
          40,
          875,
          97,
          869,
          41,
          877,
          54
        ]
      ],
      "transformers/src/transformers/utils/quantization_config.py": [
        [
          "to_json_file",
          137,
          152,
          150,
          27,
          150,
          75,
          137,
          22,
          152,
          37
        ],
        [
          "to_json_string",
          169,
          185,
          185,
          16,
          185,
          64,
          185,
          16,
          185,
          71
        ],
        [
          "__repr__",
          378,
          380,
          380,
          45,
          380,
          93,
          378,
          18,
          380,
          97
        ],
        [
          "__repr__",
          608,
          610,
          610,
          45,
          610,
          93,
          608,
          18,
          610,
          97
        ]
      ],
      "transformers/examples/legacy/run_chinese_ref.py": [
        [
          "listcomp",
          128,
          128,
          128,
          17,
          128,
          31,
          128,
          44,
          128,
          38
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          1056,
          25,
          1056,
          57,
          1056,
          13,
          1057,
          63
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "main",
          338,
          1035,
          1034,
          25,
          1034,
          57,
          1034,
          13,
          1035,
          63
        ]
      ],
      "transformers/utils/scan_skipped_tests.py": [
        [
          "save_json",
          89,
          91,
          91,
          28,
          91,
          52,
          89,
          15,
          91,
          71
        ]
      ],
      "transformers/src/transformers/data/metrics/squad_metrics.py": [
        [
          "compute_predictions_logits",
          383,
          587,
          581,
          26,
          581,
          61,
          575,
          8,
          583,
          32
        ],
        [
          "compute_predictions_logits",
          383,
          587,
          577,
          26,
          577,
          62,
          575,
          8,
          583,
          32
        ],
        [
          "compute_predictions_logits",
          383,
          587,
          585,
          26,
          585,
          63,
          584,
          14,
          585,
          71
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          770,
          22,
          770,
          58,
          769,
          10,
          775,
          30
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          773,
          22,
          773,
          57,
          769,
          10,
          775,
          30
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          777,
          26,
          777,
          63,
          776,
          14,
          777,
          71
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_pattern_matching_fallback",
          63,
          71,
          69,
          25,
          69,
          38,
          63,
          40,
          71,
          57
        ]
      ],
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUp",
          113,
          178,
          172,
          22,
          172,
          45,
          113,
          15,
          178,
          55
        ]
      ]
    },
    "re.sub": {
      "transformers/tests/models/vision_encoder_decoder/test_modeling_vision_encoder_decoder.py": [
        [
          "test_inference_docvqa",
          1254,
          1315,
          1302,
          20,
          1302,
          58,
          1254,
          31,
          1315,
          9
        ],
        [
          "test_inference_cordv2",
          1318,
          1377,
          1365,
          20,
          1365,
          58,
          1318,
          31,
          1377,
          9
        ],
        [
          "test_inference_rvlcdip",
          1380,
          1438,
          1427,
          20,
          1427,
          58,
          1380,
          32,
          1438,
          9
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "clean_code",
          97,
          126,
          122,
          16,
          122,
          39,
          120,
          9,
          124,
          25
        ],
        [
          "keep_doc_examples_only",
          129,
          153,
          149,
          16,
          149,
          39,
          147,
          9,
          151,
          25
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "_decode",
          185,
          231,
          218,
          20,
          218,
          75,
          218,
          20,
          218,
          16
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "apply_print_resets",
          1587,
          1588,
          1588,
          12,
          1588,
          53,
          1587,
          24,
          1588,
          53
        ],
        [
          "summary_failures_short",
          2295,
          2306,
          2305,
          24,
          2305,
          106,
          2301,
          13,
          2306,
          33
        ],
        [
          "pytest_xdist_worker_id",
          2447,
          2454,
          2453,
          14,
          2453,
          56,
          2448,
          5,
          2454,
          22
        ],
        [
          "preprocess_string",
          2807,
          2833,
          2820,
          29,
          2820,
          107,
          2820,
          29,
          2820,
          25
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "replace_unicode_punct",
          66,
          106,
          71,
          12,
          71,
          38,
          66,
          27,
          106,
          15
        ],
        [
          "replace_unicode_punct",
          66,
          106,
          96,
          12,
          96,
          38,
          66,
          27,
          106,
          15
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "replace_unicode_punct",
          49,
          89,
          54,
          12,
          54,
          38,
          49,
          27,
          89,
          15
        ],
        [
          "replace_unicode_punct",
          49,
          89,
          79,
          12,
          79,
          38,
          49,
          27,
          89,
          15
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "replace_unicode_punct",
          48,
          88,
          53,
          12,
          53,
          38,
          48,
          27,
          88,
          15
        ],
        [
          "replace_unicode_punct",
          48,
          88,
          78,
          12,
          78,
          38,
          48,
          27,
          88,
          15
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "text_standardize",
          220,
          232,
          229,
          12,
          229,
          109,
          220,
          22,
          232,
          23
        ],
        [
          "text_standardize",
          220,
          232,
          230,
          12,
          230,
          44,
          220,
          22,
          232,
          23
        ],
        [
          "text_standardize",
          220,
          232,
          231,
          12,
          231,
          41,
          220,
          22,
          232,
          23
        ]
      ],
      "transformers/src/transformers/models/nougat/tokenization_nougat_fast.py": [
        [
          "markdown_compatible",
          56,
          95,
          71,
          12,
          71,
          106,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          73,
          12,
          73,
          106,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          75,
          12,
          80,
          5,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          85,
          12,
          85,
          74,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          87,
          12,
          91,
          5,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          93,
          12,
          93,
          79,
          56,
          25,
          95,
          15
        ],
        [
          "_clean",
          236,
          237,
          237,
          16,
          237,
          47,
          236,
          16,
          237,
          55
        ],
        [
          "remove_hallucinated_references",
          423,
          451,
          446,
          16,
          450,
          9,
          446,
          16,
          451,
          19
        ],
        [
          "correct_tables",
          453,
          486,
          480,
          22,
          480,
          100,
          476,
          22,
          486,
          25
        ],
        [
          "post_process_single",
          488,
          581,
          500,
          22,
          502,
          9,
          488,
          29,
          511,
          36
        ],
        [
          "post_process_single",
          488,
          581,
          508,
          22,
          508,
          108,
          488,
          29,
          511,
          36
        ],
        [
          "post_process_single",
          488,
          581,
          519,
          22,
          519,
          103,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          521,
          22,
          521,
          95,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          523,
          22,
          523,
          65,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          525,
          22,
          529,
          9,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          530,
          22,
          530,
          95,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          532,
          22,
          536,
          9,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          538,
          22,
          538,
          84,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          565,
          22,
          569,
          9,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          571,
          22,
          571,
          76,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          573,
          22,
          573,
          84,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          575,
          22,
          575,
          75,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          577,
          22,
          577,
          58,
          561,
          22,
          578,
          23
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "canonicalize_text",
          275,
          294,
          291,
          16,
          291,
          40,
          291,
          16,
          294,
          19
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "tokenize_numbers",
          68,
          91,
          88,
          20,
          88,
          50,
          86,
          9,
          89,
          34
        ],
        [
          "detokenize_numbers",
          94,
          112,
          111,
          16,
          111,
          37,
          110,
          9,
          111,
          12
        ]
      ],
      "transformers/src/transformers/tokenization_utils.py": [
        [
          "tokenize",
          621,
          699,
          653,
          20,
          653,
          90,
          646,
          68,
          653,
          16
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "prepare_for_tokenization",
          142,
          205,
          200,
          29,
          200,
          62,
          192,
          29,
          200,
          25
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "_filter_timestamp_ids",
          308,
          309,
          309,
          16,
          309,
          56,
          308,
          31,
          309,
          56
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "_parse_date",
          2409,
          2423,
          2411,
          12,
          2411,
          41,
          2409,
          17,
          2412,
          59
        ],
        [
          "format_text",
          2469,
          2480,
          2475,
          12,
          2475,
          41,
          2475,
          12,
          2478,
          11
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "replace_unicode_punct",
          66,
          106,
          71,
          12,
          71,
          38,
          66,
          27,
          106,
          15
        ],
        [
          "replace_unicode_punct",
          66,
          106,
          96,
          12,
          96,
          38,
          66,
          27,
          106,
          15
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "get_fast_image_processing_content_header",
          275,
          308,
          302,
          22,
          302,
          99,
          300,
          22,
          305,
          12
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "create_doc_file",
          217,
          270,
          231,
          30,
          231,
          58,
          217,
          21,
          262,
          32
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          93,
          26,
          93,
          75,
          86,
          21,
          95,
          47
        ]
      ],
      "transformers/src/transformers/utils/chat_template_utils.py": [
        [
          "dictcomp",
          230,
          230,
          230,
          32,
          230,
          74,
          230,
          80,
          230,
          74
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "stream_output",
          130,
          174,
          142,
          27,
          142,
          70,
          142,
          27,
          158,
          45
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "replace_code",
          463,
          485,
          480,
          20,
          480,
          43,
          479,
          34,
          481,
          45
        ],
        [
          "replace_code",
          463,
          485,
          482,
          24,
          482,
          63,
          482,
          24,
          483,
          20
        ],
        [
          "replace_code",
          463,
          485,
          483,
          24,
          483,
          63,
          482,
          24,
          483,
          20
        ]
      ],
      "transformers/src/transformers/models/aimv2/convert_aimv2_original_pytorch_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          111,
          124,
          120,
          28,
          120,
          56,
          120,
          28,
          121,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          111,
          124,
          122,
          24,
          122,
          61,
          122,
          24,
          122,
          20
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "genexpr",
          150,
          150,
          150,
          16,
          150,
          36,
          150,
          16,
          150,
          39
        ],
        [
          "genexpr",
          150,
          150,
          150,
          68,
          150,
          90,
          150,
          68,
          150,
          93
        ]
      ],
      "transformers/src/transformers/models/blip/convert_blip_original_pytorch_to_hf.py": [
        [
          "rename_key",
          54,
          78,
          56,
          15,
          56,
          68,
          56,
          15,
          56,
          11
        ],
        [
          "rename_key",
          54,
          78,
          58,
          15,
          58,
          46,
          58,
          15,
          58,
          11
        ],
        [
          "rename_key",
          54,
          78,
          60,
          15,
          60,
          47,
          60,
          15,
          60,
          11
        ],
        [
          "rename_key",
          54,
          78,
          62,
          15,
          62,
          50,
          62,
          15,
          62,
          11
        ],
        [
          "rename_key",
          54,
          78,
          64,
          15,
          64,
          50,
          64,
          15,
          64,
          11
        ],
        [
          "rename_key",
          54,
          78,
          66,
          15,
          66,
          60,
          66,
          15,
          66,
          11
        ],
        [
          "rename_key",
          54,
          78,
          68,
          15,
          68,
          84,
          68,
          15,
          68,
          11
        ],
        [
          "rename_key",
          54,
          78,
          71,
          15,
          71,
          80,
          71,
          15,
          71,
          11
        ],
        [
          "rename_key",
          54,
          78,
          73,
          15,
          73,
          77,
          73,
          15,
          73,
          11
        ],
        [
          "rename_key",
          54,
          78,
          76,
          15,
          76,
          68,
          76,
          15,
          76,
          11
        ]
      ],
      "transformers/src/transformers/models/csm/convert_csm.py": [
        [
          "convert_key",
          73,
          76,
          75,
          15,
          75,
          47,
          74,
          9,
          75,
          11
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_old_keys_to_new_keys",
          91,
          106,
          102,
          28,
          102,
          56,
          102,
          28,
          103,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          91,
          106,
          104,
          24,
          104,
          61,
          104,
          24,
          104,
          20
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          323,
          331,
          327,
          23,
          327,
          62,
          326,
          13,
          328,
          29
        ]
      ],
      "transformers/src/transformers/models/dia/convert_dia_to_hf.py": [
        [
          "convert_dia_model_to_hf",
          78,
          155,
          127,
          14,
          127,
          37,
          127,
          14,
          127,
          78
        ],
        [
          "convert_dia_model_to_hf",
          78,
          155,
          117,
          23,
          117,
          51,
          117,
          23,
          117,
          19
        ],
        [
          "convert_dia_model_to_hf",
          78,
          155,
          130,
          23,
          130,
          73,
          130,
          23,
          130,
          19
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          120,
          28,
          120,
          56,
          120,
          28,
          121,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          122,
          24,
          122,
          61,
          122,
          24,
          122,
          20
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "convert_key_pattern",
          98,
          105,
          104,
          20,
          104,
          52,
          104,
          20,
          104,
          52
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          78,
          93,
          89,
          28,
          89,
          56,
          89,
          28,
          90,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          78,
          93,
          91,
          24,
          91,
          61,
          91,
          24,
          91,
          20
        ]
      ],
      "transformers/src/transformers/models/edgetam_video/convert_edgetam_video_to_hf.py": [
        [
          "replace_keys",
          110,
          232,
          144,
          23,
          144,
          55,
          144,
          23,
          144,
          19
        ]
      ],
      "transformers/src/transformers/models/efficientloftr/convert_efficientloftr_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          120,
          28,
          120,
          56,
          120,
          28,
          121,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          122,
          24,
          122,
          61,
          122,
          24,
          122,
          20
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          72,
          81,
          77,
          32,
          77,
          64,
          77,
          32,
          77,
          28
        ],
        [
          "convert_old_keys_to_new_keys",
          72,
          81,
          79,
          32,
          79,
          66,
          79,
          32,
          79,
          28
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_state_dict_to_hf",
          239,
          252,
          249,
          19,
          249,
          55,
          248,
          13,
          249,
          15
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_espnet_state_dict_to_hf",
          104,
          151,
          134,
          27,
          134,
          63,
          132,
          21,
          134,
          23
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "genexpr",
          81,
          81,
          81,
          16,
          81,
          36,
          81,
          16,
          81,
          39
        ],
        [
          "genexpr",
          81,
          81,
          81,
          68,
          81,
          90,
          81,
          68,
          81,
          93
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          158,
          14,
          158,
          58,
          156,
          10,
          168,
          35
        ]
      ],
      "transformers/src/transformers/models/ijepa/convert_ijepa_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          67,
          91,
          85,
          28,
          85,
          56,
          85,
          28,
          86,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          67,
          91,
          87,
          24,
          87,
          61,
          87,
          24,
          87,
          20
        ]
      ],
      "transformers/src/transformers/models/internvl/convert_internvl_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          160,
          24,
          160,
          61,
          159,
          13,
          160,
          20
        ],
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          166,
          28,
          166,
          65,
          165,
          17,
          166,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          169,
          28,
          169,
          65,
          168,
          17,
          169,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          180,
          24,
          180,
          61,
          179,
          13,
          180,
          20
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          120,
          129,
          125,
          32,
          125,
          64,
          125,
          32,
          125,
          28
        ],
        [
          "convert_old_keys_to_new_keys",
          120,
          129,
          127,
          32,
          127,
          66,
          127,
          32,
          127,
          28
        ]
      ],
      "transformers/src/transformers/models/kyutai_speech_to_text/convert_kyutai_speech_to_text_to_hf.py": [
        [
          "convert_key",
          87,
          90,
          89,
          15,
          89,
          47,
          88,
          9,
          89,
          11
        ]
      ],
      "transformers/src/transformers/models/lightglue/convert_lightglue_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          92,
          107,
          103,
          28,
          103,
          56,
          103,
          28,
          104,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          92,
          107,
          105,
          24,
          105,
          61,
          105,
          24,
          105,
          20
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          94,
          109,
          105,
          28,
          105,
          56,
          105,
          28,
          106,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          94,
          109,
          107,
          24,
          107,
          61,
          107,
          24,
          107,
          20
        ],
        [
          "write_model",
          213,
          554,
          437,
          28,
          437,
          84,
          436,
          24,
          439,
          38
        ],
        [
          "write_model",
          213,
          554,
          438,
          26,
          438,
          80,
          436,
          24,
          439,
          38
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "convert_state_dict_from_mamba_ssm",
          34,
          83,
          50,
          13,
          50,
          63,
          37,
          9,
          56,
          25
        ],
        [
          "convert_state_dict_from_mamba_ssm",
          34,
          83,
          51,
          13,
          51,
          65,
          37,
          9,
          56,
          25
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          212,
          227,
          223,
          28,
          223,
          56,
          223,
          28,
          224,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          212,
          227,
          225,
          24,
          225,
          61,
          225,
          24,
          225,
          20
        ]
      ],
      "transformers/src/transformers/models/mm_grounding_dino/convert_mm_grounding_dino_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          391,
          406,
          402,
          28,
          402,
          56,
          402,
          28,
          403,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          391,
          406,
          404,
          24,
          404,
          61,
          404,
          24,
          404,
          20
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "convert_key",
          51,
          54,
          53,
          15,
          53,
          47,
          52,
          9,
          53,
          11
        ]
      ],
      "transformers/src/transformers/models/ovis2/convert_ovis2_weights_to_hf.py": [
        [
          "convert_orig2hf",
          235,
          274,
          253,
          19,
          253,
          51,
          252,
          13,
          253,
          15
        ]
      ],
      "transformers/src/transformers/models/pix2struct/convert_pix2struct_original_pytorch_to_hf.py": [
        [
          "rename_and_convert_flax_params",
          40,
          102,
          85,
          27,
          85,
          71,
          85,
          27,
          86,
          23
        ],
        [
          "rename_and_convert_flax_params",
          40,
          102,
          90,
          27,
          90,
          71,
          90,
          27,
          90,
          23
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          134,
          151,
          148,
          35,
          148,
          71,
          148,
          35,
          148,
          31
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_seer_10b_to_pytorch.py": [
        [
          "convert_weights_and_push",
          162,
          272,
          220,
          23,
          220,
          44,
          218,
          13,
          225,
          37
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_state_dict",
          49,
          77,
          60,
          16,
          60,
          74,
          60,
          16,
          64,
          39
        ],
        [
          "convert_state_dict",
          49,
          77,
          62,
          16,
          62,
          77,
          60,
          16,
          64,
          39
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          163,
          171,
          167,
          23,
          167,
          62,
          166,
          13,
          168,
          29
        ]
      ],
      "transformers/src/transformers/models/siglip2/convert_siglip2_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          265,
          280,
          276,
          28,
          276,
          56,
          276,
          28,
          277,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          265,
          280,
          278,
          24,
          278,
          61,
          278,
          24,
          278,
          20
        ]
      ],
      "transformers/src/transformers/models/superglue/convert_superglue_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          100,
          115,
          111,
          28,
          111,
          56,
          111,
          28,
          112,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          100,
          115,
          113,
          24,
          113,
          61,
          113,
          24,
          113,
          20
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "convert_textnet_checkpoint",
          116,
          181,
          159,
          23,
          159,
          60,
          152,
          23,
          160,
          39
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": [
        [
          "rename_keys",
          197,
          247,
          205,
          23,
          205,
          73,
          205,
          23,
          205,
          19
        ],
        [
          "rename_keys",
          197,
          247,
          212,
          27,
          212,
          63,
          212,
          27,
          213,
          23
        ],
        [
          "rename_keys",
          197,
          247,
          213,
          27,
          213,
          85,
          212,
          27,
          213,
          23
        ],
        [
          "rename_keys",
          197,
          247,
          216,
          27,
          216,
          63,
          216,
          27,
          217,
          23
        ],
        [
          "rename_keys",
          197,
          247,
          217,
          27,
          217,
          85,
          216,
          27,
          217,
          23
        ]
      ],
      "transformers/src/transformers/models/moonshine/convert_usefulsensors_to_hf.py": [
        [
          "_convert_layer_names",
          56,
          92,
          88,
          12,
          88,
          45,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          57,
          12,
          62,
          5,
          56,
          26,
          63,
          16
        ],
        [
          "_convert_layer_names",
          56,
          92,
          64,
          16,
          64,
          71,
          64,
          16,
          65,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          65,
          16,
          65,
          73,
          64,
          16,
          65,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          67,
          16,
          67,
          91,
          67,
          16,
          68,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          68,
          16,
          68,
          93,
          67,
          16,
          68,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          69,
          12,
          69,
          74,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          70,
          12,
          70,
          76,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          71,
          12,
          71,
          76,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          72,
          12,
          72,
          91,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          73,
          12,
          73,
          72,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          74,
          12,
          74,
          74,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          75,
          12,
          75,
          74,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          76,
          12,
          76,
          75,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          77,
          12,
          77,
          80,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          78,
          12,
          78,
          82,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          79,
          12,
          79,
          82,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          80,
          12,
          80,
          83,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          81,
          12,
          81,
          79,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          82,
          12,
          82,
          81,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          83,
          12,
          83,
          81,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          84,
          12,
          84,
          82,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          85,
          12,
          85,
          69,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          86,
          12,
          86,
          80,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          87,
          12,
          87,
          71,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          89,
          12,
          89,
          43,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          90,
          12,
          90,
          72,
          69,
          12,
          92,
          15
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_classifier_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          125,
          139,
          135,
          24,
          135,
          52,
          135,
          24,
          136,
          20
        ],
        [
          "convert_old_keys_to_new_keys",
          125,
          139,
          137,
          20,
          137,
          57,
          137,
          20,
          137,
          16
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          164,
          179,
          175,
          28,
          175,
          56,
          175,
          28,
          176,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          164,
          179,
          177,
          24,
          177,
          61,
          177,
          24,
          177,
          20
        ],
        [
          "write_model",
          190,
          396,
          233,
          23,
          233,
          107,
          232,
          30,
          243,
          51
        ],
        [
          "write_model",
          190,
          396,
          248,
          31,
          248,
          95,
          246,
          33,
          248,
          27
        ]
      ],
      "transformers/src/transformers/pipelines/document_question_answering.py": [
        [
          "postprocess_encoder_decoder_single",
          487,
          501,
          493,
          20,
          493,
          58,
          487,
          44,
          499,
          29
        ]
      ],
      "transformers/src/transformers/utils/doc.py": [
        [
          "_convert_output_args_doc",
          104,
          127,
          125,
          21,
          125,
          66,
          123,
          9,
          125,
          17
        ],
        [
          "_convert_output_args_doc",
          104,
          127,
          124,
          21,
          124,
          75,
          123,
          9,
          125,
          17
        ],
        [
          "filter_outputs_from_example",
          992,
          1003,
          1001,
          21,
          1001,
          75,
          1000,
          19,
          1001,
          17
        ]
      ],
      "transformers/src/transformers/integrations/fbgemm_fp8.py": [
        [
          "_replace_with_fbgemm_fp8_linear",
          157,
          231,
          210,
          29,
          210,
          90,
          209,
          22,
          214,
          51
        ]
      ],
      "transformers/src/transformers/models/whisper/english_normalizer.py": [
        [
          "__call__",
          573,
          597,
          595,
          13,
          595,
          34,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          573,
          597,
          584,
          13,
          584,
          44,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          82,
          93,
          84,
          13,
          84,
          47,
          82,
          18,
          88,
          29
        ],
        [
          "__call__",
          82,
          93,
          85,
          13,
          85,
          42,
          82,
          18,
          88,
          29
        ],
        [
          "__call__",
          82,
          93,
          91,
          13,
          91,
          34,
          91,
          13,
          93,
          16
        ],
        [
          "preprocess",
          436,
          463,
          457,
          13,
          457,
          50,
          454,
          13,
          463,
          16
        ],
        [
          "preprocess",
          436,
          463,
          458,
          13,
          458,
          50,
          454,
          13,
          463,
          16
        ],
        [
          "preprocess",
          436,
          463,
          461,
          13,
          461,
          62,
          454,
          13,
          463,
          16
        ],
        [
          "postprocess",
          465,
          488,
          482,
          13,
          482,
          81,
          465,
          21,
          488,
          16
        ],
        [
          "postprocess",
          465,
          488,
          483,
          13,
          483,
          62,
          465,
          21,
          488,
          16
        ],
        [
          "postprocess",
          465,
          488,
          486,
          13,
          486,
          45,
          465,
          21,
          488,
          16
        ],
        [
          "__call__",
          573,
          597,
          576,
          13,
          576,
          47,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          577,
          13,
          577,
          42,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          578,
          13,
          578,
          47,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          579,
          13,
          579,
          35,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          582,
          17,
          582,
          47,
          581,
          13,
          582,
          13
        ],
        [
          "__call__",
          573,
          597,
          585,
          13,
          585,
          46,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          573,
          597,
          592,
          13,
          592,
          49,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          573,
          597,
          593,
          13,
          593,
          43,
          584,
          13,
          597,
          16
        ]
      ],
      "transformers/src/transformers/utils/hp_naming.py": [
        [
          "parse_repr",
          138,
          162,
          151,
          23,
          151,
          49,
          151,
          23,
          152,
          19
        ],
        [
          "parse_repr",
          138,
          162,
          152,
          29,
          152,
          56,
          151,
          23,
          152,
          19
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "dictcomp",
          1499,
          1499,
          1499,
          34,
          1499,
          73,
          1499,
          82,
          1499,
          76
        ]
      ],
      "transformers/src/transformers/modeling_gguf_pytorch_utils.py": [
        [
          "get_gguf_hf_weights_map",
          281,
          360,
          338,
          23,
          338,
          74,
          338,
          23,
          338,
          19
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "update_key_name",
          878,
          909,
          886,
          29,
          886,
          58,
          885,
          13,
          886,
          65
        ],
        [
          "update_key_name",
          878,
          909,
          887,
          26,
          887,
          55,
          887,
          17,
          887,
          70
        ],
        [
          "update_key_name",
          878,
          909,
          888,
          22,
          888,
          51,
          888,
          13,
          888,
          67
        ],
        [
          "update_key_name",
          878,
          909,
          892,
          16,
          892,
          45,
          891,
          9,
          895,
          49
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3870,
          35,
          3870,
          68,
          3868,
          21,
          3873,
          36
        ],
        [
          "caching_allocator_warmup",
          5760,
          5840,
          5815,
          28,
          5815,
          64,
          5815,
          28,
          5816,
          105
        ]
      ],
      "transformers/src/transformers/models/florence2/modular_florence2.py": [
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          874,
          33,
          874,
          79,
          873,
          13,
          875,
          36
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_strip_source_for_tokens",
          161,
          173,
          172,
          12,
          172,
          35,
          161,
          30,
          173,
          102
        ],
        [
          "_sanitize_for_embedding",
          203,
          231,
          226,
          26,
          226,
          51,
          224,
          13,
          226,
          52
        ],
        [
          "_normalize",
          148,
          158,
          158,
          12,
          158,
          52,
          158,
          12,
          158,
          52
        ],
        [
          "_strip_source_for_tokens",
          161,
          173,
          171,
          12,
          171,
          56,
          161,
          30,
          173,
          102
        ],
        [
          "_sanitize_for_embedding",
          203,
          231,
          220,
          22,
          220,
          51,
          218,
          9,
          220,
          52
        ],
        [
          "_sanitize_for_embedding",
          203,
          231,
          230,
          21,
          230,
          87,
          229,
          9,
          230,
          17
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "update_body",
          256,
          298,
          290,
          33,
          290,
          73,
          287,
          13,
          291,
          48
        ],
        [
          "update_body",
          256,
          298,
          283,
          33,
          283,
          73,
          282,
          33,
          285,
          49
        ],
        [
          "leave_ImportFrom",
          144,
          158,
          154,
          26,
          156,
          13,
          152,
          24,
          157,
          24
        ],
        [
          "update_body",
          256,
          298,
          282,
          33,
          282,
          90,
          282,
          33,
          285,
          49
        ],
        [
          "update_body",
          256,
          298,
          289,
          33,
          289,
          56,
          287,
          13,
          291,
          48
        ],
        [
          "_fix_post_init_location",
          300,
          313,
          306,
          33,
          306,
          56,
          304,
          13,
          308,
          53
        ],
        [
          "_fix_post_init_location",
          300,
          313,
          307,
          33,
          307,
          73,
          304,
          13,
          308,
          53
        ],
        [
          "_fix_init_location",
          315,
          330,
          323,
          33,
          323,
          56,
          322,
          20,
          325,
          54
        ],
        [
          "_fix_init_location",
          315,
          330,
          324,
          33,
          324,
          73,
          322,
          20,
          325,
          54
        ]
      ],
      "transformers/src/transformers/utils/notebook.py": [
        [
          "on_evaluate",
          342,
          375,
          357,
          41,
          357,
          65,
          357,
          41,
          357,
          37
        ]
      ],
      "transformers/src/transformers/models/speecht5/number_normalizer.py": [
        [
          "__call__",
          178,
          192,
          186,
          16,
          186,
          88,
          178,
          18,
          192,
          29
        ],
        [
          "__call__",
          178,
          192,
          189,
          26,
          189,
          90,
          178,
          18,
          192,
          29
        ],
        [
          "__call__",
          178,
          192,
          190,
          26,
          190,
          58,
          178,
          18,
          192,
          29
        ]
      ],
      "transformers/src/transformers/models/clvp/number_normalizer.py": [
        [
          "normalize_numbers",
          204,
          215,
          209,
          16,
          209,
          72,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          210,
          16,
          210,
          61,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          211,
          16,
          211,
          71,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          212,
          16,
          212,
          77,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          213,
          16,
          213,
          74,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          214,
          16,
          214,
          59,
          204,
          27,
          215,
          19
        ],
        [
          "expand_abbreviations",
          217,
          223,
          222,
          20,
          222,
          51,
          221,
          13,
          222,
          16
        ],
        [
          "collapse_whitespace",
          225,
          229,
          229,
          16,
          229,
          52,
          225,
          29,
          229,
          52
        ]
      ],
      "transformers/src/transformers/models/florence2/processing_florence2.py": [
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          681,
          33,
          681,
          79,
          680,
          13,
          682,
          36
        ]
      ],
      "transformers/src/transformers/models/kosmos2/processing_kosmos2.py": [
        [
          "adjust_entity_positions",
          634,
          641,
          639,
          24,
          639,
          54,
          634,
          29,
          641,
          26
        ],
        [
          "adjust_entity_positions",
          634,
          641,
          638,
          26,
          638,
          58,
          634,
          29,
          641,
          26
        ],
        [
          "clean_text_and_extract_entities_with_bboxes",
          665,
          691,
          680,
          22,
          680,
          46,
          665,
          49,
          684,
          43
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/processing_phi4_multimodal.py": [
        [
          "listcomp",
          155,
          156,
          156,
          13,
          156,
          93,
          156,
          99,
          156,
          93
        ],
        [
          "listcomp",
          152,
          153,
          153,
          13,
          153,
          93,
          153,
          99,
          153,
          93
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "remove_special_characters",
          518,
          523,
          520,
          36,
          520,
          93,
          520,
          36,
          520,
          32
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "remove_special_characters",
          495,
          500,
          497,
          36,
          497,
          93,
          497,
          36,
          497,
          32
        ]
      ],
      "transformers/examples/legacy/seq2seq/sentence_splitter.py": [
        [
          "add_newline_to_end_of_each_sentence",
          31,
          35,
          33,
          5,
          33,
          24,
          31,
          41,
          34,
          25
        ]
      ],
      "transformers/src/transformers/data/metrics/squad_metrics.py": [
        [
          "remove_articles",
          39,
          41,
          41,
          16,
          41,
          39,
          39,
          25,
          41,
          39
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "get_processor_inputs_from_inbound_messages",
          911,
          954,
          942,
          46,
          942,
          110,
          942,
          46,
          948,
          53
        ]
      ],
      "transformers/src/transformers/integrations/tensor_parallel.py": [
        [
          "_get_parameter_tp_plan",
          123,
          138,
          133,
          26,
          133,
          60,
          123,
          28,
          134,
          36
        ],
        [
          "setcomp",
          1069,
          1069,
          1069,
          21,
          1069,
          44,
          1069,
          50,
          1069,
          44
        ],
        [
          "verify_tp_plan",
          1061,
          1089,
          1075,
          30,
          1075,
          60,
          1074,
          22,
          1077,
          40
        ]
      ]
    },
    "repr": {
      "transformers/tests/test_processing_common.py": [
        [
          "test_processor_from_and_save_pretrained",
          202,
          219,
          219,
          42,
          219,
          62,
          219,
          25,
          219,
          87
        ],
        [
          "test_processor_from_and_save_pretrained",
          202,
          219,
          219,
          65,
          219,
          86,
          219,
          25,
          219,
          87
        ],
        [
          "test_processor_from_and_save_pretrained_as_nested_dict",
          221,
          249,
          249,
          38,
          249,
          58,
          249,
          21,
          249,
          85
        ],
        [
          "test_processor_from_and_save_pretrained_as_nested_dict",
          221,
          249,
          249,
          61,
          249,
          84,
          249,
          21,
          249,
          85
        ]
      ],
      "transformers/tests/quantization/torchao_integration/test_torchao.py": [
        [
          "test_repr",
          115,
          120,
          120,
          9,
          120,
          33,
          115,
          19,
          120,
          33
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "get_argument_name",
          3470,
          3479,
          3477,
          20,
          3477,
          35,
          3477,
          20,
          3477,
          35
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "setcomp",
          181,
          181,
          181,
          43,
          181,
          53,
          181,
          60,
          181,
          54
        ],
        [
          "listcomp",
          182,
          183,
          185,
          21,
          185,
          31,
          184,
          17,
          185,
          65
        ]
      ],
      "transformers/src/transformers/utils/attention_visualizer.py": [
        [
          "genexpr",
          56,
          56,
          56,
          31,
          56,
          40,
          56,
          47,
          56,
          41
        ],
        [
          "generate_attention_matrix_from_mask",
          40,
          145,
          118,
          21,
          118,
          30,
          117,
          9,
          119,
          73
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "fix_docstring",
          798,
          870,
          852,
          44,
          852,
          61,
          844,
          20,
          854,
          9
        ],
        [
          "fix_docstring",
          798,
          870,
          853,
          48,
          853,
          72,
          844,
          20,
          854,
          9
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          309,
          30,
          309,
          49,
          297,
          9,
          311,
          53
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          98,
          357,
          298,
          30,
          298,
          49,
          286,
          9,
          300,
          59
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "_serialize_tensor_like_io",
          70,
          116,
          104,
          18,
          104,
          34,
          103,
          9,
          107,
          68
        ],
        [
          "_serialize_tensor_like_io",
          70,
          116,
          103,
          18,
          103,
          34,
          103,
          9,
          107,
          68
        ],
        [
          "_dtensor_repr",
          63,
          67,
          66,
          38,
          66,
          58,
          66,
          16,
          66,
          60
        ],
        [
          "_serialize_tensor_like_io",
          70,
          116,
          110,
          49,
          110,
          66,
          108,
          9,
          115,
          9
        ],
        [
          "_serialize_tensor_like_io",
          70,
          116,
          111,
          48,
          111,
          64,
          108,
          9,
          115,
          9
        ],
        [
          "_serialize_tensor_like_io",
          70,
          116,
          112,
          48,
          112,
          64,
          108,
          9,
          115,
          9
        ],
        [
          "_serialize_tensor_like_io",
          70,
          116,
          113,
          48,
          113,
          64,
          108,
          9,
          115,
          9
        ],
        [
          "_serialize_io",
          119,
          159,
          159,
          36,
          159,
          46,
          159,
          12,
          159,
          47
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "listcomp",
          719,
          719,
          719,
          41,
          719,
          65,
          719,
          73,
          719,
          67
        ]
      ],
      "transformers/src/transformers/safetensors_conversion.py": [
        [
          "spawn_conversion",
          23,
          55,
          55,
          56,
          55,
          62,
          54,
          9,
          55,
          65
        ]
      ],
      "transformers/scripts/stale.py": [
        [
          "main",
          36,
          72,
          56,
          52,
          56,
          58,
          55,
          13,
          56,
          59
        ],
        [
          "main",
          36,
          72,
          72,
          51,
          72,
          57,
          71,
          13,
          72,
          58
        ]
      ],
      "transformers/tests/generation/test_continuous_batching.py": [
        [
          "_continuous_batching_parity",
          134,
          209,
          201,
          28,
          201,
          54,
          199,
          21,
          202,
          21
        ],
        [
          "_continuous_batching_parity",
          134,
          209,
          201,
          63,
          201,
          85,
          199,
          21,
          202,
          21
        ],
        [
          "_continuous_batching_parity",
          134,
          209,
          208,
          32,
          208,
          52,
          204,
          21,
          209,
          21
        ],
        [
          "_continuous_batching_parity",
          134,
          209,
          208,
          61,
          208,
          83,
          204,
          21,
          209,
          21
        ]
      ],
      "transformers/tests/models/aria/test_modeling_aria.py": [
        [
          "test_small_model_integration_test_llama_single",
          279,
          306,
          305,
          26,
          305,
          52,
          279,
          56,
          306,
          9
        ],
        [
          "test_small_model_integration_test_llama_single",
          279,
          306,
          305,
          65,
          305,
          84,
          279,
          56,
          306,
          9
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "test_model_matches_original_20b",
          429,
          492,
          485,
          41,
          485,
          59,
          471,
          17,
          489,
          17
        ],
        [
          "test_model_matches_original_120b",
          494,
          558,
          551,
          41,
          551,
          59,
          537,
          17,
          555,
          17
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py": [
        [
          "test_small_model_integration_test_batch_different_resolutions",
          577,
          617,
          616,
          39,
          616,
          51,
          612,
          13,
          617,
          13
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          577,
          617,
          616,
          95,
          616,
          108,
          612,
          13,
          617,
          13
        ]
      ]
    },
    "warnings.warn": {
      "transformers/src/transformers/pipelines/text_classification.py": [
        [
          "_sanitize_parameters",
          91,
          119,
          104,
          13,
          108,
          13,
          104,
          13,
          109,
          32
        ]
      ],
      "transformers/src/transformers/pipelines/text2text_generation.py": [
        [
          "_sanitize_parameters",
          84,
          124,
          112,
          17,
          115,
          17,
          112,
          17,
          115,
          17
        ]
      ],
      "transformers/src/transformers/pipelines/token_classification.py": [
        [
          "_sanitize_parameters",
          147,
          225,
          177,
          17,
          180,
          17,
          171,
          18,
          181,
          42
        ],
        [
          "_sanitize_parameters",
          147,
          225,
          177,
          17,
          180,
          17,
          176,
          16,
          181,
          42
        ],
        [
          "_sanitize_parameters",
          147,
          225,
          182,
          17,
          185,
          17,
          169,
          16,
          185,
          17
        ],
        [
          "_sanitize_parameters",
          147,
          225,
          182,
          17,
          185,
          17,
          182,
          17,
          185,
          17
        ],
        [
          "gather_pre_entities",
          423,
          493,
          470,
          25,
          473,
          25,
          470,
          25,
          473,
          25
        ]
      ],
      "transformers/src/transformers/models/auto/tokenization_auto.py": [
        [
          "get_tokenizer_config",
          821,
          924,
          892,
          9,
          895,
          9,
          892,
          9,
          896,
          28
        ],
        [
          "from_pretrained",
          943,
          1166,
          1019,
          13,
          1022,
          13,
          1019,
          13,
          1023,
          46
        ]
      ],
      "transformers/src/transformers/models/byt5/tokenization_byt5.py": [
        [
          "_add_eos_if_not_present",
          138,
          147,
          141,
          13,
          144,
          13,
          141,
          13,
          145,
          28
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "_setup_normalizer",
          169,
          176,
          175,
          13,
          175,
          65,
          174,
          9,
          176,
          32
        ]
      ],
      "transformers/src/transformers/tokenization_mistral_common.py": [
        [
          "_get_padding_truncation_strategies",
          941,
          1054,
          976,
          25,
          979,
          25,
          976,
          25,
          979,
          25
        ]
      ],
      "transformers/src/transformers/models/myt5/tokenization_myt5.py": [
        [
          "_add_eos_if_not_present",
          250,
          259,
          253,
          13,
          256,
          13,
          253,
          13,
          257,
          28
        ]
      ],
      "transformers/src/transformers/models/rag/tokenization_rag.py": [
        [
          "prepare_seq2seq_batch",
          77,
          121,
          88,
          9,
          94,
          9,
          78,
          9,
          95,
          29
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "_add_eos_if_not_present",
          193,
          202,
          196,
          13,
          199,
          13,
          196,
          13,
          200,
          28
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "_eventually_correct_t5_max_length",
          218,
          237,
          224,
          17,
          235,
          17,
          223,
          18,
          235,
          17
        ],
        [
          "_add_eos_if_not_present",
          284,
          293,
          287,
          13,
          290,
          13,
          287,
          13,
          291,
          28
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5_fast.py": [
        [
          "_eventually_correct_t5_max_length",
          135,
          154,
          141,
          17,
          152,
          17,
          140,
          18,
          152,
          17
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "_add_eos_if_not_present",
          348,
          357,
          351,
          13,
          354,
          13,
          351,
          13,
          355,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py": [
        [
          "__init__",
          698,
          738,
          711,
          9,
          715,
          9,
          699,
          9,
          738,
          9
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "_normalize",
          405,
          410,
          406,
          9,
          409,
          9,
          405,
          20,
          410,
          35
        ],
        [
          "_basic_normalize",
          413,
          418,
          414,
          9,
          417,
          9,
          413,
          26,
          418,
          78
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "prepare_seq2seq_batch",
          4078,
          4197,
          4166,
          9,
          4166,
          55,
          4079,
          9,
          4170,
          29
        ],
        [
          "words",
          351,
          373,
          368,
          9,
          372,
          9,
          368,
          9,
          373,
          41
        ],
        [
          "from_pretrained",
          1859,
          2128,
          1955,
          13,
          1958,
          13,
          1955,
          13,
          1959,
          32
        ],
        [
          "from_pretrained",
          1859,
          2128,
          1985,
          13,
          1989,
          13,
          1985,
          13,
          1993,
          26
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2517,
          13,
          2520,
          13,
          2517,
          13,
          2521,
          46
        ],
        [
          "_get_padding_truncation_strategies",
          2769,
          2872,
          2798,
          25,
          2801,
          25,
          2798,
          25,
          2801,
          25
        ],
        [
          "as_target_tokenizer",
          4040,
          4054,
          4045,
          9,
          4049,
          9,
          4040,
          29,
          4054,
          36
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "_normalize",
          502,
          507,
          503,
          9,
          506,
          9,
          502,
          20,
          507,
          35
        ],
        [
          "_basic_normalize",
          509,
          514,
          510,
          9,
          513,
          9,
          509,
          26,
          514,
          78
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "reissue_pt_warnings",
          240,
          245,
          245,
          17,
          245,
          52,
          245,
          17,
          245,
          52
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "__init__",
          399,
          764,
          468,
          17,
          473,
          17,
          468,
          17,
          473,
          17
        ],
        [
          "__init__",
          399,
          764,
          716,
          17,
          720,
          17,
          716,
          17,
          721,
          35
        ],
        [
          "_sorted_checkpoints",
          4183,
          4218,
          4204,
          17,
          4204,
          113,
          4204,
          17,
          4207,
          17
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "__post_init__",
          1467,
          1917,
          1764,
          17,
          1764,
          91,
          1764,
          17,
          1764,
          91
        ],
        [
          "__post_init__",
          1467,
          1917,
          1781,
          13,
          1781,
          88,
          1781,
          13,
          1781,
          88
        ],
        [
          "__post_init__",
          1467,
          1917,
          1784,
          13,
          1784,
          103,
          1784,
          13,
          1784,
          103
        ],
        [
          "__post_init__",
          1467,
          1917,
          1806,
          17,
          1806,
          86,
          1806,
          17,
          1806,
          86
        ],
        [
          "__post_init__",
          1467,
          1917,
          1809,
          17,
          1809,
          99,
          1809,
          17,
          1809,
          99
        ]
      ],
      "transformers/src/transformers/generation/utils.py": [
        [
          "_get_logits_processor",
          1068,
          1287,
          1114,
          17,
          1118,
          17,
          1114,
          17,
          1118,
          17
        ],
        [
          "_get_logits_processor",
          1068,
          1287,
          1135,
          17,
          1139,
          17,
          1135,
          17,
          1139,
          17
        ],
        [
          "_validate_generated_length",
          1582,
          1624,
          1587,
          13,
          1592,
          13,
          1587,
          13,
          1592,
          13
        ],
        [
          "_validate_generated_length",
          1582,
          1624,
          1611,
          13,
          1615,
          13,
          1611,
          13,
          1615,
          13
        ],
        [
          "_validate_generated_length",
          1582,
          1624,
          1619,
          17,
          1624,
          17,
          1619,
          17,
          1624,
          17
        ],
        [
          "_prepare_generation_config",
          1682,
          1787,
          1711,
          21,
          1717,
          21,
          1711,
          21,
          1718,
          42
        ],
        [
          "generate",
          2212,
          2559,
          2510,
          13,
          2518,
          13,
          2510,
          13,
          2518,
          13
        ]
      ],
      "transformers/src/transformers/pipelines/video_classification.py": [
        [
          "__call__",
          91,
          138,
          131,
          13,
          134,
          13,
          131,
          13,
          135,
          18
        ]
      ],
      "transformers/src/transformers/models/auto/video_processing_auto.py": [
        [
          "get_video_processor_config",
          105,
          197,
          172,
          9,
          175,
          9,
          172,
          9,
          176,
          28
        ],
        [
          "from_pretrained",
          217,
          365,
          287,
          13,
          290,
          13,
          287,
          13,
          291,
          46
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "from_pretrained",
          439,
          547,
          532,
          13,
          535,
          13,
          532,
          13,
          536,
          32
        ],
        [
          "save_pretrained",
          549,
          608,
          567,
          13,
          570,
          13,
          567,
          13,
          571,
          46
        ],
        [
          "get_video_processor_dict",
          611,
          724,
          641,
          13,
          644,
          13,
          641,
          13,
          645,
          32
        ],
        [
          "fetch_videos",
          865,
          883,
          874,
          13,
          877,
          13,
          874,
          13,
          878,
          19
        ]
      ],
      "transformers/src/transformers/video_utils.py": [
        [
          "read_video_torchvision",
          500,
          555,
          524,
          5,
          527,
          5,
          501,
          5,
          537,
          56
        ]
      ],
      "transformers/src/transformers/pipelines/zero_shot_image_classification.py": [
        [
          "_sanitize_parameters",
          127,
          142,
          136,
          13,
          139,
          13,
          136,
          13,
          140,
          49
        ]
      ],
      "transformers/src/transformers/data/metrics/__init__.py": [
        [
          "simple_accuracy",
          30,
          33,
          31,
          5,
          31,
          53,
          30,
          21,
          33,
          35
        ],
        [
          "acc_and_f1",
          36,
          45,
          37,
          5,
          37,
          53,
          36,
          16,
          45,
          5
        ],
        [
          "pearson_and_spearman",
          48,
          57,
          49,
          5,
          49,
          53,
          48,
          26,
          57,
          5
        ],
        [
          "glue_compute_metrics",
          60,
          87,
          61,
          5,
          61,
          53,
          60,
          26,
          63,
          36
        ],
        [
          "xnli_compute_metrics",
          90,
          98,
          91,
          5,
          91,
          53,
          90,
          26,
          93,
          32
        ]
      ],
      "transformers/src/transformers/pipelines/__init__.py": [
        [
          "get_task",
          344,
          368,
          347,
          9,
          350,
          9,
          347,
          9,
          351,
          28
        ],
        [
          "pipeline",
          514,
          1094,
          702,
          9,
          705,
          9,
          702,
          9,
          706,
          28
        ],
        [
          "pipeline",
          514,
          1094,
          1070,
          17,
          1073,
          17,
          1069,
          24,
          1074,
          21
        ]
      ],
      "transformers/src/transformers/audio_utils.py": [
        [
          "mel_filter_bank",
          442,
          533,
          527,
          9,
          531,
          9,
          527,
          9,
          531,
          9
        ]
      ],
      "transformers/src/transformers/models/auto/auto_factory.py": [
        [
          "from_pretrained",
          251,
          391,
          273,
          13,
          276,
          13,
          273,
          13,
          277,
          32
        ]
      ],
      "transformers/src/transformers/quantizers/auto.py": [
        [
          "merge_quantization_configs",
          193,
          243,
          239,
          13,
          239,
          38,
          239,
          13,
          239,
          38
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "save_pretrained",
          956,
          1024,
          976,
          13,
          979,
          13,
          976,
          13,
          980,
          46
        ]
      ],
      "transformers/src/transformers/integrations/bitsandbytes.py": [
        [
          "replace_8bit_linear",
          274,
          279,
          275,
          5,
          278,
          5,
          274,
          26,
          279,
          51
        ],
        [
          "set_module_8bit_tensor_to_device",
          283,
          288,
          284,
          5,
          287,
          5,
          283,
          39,
          288,
          65
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "check_missing_backends",
          417,
          439,
          434,
          13,
          439,
          13,
          434,
          13,
          439,
          13
        ]
      ],
      "transformers/src/transformers/onnx/config.py": [
        [
          "generate_dummy_inputs",
          283,
          398,
          335,
          13,
          339,
          13,
          335,
          13,
          341,
          24
        ]
      ],
      "transformers/src/transformers/models/beit/configuration_beit.py": [
        [
          "__init__",
          127,
          209,
          197,
          13,
          200,
          13,
          197,
          13,
          201,
          23
        ]
      ],
      "transformers/src/transformers/models/bart/configuration_bart.py": [
        [
          "__init__",
          112,
          180,
          177,
          13,
          180,
          13,
          176,
          40,
          180,
          13
        ]
      ],
      "transformers/src/transformers/models/auto/configuration_auto.py": [
        [
          "from_pretrained",
          1232,
          1381,
          1314,
          13,
          1317,
          13,
          1314,
          13,
          1318,
          46
        ]
      ],
      "transformers/src/transformers/models/llama4/configuration_llama4.py": [
        [
          "vision_feature_layer",
          130,
          135,
          131,
          13,
          134,
          13,
          130,
          34,
          135,
          45
        ]
      ],
      "transformers/src/transformers/models/mvp/configuration_mvp.py": [
        [
          "__init__",
          109,
          180,
          177,
          13,
          180,
          13,
          176,
          40,
          180,
          13
        ]
      ],
      "transformers/src/transformers/models/segformer/configuration_segformer.py": [
        [
          "__init__",
          99,
          148,
          124,
          13,
          128,
          13,
          124,
          13,
          128,
          13
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "save_pretrained",
          695,
          766,
          730,
          13,
          734,
          13,
          730,
          13,
          735,
          46
        ],
        [
          "from_pretrained",
          769,
          945,
          870,
          13,
          873,
          13,
          870,
          13,
          874,
          32
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "__init__",
          207,
          345,
          333,
          13,
          337,
          13,
          333,
          13,
          337,
          13
        ],
        [
          "save_pretrained",
          432,
          494,
          455,
          13,
          462,
          13,
          455,
          13,
          462,
          13
        ],
        [
          "_set_token_in_kwargs",
          497,
          521,
          510,
          13,
          513,
          13,
          510,
          13,
          514,
          32
        ],
        [
          "from_text_vision_configs",
          1261,
          1276,
          1270,
          9,
          1274,
          9,
          1261,
          34,
          1276,
          102
        ],
        [
          "from_text_audio_configs",
          1279,
          1294,
          1288,
          9,
          1292,
          9,
          1279,
          33,
          1294,
          100
        ]
      ],
      "transformers/src/transformers/models/xlnet/configuration_xlnet.py": [
        [
          "__init__",
          143,
          221,
          212,
          13,
          216,
          13,
          212,
          13,
          217,
          25
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "_check_layer_entries",
          562,
          571,
          567,
          13,
          567,
          97,
          567,
          13,
          567,
          97
        ],
        [
          "_check_layer_entries",
          562,
          571,
          569,
          13,
          569,
          97,
          569,
          13,
          569,
          97
        ],
        [
          "_check_layer_entries",
          562,
          571,
          571,
          13,
          571,
          97,
          571,
          13,
          571,
          97
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_get_generation_config",
          65,
          93,
          85,
          9,
          91,
          9,
          82,
          15,
          93,
          18
        ],
        [
          "_download",
          147,
          182,
          162,
          13,
          162,
          119,
          162,
          13,
          162,
          119
        ]
      ],
      "transformers/src/transformers/convert_slow_tokenizer.py": [
        [
          "__init__",
          550,
          569,
          564,
          13,
          569,
          13,
          564,
          13,
          569,
          13
        ]
      ],
      "transformers/src/transformers/utils/deprecation.py": [
        [
          "wrapped_func",
          121,
          172,
          170,
          17,
          170,
          67,
          170,
          17,
          170,
          67
        ]
      ],
      "transformers/src/transformers/data/data_collator.py": [
        [
          "__post_init__",
          692,
          732,
          719,
          17,
          722,
          17,
          719,
          17,
          722,
          17
        ],
        [
          "__post_init__",
          692,
          732,
          725,
          17,
          728,
          17,
          725,
          17,
          730,
          40
        ],
        [
          "__init__",
          1027,
          1035,
          1028,
          9,
          1032,
          9,
          1027,
          18,
          1035,
          28
        ],
        [
          "__init__",
          1064,
          1069,
          1065,
          9,
          1069,
          9,
          1064,
          18,
          1069,
          9
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_cached_module_file",
          316,
          485,
          376,
          9,
          379,
          9,
          376,
          9,
          380,
          28
        ],
        [
          "get_class_from_dynamic_module",
          488,
          605,
          576,
          9,
          579,
          9,
          576,
          9,
          580,
          28
        ]
      ],
      "transformers/src/transformers/models/auto/feature_extraction_auto.py": [
        [
          "get_feature_extractor_config",
          106,
          201,
          173,
          9,
          176,
          9,
          173,
          9,
          177,
          28
        ],
        [
          "from_pretrained",
          220,
          353,
          290,
          13,
          293,
          13,
          290,
          13,
          294,
          46
        ]
      ],
      "transformers/src/transformers/models/speecht5/feature_extraction_speecht5.py": [
        [
          "__init__",
          78,
          136,
          133,
          13,
          136,
          13,
          133,
          13,
          136,
          13
        ],
        [
          "__init__",
          78,
          136,
          128,
          13,
          131,
          13,
          128,
          13,
          131,
          13
        ]
      ],
      "transformers/src/transformers/models/pop2piano/feature_extraction_pop2piano.py": [
        [
          "__call__",
          344,
          452,
          411,
          21,
          416,
          21,
          411,
          21,
          416,
          21
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "from_pretrained",
          247,
          353,
          338,
          13,
          341,
          13,
          338,
          13,
          342,
          32
        ],
        [
          "save_pretrained",
          355,
          414,
          373,
          13,
          376,
          13,
          373,
          13,
          377,
          46
        ],
        [
          "get_feature_extractor_dict",
          417,
          529,
          441,
          13,
          444,
          13,
          441,
          13,
          445,
          32
        ]
      ],
      "transformers/src/transformers/models/whisper/generation_whisper.py": [
        [
          "generate",
          386,
          979,
          655,
          13,
          658,
          13,
          654,
          30,
          658,
          13
        ]
      ],
      "transformers/src/transformers/data/datasets/glue.py": [
        [
          "__init__",
          76,
          149,
          84,
          9,
          89,
          9,
          77,
          9,
          93,
          32
        ]
      ],
      "transformers/src/transformers/data/processors/glue.py": [
        [
          "__init__",
          238,
          240,
          240,
          9,
          240,
          77,
          238,
          18,
          240,
          77
        ],
        [
          "glue_convert_examples_to_features",
          37,
          63,
          60,
          5,
          60,
          72,
          38,
          5,
          63,
          5
        ],
        [
          "__init__",
          129,
          131,
          131,
          9,
          131,
          77,
          129,
          18,
          131,
          77
        ],
        [
          "__init__",
          176,
          178,
          178,
          9,
          178,
          77,
          176,
          18,
          178,
          77
        ],
        [
          "__init__",
          222,
          224,
          224,
          9,
          224,
          77,
          222,
          18,
          224,
          77
        ],
        [
          "__init__",
          285,
          287,
          287,
          9,
          287,
          77,
          285,
          18,
          287,
          77
        ],
        [
          "__init__",
          331,
          333,
          333,
          9,
          333,
          77,
          331,
          18,
          333,
          77
        ],
        [
          "__init__",
          377,
          379,
          379,
          9,
          379,
          77,
          377,
          18,
          379,
          77
        ],
        [
          "__init__",
          429,
          431,
          431,
          9,
          431,
          77,
          429,
          18,
          431,
          77
        ],
        [
          "__init__",
          475,
          477,
          477,
          9,
          477,
          77,
          475,
          18,
          477,
          77
        ],
        [
          "__init__",
          521,
          523,
          523,
          9,
          523,
          77,
          521,
          18,
          523,
          77
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "wrapper",
          619,
          648,
          641,
          17,
          646,
          17,
          641,
          17,
          646,
          17
        ],
        [
          "wrapper",
          799,
          969,
          869,
          21,
          873,
          21,
          869,
          21,
          873,
          21
        ]
      ],
      "transformers/src/transformers/utils/fx.py": [
        [
          "create_proxy",
          1065,
          1132,
          1127,
          17,
          1127,
          92,
          1127,
          17,
          1127,
          92
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "has_file",
          609,
          701,
          635,
          9,
          638,
          9,
          635,
          9,
          639,
          28
        ],
        [
          "cached_files",
          319,
          579,
          400,
          9,
          403,
          9,
          400,
          9,
          404,
          28
        ],
        [
          "download_url",
          582,
          606,
          596,
          5,
          602,
          5,
          582,
          18,
          606,
          19
        ],
        [
          "_create_repo",
          709,
          742,
          722,
          13,
          725,
          13,
          722,
          13,
          726,
          34
        ],
        [
          "_create_repo",
          709,
          742,
          732,
          13,
          735,
          13,
          732,
          13,
          736,
          51
        ],
        [
          "push_to_hub",
          829,
          975,
          898,
          13,
          901,
          13,
          898,
          13,
          902,
          32
        ],
        [
          "push_to_hub",
          829,
          975,
          912,
          13,
          916,
          13,
          912,
          13,
          917,
          34
        ],
        [
          "get_checkpoint_shard_files",
          1011,
          1078,
          1038,
          9,
          1041,
          9,
          1038,
          9,
          1042,
          28
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "get_image_processor_dict",
          264,
          382,
          297,
          13,
          300,
          13,
          297,
          13,
          301,
          32
        ],
        [
          "from_pretrained",
          92,
          200,
          185,
          13,
          188,
          13,
          185,
          13,
          189,
          32
        ],
        [
          "save_pretrained",
          202,
          261,
          220,
          13,
          223,
          13,
          220,
          13,
          224,
          46
        ]
      ],
      "transformers/src/transformers/models/auto/image_processing_auto.py": [
        [
          "from_pretrained",
          365,
          618,
          441,
          13,
          444,
          13,
          441,
          13,
          445,
          46
        ],
        [
          "get_image_processor_config",
          243,
          338,
          310,
          9,
          313,
          9,
          310,
          9,
          314,
          28
        ],
        [
          "register",
          621,
          677,
          639,
          13,
          642,
          13,
          639,
          13,
          643,
          38
        ]
      ],
      "transformers/src/transformers/models/lightglue/image_processing_lightglue.py": [
        [
          "plot_keypoint_matching",
          464,
          517,
          479,
          9,
          483,
          9,
          464,
          32,
          485,
          36
        ]
      ],
      "transformers/src/transformers/models/maskformer/image_processing_maskformer.py": [
        [
          "post_process_segmentation",
          992,
          1038,
          1010,
          9,
          1014,
          9,
          993,
          9,
          1020,
          34
        ]
      ],
      "transformers/src/transformers/models/maskformer/image_processing_maskformer_fast.py": [
        [
          "post_process_segmentation",
          406,
          452,
          424,
          9,
          428,
          9,
          407,
          9,
          434,
          34
        ]
      ],
      "transformers/src/transformers/models/owlv2/image_processing_owlv2.py": [
        [
          "resize",
          301,
          366,
          350,
          21,
          352,
          21,
          350,
          21,
          352,
          21
        ]
      ],
      "transformers/src/transformers/models/owlvit/image_processing_owlvit_fast.py": [
        [
          "post_process",
          52,
          95,
          68,
          9,
          72,
          9,
          52,
          22,
          76,
          43
        ]
      ],
      "transformers/src/transformers/models/owlvit/image_processing_owlvit.py": [
        [
          "post_process",
          443,
          486,
          459,
          9,
          463,
          9,
          443,
          22,
          467,
          43
        ]
      ],
      "transformers/src/transformers/models/owlv2/image_processing_owlv2_fast.py": [
        [
          "resize",
          268,
          322,
          305,
          21,
          307,
          21,
          305,
          21,
          307,
          21
        ],
        [
          "post_process",
          56,
          99,
          72,
          9,
          76,
          9,
          56,
          22,
          80,
          43
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          110,
          129,
          111,
          9,
          116,
          9,
          110,
          18,
          117,
          45
        ],
        [
          "__init__",
          187,
          226,
          188,
          9,
          193,
          9,
          187,
          18,
          194,
          43
        ],
        [
          "__init__",
          41,
          100,
          49,
          9,
          54,
          9,
          42,
          9,
          55,
          45
        ],
        [
          "__init__",
          139,
          173,
          140,
          9,
          145,
          9,
          139,
          18,
          146,
          45
        ],
        [
          "__init__",
          335,
          418,
          344,
          9,
          349,
          9,
          336,
          9,
          350,
          40
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "__init__",
          91,
          112,
          92,
          9,
          94,
          9,
          91,
          18,
          107,
          40
        ]
      ],
      "transformers/src/transformers/models/beit/modeling_beit.py": [
        [
          "forward",
          162,
          192,
          169,
          13,
          172,
          13,
          169,
          13,
          172,
          13
        ]
      ],
      "transformers/src/transformers/models/bart/modeling_bart.py": [
        [
          "__init_subclass__",
          701,
          705,
          702,
          9,
          705,
          9,
          701,
          27,
          705,
          9
        ],
        [
          "__init_subclass__",
          709,
          713,
          710,
          9,
          713,
          9,
          709,
          27,
          713,
          9
        ]
      ],
      "transformers/src/transformers/models/bark/modeling_bark.py": [
        [
          "enable_cpu_offload",
          1365,
          1421,
          1389,
          13,
          1392,
          13,
          1389,
          13,
          1393,
          26
        ]
      ],
      "transformers/src/transformers/models/bert/modeling_bert.py": [
        [
          "forward",
          1171,
          1240,
          1209,
          13,
          1213,
          13,
          1209,
          13,
          1214,
          18
        ]
      ],
      "transformers/src/transformers/models/auto/modeling_auto.py": [
        [
          "from_config",
          2252,
          2259,
          2253,
          9,
          2258,
          9,
          2252,
          21,
          2259,
          52
        ],
        [
          "from_pretrained",
          2262,
          2269,
          2263,
          9,
          2268,
          9,
          2262,
          25,
          2269,
          92
        ],
        [
          "from_config",
          2274,
          2280,
          2275,
          9,
          2279,
          9,
          2274,
          21,
          2280,
          52
        ],
        [
          "from_pretrained",
          2283,
          2289,
          2284,
          9,
          2288,
          9,
          2283,
          25,
          2289,
          92
        ]
      ],
      "transformers/src/transformers/models/blenderbot/modeling_blenderbot.py": [
        [
          "from_pretrained",
          1074,
          1084,
          1076,
          13,
          1081,
          13,
          1076,
          13,
          1082,
          86
        ],
        [
          "from_pretrained",
          1220,
          1230,
          1222,
          13,
          1227,
          13,
          1222,
          13,
          1228,
          105
        ]
      ],
      "transformers/src/transformers/models/blip/modeling_blip.py": [
        [
          "decoder_logits",
          88,
          94,
          89,
          9,
          93,
          9,
          88,
          24,
          94,
          26
        ]
      ],
      "transformers/src/transformers/models/blip_2/modeling_blip_2.py": [
        [
          "get_text_features",
          1110,
          1180,
          1157,
          13,
          1161,
          13,
          1157,
          13,
          1161,
          13
        ],
        [
          "get_image_features",
          1184,
          1227,
          1215,
          13,
          1219,
          13,
          1215,
          13,
          1219,
          13
        ],
        [
          "get_qformer_features",
          1231,
          1289,
          1264,
          13,
          1268,
          13,
          1264,
          13,
          1268,
          13
        ]
      ],
      "transformers/src/transformers/models/bloom/modeling_bloom.py": [
        [
          "forward",
          483,
          597,
          511,
          13,
          515,
          13,
          511,
          13,
          515,
          13
        ],
        [
          "forward",
          814,
          896,
          849,
          13,
          853,
          13,
          849,
          13,
          853,
          13
        ],
        [
          "forward",
          924,
          1035,
          956,
          13,
          960,
          13,
          956,
          13,
          960,
          13
        ],
        [
          "forward",
          1058,
          1134,
          1090,
          13,
          1094,
          13,
          1090,
          13,
          1094,
          13
        ]
      ],
      "transformers/src/transformers/models/data2vec/modeling_data2vec_vision.py": [
        [
          "forward",
          161,
          191,
          168,
          13,
          171,
          13,
          168,
          13,
          171,
          13
        ]
      ],
      "transformers/src/transformers/models/data2vec/modeling_data2vec_audio.py": [
        [
          "freeze_feature_extractor",
          862,
          872,
          867,
          9,
          871,
          9,
          862,
          34,
          872,
          37
        ],
        [
          "freeze_feature_extractor",
          977,
          987,
          982,
          9,
          986,
          9,
          977,
          34,
          987,
          37
        ],
        [
          "freeze_feature_extractor",
          1092,
          1102,
          1097,
          9,
          1101,
          9,
          1092,
          34,
          1102,
          37
        ],
        [
          "forward",
          1214,
          1232,
          1220,
          17,
          1223,
          17,
          1220,
          17,
          1223,
          17
        ],
        [
          "freeze_feature_extractor",
          1260,
          1270,
          1265,
          9,
          1269,
          9,
          1260,
          34,
          1270,
          37
        ]
      ],
      "transformers/src/transformers/models/deepseek_v2/modeling_deepseek_v2.py": [
        [
          "forward",
          307,
          372,
          318,
          13,
          320,
          13,
          318,
          13,
          320,
          13
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/modeling_deformable_detr.py": [
        [
          "__init__",
          489,
          519,
          501,
          13,
          505,
          13,
          500,
          12,
          505,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/modeling_deta.py": [
        [
          "__init__",
          571,
          608,
          588,
          13,
          592,
          13,
          587,
          12,
          592,
          13
        ]
      ],
      "transformers/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py": [
        [
          "forward",
          345,
          487,
          472,
          13,
          472,
          61,
          456,
          27,
          487,
          9
        ]
      ],
      "transformers/src/transformers/models/ernie/modeling_ernie.py": [
        [
          "forward",
          1260,
          1336,
          1304,
          13,
          1308,
          13,
          1304,
          13,
          1309,
          18
        ]
      ],
      "transformers/src/transformers/models/fnet/modeling_fnet.py": [
        [
          "forward",
          706,
          777,
          742,
          13,
          746,
          13,
          742,
          13,
          747,
          18
        ]
      ],
      "transformers/src/transformers/models/grounding_dino/modeling_grounding_dino.py": [
        [
          "__init__",
          521,
          551,
          533,
          13,
          537,
          13,
          532,
          12,
          537,
          13
        ]
      ],
      "transformers/src/transformers/models/hubert/modeling_hubert.py": [
        [
          "freeze_feature_extractor",
          1056,
          1066,
          1061,
          9,
          1065,
          9,
          1056,
          34,
          1066,
          37
        ],
        [
          "freeze_feature_extractor",
          1179,
          1189,
          1184,
          9,
          1188,
          9,
          1179,
          34,
          1189,
          37
        ]
      ],
      "transformers/src/transformers/models/led/modeling_led.py": [
        [
          "__init__",
          2121,
          2138,
          2122,
          9,
          2127,
          9,
          2121,
          18,
          2138,
          24
        ]
      ],
      "transformers/src/transformers/models/lxmert/modeling_lxmert.py": [
        [
          "forward",
          1003,
          1149,
          1059,
          13,
          1063,
          13,
          1059,
          13,
          1064,
          18
        ]
      ],
      "transformers/src/transformers/models/megatron_bert/modeling_megatron_bert.py": [
        [
          "forward",
          1080,
          1158,
          1120,
          13,
          1124,
          13,
          1120,
          13,
          1125,
          18
        ]
      ],
      "transformers/src/transformers/models/mask2former/modeling_mask2former.py": [
        [
          "__init__",
          894,
          919,
          903,
          13,
          907,
          13,
          902,
          12,
          907,
          13
        ]
      ],
      "transformers/src/transformers/models/mm_grounding_dino/modeling_mm_grounding_dino.py": [
        [
          "__init__",
          154,
          184,
          166,
          13,
          170,
          13,
          165,
          12,
          170,
          13
        ]
      ],
      "transformers/src/transformers/models/mobilebert/modeling_mobilebert.py": [
        [
          "forward",
          916,
          983,
          953,
          13,
          957,
          13,
          953,
          13,
          958,
          18
        ]
      ],
      "transformers/src/transformers/models/deprecated/nezha/modeling_nezha.py": [
        [
          "forward",
          1116,
          1195,
          1158,
          13,
          1162,
          13,
          1158,
          13,
          1163,
          18
        ]
      ],
      "transformers/src/transformers/models/omdet_turbo/modeling_omdet_turbo.py": [
        [
          "__init__",
          300,
          330,
          312,
          13,
          316,
          13,
          311,
          12,
          316,
          13
        ]
      ],
      "transformers/src/transformers/modeling_outputs.py": [
        [
          "logits",
          1711,
          1717,
          1712,
          9,
          1716,
          9,
          1711,
          16,
          1717,
          34
        ]
      ],
      "transformers/src/transformers/models/oneformer/modeling_oneformer.py": [
        [
          "__init__",
          980,
          1005,
          989,
          13,
          993,
          13,
          988,
          12,
          993,
          13
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/modeling_phi4_multimodal.py": [
        [
          "_trunc_normal_",
          212,
          245,
          220,
          9,
          224,
          9,
          220,
          9,
          224,
          9
        ]
      ],
      "transformers/src/transformers/models/prophetnet/modeling_prophetnet.py": [
        [
          "decoder_cross_attentions",
          166,
          172,
          167,
          9,
          171,
          9,
          166,
          34,
          172,
          36
        ],
        [
          "decoder_cross_attentions",
          225,
          231,
          226,
          9,
          230,
          9,
          225,
          34,
          231,
          36
        ]
      ],
      "transformers/src/transformers/models/deprecated/qdqbert/modeling_qdqbert.py": [
        [
          "forward",
          1162,
          1242,
          1204,
          13,
          1208,
          13,
          1204,
          13,
          1209,
          18
        ]
      ],
      "transformers/src/transformers/models/rt_detr/modeling_rt_detr.py": [
        [
          "__init__",
          669,
          699,
          681,
          13,
          685,
          13,
          680,
          12,
          685,
          13
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py": [
        [
          "__init__",
          122,
          161,
          134,
          13,
          138,
          13,
          133,
          12,
          138,
          13
        ]
      ],
      "transformers/src/transformers/models/sew/modeling_sew.py": [
        [
          "freeze_feature_extractor",
          878,
          888,
          883,
          9,
          887,
          9,
          878,
          34,
          888,
          37
        ],
        [
          "freeze_feature_extractor",
          1001,
          1011,
          1006,
          9,
          1010,
          9,
          1001,
          34,
          1011,
          37
        ]
      ],
      "transformers/src/transformers/models/sew_d/modeling_sew_d.py": [
        [
          "__init__",
          438,
          445,
          440,
          9,
          445,
          9,
          438,
          18,
          445,
          9
        ],
        [
          "freeze_feature_extractor",
          1432,
          1442,
          1437,
          9,
          1441,
          9,
          1432,
          34,
          1442,
          37
        ],
        [
          "freeze_feature_extractor",
          1556,
          1566,
          1561,
          9,
          1565,
          9,
          1556,
          34,
          1566,
          37
        ]
      ],
      "transformers/src/transformers/models/siglip2/modeling_siglip2.py": [
        [
          "_trunc_normal_",
          444,
          477,
          452,
          9,
          456,
          9,
          452,
          9,
          456,
          9
        ]
      ],
      "transformers/src/transformers/models/siglip/modeling_siglip.py": [
        [
          "_trunc_normal_",
          45,
          78,
          53,
          9,
          57,
          9,
          53,
          9,
          57,
          9
        ]
      ],
      "transformers/src/transformers/models/swin/modeling_swin.py": [
        [
          "logits",
          116,
          122,
          117,
          9,
          121,
          9,
          116,
          16,
          122,
          34
        ]
      ],
      "transformers/src/transformers/models/swinv2/modeling_swinv2.py": [
        [
          "logits",
          119,
          125,
          120,
          9,
          124,
          9,
          119,
          16,
          125,
          34
        ]
      ],
      "transformers/examples/modular-transformers/modeling_test_detr.py": [
        [
          "__init__",
          376,
          406,
          388,
          13,
          392,
          13,
          387,
          12,
          392,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py": [
        [
          "__init__",
          847,
          871,
          854,
          13,
          859,
          13,
          854,
          13,
          859,
          13
        ]
      ],
      "transformers/src/transformers/models/unispeech/modeling_unispeech.py": [
        [
          "freeze_feature_extractor",
          1115,
          1125,
          1120,
          9,
          1124,
          9,
          1115,
          34,
          1125,
          37
        ],
        [
          "freeze_feature_extractor",
          1285,
          1295,
          1290,
          9,
          1294,
          9,
          1285,
          34,
          1295,
          37
        ],
        [
          "freeze_feature_extractor",
          1408,
          1418,
          1413,
          9,
          1417,
          9,
          1408,
          34,
          1418,
          37
        ]
      ],
      "transformers/src/transformers/models/unispeech_sat/modeling_unispeech_sat.py": [
        [
          "freeze_feature_extractor",
          1126,
          1136,
          1131,
          9,
          1135,
          9,
          1126,
          34,
          1136,
          37
        ],
        [
          "freeze_feature_extractor",
          1280,
          1290,
          1285,
          9,
          1289,
          9,
          1280,
          34,
          1290,
          37
        ],
        [
          "freeze_feature_extractor",
          1403,
          1413,
          1408,
          9,
          1412,
          9,
          1403,
          34,
          1413,
          37
        ],
        [
          "freeze_feature_extractor",
          1518,
          1528,
          1523,
          9,
          1527,
          9,
          1518,
          34,
          1528,
          37
        ],
        [
          "forward",
          1640,
          1658,
          1646,
          17,
          1649,
          17,
          1646,
          17,
          1649,
          17
        ],
        [
          "freeze_feature_extractor",
          1686,
          1696,
          1691,
          9,
          1695,
          9,
          1686,
          34,
          1696,
          37
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "create_extended_attention_mask_for_decoder",
          1530,
          1554,
          1532,
          13,
          1534,
          13,
          1532,
          13,
          1534,
          13
        ],
        [
          "get_extended_attention_mask",
          1556,
          1610,
          1581,
          17,
          1583,
          17,
          1581,
          17,
          1583,
          17
        ],
        [
          "tp_plan",
          2073,
          2120,
          2115,
          33,
          2118,
          33,
          2115,
          33,
          2118,
          33
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3715,
          13,
          3718,
          13,
          3715,
          13,
          3719,
          32
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3744,
          13,
          3746,
          13,
          3744,
          13,
          3747,
          27
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3795,
          21,
          3800,
          21,
          3795,
          21,
          3801,
          90
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3847,
          17,
          3849,
          17,
          3847,
          17,
          3850,
          65
        ],
        [
          "from_pretrained",
          4261,
          4989,
          4572,
          13,
          4575,
          13,
          4572,
          13,
          4576,
          32
        ]
      ],
      "transformers/src/transformers/models/voxtral/modeling_voxtral.py": [
        [
          "get_audio_embeds",
          445,
          449,
          446,
          9,
          448,
          9,
          445,
          26,
          449,
          54
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py": [
        [
          "__init__",
          433,
          440,
          435,
          9,
          440,
          9,
          433,
          18,
          440,
          9
        ],
        [
          "load_adapter",
          1139,
          1325,
          1216,
          13,
          1219,
          13,
          1216,
          13,
          1220,
          32
        ],
        [
          "freeze_feature_extractor",
          1350,
          1360,
          1355,
          9,
          1359,
          9,
          1350,
          34,
          1360,
          37
        ],
        [
          "freeze_feature_extractor",
          1499,
          1509,
          1504,
          9,
          1508,
          9,
          1499,
          34,
          1509,
          37
        ],
        [
          "__init__",
          1701,
          1713,
          1704,
          9,
          1706,
          9,
          1701,
          18,
          1713,
          24
        ],
        [
          "freeze_feature_extractor",
          1801,
          1811,
          1806,
          9,
          1810,
          9,
          1801,
          34,
          1811,
          37
        ],
        [
          "freeze_feature_extractor",
          1924,
          1934,
          1929,
          9,
          1933,
          9,
          1924,
          34,
          1934,
          37
        ],
        [
          "freeze_feature_extractor",
          2039,
          2049,
          2044,
          9,
          2048,
          9,
          2039,
          34,
          2049,
          37
        ],
        [
          "forward",
          2161,
          2179,
          2167,
          17,
          2170,
          17,
          2167,
          17,
          2170,
          17
        ],
        [
          "freeze_feature_extractor",
          2207,
          2217,
          2212,
          9,
          2216,
          9,
          2207,
          34,
          2217,
          37
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py": [
        [
          "forward",
          1362,
          1380,
          1368,
          17,
          1371,
          17,
          1368,
          17,
          1371,
          17
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py": [
        [
          "forward",
          1761,
          1779,
          1767,
          17,
          1770,
          17,
          1767,
          17,
          1770,
          17
        ]
      ],
      "transformers/src/transformers/models/wavlm/modeling_wavlm.py": [
        [
          "forward",
          1528,
          1546,
          1534,
          17,
          1537,
          17,
          1534,
          17,
          1537,
          17
        ],
        [
          "freeze_feature_extractor",
          985,
          995,
          990,
          9,
          994,
          9,
          985,
          34,
          995,
          37
        ],
        [
          "freeze_feature_extractor",
          1168,
          1178,
          1173,
          9,
          1177,
          9,
          1168,
          34,
          1178,
          37
        ],
        [
          "freeze_feature_extractor",
          1291,
          1301,
          1296,
          9,
          1300,
          9,
          1291,
          34,
          1301,
          37
        ],
        [
          "freeze_feature_extractor",
          1406,
          1416,
          1411,
          9,
          1415,
          9,
          1406,
          34,
          1416,
          37
        ],
        [
          "freeze_feature_extractor",
          1574,
          1584,
          1579,
          9,
          1583,
          9,
          1574,
          34,
          1584,
          37
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py": [
        [
          "decoder_cross_attentions",
          302,
          308,
          303,
          9,
          307,
          9,
          302,
          34,
          308,
          36
        ],
        [
          "decoder_cross_attentions",
          388,
          394,
          389,
          9,
          393,
          9,
          388,
          34,
          394,
          36
        ]
      ],
      "transformers/src/transformers/models/xlnet/modeling_xlnet.py": [
        [
          "forward",
          997,
          1232,
          1054,
          13,
          1058,
          13,
          1054,
          13,
          1059,
          20
        ]
      ],
      "transformers/src/transformers/models/deepseek_v2/modular_deepseek_v2.py": [
        [
          "forward",
          358,
          423,
          369,
          13,
          371,
          13,
          369,
          13,
          371,
          13
        ]
      ],
      "transformers/src/transformers/models/ernie/modular_ernie.py": [
        [
          "forward",
          611,
          687,
          655,
          13,
          659,
          13,
          655,
          13,
          660,
          18
        ]
      ],
      "transformers/src/transformers/models/lightglue/modular_lightglue.py": [
        [
          "plot_keypoint_matching",
          291,
          344,
          306,
          9,
          310,
          9,
          291,
          32,
          312,
          36
        ]
      ],
      "transformers/src/transformers/models/owlv2/modular_owlv2.py": [
        [
          "resize",
          92,
          146,
          129,
          21,
          131,
          21,
          129,
          21,
          131,
          21
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/modular_rt_detr_v2.py": [
        [
          "__init__",
          479,
          518,
          491,
          13,
          495,
          13,
          490,
          12,
          495,
          13
        ]
      ],
      "transformers/src/transformers/models/unispeech/modular_unispeech.py": [
        [
          "freeze_feature_extractor",
          320,
          330,
          325,
          9,
          329,
          9,
          320,
          34,
          330,
          37
        ]
      ],
      "transformers/src/transformers/models/unispeech_sat/modular_unispeech_sat.py": [
        [
          "freeze_feature_extractor",
          338,
          348,
          343,
          9,
          347,
          9,
          338,
          34,
          348,
          37
        ]
      ],
      "transformers/src/transformers/models/voxtral/modular_voxtral.py": [
        [
          "get_audio_embeds",
          190,
          194,
          191,
          9,
          193,
          9,
          190,
          26,
          194,
          54
        ]
      ],
      "transformers/src/transformers/optimization.py": [
        [
          "get_wsd_schedule",
          506,
          576,
          555,
          9,
          555,
          115,
          555,
          9,
          555,
          115
        ]
      ],
      "transformers/src/transformers/models/chinese_clip/processing_chinese_clip.py": [
        [
          "__init__",
          43,
          56,
          46,
          13,
          50,
          13,
          46,
          13,
          51,
          29
        ],
        [
          "feature_extractor_class",
          59,
          64,
          60,
          9,
          63,
          9,
          59,
          33,
          64,
          41
        ]
      ],
      "transformers/src/transformers/models/clip/processing_clip.py": [
        [
          "__init__",
          42,
          54,
          45,
          13,
          49,
          13,
          45,
          13,
          50,
          29
        ],
        [
          "feature_extractor_class",
          57,
          62,
          58,
          9,
          61,
          9,
          57,
          33,
          62,
          41
        ],
        [
          "feature_extractor",
          65,
          70,
          66,
          9,
          69,
          9,
          65,
          27,
          70,
          35
        ]
      ],
      "transformers/src/transformers/models/clipseg/processing_clipseg.py": [
        [
          "feature_extractor",
          136,
          141,
          137,
          9,
          140,
          9,
          136,
          27,
          141,
          35
        ],
        [
          "feature_extractor_class",
          128,
          133,
          129,
          9,
          132,
          9,
          128,
          33,
          133,
          41
        ],
        [
          "__init__",
          43,
          55,
          46,
          13,
          50,
          13,
          46,
          13,
          51,
          29
        ]
      ],
      "transformers/src/transformers/models/donut/processing_donut.py": [
        [
          "feature_extractor",
          202,
          207,
          203,
          9,
          206,
          9,
          202,
          27,
          207,
          35
        ],
        [
          "__init__",
          57,
          71,
          60,
          13,
          64,
          13,
          60,
          13,
          65,
          29
        ],
        [
          "as_target_processor",
          120,
          133,
          124,
          9,
          128,
          9,
          120,
          29,
          133,
          39
        ],
        [
          "feature_extractor_class",
          194,
          199,
          195,
          9,
          198,
          9,
          194,
          33,
          199,
          41
        ]
      ],
      "transformers/src/transformers/models/flava/processing_flava.py": [
        [
          "feature_extractor_class",
          55,
          60,
          56,
          9,
          59,
          9,
          55,
          33,
          60,
          41
        ],
        [
          "feature_extractor",
          63,
          68,
          64,
          9,
          67,
          9,
          63,
          27,
          68,
          35
        ],
        [
          "__init__",
          40,
          52,
          43,
          13,
          47,
          13,
          43,
          13,
          48,
          29
        ]
      ],
      "transformers/src/transformers/models/auto/processing_auto.py": [
        [
          "from_pretrained",
          204,
          425,
          270,
          13,
          273,
          13,
          270,
          13,
          274,
          46
        ]
      ],
      "transformers/src/transformers/models/grounding_dino/processing_grounding_dino.py": [
        [
          "__getitem__",
          90,
          93,
          92,
          13,
          92,
          54,
          92,
          13,
          92,
          54
        ],
        [
          "get",
          95,
          98,
          97,
          13,
          97,
          54,
          97,
          13,
          97,
          54
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/processing_layoutlmv2.py": [
        [
          "feature_extractor_class",
          170,
          175,
          171,
          9,
          174,
          9,
          170,
          33,
          175,
          41
        ],
        [
          "__init__",
          51,
          63,
          54,
          13,
          58,
          13,
          54,
          13,
          59,
          29
        ],
        [
          "feature_extractor",
          178,
          183,
          179,
          9,
          182,
          9,
          178,
          27,
          183,
          35
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/processing_layoutlmv3.py": [
        [
          "feature_extractor_class",
          168,
          173,
          169,
          9,
          172,
          9,
          168,
          33,
          173,
          41
        ],
        [
          "__init__",
          51,
          63,
          54,
          13,
          58,
          13,
          54,
          13,
          59,
          29
        ],
        [
          "feature_extractor",
          176,
          181,
          177,
          9,
          180,
          9,
          176,
          27,
          181,
          35
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/processing_layoutxlm.py": [
        [
          "feature_extractor",
          177,
          182,
          178,
          9,
          181,
          9,
          177,
          27,
          182,
          35
        ],
        [
          "feature_extractor_class",
          169,
          174,
          170,
          9,
          173,
          9,
          169,
          33,
          174,
          41
        ],
        [
          "__init__",
          51,
          62,
          53,
          13,
          57,
          13,
          53,
          13,
          58,
          29
        ]
      ],
      "transformers/src/transformers/models/deprecated/mctct/processing_mctct.py": [
        [
          "__call__",
          47,
          83,
          59,
          13,
          59,
          105,
          59,
          13,
          60,
          17
        ],
        [
          "as_target_processor",
          123,
          136,
          127,
          9,
          131,
          9,
          123,
          29,
          136,
          39
        ]
      ],
      "transformers/src/transformers/models/omdet_turbo/processing_omdet_turbo.py": [
        [
          "__getitem__",
          77,
          81,
          79,
          13,
          79,
          54,
          79,
          13,
          80,
          53
        ],
        [
          "get",
          83,
          87,
          85,
          13,
          85,
          54,
          85,
          13,
          86,
          62
        ]
      ],
      "transformers/src/transformers/models/mgp_str/processing_mgp_str.py": [
        [
          "__init__",
          59,
          75,
          62,
          13,
          66,
          13,
          62,
          13,
          67,
          29
        ]
      ],
      "transformers/src/transformers/models/owlv2/processing_owlv2.py": [
        [
          "post_process_object_detection",
          178,
          188,
          183,
          9,
          187,
          9,
          178,
          39,
          188,
          82
        ]
      ],
      "transformers/src/transformers/models/owlvit/processing_owlvit.py": [
        [
          "feature_extractor",
          295,
          300,
          296,
          9,
          299,
          9,
          295,
          27,
          300,
          35
        ],
        [
          "post_process_object_detection",
          193,
          203,
          198,
          9,
          202,
          9,
          193,
          39,
          203,
          82
        ],
        [
          "__init__",
          73,
          85,
          76,
          13,
          80,
          13,
          76,
          13,
          81,
          29
        ],
        [
          "feature_extractor_class",
          287,
          292,
          288,
          9,
          291,
          9,
          287,
          33,
          292,
          41
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/processing_speech_to_text.py": [
        [
          "__call__",
          49,
          86,
          62,
          13,
          62,
          105,
          62,
          13,
          63,
          17
        ],
        [
          "as_target_processor",
          89,
          103,
          94,
          9,
          98,
          9,
          89,
          29,
          103,
          39
        ]
      ],
      "transformers/src/transformers/models/deprecated/speech_to_text_2/processing_speech_to_text_2.py": [
        [
          "__call__",
          48,
          85,
          61,
          13,
          61,
          105,
          61,
          13,
          62,
          17
        ],
        [
          "as_target_processor",
          88,
          102,
          93,
          9,
          97,
          9,
          88,
          29,
          102,
          39
        ]
      ],
      "transformers/src/transformers/models/trocr/processing_trocr.py": [
        [
          "as_target_processor",
          112,
          125,
          116,
          9,
          120,
          9,
          112,
          29,
          125,
          39
        ],
        [
          "feature_extractor",
          136,
          141,
          137,
          9,
          140,
          9,
          136,
          27,
          141,
          35
        ],
        [
          "feature_extractor_class",
          128,
          133,
          129,
          9,
          132,
          9,
          128,
          33,
          133,
          41
        ],
        [
          "__init__",
          52,
          66,
          55,
          13,
          59,
          13,
          55,
          13,
          60,
          29
        ]
      ],
      "transformers/src/transformers/models/vilt/processing_vilt.py": [
        [
          "feature_extractor_class",
          73,
          78,
          74,
          9,
          77,
          9,
          73,
          33,
          78,
          41
        ],
        [
          "feature_extractor",
          81,
          86,
          82,
          9,
          85,
          9,
          81,
          27,
          86,
          35
        ],
        [
          "__init__",
          58,
          70,
          61,
          13,
          65,
          13,
          61,
          13,
          66,
          29
        ]
      ],
      "transformers/src/transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py": [
        [
          "feature_extractor_class",
          63,
          68,
          64,
          9,
          67,
          9,
          63,
          33,
          68,
          41
        ],
        [
          "feature_extractor",
          71,
          76,
          72,
          9,
          75,
          9,
          71,
          27,
          76,
          35
        ],
        [
          "__init__",
          48,
          60,
          51,
          13,
          55,
          13,
          51,
          13,
          56,
          29
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_bert/processing_wav2vec2_bert.py": [
        [
          "from_pretrained",
          54,
          70,
          58,
          13,
          65,
          13,
          57,
          9,
          70,
          80
        ]
      ],
      "transformers/src/transformers/models/x_clip/processing_x_clip.py": [
        [
          "feature_extractor",
          66,
          71,
          67,
          9,
          70,
          9,
          66,
          27,
          71,
          35
        ],
        [
          "__init__",
          42,
          55,
          45,
          13,
          49,
          13,
          45,
          13,
          50,
          29
        ],
        [
          "feature_extractor_class",
          58,
          63,
          59,
          9,
          62,
          9,
          58,
          33,
          63,
          41
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/processing_wav2vec2.py": [
        [
          "from_pretrained",
          57,
          73,
          61,
          13,
          68,
          13,
          60,
          9,
          73,
          80
        ],
        [
          "__call__",
          75,
          126,
          96,
          13,
          96,
          105,
          96,
          13,
          97,
          17
        ],
        [
          "as_target_processor",
          172,
          186,
          177,
          9,
          181,
          9,
          172,
          29,
          186,
          39
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py": [
        [
          "__call__",
          222,
          259,
          235,
          13,
          235,
          105,
          235,
          13,
          236,
          17
        ],
        [
          "as_target_processor",
          642,
          656,
          647,
          9,
          651,
          9,
          642,
          29,
          656,
          39
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "save_pretrained",
          723,
          896,
          754,
          13,
          757,
          13,
          754,
          13,
          758,
          46
        ],
        [
          "from_pretrained",
          1367,
          1427,
          1412,
          13,
          1415,
          13,
          1412,
          13,
          1416,
          32
        ]
      ],
      "transformers/src/transformers/pipelines/question_answering.py": [
        [
          "__call__",
          171,
          226,
          183,
          13,
          186,
          13,
          183,
          13,
          187,
          18
        ],
        [
          "__call__",
          171,
          226,
          189,
          13,
          192,
          13,
          189,
          13,
          193,
          18
        ],
        [
          "_sanitize_parameters",
          299,
          339,
          325,
          13,
          325,
          89,
          325,
          13,
          326,
          17
        ],
        [
          "__call__",
          341,
          389,
          381,
          13,
          384,
          13,
          381,
          13,
          384,
          13
        ]
      ],
      "transformers/examples/pytorch/audio-classification/run_audio_classification.py": [
        [
          "__post_init__",
          192,
          205,
          194,
          13,
          199,
          13,
          194,
          13,
          199,
          13
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval.py": [
        [
          "run_generate",
          85,
          178,
          139,
          9,
          139,
          98,
          139,
          9,
          139,
          98
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa.py": [
        [
          "main",
          227,
          701,
          622,
          9,
          622,
          97,
          622,
          9,
          622,
          97
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "__post_init__",
          132,
          142,
          139,
          13,
          142,
          13,
          138,
          37,
          142,
          13
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "parse_args",
          87,
          250,
          242,
          9,
          245,
          9,
          241,
          33,
          245,
          9
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          753,
          9,
          759,
          9,
          752,
          5,
          760,
          17
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          748,
          9,
          754,
          9,
          747,
          5,
          755,
          17
        ]
      ],
      "transformers/src/transformers/generation/stopping_criteria.py": [
        [
          "validate_stopping_criteria",
          513,
          520,
          517,
          9,
          517,
          117,
          517,
          9,
          517,
          117
        ]
      ]
    },
    "str.replace": {
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "preprocess_text",
          185,
          198,
          190,
          19,
          190,
          44,
          190,
          19,
          192,
          32
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "_format_tensor",
          3791,
          3858,
          3814,
          17,
          3814,
          44,
          3808,
          13,
          3814,
          13
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "preprocess_text",
          188,
          201,
          193,
          19,
          193,
          44,
          193,
          19,
          195,
          32
        ],
        [
          "_decode",
          344,
          347,
          346,
          16,
          346,
          36,
          344,
          17,
          347,
          19
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "preprocess_text",
          159,
          172,
          164,
          19,
          164,
          44,
          164,
          19,
          166,
          32
        ],
        [
          "_decode",
          222,
          241,
          240,
          20,
          240,
          50,
          240,
          20,
          240,
          16
        ]
      ],
      "transformers/src/transformers/models/nougat/tokenization_nougat_fast.py": [
        [
          "remove_hallucinated_references",
          423,
          451,
          445,
          20,
          445,
          73,
          444,
          13,
          445,
          16
        ],
        [
          "correct_tables",
          453,
          486,
          473,
          30,
          473,
          54,
          473,
          30,
          473,
          26
        ],
        [
          "correct_tables",
          453,
          486,
          476,
          22,
          476,
          110,
          476,
          22,
          486,
          25
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "_preprocess_char",
          136,
          140,
          139,
          20,
          139,
          41,
          139,
          20,
          139,
          16
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "clean_up_tokenization",
          3983,
          4005,
          3994,
          13,
          3994,
          41,
          3983,
          31,
          4005,
          25
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "preprocess_text",
          193,
          206,
          198,
          19,
          198,
          44,
          198,
          19,
          200,
          32
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_release_date",
          124,
          136,
          126,
          16,
          126,
          65,
          126,
          16,
          129,
          29
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_to_doc",
          166,
          197,
          175,
          57,
          175,
          84,
          175,
          21,
          175,
          17
        ],
        [
          "add_fast_image_processor",
          449,
          507,
          478,
          41,
          478,
          95,
          476,
          28,
          507,
          5
        ]
      ],
      "transformers/src/transformers/utils/attention_visualizer.py": [
        [
          "visualize_attention_mask",
          177,
          251,
          192,
          34,
          192,
          77,
          192,
          34,
          192,
          30
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "add_model_to_auto_mappings",
          150,
          214,
          170,
          49,
          170,
          84,
          151,
          5,
          178,
          40
        ],
        [
          "create_modular_file",
          375,
          424,
          393,
          49,
          393,
          84,
          376,
          5,
          401,
          44
        ],
        [
          "create_test_files",
          427,
          474,
          440,
          49,
          440,
          84,
          427,
          23,
          449,
          40
        ]
      ],
      "transformers/src/transformers/utils/auto_docstring.py": [
        [
          "_process_kwargs_parameters",
          1448,
          1537,
          1497,
          37,
          1497,
          76,
          1497,
          34,
          1497,
          30
        ],
        [
          "auto_class_docstring",
          1767,
          1881,
          1840,
          37,
          1840,
          76,
          1840,
          34,
          1840,
          30
        ]
      ],
      "transformers/src/transformers/utils/chat_template_utils.py": [
        [
          "_parse_type_hint",
          104,
          180,
          158,
          34,
          158,
          65,
          157,
          19,
          163,
          13
        ]
      ],
      "transformers/utils/check_inits.py": [
        [
          "get_transformers_submodules",
          282,
          306,
          297,
          25,
          297,
          60,
          296,
          26,
          298,
          40
        ],
        [
          "get_transformers_submodules",
          282,
          306,
          303,
          25,
          303,
          53,
          302,
          26,
          304,
          45
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "replace_code",
          463,
          485,
          474,
          20,
          474,
          54,
          474,
          20,
          476,
          31
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "replace_default_in_arg_description",
          568,
          630,
          580,
          19,
          580,
          69,
          568,
          40,
          582,
          32
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "check_models_are_tested",
          662,
          694,
          676,
          12,
          676,
          46,
          676,
          12,
          676,
          81
        ]
      ],
      "transformers/src/transformers/models/auto/configuration_auto.py": [
        [
          "model_type_to_module_name",
          1005,
          1019,
          1015,
          11,
          1015,
          31,
          1015,
          11,
          1016,
          31
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "shard_on_the_fly",
          70,
          149,
          105,
          28,
          105,
          106,
          104,
          25,
          111,
          30
        ],
        [
          "shard_on_the_fly",
          70,
          149,
          119,
          20,
          119,
          98,
          118,
          17,
          125,
          36
        ],
        [
          "shard_on_the_fly",
          70,
          149,
          132,
          22,
          134,
          9,
          131,
          9,
          138,
          24
        ],
        [
          "shard_on_the_fly",
          70,
          149,
          135,
          49,
          135,
          106,
          131,
          9,
          138,
          24
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "convert_hf_blt_to_unified",
          362,
          410,
          392,
          24,
          392,
          67,
          392,
          24,
          392,
          20
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "convert_hf_name_to_opus_name",
          173,
          182,
          181,
          25,
          181,
          55,
          181,
          25,
          181,
          21
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          84,
          28,
          84,
          106,
          80,
          28,
          88,
          22
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          94,
          20,
          94,
          98,
          93,
          17,
          103,
          36
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          112,
          22,
          112,
          106,
          111,
          9,
          115,
          24
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          113,
          49,
          113,
          106,
          111,
          9,
          115,
          24
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "rename_key",
          88,
          122,
          94,
          16,
          94,
          71,
          94,
          16,
          94,
          12
        ],
        [
          "rename_key",
          88,
          122,
          112,
          16,
          112,
          60,
          112,
          16,
          112,
          12
        ],
        [
          "rename_key",
          88,
          122,
          90,
          16,
          90,
          46,
          90,
          16,
          90,
          12
        ],
        [
          "rename_key",
          88,
          122,
          102,
          16,
          102,
          54,
          102,
          16,
          102,
          12
        ],
        [
          "rename_key",
          88,
          122,
          92,
          16,
          92,
          64,
          92,
          16,
          92,
          12
        ],
        [
          "rename_key",
          88,
          122,
          96,
          16,
          96,
          79,
          96,
          16,
          96,
          12
        ],
        [
          "rename_key",
          88,
          122,
          98,
          16,
          98,
          74,
          98,
          16,
          98,
          12
        ],
        [
          "rename_key",
          88,
          122,
          100,
          16,
          100,
          89,
          100,
          16,
          100,
          12
        ],
        [
          "rename_key",
          88,
          122,
          104,
          16,
          104,
          66,
          104,
          16,
          104,
          12
        ],
        [
          "rename_key",
          88,
          122,
          106,
          16,
          106,
          53,
          106,
          16,
          106,
          12
        ],
        [
          "rename_key",
          88,
          122,
          108,
          16,
          108,
          56,
          108,
          16,
          108,
          12
        ],
        [
          "rename_key",
          88,
          122,
          110,
          16,
          110,
          55,
          110,
          16,
          110,
          12
        ],
        [
          "rename_key",
          88,
          122,
          114,
          16,
          114,
          54,
          114,
          16,
          114,
          12
        ],
        [
          "rename_key",
          88,
          122,
          116,
          16,
          116,
          69,
          116,
          16,
          116,
          12
        ],
        [
          "rename_key",
          88,
          122,
          118,
          16,
          118,
          59,
          118,
          16,
          118,
          12
        ],
        [
          "rename_key",
          88,
          122,
          120,
          16,
          120,
          56,
          120,
          16,
          120,
          12
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "get_model_doc_path",
          80,
          90,
          82,
          27,
          82,
          49,
          80,
          24,
          86,
          71
        ],
        [
          "get_model_doc_path",
          80,
          90,
          82,
          52,
          82,
          73,
          80,
          24,
          86,
          71
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "_sanitize_module_name",
          51,
          81,
          68,
          16,
          68,
          41,
          51,
          27,
          69,
          15
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "save_pretrained",
          3648,
          4088,
          3975,
          28,
          3975,
          71,
          3975,
          28,
          3981,
          38
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3992,
          33,
          3992,
          64,
          3988,
          13,
          3999,
          54
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          4997,
          20,
          4997,
          66,
          4997,
          20,
          4997,
          72
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          4999,
          20,
          4999,
          69,
          4999,
          20,
          4999,
          75
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5006,
          24,
          5006,
          83,
          5006,
          24,
          5006,
          89
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5008,
          24,
          5008,
          83,
          5008,
          24,
          5008,
          89
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5011,
          24,
          5011,
          83,
          5011,
          24,
          5011,
          89
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5013,
          24,
          5013,
          83,
          5013,
          24,
          5013,
          89
        ],
        [
          "_load_pretrained_model",
          5108,
          5377,
          5214,
          29,
          5214,
          60,
          5214,
          29,
          5214,
          60
        ]
      ],
      "transformers/src/transformers/models/florence2/modular_florence2.py": [
        [
          "parse_ocr_from_text_and_spans",
          687,
          730,
          706,
          16,
          706,
          38,
          688,
          9,
          707,
          26
        ],
        [
          "parse_phrase_grounding_from_text_and_spans",
          732,
          771,
          747,
          16,
          747,
          38,
          733,
          9,
          754,
          34
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          776,
          827,
          796,
          16,
          796,
          38,
          777,
          9,
          798,
          29
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          861,
          16,
          861,
          38,
          830,
          9,
          863,
          29
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "get_cased_name",
          81,
          89,
          83,
          26,
          83,
          57,
          81,
          20,
          84,
          45
        ],
        [
          "__init__",
          111,
          127,
          113,
          20,
          113,
          45,
          111,
          18,
          127,
          21
        ],
        [
          "__init__",
          111,
          127,
          114,
          20,
          114,
          45,
          111,
          18,
          127,
          21
        ],
        [
          "replace_class_node",
          862,
          1052,
          898,
          20,
          898,
          65,
          896,
          25,
          900,
          30
        ],
        [
          "find_file_type",
          1073,
          1086,
          1081,
          47,
          1081,
          96,
          1073,
          20,
          1082,
          12
        ],
        [
          "save_modeling_files",
          1718,
          1727,
          1723,
          25,
          1723,
          80,
          1722,
          28,
          1727,
          47
        ]
      ],
      "transformers/src/transformers/models/fuyu/processing_fuyu.py": [
        [
          "_replace_string_repr_with_token_tags",
          136,
          141,
          137,
          14,
          137,
          74,
          136,
          42,
          141,
          17
        ]
      ],
      "transformers/src/transformers/models/florence2/processing_florence2.py": [
        [
          "parse_ocr_from_text_and_spans",
          494,
          537,
          513,
          16,
          513,
          38,
          495,
          9,
          514,
          26
        ],
        [
          "parse_phrase_grounding_from_text_and_spans",
          539,
          578,
          554,
          16,
          554,
          38,
          540,
          9,
          561,
          34
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          583,
          634,
          603,
          16,
          603,
          38,
          584,
          9,
          605,
          29
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          668,
          16,
          668,
          38,
          637,
          9,
          670,
          29
        ]
      ],
      "transformers/src/transformers/quantizers/quantizer_mxfp4.py": [
        [
          "update_param_name",
          368,
          379,
          371,
          24,
          371,
          56,
          371,
          24,
          371,
          56
        ],
        [
          "update_param_name",
          368,
          379,
          373,
          24,
          373,
          56,
          373,
          24,
          373,
          56
        ],
        [
          "update_param_name",
          368,
          379,
          376,
          24,
          376,
          80,
          376,
          24,
          376,
          80
        ],
        [
          "update_param_name",
          368,
          379,
          378,
          24,
          378,
          74,
          378,
          24,
          378,
          74
        ]
      ]
    },
    "sys.stdout.write": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "__exit__",
          1716,
          1729,
          1721,
          17,
          1721,
          42,
          1721,
          17,
          1721,
          42
        ]
      ]
    },
    "sys.stderr.write": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "__exit__",
          1716,
          1729,
          1728,
          17,
          1728,
          42,
          1728,
          17,
          1728,
          42
        ]
      ]
    },
    "logging.StreamHandler": {
      "transformers/src/transformers/testing_utils.py": [
        [
          "__init__",
          1785,
          1789,
          1788,
          19,
          1788,
          48,
          1785,
          18,
          1789,
          16
        ]
      ],
      "transformers/src/transformers/utils/logging.py": [
        [
          "_configure_library_root_logger",
          80,
          104,
          87,
          28,
          87,
          50,
          87,
          28,
          89,
          29
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "setup_logging",
          33,
          48,
          39,
          17,
          39,
          49,
          39,
          17,
          41,
          26
        ]
      ],
      "transformers/examples/pytorch/audio-classification/run_audio_classification.py": [
        [
          "main",
          208,
          435,
          225,
          19,
          225,
          51,
          222,
          5,
          228,
          31
        ]
      ],
      "transformers/examples/pytorch/contrastive-image-text/run_clip.py": [
        [
          "main",
          236,
          533,
          254,
          19,
          254,
          51,
          251,
          5,
          257,
          31
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          303,
          19,
          303,
          51,
          300,
          5,
          306,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm.py": [
        [
          "main",
          282,
          720,
          299,
          19,
          299,
          51,
          296,
          5,
          302,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim.py": [
        [
          "main",
          309,
          854,
          326,
          19,
          326,
          51,
          323,
          5,
          329,
          31
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          248,
          19,
          248,
          51,
          245,
          5,
          251,
          31
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "main",
          191,
          445,
          208,
          19,
          208,
          51,
          205,
          5,
          211,
          31
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          220,
          19,
          220,
          51,
          217,
          5,
          222,
          60
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation.py": [
        [
          "setup_logging",
          311,
          328,
          317,
          19,
          317,
          51,
          311,
          19,
          320,
          31
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mae.py": [
        [
          "main",
          183,
          403,
          200,
          19,
          200,
          51,
          197,
          5,
          203,
          31
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "setup_logging",
          369,
          384,
          375,
          19,
          375,
          51,
          369,
          19,
          378,
          40
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim.py": [
        [
          "main",
          247,
          483,
          264,
          19,
          264,
          51,
          261,
          5,
          267,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm.py": [
        [
          "main",
          254,
          678,
          271,
          19,
          271,
          51,
          268,
          5,
          274,
          31
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          245,
          19,
          245,
          51,
          242,
          5,
          248,
          31
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection.py": [
        [
          "main",
          339,
          534,
          356,
          19,
          356,
          51,
          353,
          5,
          359,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_plm.py": [
        [
          "main",
          234,
          575,
          251,
          19,
          251,
          51,
          248,
          5,
          254,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa.py": [
        [
          "main",
          227,
          701,
          244,
          19,
          244,
          51,
          241,
          5,
          247,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search.py": [
        [
          "main",
          225,
          728,
          242,
          19,
          242,
          51,
          239,
          5,
          245,
          31
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          204,
          19,
          204,
          51,
          201,
          5,
          207,
          31
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          451,
          19,
          451,
          51,
          448,
          5,
          453,
          77
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_seq2seq_qa.py": [
        [
          "main",
          272,
          729,
          289,
          19,
          289,
          51,
          286,
          5,
          292,
          31
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py": [
        [
          "main",
          302,
          657,
          320,
          19,
          320,
          51,
          317,
          5,
          329,
          77
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          428,
          19,
          428,
          51,
          425,
          5,
          430,
          77
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag.py": [
        [
          "main",
          178,
          442,
          195,
          19,
          195,
          51,
          192,
          5,
          198,
          31
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          344,
          19,
          344,
          51,
          341,
          5,
          347,
          31
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          292,
          19,
          292,
          51,
          289,
          5,
          295,
          31
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_xnli.py": [
        [
          "main",
          194,
          461,
          206,
          19,
          206,
          51,
          199,
          14,
          209,
          31
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "test_run_semantic_segmentation_no_trainer",
          287,
          306,
          288,
          26,
          288,
          58,
          287,
          51,
          306,
          70
        ],
        [
          "test_run_object_detection_no_trainer",
          336,
          356,
          337,
          26,
          337,
          58,
          336,
          46,
          356,
          57
        ],
        [
          "test_run_instance_segmentation_no_trainer",
          360,
          381,
          361,
          26,
          361,
          58,
          360,
          51,
          381,
          56
        ]
      ]
    },
    "logging.getLogger": {
      "transformers/benchmark_v2/benchmark_framework.py": [
        [
          "__init__",
          279,
          291,
          281,
          33,
          281,
          59,
          281,
          33,
          281,
          59
        ],
        [
          "__init__",
          444,
          448,
          446,
          33,
          446,
          59,
          446,
          33,
          446,
          59
        ]
      ],
      "transformers/src/transformers/utils/logging.py": [
        [
          "_get_default_logging_level",
          55,
          69,
          65,
          13,
          65,
          31,
          65,
          13,
          68,
          13
        ],
        [
          "_get_library_root_logger",
          76,
          77,
          77,
          12,
          77,
          49,
          77,
          12,
          77,
          49
        ],
        [
          "get_logger",
          147,
          158,
          158,
          12,
          158,
          34,
          157,
          5,
          158,
          34
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "__init__",
          245,
          259,
          247,
          13,
          247,
          35,
          246,
          13,
          247,
          59
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "setup_logging",
          33,
          48,
          48,
          12,
          48,
          38,
          44,
          5,
          48,
          38
        ],
        [
          "upload_results_to_hf_dataset",
          193,
          275,
          215,
          18,
          215,
          44,
          215,
          18,
          215,
          14
        ]
      ],
      "transformers/tests/utils/test_logging.py": [
        [
          "test_env_invalid_override",
          99,
          106,
          102,
          18,
          102,
          44,
          99,
          35,
          106,
          82
        ]
      ]
    },
    "logging.info": {
      "transformers/src/transformers/models/esm/openfold_utils/chunk_utils.py": [
        [
          "_determine_favorable_chunk_size",
          326,
          355,
          327,
          9,
          327,
          44,
          326,
          41,
          329,
          48
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "convert_textnet_checkpoint",
          116,
          181,
          181,
          5,
          181,
          86,
          177,
          5,
          181,
          86
        ]
      ],
      "transformers/src/transformers/integrations/executorch.py": [
        [
          "__init__",
          201,
          236,
          229,
          13,
          231,
          13,
          229,
          13,
          232,
          22
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "build_index",
          417,
          450,
          440,
          9,
          442,
          9,
          440,
          9,
          450,
          22
        ],
        [
          "push_index_to_hub",
          290,
          301,
          295,
          13,
          295,
          66,
          294,
          13,
          301,
          13
        ],
        [
          "ensure_local_index",
          268,
          288,
          280,
          9,
          280,
          77,
          280,
          9,
          286,
          18
        ],
        [
          "build_index",
          417,
          450,
          419,
          9,
          419,
          40,
          417,
          21,
          427,
          63
        ],
        [
          "build_index",
          417,
          450,
          421,
          9,
          421,
          51,
          417,
          21,
          427,
          63
        ],
        [
          "analyze_file",
          518,
          576,
          553,
          9,
          555,
          9,
          536,
          16,
          559,
          63
        ],
        [
          "build_date_data",
          584,
          613,
          606,
          13,
          606,
          60,
          604,
          9,
          606,
          60
        ],
        [
          "main",
          691,
          908,
          743,
          9,
          746,
          9,
          741,
          22,
          746,
          9
        ],
        [
          "main",
          691,
          908,
          779,
          9,
          779,
          46,
          773,
          24,
          781,
          39
        ],
        [
          "main",
          691,
          908,
          779,
          9,
          779,
          46,
          775,
          52,
          781,
          39
        ],
        [
          "main",
          691,
          908,
          899,
          17,
          904,
          17,
          899,
          17,
          905,
          28
        ],
        [
          "main",
          691,
          908,
          907,
          13,
          907,
          72,
          907,
          13,
          908,
          28
        ],
        [
          "main",
          691,
          908,
          908,
          13,
          908,
          28,
          907,
          13,
          908,
          28
        ]
      ],
      "transformers/tests/models/gemma3/test_modeling_gemma3.py": [
        [
          "test_export_text_only_with_hybrid_cache",
          737,
          778,
          754,
          9,
          754,
          63,
          741,
          14,
          778,
          69
        ],
        [
          "test_export_text_only_with_hybrid_cache",
          737,
          778,
          764,
          9,
          764,
          76,
          741,
          14,
          778,
          69
        ],
        [
          "test_export_text_only_with_hybrid_cache",
          737,
          778,
          776,
          9,
          776,
          74,
          741,
          14,
          778,
          69
        ]
      ],
      "transformers/tests/models/ministral/test_modeling_ministral.py": [
        [
          "test_export_text_with_hybrid_cache",
          170,
          223,
          199,
          9,
          199,
          63,
          177,
          14,
          223,
          69
        ],
        [
          "test_export_text_with_hybrid_cache",
          170,
          223,
          221,
          9,
          221,
          74,
          177,
          14,
          223,
          69
        ],
        [
          "test_export_text_with_hybrid_cache",
          170,
          223,
          209,
          9,
          209,
          76,
          177,
          14,
          223,
          69
        ]
      ]
    },
    "logging.basicConfig": {
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "main",
          413,
          483,
          468,
          5,
          468,
          44,
          414,
          14,
          471,
          33
        ]
      ],
      "transformers/examples/legacy/seq2seq/finetune_trainer.py": [
        [
          "main",
          157,
          366,
          174,
          5,
          178,
          5,
          177,
          15,
          190,
          48
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "main",
          691,
          908,
          693,
          5,
          693,
          65,
          692,
          5,
          708,
          17
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "setup_logging",
          33,
          48,
          44,
          5,
          46,
          5,
          44,
          5,
          48,
          38
        ]
      ],
      "transformers/examples/pytorch/audio-classification/run_audio_classification.py": [
        [
          "main",
          208,
          435,
          222,
          5,
          226,
          5,
          222,
          5,
          228,
          31
        ]
      ],
      "transformers/examples/pytorch/contrastive-image-text/run_clip.py": [
        [
          "main",
          236,
          533,
          251,
          5,
          255,
          5,
          251,
          5,
          257,
          31
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          300,
          5,
          304,
          5,
          300,
          5,
          306,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm.py": [
        [
          "main",
          282,
          720,
          296,
          5,
          300,
          5,
          296,
          5,
          302,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          283,
          5,
          287,
          5,
          280,
          19,
          289,
          40
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim.py": [
        [
          "main",
          309,
          854,
          323,
          5,
          327,
          5,
          323,
          5,
          329,
          31
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          245,
          5,
          249,
          5,
          245,
          5,
          251,
          31
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "main",
          191,
          445,
          205,
          5,
          209,
          5,
          205,
          5,
          211,
          31
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          245,
          5,
          249,
          5,
          242,
          9,
          251,
          40
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          343,
          5,
          347,
          5,
          340,
          19,
          349,
          40
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          217,
          5,
          221,
          5,
          217,
          5,
          222,
          60
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation.py": [
        [
          "setup_logging",
          311,
          328,
          314,
          5,
          318,
          5,
          311,
          19,
          320,
          31
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "main",
          197,
          364,
          222,
          5,
          226,
          5,
          225,
          15,
          236,
          48
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "main",
          234,
          650,
          250,
          5,
          254,
          5,
          246,
          19,
          256,
          40
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mae.py": [
        [
          "main",
          183,
          403,
          197,
          5,
          201,
          5,
          197,
          5,
          203,
          31
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "setup_logging",
          369,
          384,
          372,
          5,
          376,
          5,
          369,
          19,
          378,
          40
        ]
      ],
      "transformers/examples/legacy/multiple_choice/run_multiple_choice.py": [
        [
          "main",
          90,
          234,
          110,
          5,
          114,
          5,
          113,
          15,
          124,
          48
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          402,
          5,
          406,
          5,
          396,
          19,
          408,
          40
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim.py": [
        [
          "main",
          247,
          483,
          261,
          5,
          265,
          5,
          261,
          5,
          267,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm.py": [
        [
          "main",
          254,
          678,
          268,
          5,
          272,
          5,
          268,
          5,
          274,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          290,
          5,
          294,
          5,
          287,
          19,
          296,
          40
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          136,
          5,
          140,
          5,
          139,
          15,
          150,
          48
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          294,
          5,
          298,
          5,
          291,
          9,
          300,
          40
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          242,
          5,
          246,
          5,
          242,
          5,
          248,
          31
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection.py": [
        [
          "main",
          339,
          534,
          353,
          5,
          357,
          5,
          353,
          5,
          359,
          31
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_plm.py": [
        [
          "main",
          234,
          575,
          248,
          5,
          252,
          5,
          248,
          5,
          254,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa.py": [
        [
          "main",
          227,
          701,
          241,
          5,
          245,
          5,
          241,
          5,
          247,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search.py": [
        [
          "main",
          225,
          728,
          239,
          5,
          243,
          5,
          239,
          5,
          245,
          31
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          201,
          5,
          205,
          5,
          201,
          5,
          207,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          314,
          5,
          318,
          5,
          311,
          19,
          320,
          40
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "main",
          338,
          1035,
          353,
          5,
          357,
          5,
          350,
          19,
          359,
          40
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          448,
          5,
          452,
          5,
          448,
          5,
          453,
          77
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_seq2seq_qa.py": [
        [
          "main",
          272,
          729,
          286,
          5,
          290,
          5,
          286,
          5,
          292,
          31
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad_trainer.py": [
        [
          "main",
          65,
          176,
          91,
          5,
          95,
          5,
          94,
          15,
          105,
          48
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py": [
        [
          "main",
          302,
          657,
          317,
          5,
          321,
          5,
          317,
          5,
          329,
          77
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          425,
          5,
          429,
          5,
          425,
          5,
          430,
          77
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag.py": [
        [
          "main",
          178,
          442,
          192,
          5,
          196,
          5,
          192,
          5,
          198,
          31
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          253,
          5,
          257,
          5,
          250,
          19,
          259,
          40
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          364,
          5,
          368,
          5,
          364,
          5,
          370,
          40
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "main",
          470,
          835,
          713,
          5,
          717,
          5,
          716,
          15,
          727,
          39
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "main",
          473,
          717,
          620,
          5,
          624,
          5,
          623,
          15,
          634,
          39
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          341,
          5,
          345,
          5,
          341,
          5,
          347,
          31
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          289,
          5,
          293,
          5,
          289,
          5,
          295,
          31
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          341,
          5,
          345,
          5,
          337,
          9,
          347,
          40
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_xnli.py": [
        [
          "main",
          194,
          461,
          203,
          5,
          207,
          5,
          199,
          14,
          209,
          31
        ]
      ]
    },
    "logging.warning": {
      "transformers/src/transformers/integrations/executorch.py": [
        [
          "export",
          261,
          351,
          324,
          13,
          326,
          13,
          323,
          28,
          326,
          13
        ],
        [
          "convert_and_export_with_cache",
          746,
          816,
          800,
          17,
          802,
          17,
          800,
          17,
          802,
          17
        ],
        [
          "convert_and_export_with_cache",
          746,
          816,
          804,
          17,
          804,
          118,
          804,
          17,
          804,
          118
        ],
        [
          "_get_cache_dict",
          1088,
          1099,
          1094,
          9,
          1094,
          118,
          1094,
          9,
          1094,
          118
        ]
      ],
      "transformers/src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py": [
        [
          "apply_chat_template",
          318,
          337,
          330,
          17,
          333,
          17,
          330,
          17,
          333,
          17
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "discover_benchmarks",
          51,
          101,
          96,
          17,
          96,
          73,
          96,
          17,
          96,
          73
        ]
      ]
    },
    "logging.Logger.info": {
      "transformers/benchmark/benches/llama.py": [
        [
          "run_benchmark",
          68,
          354,
          326,
          9,
          326,
          82,
          326,
          9,
          326,
          82
        ],
        [
          "run_benchmark",
          68,
          354,
          129,
          9,
          129,
          59,
          129,
          9,
          129,
          59
        ],
        [
          "run_benchmark",
          68,
          354,
          201,
          9,
          201,
          53,
          201,
          21,
          201,
          53
        ],
        [
          "run_benchmark",
          68,
          354,
          234,
          9,
          234,
          60,
          234,
          21,
          234,
          60
        ],
        [
          "run_benchmark",
          68,
          354,
          281,
          9,
          281,
          82,
          281,
          9,
          281,
          82
        ],
        [
          "run_benchmark",
          68,
          354,
          104,
          9,
          104,
          86,
          104,
          9,
          104,
          86
        ],
        [
          "run_benchmark",
          68,
          354,
          110,
          9,
          110,
          72,
          110,
          21,
          110,
          72
        ],
        [
          "run_benchmark",
          68,
          354,
          116,
          9,
          116,
          42,
          116,
          21,
          116,
          42
        ],
        [
          "run_benchmark",
          68,
          354,
          120,
          9,
          120,
          36,
          120,
          21,
          120,
          36
        ],
        [
          "run_benchmark",
          68,
          354,
          164,
          9,
          164,
          55,
          164,
          21,
          164,
          55
        ],
        [
          "run_benchmark",
          68,
          354,
          170,
          9,
          170,
          91,
          170,
          9,
          170,
          91
        ],
        [
          "run_benchmark",
          68,
          354,
          173,
          9,
          173,
          56,
          173,
          21,
          173,
          56
        ],
        [
          "run_benchmark",
          68,
          354,
          179,
          9,
          179,
          93,
          179,
          9,
          179,
          93
        ],
        [
          "run_benchmark",
          68,
          354,
          182,
          9,
          182,
          53,
          182,
          21,
          182,
          53
        ],
        [
          "run_benchmark",
          68,
          354,
          188,
          9,
          188,
          89,
          188,
          9,
          188,
          89
        ],
        [
          "run_benchmark",
          68,
          354,
          189,
          9,
          189,
          82,
          189,
          9,
          189,
          82
        ],
        [
          "run_benchmark",
          68,
          354,
          192,
          9,
          192,
          54,
          192,
          21,
          192,
          54
        ],
        [
          "run_benchmark",
          68,
          354,
          198,
          9,
          198,
          91,
          198,
          9,
          198,
          91
        ],
        [
          "run_benchmark",
          68,
          354,
          199,
          9,
          199,
          82,
          199,
          9,
          199,
          82
        ],
        [
          "run_benchmark",
          68,
          354,
          250,
          9,
          250,
          53,
          250,
          21,
          250,
          53
        ],
        [
          "run_benchmark",
          68,
          354,
          262,
          9,
          262,
          38,
          262,
          21,
          262,
          38
        ],
        [
          "run_benchmark",
          68,
          354,
          280,
          9,
          280,
          93,
          280,
          9,
          280,
          93
        ],
        [
          "run_benchmark",
          68,
          354,
          295,
          9,
          295,
          95,
          295,
          9,
          295,
          95
        ],
        [
          "run_benchmark",
          68,
          354,
          296,
          9,
          296,
          82,
          296,
          9,
          296,
          82
        ],
        [
          "run_benchmark",
          68,
          354,
          310,
          9,
          310,
          93,
          310,
          9,
          310,
          93
        ],
        [
          "run_benchmark",
          68,
          354,
          311,
          9,
          311,
          82,
          311,
          9,
          311,
          82
        ],
        [
          "run_benchmark",
          68,
          354,
          325,
          9,
          325,
          95,
          325,
          9,
          325,
          95
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "run_single_benchmark",
          104,
          161,
          153,
          13,
          153,
          77,
          153,
          13,
          153,
          77
        ],
        [
          "run_single_benchmark",
          104,
          161,
          122,
          5,
          122,
          55,
          105,
          5,
          126,
          22
        ],
        [
          "generate_summary_report",
          164,
          190,
          189,
          5,
          189,
          59,
          165,
          5,
          190,
          23
        ]
      ]
    },
    "logging.Logger.error": {
      "transformers/benchmark/benches/llama.py": [
        [
          "run_benchmark",
          68,
          354,
          79,
          9,
          79,
          113,
          79,
          9,
          82,
          14
        ],
        [
          "run_benchmark",
          68,
          354,
          80,
          9,
          80,
          54,
          79,
          9,
          82,
          14
        ],
        [
          "run_benchmark",
          68,
          354,
          81,
          9,
          81,
          77,
          79,
          9,
          82,
          14
        ],
        [
          "run_benchmark",
          68,
          354,
          96,
          13,
          96,
          67,
          95,
          9,
          97,
          18
        ],
        [
          "run_benchmark",
          68,
          354,
          347,
          9,
          347,
          46,
          346,
          5,
          347,
          46
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "run_single_benchmark",
          104,
          161,
          157,
          9,
          157,
          63,
          156,
          5,
          161,
          19
        ]
      ]
    },
    "logging.Formatter": {
      "transformers/src/transformers/utils/logging.py": [
        [
          "_configure_library_root_logger",
          80,
          104,
          100,
          25,
          100,
          111,
          100,
          25,
          101,
          52
        ],
        [
          "enable_explicit_format",
          278,
          290,
          289,
          21,
          289,
          107,
          288,
          9,
          290,
          39
        ]
      ]
    },
    "logging.captureWarnings": {
      "transformers/src/transformers/utils/logging.py": [
        [
          "captureWarnings",
          124,
          144,
          144,
          5,
          144,
          29,
          142,
          5,
          144,
          29
        ]
      ]
    },
    "logging.FileHandler": {
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "setup_logging",
          33,
          48,
          42,
          25,
          42,
          108,
          42,
          9,
          42,
          109
        ]
      ]
    },
    "logging.error": {
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "discover_benchmarks",
          51,
          101,
          99,
          13,
          99,
          61,
          98,
          9,
          99,
          61
        ]
      ]
    },
    "logging.Logger.debug": {
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "run_single_benchmark",
          104,
          161,
          160,
          9,
          160,
          44,
          156,
          5,
          161,
          19
        ]
      ]
    }
  },
  "CWE-326": {},
  "CWE-327": {
    "hashlib.sha256": {
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_class_in_module",
          268,
          313,
          300,
          28,
          300,
          100,
          295,
          47,
          303,
          32
        ]
      ]
    }
  },
  "CWE-329": {
    "numpy.random.randint": {
      "transformers/tests/models/siglip/test_modeling_siglip.py": [
        [
          "prepare_config_and_inputs",
          292,
          308,
          301,
          33,
          301,
          88,
          300,
          38,
          302,
          70
        ]
      ],
      "transformers/tests/models/siglip2/test_modeling_siglip2.py": [
        [
          "prepare_config_and_inputs",
          384,
          400,
          393,
          33,
          393,
          88,
          392,
          38,
          394,
          70
        ]
      ],
      "transformers/tests/models/x_clip/test_modeling_x_clip.py": [
        [
          "prepare_config_and_inputs",
          351,
          367,
          360,
          33,
          360,
          88,
          359,
          38,
          361,
          70
        ]
      ],
      "transformers/tests/models/gemma3n/test_processing_gemma3n.py": [
        [
          "test_image_processor",
          102,
          119,
          110,
          21,
          110,
          95,
          102,
          30,
          114,
          40
        ]
      ],
      "transformers/tests/test_processing_common.py": [
        [
          "prepare_image_inputs",
          72,
          76,
          74,
          21,
          74,
          77,
          73,
          5,
          76,
          23
        ],
        [
          "prepare_video_inputs",
          170,
          176,
          172,
          24,
          172,
          80,
          170,
          30,
          174,
          29
        ]
      ],
      "transformers/tests/models/idefics/test_processing_idefics.py": [
        [
          "listcomp",
          73,
          73,
          73,
          19,
          73,
          75,
          73,
          81,
          73,
          75
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "prepare_image_inputs",
          75,
          81,
          79,
          25,
          79,
          81,
          75,
          30,
          81,
          27
        ]
      ],
      "transformers/tests/models/mistral3/test_processing_mistral3.py": [
        [
          "setUpClass",
          39,
          56,
          43,
          23,
          43,
          81,
          39,
          20,
          56,
          23
        ],
        [
          "setUpClass",
          39,
          56,
          45,
          23,
          45,
          80,
          39,
          20,
          56,
          23
        ],
        [
          "setUpClass",
          39,
          56,
          46,
          23,
          46,
          82,
          39,
          20,
          56,
          23
        ]
      ],
      "transformers/tests/models/pixtral/test_processing_pixtral.py": [
        [
          "setUpClass",
          36,
          43,
          40,
          23,
          40,
          81,
          36,
          20,
          43,
          19
        ],
        [
          "setUpClass",
          36,
          43,
          42,
          23,
          42,
          80,
          36,
          20,
          43,
          19
        ],
        [
          "setUpClass",
          36,
          43,
          43,
          23,
          43,
          82,
          36,
          20,
          43,
          19
        ]
      ],
      "transformers/tests/models/oneformer/test_processing_oneformer.py": [
        [
          "listcomp",
          383,
          384,
          384,
          17,
          384,
          74,
          384,
          97,
          384,
          91
        ]
      ],
      "transformers/tests/models/sam_hq/test_processing_samhq.py": [
        [
          "prepare_mask_inputs",
          59,
          65,
          63,
          24,
          63,
          77,
          59,
          29,
          65,
          26
        ]
      ],
      "transformers/tests/models/sam/test_processing_sam.py": [
        [
          "prepare_mask_inputs",
          56,
          62,
          60,
          24,
          60,
          77,
          56,
          29,
          62,
          26
        ]
      ],
      "transformers/tests/models/smolvlm/test_processing_smolvlm.py": [
        [
          "prepare_video_inputs",
          104,
          109,
          106,
          24,
          106,
          80,
          104,
          30,
          107,
          29
        ]
      ],
      "transformers/tests/test_video_processing_common.py": [
        [
          "prepare_video",
          47,
          64,
          52,
          22,
          52,
          95,
          51,
          9,
          52,
          96
        ]
      ],
      "transformers/tests/utils/test_video_utils.py": [
        [
          "get_random_video",
          47,
          53,
          48,
          20,
          48,
          80,
          47,
          22,
          50,
          19
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "__init__",
          308,
          314,
          311,
          17,
          311,
          65,
          308,
          18,
          314,
          15
        ],
        [
          "create_dummy_dataset_for_text_generation",
          525,
          534,
          529,
          21,
          529,
          79,
          525,
          50,
          534,
          22
        ]
      ],
      "transformers/src/transformers/models/git/convert_git_to_pytorch.py": [
        [
          "sample_frame_indices",
          219,
          236,
          232,
          19,
          232,
          59,
          219,
          30,
          236,
          22
        ]
      ],
      "transformers/src/transformers/data/data_collator.py": [
        [
          "numpy_mask_tokens",
          890,
          970,
          964,
          28,
          966,
          13,
          960,
          17,
          964,
          24
        ]
      ],
      "transformers/src/transformers/models/clap/feature_extraction_clap.py": [
        [
          "_get_input_mel",
          202,
          258,
          222,
          23,
          222,
          56,
          219,
          26,
          224,
          25
        ],
        [
          "__call__",
          260,
          362,
          347,
          24,
          347,
          59,
          347,
          24,
          348,
          31
        ]
      ],
      "transformers/src/transformers/models/donut/image_processing_donut.py": [
        [
          "pad_image",
          190,
          230,
          220,
          23,
          220,
          69,
          220,
          23,
          221,
          20
        ],
        [
          "pad_image",
          190,
          230,
          221,
          24,
          221,
          69,
          220,
          23,
          221,
          20
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py": [
        [
          "_sample_negative_indices",
          228,
          261,
          251,
          27,
          251,
          84,
          246,
          9,
          259,
          43
        ]
      ],
      "transformers/tests/trainer/test_data_collator.py": [
        [
          "listcomp",
          72,
          72,
          72,
          44,
          72,
          73,
          72,
          80,
          72,
          74
        ],
        [
          "listcomp",
          79,
          79,
          79,
          58,
          79,
          87,
          79,
          94,
          79,
          88
        ],
        [
          "test_plm",
          644,
          668,
          665,
          20,
          665,
          47,
          644,
          18,
          668,
          34
        ],
        [
          "listcomp",
          1069,
          1069,
          1069,
          44,
          1069,
          73,
          1069,
          80,
          1069,
          74
        ],
        [
          "listcomp",
          1076,
          1076,
          1076,
          54,
          1076,
          83,
          1076,
          90,
          1076,
          84
        ],
        [
          "test_plm",
          1472,
          1496,
          1493,
          20,
          1493,
          47,
          1472,
          18,
          1496,
          34
        ]
      ],
      "transformers/tests/models/pop2piano/test_feature_extraction_pop2piano.py": [
        [
          "test_batch_feature_np",
          195,
          212,
          199,
          25,
          199,
          71,
          195,
          31,
          212,
          72
        ],
        [
          "test_attention_mask",
          151,
          176,
          154,
          25,
          154,
          71,
          151,
          29,
          176,
          92
        ],
        [
          "test_batch_feature",
          178,
          193,
          182,
          25,
          182,
          71,
          178,
          28,
          193,
          77
        ],
        [
          "test_batch_feature_pt",
          214,
          231,
          218,
          25,
          218,
          71,
          214,
          31,
          231,
          72
        ]
      ],
      "transformers/tests/models/aria/test_image_processing_aria.py": [
        [
          "prepare_image_inputs",
          98,
          149,
          135,
          31,
          135,
          104,
          135,
          17,
          135,
          105
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "prepare_image_inputs",
          57,
          98,
          85,
          29,
          85,
          102,
          85,
          9,
          85,
          103
        ],
        [
          "prepare_video",
          101,
          115,
          106,
          22,
          106,
          95,
          105,
          9,
          106,
          96
        ]
      ],
      "transformers/tests/models/efficientloftr/test_image_processing_efficientloftr.py": [
        [
          "random_array",
          47,
          48,
          48,
          12,
          48,
          44,
          47,
          18,
          48,
          44
        ],
        [
          "prepare_keypoint_matching_output",
          74,
          93,
          82,
          40,
          82,
          82,
          81,
          13,
          92,
          49
        ],
        [
          "prepare_keypoint_matching_output",
          74,
          93,
          83,
          40,
          83,
          82,
          81,
          13,
          92,
          49
        ],
        [
          "prepare_keypoint_matching_output",
          74,
          93,
          84,
          37,
          84,
          113,
          81,
          13,
          92,
          49
        ]
      ],
      "transformers/tests/models/gemma3/test_image_processing_gemma3.py": [
        [
          "test_pan_and_scan",
          168,
          196,
          178,
          29,
          178,
          86,
          173,
          13,
          196,
          86
        ]
      ],
      "transformers/tests/models/idefics3/test_image_processing_idefics3.py": [
        [
          "prepare_image_inputs",
          114,
          165,
          151,
          31,
          151,
          104,
          151,
          17,
          151,
          105
        ]
      ],
      "transformers/tests/models/idefics2/test_image_processing_idefics2.py": [
        [
          "prepare_image_inputs",
          131,
          173,
          161,
          31,
          161,
          104,
          161,
          17,
          161,
          105
        ]
      ],
      "transformers/tests/models/lightglue/test_image_processing_lightglue.py": [
        [
          "random_array",
          34,
          35,
          35,
          12,
          35,
          44,
          34,
          18,
          35,
          44
        ],
        [
          "prepare_keypoint_matching_output",
          61,
          86,
          71,
          40,
          71,
          82,
          70,
          13,
          83,
          49
        ],
        [
          "prepare_keypoint_matching_output",
          61,
          86,
          72,
          40,
          72,
          82,
          70,
          13,
          83,
          49
        ],
        [
          "prepare_keypoint_matching_output",
          61,
          86,
          73,
          37,
          73,
          113,
          70,
          13,
          83,
          49
        ]
      ],
      "transformers/tests/models/mask2former/test_image_processing_mask2former.py": [
        [
          "listcomp",
          214,
          217,
          215,
          17,
          215,
          104,
          215,
          48,
          217,
          17
        ]
      ],
      "transformers/tests/models/mllama/test_image_processing_mllama.py": [
        [
          "prepare_image_inputs",
          90,
          137,
          127,
          31,
          127,
          104,
          127,
          17,
          127,
          105
        ]
      ],
      "transformers/tests/models/maskformer/test_image_processing_maskformer.py": [
        [
          "listcomp",
          204,
          205,
          205,
          17,
          205,
          74,
          205,
          97,
          205,
          91
        ]
      ],
      "transformers/tests/models/oneformer/test_image_processing_oneformer.py": [
        [
          "listcomp",
          215,
          216,
          216,
          17,
          216,
          74,
          216,
          97,
          216,
          91
        ]
      ],
      "transformers/tests/models/smolvlm/test_image_processing_smolvlm.py": [
        [
          "prepare_image_inputs",
          114,
          165,
          151,
          31,
          151,
          104,
          151,
          17,
          151,
          105
        ]
      ],
      "transformers/tests/models/superpoint/test_image_processing_superpoint.py": [
        [
          "prepare_keypoint_detection_output",
          81,
          96,
          89,
          39,
          89,
          80,
          88,
          13,
          93,
          52
        ]
      ],
      "transformers/tests/models/superglue/test_image_processing_superglue.py": [
        [
          "random_array",
          37,
          38,
          38,
          12,
          38,
          44,
          37,
          18,
          38,
          44
        ],
        [
          "prepare_keypoint_matching_output",
          94,
          115,
          102,
          40,
          102,
          82,
          101,
          13,
          114,
          49
        ],
        [
          "prepare_keypoint_matching_output",
          94,
          115,
          103,
          40,
          103,
          82,
          101,
          13,
          114,
          49
        ],
        [
          "prepare_keypoint_matching_output",
          94,
          115,
          104,
          37,
          104,
          113,
          101,
          13,
          114,
          49
        ]
      ],
      "transformers/tests/models/timm_wrapper/test_image_processing_timm_wrapper.py": [
        [
          "test_image_processor_call_numpy",
          62,
          74,
          65,
          24,
          65,
          81,
          62,
          41,
          74,
          62
        ],
        [
          "test_image_processor_call_pil",
          76,
          88,
          79,
          40,
          79,
          97,
          76,
          39,
          88,
          62
        ],
        [
          "test_image_processor_call_tensor",
          90,
          102,
          93,
          41,
          93,
          98,
          90,
          42,
          102,
          62
        ]
      ],
      "transformers/tests/models/vitmatte/test_image_processing_vitmatte.py": [
        [
          "test_call_numpy",
          132,
          148,
          140,
          18,
          140,
          62,
          139,
          17,
          141,
          63
        ],
        [
          "test_call_pytorch",
          150,
          187,
          159,
          18,
          159,
          62,
          158,
          17,
          160,
          63
        ],
        [
          "test_call_pil",
          189,
          205,
          197,
          18,
          197,
          63,
          196,
          17,
          198,
          63
        ],
        [
          "test_call_numpy_4_channels",
          207,
          231,
          216,
          18,
          216,
          62,
          207,
          36,
          217,
          63
        ],
        [
          "test_image_processor_preprocess_arguments",
          254,
          269,
          261,
          22,
          261,
          67,
          258,
          13,
          269,
          53
        ],
        [
          "test_slow_fast_equivalence",
          302,
          316,
          310,
          24,
          310,
          75,
          309,
          23,
          316,
          106
        ],
        [
          "listcomp",
          332,
          332,
          332,
          26,
          332,
          70,
          332,
          76,
          332,
          70
        ],
        [
          "test_can_compile_fast_image_processor",
          345,
          361,
          354,
          24,
          354,
          74,
          352,
          9,
          361,
          113
        ]
      ],
      "transformers/tests/test_image_transforms.py": [
        [
          "test_resize",
          211,
          242,
          239,
          17,
          239,
          56,
          211,
          21,
          242,
          58
        ],
        [
          "test_normalize",
          244,
          311,
          283,
          17,
          283,
          56,
          244,
          24,
          311,
          81
        ],
        [
          "test_resize",
          211,
          242,
          212,
          17,
          212,
          56,
          211,
          21,
          242,
          58
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          194,
          17,
          194,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          181,
          17,
          181,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "get_random_image",
          47,
          50,
          49,
          20,
          49,
          67,
          48,
          13,
          50,
          23
        ],
        [
          "test_to_pil_image",
          66,
          73,
          67,
          17,
          67,
          54,
          66,
          27,
          73,
          64
        ],
        [
          "test_to_pil_image_from_mask",
          99,
          117,
          101,
          17,
          101,
          50,
          99,
          37,
          117,
          42
        ],
        [
          "test_to_pil_image_from_mask",
          99,
          117,
          110,
          17,
          110,
          50,
          99,
          37,
          117,
          42
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          158,
          17,
          158,
          56,
          157,
          43,
          209,
          57
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          173,
          17,
          173,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          177,
          17,
          177,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          186,
          17,
          186,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          199,
          17,
          199,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          203,
          17,
          203,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "test_get_resize_output_image_size",
          157,
          209,
          207,
          17,
          207,
          54,
          157,
          43,
          209,
          57
        ],
        [
          "test_normalize",
          244,
          311,
          245,
          17,
          245,
          56,
          244,
          24,
          311,
          81
        ],
        [
          "test_normalize",
          244,
          311,
          272,
          17,
          272,
          56,
          244,
          24,
          311,
          81
        ],
        [
          "test_normalize",
          244,
          311,
          292,
          17,
          292,
          56,
          244,
          24,
          311,
          81
        ],
        [
          "test_normalize",
          244,
          311,
          305,
          17,
          305,
          70,
          244,
          24,
          311,
          81
        ],
        [
          "test_center_crop",
          313,
          343,
          314,
          17,
          314,
          56,
          313,
          26,
          343,
          118
        ],
        [
          "test_center_crop",
          313,
          343,
          341,
          17,
          341,
          56,
          313,
          26,
          343,
          118
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "test_get_channel_dimension_axis",
          911,
          932,
          930,
          17,
          930,
          55,
          911,
          41,
          932,
          42
        ],
        [
          "test_get_channel_dimension_axis",
          911,
          932,
          925,
          17,
          925,
          52,
          911,
          41,
          932,
          42
        ],
        [
          "test_make_nested_list_of_images_numpy",
          312,
          352,
          314,
          18,
          314,
          55,
          312,
          47,
          352,
          72
        ],
        [
          "test_make_nested_list_of_images_numpy",
          312,
          352,
          321,
          18,
          321,
          58,
          312,
          47,
          352,
          72
        ],
        [
          "get_random_image",
          54,
          56,
          55,
          20,
          55,
          80,
          54,
          22,
          56,
          44
        ],
        [
          "test_conversion_array_to_array",
          88,
          120,
          90,
          17,
          90,
          70,
          88,
          40,
          120,
          55
        ],
        [
          "test_make_list_of_images_numpy",
          137,
          164,
          139,
          18,
          139,
          55,
          137,
          40,
          164,
          47
        ],
        [
          "test_make_list_of_images_numpy",
          137,
          164,
          146,
          18,
          146,
          58,
          137,
          40,
          164,
          47
        ],
        [
          "listcomp",
          153,
          153,
          153,
          19,
          153,
          56,
          153,
          62,
          153,
          56
        ],
        [
          "test_make_list_of_images_numpy",
          137,
          164,
          160,
          17,
          160,
          52,
          137,
          40,
          164,
          47
        ],
        [
          "test_make_flat_list_of_images_numpy",
          211,
          247,
          213,
          18,
          213,
          55,
          211,
          45,
          247,
          48
        ],
        [
          "test_make_flat_list_of_images_numpy",
          211,
          247,
          220,
          18,
          220,
          58,
          211,
          45,
          247,
          48
        ],
        [
          "listcomp",
          228,
          228,
          228,
          19,
          228,
          56,
          228,
          62,
          228,
          56
        ],
        [
          "listcomp",
          235,
          235,
          235,
          19,
          235,
          59,
          235,
          65,
          235,
          59
        ],
        [
          "listcomp",
          243,
          243,
          243,
          20,
          243,
          57,
          243,
          63,
          243,
          57
        ],
        [
          "listcomp",
          330,
          330,
          330,
          19,
          330,
          56,
          330,
          62,
          330,
          56
        ],
        [
          "listcomp",
          338,
          338,
          338,
          20,
          338,
          57,
          338,
          63,
          338,
          57
        ],
        [
          "listcomp",
          346,
          346,
          346,
          19,
          346,
          59,
          346,
          65,
          346,
          59
        ],
        [
          "test_conversion_array_to_image",
          442,
          469,
          444,
          17,
          444,
          70,
          442,
          40,
          469,
          64
        ],
        [
          "test_get_image_size",
          861,
          871,
          863,
          17,
          863,
          54,
          861,
          29,
          871,
          91
        ],
        [
          "test_get_image_size",
          861,
          871,
          866,
          17,
          866,
          54,
          861,
          29,
          871,
          91
        ],
        [
          "test_get_image_size",
          861,
          871,
          870,
          17,
          870,
          54,
          861,
          29,
          871,
          91
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          876,
          44,
          876,
          78,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          879,
          44,
          879,
          90,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          883,
          44,
          883,
          81,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          886,
          55,
          886,
          92,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          890,
          17,
          890,
          52,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          894,
          17,
          894,
          52,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          898,
          17,
          898,
          52,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          902,
          17,
          902,
          52,
          873,
          38,
          909,
          62
        ],
        [
          "test_infer_channel_dimension",
          873,
          909,
          907,
          17,
          907,
          55,
          873,
          38,
          909,
          62
        ],
        [
          "test_get_channel_dimension_axis",
          911,
          932,
          913,
          17,
          913,
          52,
          911,
          41,
          932,
          42
        ],
        [
          "test_get_channel_dimension_axis",
          911,
          932,
          917,
          17,
          917,
          52,
          911,
          41,
          932,
          42
        ],
        [
          "test_get_channel_dimension_axis",
          911,
          932,
          921,
          17,
          921,
          52,
          911,
          41,
          932,
          42
        ]
      ],
      "transformers/tests/models/aimv2/test_modeling_aimv2.py": [
        [
          "prepare_config_and_inputs",
          261,
          277,
          270,
          33,
          270,
          88,
          269,
          38,
          271,
          70
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "prepare_config_and_inputs",
          245,
          261,
          254,
          33,
          254,
          88,
          253,
          38,
          255,
          70
        ]
      ],
      "transformers/tests/generation/test_logits_process.py": [
        [
          "test_synthidtext_watermarking_processor_bias_uniformity",
          1039,
          1062,
          1045,
          21,
          1045,
          76,
          1039,
          65,
          1062,
          62
        ],
        [
          "test_synthidtext_watermark_processor_bias_uniformity_across_vocab",
          1065,
          1095,
          1073,
          21,
          1073,
          76,
          1065,
          75,
          1095,
          63
        ],
        [
          "test_synthidtext_watermark_processor_distributional_convergence",
          1098,
          1154,
          1122,
          25,
          1122,
          78,
          1119,
          13,
          1139,
          66
        ],
        [
          "listcomp",
          1163,
          1163,
          1163,
          17,
          1163,
          43,
          1163,
          49,
          1163,
          43
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip_text.py": [
        [
          "prepare_config_and_inputs",
          75,
          91,
          84,
          33,
          84,
          88,
          83,
          38,
          85,
          70
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip.py": [
        [
          "prepare_config_and_inputs",
          262,
          278,
          271,
          33,
          271,
          88,
          270,
          38,
          272,
          70
        ]
      ],
      "transformers/tests/models/blip_2/test_modeling_blip_2.py": [
        [
          "prepare_config_and_inputs",
          270,
          286,
          279,
          33,
          279,
          88,
          278,
          38,
          280,
          70
        ]
      ],
      "transformers/tests/models/clap/test_modeling_clap.py": [
        [
          "prepare_config_and_inputs",
          319,
          335,
          328,
          33,
          328,
          88,
          327,
          38,
          329,
          70
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "prepare_config_and_inputs",
          247,
          263,
          256,
          33,
          256,
          88,
          255,
          38,
          257,
          70
        ]
      ],
      "transformers/tests/models/clip/test_modeling_clip.py": [
        [
          "prepare_config_and_inputs",
          339,
          355,
          348,
          33,
          348,
          88,
          347,
          38,
          349,
          70
        ]
      ],
      "transformers/tests/models/clvp/test_modeling_clvp.py": [
        [
          "prepare_config_and_inputs",
          105,
          121,
          114,
          33,
          114,
          88,
          113,
          38,
          115,
          70
        ],
        [
          "prepare_config_and_inputs",
          243,
          259,
          252,
          33,
          252,
          88,
          251,
          38,
          253,
          70
        ]
      ],
      "transformers/tests/models/flava/test_modeling_flava.py": [
        [
          "prepare_config_and_inputs",
          374,
          395,
          383,
          33,
          383,
          88,
          382,
          38,
          384,
          70
        ],
        [
          "prepare_config_and_inputs",
          518,
          534,
          527,
          33,
          527,
          88,
          526,
          38,
          528,
          70
        ]
      ],
      "transformers/tests/models/groupvit/test_modeling_groupvit.py": [
        [
          "prepare_config_and_inputs",
          380,
          397,
          390,
          33,
          390,
          88,
          389,
          38,
          391,
          70
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_modeling_instructblipvideo.py": [
        [
          "prepare_config_and_inputs",
          274,
          292,
          285,
          33,
          285,
          88,
          284,
          38,
          286,
          70
        ]
      ],
      "transformers/tests/models/instructblip/test_modeling_instructblip.py": [
        [
          "prepare_config_and_inputs",
          264,
          282,
          275,
          33,
          275,
          88,
          274,
          38,
          276,
          70
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_modeling_kosmos2_5.py": [
        [
          "prepare_config_and_inputs",
          161,
          177,
          170,
          33,
          170,
          88,
          169,
          38,
          171,
          70
        ]
      ],
      "transformers/tests/models/kosmos2/test_modeling_kosmos2.py": [
        [
          "prepare_config_and_inputs",
          164,
          180,
          173,
          33,
          173,
          88,
          172,
          38,
          174,
          70
        ]
      ],
      "transformers/tests/models/metaclip_2/test_modeling_metaclip_2.py": [
        [
          "prepare_config_and_inputs",
          342,
          360,
          353,
          33,
          353,
          88,
          352,
          38,
          354,
          70
        ]
      ],
      "transformers/tests/models/owlv2/test_modeling_owlv2.py": [
        [
          "prepare_config_and_inputs",
          255,
          272,
          265,
          33,
          265,
          86,
          263,
          36,
          266,
          64
        ]
      ],
      "transformers/tests/models/owlvit/test_modeling_owlvit.py": [
        [
          "prepare_config_and_inputs",
          252,
          269,
          262,
          33,
          262,
          86,
          260,
          36,
          263,
          64
        ]
      ],
      "transformers/tests/models/pix2struct/test_modeling_pix2struct.py": [
        [
          "prepare_config_and_inputs",
          262,
          278,
          271,
          33,
          271,
          88,
          270,
          38,
          272,
          70
        ]
      ]
    },
    "uuid.uuid4": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "setUp",
          2163,
          2164,
          2164,
          63,
          2164,
          74,
          2163,
          15,
          2164,
          22
        ]
      ],
      "transformers/benchmark/benchmarks_entrypoint.py": [
        [
          "initialise_benchmark",
          103,
          144,
          108,
          28,
          108,
          39,
          103,
          30,
          110,
          28
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "generate_uuid",
          83,
          84,
          84,
          16,
          84,
          27,
          84,
          12,
          84,
          28
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "main",
          278,
          491,
          281,
          30,
          281,
          41,
          279,
          5,
          380,
          40
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "get_or_set_request_id",
          751,
          756,
          752,
          67,
          752,
          78,
          752,
          63,
          752,
          79
        ]
      ]
    },
    "random.randint": {
      "transformers/tests/models/whisper/test_modeling_whisper.py": [
        [
          "__init__",
          77,
          99,
          99,
          45,
          99,
          65,
          98,
          21,
          99,
          71
        ]
      ],
      "transformers/src/transformers/data/data_collator.py": [
        [
          "numpy_mask_tokens",
          1265,
          1360,
          1302,
          31,
          1302,
          66,
          1302,
          31,
          1309,
          23
        ],
        [
          "numpy_mask_tokens",
          1265,
          1360,
          1306,
          41,
          1306,
          84,
          1302,
          31,
          1309,
          23
        ]
      ],
      "transformers/src/transformers/utils/fx.py": [
        [
          "_generate_random_int",
          847,
          853,
          850,
          13,
          850,
          37,
          850,
          13,
          850,
          9
        ],
        [
          "_generate_random_int",
          847,
          853,
          852,
          17,
          852,
          41,
          852,
          17,
          852,
          13
        ]
      ],
      "transformers/src/transformers/models/flava/image_processing_flava_fast.py": [
        [
          "_mask",
          85,
          105,
          93,
          23,
          93,
          61,
          93,
          23,
          98,
          70
        ],
        [
          "_mask",
          85,
          105,
          94,
          24,
          94,
          60,
          93,
          23,
          98,
          70
        ]
      ],
      "transformers/src/transformers/models/flava/image_processing_flava.py": [
        [
          "_mask",
          182,
          204,
          190,
          23,
          190,
          61,
          190,
          23,
          195,
          70
        ],
        [
          "_mask",
          182,
          204,
          191,
          24,
          191,
          60,
          190,
          23,
          195,
          70
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "create_examples_from_document",
          228,
          325,
          268,
          33,
          268,
          73,
          268,
          33,
          268,
          29
        ],
        [
          "create_examples_from_document",
          228,
          325,
          243,
          33,
          243,
          65,
          243,
          33,
          243,
          29
        ],
        [
          "create_examples_from_document",
          420,
          508,
          434,
          33,
          434,
          65,
          434,
          33,
          434,
          29
        ],
        [
          "create_examples_from_document",
          420,
          508,
          450,
          33,
          450,
          73,
          450,
          33,
          450,
          29
        ],
        [
          "create_examples_from_document",
          420,
          508,
          467,
          53,
          467,
          94,
          466,
          29,
          468,
          65
        ],
        [
          "create_examples_from_document",
          420,
          508,
          472,
          40,
          472,
          82,
          471,
          43,
          473,
          74
        ]
      ],
      "transformers/examples/pytorch/audio-classification/run_audio_classification.py": [
        [
          "random_subsample",
          63,
          69,
          68,
          21,
          68,
          60,
          68,
          21,
          69,
          61
        ]
      ]
    },
    "random.random": {
      "transformers/tests/trainer/test_trainer_distributed_worker_seed.py": [
        [
          "__getitem__",
          40,
          44,
          41,
          13,
          41,
          27,
          40,
          21,
          44,
          45
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "forward",
          492,
          506,
          497,
          25,
          497,
          39,
          496,
          23,
          499,
          32
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "create_examples_from_document",
          228,
          325,
          242,
          12,
          242,
          26,
          228,
          39,
          242,
          43
        ],
        [
          "create_examples_from_document",
          228,
          325,
          283,
          24,
          283,
          38,
          283,
          24,
          283,
          44
        ],
        [
          "truncate_seq_pair",
          289,
          303,
          300,
          32,
          300,
          46,
          300,
          32,
          300,
          52
        ],
        [
          "create_examples_from_document",
          420,
          508,
          433,
          12,
          433,
          26,
          420,
          39,
          433,
          55
        ],
        [
          "create_examples_from_document",
          420,
          508,
          458,
          51,
          458,
          65,
          458,
          51,
          458,
          88
        ]
      ]
    }
  },
  "CWE-347": {},
  "CWE-377": {
    "tempfile.TemporaryDirectory": {
      "transformers/tests/models/roberta/test_modeling_roberta.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          516,
          628,
          565,
          18,
          565,
          46,
          565,
          18,
          572,
          60
        ]
      ],
      "transformers/tests/models/roberta_prelayernorm/test_modeling_roberta_prelayernorm.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          526,
          638,
          575,
          18,
          575,
          46,
          575,
          18,
          582,
          60
        ]
      ],
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUpClass",
          1066,
          1077,
          1067,
          24,
          1067,
          52,
          1066,
          20,
          1077,
          38
        ],
        [
          "test_rag_sequence_from_pretrained",
          1116,
          1172,
          1136,
          14,
          1136,
          42,
          1116,
          43,
          1172,
          82
        ],
        [
          "test_rag_token_from_pretrained",
          1175,
          1236,
          1195,
          14,
          1195,
          42,
          1175,
          40,
          1236,
          82
        ],
        [
          "setUpClass",
          685,
          696,
          686,
          24,
          686,
          52,
          685,
          20,
          696,
          38
        ]
      ],
      "transformers/tests/models/roc_bert/test_modeling_roc_bert.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          701,
          813,
          750,
          18,
          750,
          46,
          750,
          18,
          757,
          60
        ]
      ],
      "transformers/tests/models/rt_detr/test_modeling_rt_detr.py": [
        [
          "test_inference_equivalence_for_static_and_dynamic_anchors",
          616,
          653,
          632,
          18,
          632,
          46,
          631,
          13,
          653,
          13
        ]
      ],
      "transformers/tests/models/rt_detr_v2/test_modeling_rt_detr_v2.py": [
        [
          "test_inference_equivalence_for_static_and_dynamic_anchors",
          620,
          657,
          636,
          18,
          636,
          46,
          635,
          13,
          657,
          13
        ]
      ],
      "transformers/tests/models/sam/test_modeling_sam.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          663,
          718,
          684,
          18,
          684,
          46,
          680,
          13,
          693,
          58
        ]
      ],
      "transformers/tests/models/sam2/test_modeling_sam2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          559,
          605,
          580,
          18,
          580,
          46,
          576,
          13,
          598,
          66
        ],
        [
          "flash_attn_inference_equivalence",
          608,
          696,
          627,
          18,
          627,
          46,
          624,
          35,
          638,
          70
        ]
      ],
      "transformers/tests/models/sam_hq/test_modeling_sam_hq.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          711,
          765,
          732,
          18,
          732,
          46,
          728,
          13,
          741,
          58
        ]
      ],
      "transformers/tests/models/siglip/test_modeling_siglip.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          62,
          88,
          67,
          18,
          67,
          46,
          63,
          13,
          79,
          50
        ],
        [
          "_create_and_check_torchscript",
          491,
          560,
          510,
          18,
          510,
          46,
          510,
          18,
          514,
          25
        ],
        [
          "test_load_vision_text_config",
          563,
          576,
          567,
          14,
          567,
          42,
          563,
          38,
          576,
          85
        ],
        [
          "test_load_vision_text_config",
          563,
          576,
          573,
          14,
          573,
          42,
          563,
          38,
          576,
          85
        ]
      ],
      "transformers/tests/models/speech_encoder_decoder/test_modeling_speech_encoder_decoder.py": [
        [
          "check_save_and_load",
          198,
          239,
          224,
          18,
          224,
          46,
          199,
          9,
          239,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          241,
          288,
          268,
          17,
          268,
          45,
          242,
          9,
          288,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          241,
          288,
          269,
          17,
          269,
          45,
          242,
          9,
          288,
          52
        ],
        [
          "test_real_model_save_load_from_pretrained",
          437,
          455,
          446,
          18,
          446,
          46,
          437,
          51,
          455,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          458,
          506,
          466,
          14,
          466,
          42,
          458,
          49,
          473,
          65
        ]
      ],
      "transformers/tests/models/siglip2/test_modeling_siglip2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          64,
          90,
          69,
          18,
          69,
          46,
          65,
          13,
          81,
          50
        ],
        [
          "test_flash_attn_2_inference_equivalence",
          96,
          159,
          118,
          18,
          118,
          46,
          118,
          18,
          148,
          41
        ],
        [
          "test_load_vision_text_config",
          583,
          596,
          587,
          14,
          587,
          42,
          583,
          38,
          596,
          85
        ],
        [
          "test_load_vision_text_config",
          583,
          596,
          593,
          14,
          593,
          42,
          583,
          38,
          596,
          85
        ]
      ],
      "transformers/tests/models/speech_to_text/test_modeling_speech_to_text.py": [
        [
          "check_encoder_decoder_model_standalone",
          222,
          256,
          229,
          14,
          229,
          42,
          222,
          48,
          256,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          222,
          256,
          240,
          14,
          240,
          42,
          222,
          48,
          256,
          99
        ],
        [
          "test_save_load_strict",
          280,
          288,
          285,
          18,
          285,
          46,
          282,
          13,
          288,
          54
        ],
        [
          "_create_and_check_torchscript",
          606,
          680,
          630,
          18,
          630,
          46,
          630,
          18,
          634,
          25
        ]
      ],
      "transformers/tests/models/speecht5/test_modeling_speecht5.py": [
        [
          "test_save_load_strict",
          365,
          373,
          370,
          18,
          370,
          46,
          367,
          13,
          373,
          54
        ],
        [
          "test_save_load_strict",
          871,
          879,
          876,
          18,
          876,
          46,
          873,
          13,
          879,
          54
        ],
        [
          "test_save_load_strict",
          1387,
          1395,
          1392,
          18,
          1392,
          46,
          1389,
          13,
          1395,
          54
        ]
      ],
      "transformers/tests/models/switch_transformers/test_modeling_switch_transformers.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          447,
          521,
          495,
          18,
          495,
          46,
          456,
          13,
          521,
          17
        ]
      ],
      "transformers/tests/models/t5/test_modeling_t5.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          443,
          517,
          491,
          18,
          491,
          46,
          452,
          13,
          517,
          17
        ],
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          693,
          18,
          693,
          46,
          693,
          18,
          696,
          50
        ]
      ],
      "transformers/tests/models/time_series_transformer/test_modeling_time_series_transformer.py": [
        [
          "check_encoder_decoder_model_standalone",
          144,
          174,
          151,
          14,
          151,
          42,
          144,
          48,
          174,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          144,
          174,
          164,
          14,
          164,
          42,
          144,
          48,
          174,
          99
        ],
        [
          "test_save_load_strict",
          201,
          209,
          206,
          18,
          206,
          46,
          203,
          13,
          209,
          54
        ]
      ],
      "transformers/tests/models/umt5/test_modeling_umt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          381,
          18,
          381,
          46,
          381,
          18,
          384,
          50
        ]
      ],
      "transformers/tests/models/timm_wrapper/test_modeling_timm_wrapper.py": [
        [
          "test_timm_config_labels",
          198,
          244,
          238,
          14,
          238,
          42,
          198,
          33,
          244,
          67
        ],
        [
          "test_model_init_args",
          246,
          262,
          259,
          14,
          259,
          42,
          246,
          30,
          262,
          70
        ],
        [
          "test_save_load_to_timm",
          428,
          452,
          435,
          14,
          435,
          42,
          428,
          32,
          447,
          9
        ]
      ],
      "transformers/tests/models/videomae/test_modeling_videomae.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          357,
          399,
          371,
          18,
          371,
          46,
          365,
          35,
          386,
          58
        ]
      ],
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_offline",
          276,
          322,
          290,
          22,
          290,
          50,
          290,
          22,
          290,
          50
        ],
        [
          "test_local_files_only",
          324,
          364,
          335,
          22,
          335,
          50,
          335,
          22,
          335,
          50
        ],
        [
          "test_model_from_pretrained_subfolder",
          454,
          467,
          459,
          14,
          459,
          42,
          454,
          46,
          467,
          64
        ],
        [
          "test_model_manually_shared_disjointed_tensors_optimum",
          469,
          487,
          483,
          14,
          483,
          42,
          469,
          63,
          487,
          64
        ],
        [
          "test_model_from_pretrained_subfolder_sharded",
          489,
          502,
          494,
          14,
          494,
          42,
          489,
          54,
          502,
          64
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          787,
          14,
          787,
          42,
          784,
          44,
          789,
          54
        ],
        [
          "test_checkpoint_variant_local_bin",
          834,
          852,
          837,
          14,
          837,
          42,
          834,
          43,
          851,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_bin",
          854,
          876,
          857,
          14,
          857,
          42,
          854,
          51,
          865,
          32
        ],
        [
          "test_checkpoint_variant_local_safe",
          878,
          896,
          881,
          14,
          881,
          42,
          878,
          44,
          895,
          69
        ],
        [
          "test_checkpoint_variant_local_sharded_safe",
          898,
          920,
          901,
          14,
          901,
          42,
          898,
          52,
          909,
          32
        ],
        [
          "test_checkpoint_loading_only_safetensors_available",
          922,
          953,
          930,
          14,
          930,
          42,
          922,
          60,
          937,
          32
        ],
        [
          "test_checkpoint_loading_only_pytorch_bin_available",
          955,
          986,
          963,
          14,
          963,
          42,
          955,
          60,
          970,
          32
        ],
        [
          "test_checkpoint_variant_hub",
          988,
          995,
          989,
          14,
          989,
          42,
          988,
          37,
          995,
          35
        ],
        [
          "test_checkpoint_variant_hub_sharded",
          997,
          1006,
          998,
          14,
          998,
          42,
          997,
          45,
          1006,
          35
        ],
        [
          "test_checkpoint_variant_hub_safe",
          1008,
          1015,
          1009,
          14,
          1009,
          42,
          1008,
          42,
          1015,
          35
        ],
        [
          "test_checkpoint_variant_hub_sharded_safe",
          1017,
          1026,
          1018,
          14,
          1018,
          42,
          1017,
          50,
          1026,
          35
        ],
        [
          "test_checkpoint_variant_save_load_bin",
          1028,
          1047,
          1029,
          14,
          1029,
          42,
          1028,
          47,
          1047,
          35
        ],
        [
          "test_from_pretrained_disk_offload_task_model",
          1071,
          1107,
          1084,
          14,
          1084,
          42,
          1071,
          54,
          1107,
          84
        ],
        [
          "test_from_pretrained_disk_offload_derived_to_base_model",
          1112,
          1147,
          1125,
          14,
          1125,
          42,
          1112,
          65,
          1147,
          76
        ],
        [
          "test_from_pretrained_non_contiguous_checkpoint",
          1151,
          1164,
          1162,
          14,
          1162,
          42,
          1151,
          56,
          1164,
          67
        ],
        [
          "test_save_model_with_device_map_cpu",
          1187,
          1200,
          1191,
          14,
          1191,
          42,
          1187,
          45,
          1200,
          62
        ],
        [
          "test_save_offloaded_model",
          1205,
          1237,
          1224,
          14,
          1224,
          42,
          1205,
          35,
          1237,
          69
        ],
        [
          "test_save_offloaded_model_with_direct_params",
          1242,
          1250,
          1249,
          14,
          1249,
          42,
          1242,
          54,
          1250,
          42
        ],
        [
          "test_save_offloaded_model_dynamic_tied_weights_keys",
          1255,
          1273,
          1272,
          14,
          1272,
          42,
          1255,
          61,
          1273,
          42
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1286,
          14,
          1286,
          42,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1299,
          14,
          1299,
          42,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1321,
          18,
          1321,
          46,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_safetensors_save_and_load",
          1331,
          1343,
          1333,
          14,
          1333,
          42,
          1331,
          40,
          1342,
          73
        ],
        [
          "test_safetensors_save_and_load_sharded",
          1353,
          1368,
          1355,
          14,
          1355,
          42,
          1353,
          48,
          1367,
          73
        ],
        [
          "test_base_model_to_head_model_load",
          1378,
          1398,
          1380,
          14,
          1380,
          42,
          1378,
          44,
          1385,
          79
        ],
        [
          "test_tied_weights_reload",
          1400,
          1422,
          1403,
          14,
          1403,
          42,
          1400,
          34,
          1422,
          77
        ],
        [
          "test_unexpected_keys_warnings",
          1424,
          1448,
          1427,
          14,
          1427,
          42,
          1424,
          39,
          1448,
          76
        ],
        [
          "test_safetensors_torch_from_torch",
          1583,
          1591,
          1586,
          14,
          1586,
          42,
          1583,
          43,
          1590,
          69
        ],
        [
          "test_safetensors_torch_from_torch_sharded",
          1593,
          1601,
          1596,
          14,
          1596,
          42,
          1593,
          51,
          1600,
          69
        ],
        [
          "test_modifying_model_config_gets_moved_to_generation_config",
          1603,
          1626,
          1616,
          18,
          1616,
          46,
          1603,
          69,
          1626,
          77
        ],
        [
          "test_model_from_pretrained_from_mlx",
          1628,
          1645,
          1634,
          14,
          1634,
          42,
          1628,
          45,
          1645,
          87
        ],
        [
          "test_warning_for_beta_gamma_parameters",
          1647,
          1670,
          1654,
          14,
          1654,
          42,
          1647,
          48,
          1670,
          56
        ],
        [
          "test_save_and_load_config_with_custom_generation",
          1747,
          1777,
          1763,
          14,
          1763,
          42,
          1747,
          58,
          1777,
          40
        ],
        [
          "test_unknown_quantization_config",
          1887,
          1898,
          1888,
          14,
          1888,
          42,
          1887,
          42,
          1898,
          95
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          1994,
          14,
          1994,
          42,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2020,
          14,
          2020,
          42,
          2006,
          66,
          2030,
          85
        ],
        [
          "test_ignore_missing_key_works",
          2063,
          2084,
          2066,
          16,
          2066,
          44,
          2063,
          39,
          2083,
          46
        ],
        [
          "test_device_map_works_with_unexpected_keys",
          2086,
          2107,
          2090,
          16,
          2090,
          44,
          2086,
          52,
          2107,
          112
        ],
        [
          "test_device_map_works_with_unexpected_keys_sharded",
          2109,
          2147,
          2113,
          16,
          2113,
          44,
          2109,
          60,
          2139,
          54
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          2409,
          2421,
          2416,
          18,
          2416,
          46,
          2409,
          46,
          2420,
          73
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          2455,
          2467,
          2462,
          18,
          2462,
          46,
          2455,
          62,
          2466,
          73
        ],
        [
          "test_save_and_load_model_with_tensor_extra_state",
          2968,
          3002,
          2999,
          14,
          2999,
          42,
          2968,
          58,
          3002,
          61
        ],
        [
          "test_save_and_load_model_with_dict_extra_state",
          3005,
          3039,
          3036,
          14,
          3036,
          42,
          3005,
          56,
          3039,
          61
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_modeling_vision_text_dual_encoder.py": [
        [
          "check_save_load",
          114,
          132,
          124,
          18,
          124,
          46,
          114,
          25,
          132,
          52
        ],
        [
          "test_real_model_save_load_from_pretrained",
          188,
          204,
          196,
          18,
          196,
          46,
          188,
          51,
          204,
          52
        ]
      ],
      "transformers/tests/models/vit_mae/test_modeling_vit_mae.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          271,
          317,
          285,
          18,
          285,
          46,
          279,
          35,
          304,
          58
        ],
        [
          "test_save_load",
          215,
          243,
          230,
          18,
          230,
          46,
          218,
          13,
          243,
          52
        ]
      ],
      "transformers/tests/models/vision_encoder_decoder/test_modeling_vision_encoder_decoder.py": [
        [
          "check_save_and_load",
          170,
          199,
          186,
          18,
          186,
          46,
          171,
          9,
          199,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          201,
          236,
          218,
          17,
          218,
          45,
          202,
          9,
          236,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          201,
          236,
          219,
          17,
          219,
          45,
          202,
          9,
          236,
          52
        ],
        [
          "test_real_model_save_load_from_pretrained",
          375,
          393,
          384,
          18,
          384,
          46,
          375,
          51,
          393,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          396,
          447,
          407,
          14,
          407,
          42,
          400,
          23,
          414,
          65
        ]
      ],
      "transformers/tests/models/voxtral/test_modeling_voxtral.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          191,
          226,
          203,
          18,
          203,
          46,
          199,
          13,
          208,
          73
        ]
      ],
      "transformers/tests/models/vits/test_modeling_vits.py": [
        [
          "test_save_load",
          309,
          349,
          330,
          18,
          330,
          46,
          322,
          13,
          345,
          39
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_modeling_wav2vec2_bert.py": [
        [
          "create_and_check_model_float16",
          231,
          246,
          234,
          14,
          234,
          42,
          231,
          40,
          246,
          9
        ]
      ],
      "transformers/tests/models/wav2vec2_conformer/test_modeling_wav2vec2_conformer.py": [
        [
          "create_and_check_model_float16",
          224,
          239,
          227,
          14,
          227,
          42,
          224,
          40,
          239,
          9
        ]
      ],
      "transformers/tests/models/x_clip/test_modeling_x_clip.py": [
        [
          "_create_and_check_torchscript",
          564,
          633,
          583,
          18,
          583,
          46,
          583,
          18,
          587,
          25
        ],
        [
          "test_load_vision_text_config",
          635,
          648,
          639,
          14,
          639,
          42,
          635,
          38,
          648,
          85
        ],
        [
          "test_load_vision_text_config",
          635,
          648,
          645,
          14,
          645,
          42,
          635,
          38,
          648,
          85
        ]
      ],
      "transformers/tests/models/wav2vec2/test_modeling_wav2vec2.py": [
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          759,
          18,
          759,
          46,
          759,
          18,
          762,
          50
        ],
        [
          "test_load_attn_adapter",
          1123,
          1200,
          1148,
          14,
          1148,
          42,
          1123,
          32,
          1200,
          74
        ],
        [
          "test_load_attn_adapter",
          1123,
          1200,
          1170,
          14,
          1170,
          42,
          1123,
          32,
          1200,
          74
        ]
      ],
      "transformers/tests/models/whisper/test_modeling_whisper.py": [
        [
          "check_encoder_decoder_model_standalone",
          321,
          348,
          328,
          14,
          328,
          42,
          321,
          48,
          348,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          321,
          348,
          337,
          14,
          337,
          42,
          321,
          48,
          348,
          99
        ],
        [
          "test_save_load_strict",
          418,
          426,
          423,
          18,
          423,
          46,
          420,
          13,
          426,
          54
        ],
        [
          "_create_and_check_torchscript",
          846,
          928,
          878,
          18,
          878,
          46,
          878,
          18,
          882,
          25
        ]
      ],
      "transformers/tests/models/xcodec/test_modeling_xcodec.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          207,
          18,
          207,
          46,
          207,
          18,
          211,
          25
        ]
      ],
      "transformers/tests/models/xlm_roberta_xl/test_modeling_xlm_roberta_xl.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          517,
          629,
          566,
          18,
          566,
          46,
          566,
          18,
          573,
          60
        ],
        [
          "flash_attn_inference_equivalence",
          631,
          733,
          647,
          18,
          647,
          46,
          642,
          13,
          658,
          70
        ]
      ],
      "transformers/tests/models/xmod/test_modeling_xmod.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          531,
          643,
          580,
          18,
          580,
          46,
          580,
          18,
          587,
          60
        ]
      ],
      "transformers/tests/models/zamba/test_modeling_zamba.py": [
        [
          "test_flash_attn_2_fp32_ln",
          435,
          466,
          444,
          18,
          444,
          46,
          440,
          13,
          459,
          56
        ]
      ],
      "transformers/tests/models/zamba2/test_modeling_zamba2.py": [
        [
          "test_flash_attn_2_fp32_ln",
          465,
          496,
          474,
          18,
          474,
          46,
          470,
          13,
          489,
          56
        ]
      ],
      "transformers/tests/quantization/mxfp4/test_mxfp4.py": [
        [
          "test_save_mxfp4",
          470,
          499,
          479,
          14,
          479,
          42,
          470,
          25,
          499,
          79
        ],
        [
          "test_save_mxfp4_non_quantized",
          501,
          530,
          512,
          14,
          512,
          42,
          501,
          39,
          530,
          79
        ]
      ],
      "transformers/tests/optimization/test_optimization.py": [
        [
          "unwrap_and_save_reload_schedule",
          50,
          62,
          56,
          18,
          56,
          46,
          56,
          18,
          61,
          53
        ]
      ],
      "transformers/tests/peft_integration/test_peft_integration.py": [
        [
          "test_peft_save_pretrained",
          122,
          149,
          131,
          22,
          131,
          50,
          128,
          17,
          149,
          85
        ],
        [
          "test_peft_add_adapter_from_pretrained",
          198,
          216,
          213,
          22,
          213,
          50,
          205,
          17,
          216,
          96
        ],
        [
          "test_peft_add_multi_adapter",
          302,
          364,
          363,
          53,
          363,
          81,
          334,
          17,
          364,
          53
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          531,
          22,
          531,
          50,
          521,
          17,
          536,
          86
        ],
        [
          "test_peft_save_quantized",
          515,
          556,
          550,
          22,
          550,
          50,
          540,
          17,
          556,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          577,
          22,
          577,
          50,
          567,
          17,
          582,
          86
        ],
        [
          "test_peft_save_quantized_regression",
          560,
          602,
          596,
          22,
          596,
          50,
          586,
          17,
          602,
          86
        ],
        [
          "test_peft_load_adapter_training_inference_mode_true",
          787,
          802,
          796,
          22,
          796,
          50,
          793,
          17,
          800,
          79
        ],
        [
          "test_peft_load_adapter_training_inference_mode_false",
          804,
          828,
          813,
          22,
          813,
          50,
          810,
          17,
          818,
          61
        ],
        [
          "test_prefix_tuning_trainer_load_best_model_at_end_error",
          830,
          901,
          879,
          18,
          879,
          46,
          874,
          13,
          894,
          38
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_common.py": [
        [
          "test_pipeline_pathlike",
          126,
          132,
          128,
          14,
          128,
          42,
          126,
          32,
          132,
          66
        ],
        [
          "test_auto_model_pipeline_registration_from_local_dir",
          210,
          215,
          211,
          14,
          211,
          42,
          210,
          62,
          215,
          63
        ],
        [
          "test_dynamic_pipeline",
          749,
          796,
          761,
          14,
          761,
          42,
          753,
          22,
          769,
          93
        ],
        [
          "test_push_to_hub_dynamic_pipeline",
          886,
          964,
          900,
          14,
          900,
          42,
          886,
          43,
          964,
          9
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_segmentation.py": [
        [
          "test_save_load",
          751,
          763,
          761,
          14,
          761,
          42,
          751,
          24,
          763,
          65
        ]
      ],
      "transformers/tests/models/blip_2/test_processing_blip_2.py": [
        [
          "test_save_load_pretrained_additional_features",
          58,
          74,
          59,
          14,
          59,
          42,
          58,
          55,
          74,
          76
        ]
      ],
      "transformers/tests/models/blip/test_processing_blip.py": [
        [
          "test_save_load_pretrained_additional_features",
          55,
          71,
          56,
          14,
          56,
          42,
          55,
          55,
          71,
          76
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "test_save_load_pretrained_additional_features",
          127,
          145,
          128,
          14,
          128,
          42,
          127,
          55,
          145,
          83
        ],
        [
          "test_save_load_pretrained_default",
          102,
          125,
          107,
          14,
          107,
          42,
          102,
          43,
          125,
          88
        ]
      ],
      "transformers/tests/models/clip/test_processing_clip.py": [
        [
          "test_save_load_pretrained_default",
          66,
          89,
          71,
          14,
          71,
          42,
          66,
          43,
          89,
          81
        ],
        [
          "test_save_load_pretrained_additional_features",
          91,
          109,
          92,
          14,
          92,
          42,
          91,
          55,
          109,
          76
        ]
      ],
      "transformers/tests/test_processing_common.py": [
        [
          "test_processor_from_and_save_pretrained",
          202,
          219,
          205,
          14,
          205,
          42,
          202,
          49,
          207,
          35
        ],
        [
          "test_processor_from_and_save_pretrained_as_nested_dict",
          221,
          249,
          224,
          14,
          224,
          42,
          221,
          64,
          234,
          55
        ],
        [
          "test_args_overlap_kwargs",
          511,
          521,
          518,
          14,
          518,
          42,
          514,
          27,
          521,
          73
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          947,
          14,
          947,
          42,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          957,
          14,
          957,
          42,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          968,
          14,
          968,
          42,
          945,
          39,
          984,
          77
        ],
        [
          "test_chat_template_save_loading",
          939,
          984,
          982,
          18,
          982,
          46,
          945,
          39,
          984,
          77
        ]
      ],
      "transformers/tests/models/git/test_processing_git.py": [
        [
          "test_save_load_pretrained_additional_features",
          57,
          73,
          58,
          14,
          58,
          42,
          57,
          55,
          73,
          76
        ]
      ],
      "transformers/tests/models/idefics/test_processing_idefics.py": [
        [
          "test_save_load_pretrained_additional_features",
          111,
          127,
          112,
          14,
          112,
          42,
          111,
          55,
          127,
          79
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "test_save_load_pretrained_default",
          149,
          172,
          154,
          14,
          154,
          42,
          149,
          43,
          172,
          90
        ],
        [
          "test_save_load_pretrained_additional_features",
          175,
          195,
          176,
          14,
          176,
          42,
          175,
          55,
          195,
          85
        ]
      ],
      "transformers/tests/models/instructblip/test_processing_instructblip.py": [
        [
          "test_save_load_pretrained_additional_features",
          69,
          90,
          75,
          14,
          75,
          42,
          69,
          55,
          90,
          77
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_processing_instructblipvideo.py": [
        [
          "test_save_load_pretrained_additional_features",
          72,
          93,
          78,
          14,
          78,
          42,
          72,
          55,
          93,
          77
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "test_save_load_pretrained_default",
          89,
          103,
          95,
          18,
          95,
          46,
          92,
          13,
          103,
          86
        ],
        [
          "test_save_load_pretrained_additional_features",
          105,
          141,
          106,
          14,
          106,
          42,
          105,
          55,
          141,
          82
        ]
      ],
      "transformers/tests/models/kosmos2/test_processing_kosmos2.py": [
        [
          "test_image_processor_load_save_reload",
          100,
          107,
          103,
          14,
          103,
          33,
          100,
          47,
          106,
          82
        ],
        [
          "test_save_load_pretrained_additional_features",
          109,
          125,
          110,
          14,
          110,
          42,
          109,
          55,
          125,
          76
        ]
      ],
      "transformers/tests/models/omdet_turbo/test_processing_omdet_turbo.py": [
        [
          "test_save_load_pretrained_additional_features",
          116,
          132,
          117,
          14,
          117,
          42,
          116,
          55,
          132,
          76
        ]
      ],
      "transformers/tests/models/oneformer/test_processing_oneformer.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          404,
          414,
          407,
          14,
          407,
          42,
          404,
          52,
          414,
          74
        ]
      ],
      "transformers/tests/models/pix2struct/test_processing_pix2struct.py": [
        [
          "test_save_load_pretrained_additional_features",
          64,
          80,
          65,
          14,
          65,
          42,
          64,
          55,
          80,
          82
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_processing_qwen2_audio.py": [
        [
          "test_save_load_pretrained_default",
          56,
          69,
          63,
          14,
          63,
          42,
          56,
          43,
          69,
          83
        ]
      ],
      "transformers/tests/models/pop2piano/test_processing_pop2piano.py": [
        [
          "test_save_load_pretrained_additional_features",
          85,
          113,
          86,
          14,
          86,
          42,
          85,
          55,
          113,
          85
        ]
      ],
      "transformers/tests/models/sam/test_processing_sam.py": [
        [
          "test_save_load_pretrained_additional_features",
          79,
          89,
          80,
          14,
          80,
          42,
          79,
          55,
          89,
          75
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "test_save_load_pretrained_default",
          54,
          66,
          55,
          14,
          55,
          42,
          54,
          43,
          66,
          102
        ],
        [
          "test_save_load_pretrained_additional_features",
          68,
          83,
          69,
          14,
          69,
          42,
          68,
          55,
          83,
          75
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "test_save_load_pretrained_additional_features",
          92,
          112,
          93,
          14,
          93,
          42,
          92,
          55,
          112,
          84
        ]
      ],
      "transformers/tests/models/speech_to_text/test_processing_speech_to_text.py": [
        [
          "test_save_load_pretrained_additional_features",
          85,
          105,
          86,
          14,
          86,
          42,
          85,
          55,
          105,
          87
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "test_save_load_pretrained_additional_features",
          92,
          110,
          93,
          14,
          93,
          42,
          92,
          55,
          110,
          100
        ],
        [
          "test_save_load_pretrained_default",
          77,
          90,
          82,
          14,
          82,
          42,
          77,
          43,
          90,
          100
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "test_save_load_pretrained_default",
          78,
          92,
          84,
          14,
          84,
          42,
          78,
          43,
          92,
          84
        ],
        [
          "test_save_load_pretrained_additional_features",
          94,
          116,
          95,
          14,
          95,
          42,
          94,
          55,
          116,
          84
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "test_save_load_pretrained_default",
          79,
          93,
          85,
          14,
          85,
          42,
          79,
          43,
          93,
          87
        ],
        [
          "test_save_load_pretrained_additional_features",
          95,
          117,
          96,
          14,
          96,
          42,
          95,
          55,
          117,
          87
        ]
      ],
      "transformers/tests/models/udop/test_processing_udop.py": [
        [
          "test_save_load_pretrained_additional_features",
          111,
          147,
          112,
          14,
          112,
          42,
          111,
          55,
          147,
          82
        ],
        [
          "test_save_load_pretrained_default",
          96,
          109,
          101,
          18,
          101,
          46,
          99,
          13,
          109,
          86
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_processor_kosmos2_5.py": [
        [
          "test_image_procesor_load_save_reload",
          68,
          75,
          71,
          14,
          71,
          33,
          68,
          46,
          74,
          82
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_new_processor_registration",
          234,
          270,
          255,
          18,
          255,
          46,
          255,
          18,
          255,
          46
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          126,
          14,
          126,
          42,
          125,
          55,
          135,
          71
        ],
        [
          "test_processor_from_local_directory_from_repo",
          74,
          85,
          75,
          14,
          75,
          42,
          74,
          55,
          85,
          59
        ],
        [
          "test_processor_from_local_directory_from_extractor_config",
          87,
          95,
          88,
          14,
          88,
          42,
          87,
          67,
          95,
          59
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          98,
          14,
          98,
          42,
          97,
          45,
          107,
          75
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          157,
          14,
          157,
          42,
          156,
          55,
          166,
          71
        ],
        [
          "test_processor_from_local_directory_from_model_config",
          187,
          199,
          188,
          14,
          188,
          42,
          187,
          63,
          199,
          59
        ],
        [
          "test_new_processor_registration",
          234,
          270,
          247,
          18,
          247,
          46,
          247,
          18,
          247,
          46
        ],
        [
          "test_auto_processor_save_load",
          411,
          416,
          413,
          14,
          413,
          42,
          411,
          39,
          416,
          95
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          427,
          437,
          431,
          18,
          431,
          46,
          427,
          46,
          435,
          68
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          439,
          454,
          443,
          18,
          443,
          46,
          439,
          62,
          452,
          68
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          464,
          18,
          464,
          46,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          472,
          18,
          472,
          46,
          456,
          44,
          505,
          85
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "test_canonical_hf_index_retriever_save_and_from_pretrained",
          191,
          203,
          193,
          14,
          193,
          42,
          191,
          68,
          203,
          48
        ],
        [
          "test_custom_hf_index_retriever_save_and_from_pretrained",
          220,
          230,
          222,
          14,
          222,
          42,
          220,
          65,
          230,
          44
        ],
        [
          "test_custom_hf_index_retriever_save_and_from_pretrained_from_disk",
          247,
          257,
          249,
          14,
          249,
          42,
          247,
          75,
          257,
          44
        ]
      ],
      "transformers/tests/quantization/quanto_integration/test_quanto.py": [
        [
          "test_serialization_safetensors",
          235,
          244,
          239,
          14,
          239,
          42,
          235,
          40,
          244,
          13
        ],
        [
          "test_load_from_quanto_saved",
          277,
          303,
          292,
          14,
          292,
          42,
          277,
          37,
          303,
          83
        ],
        [
          "test_serialization_bin",
          219,
          228,
          223,
          14,
          223,
          42,
          219,
          32,
          228,
          13
        ],
        [
          "setUp",
          383,
          407,
          397,
          14,
          397,
          42,
          383,
          15,
          406,
          65
        ]
      ],
      "transformers/tests/quantization/spqr_integration/test_spqr.py": [
        [
          "test_save_pretrained",
          156,
          167,
          160,
          14,
          160,
          42,
          156,
          30,
          167,
          110
        ]
      ],
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "test_get_tree_starting_at",
          465,
          493,
          466,
          14,
          466,
          42,
          465,
          35,
          479,
          50
        ],
        [
          "test_init_test_examples_dependencies",
          521,
          541,
          522,
          14,
          522,
          42,
          521,
          46,
          540,
          60
        ],
        [
          "test_create_reverse_dependency_map",
          543,
          601,
          544,
          14,
          544,
          42,
          543,
          44,
          558,
          106
        ],
        [
          "test_extract_imports_relative",
          291,
          330,
          292,
          14,
          292,
          42,
          291,
          39,
          306,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          333,
          14,
          333,
          42,
          332,
          39,
          346,
          83
        ],
        [
          "test_print_tree_deps_of",
          495,
          519,
          496,
          14,
          496,
          42,
          495,
          33,
          519,
          75
        ],
        [
          "test_checkout_commit",
          209,
          224,
          210,
          14,
          210,
          42,
          209,
          30,
          216,
          53
        ],
        [
          "test_get_all_tests",
          235,
          240,
          236,
          14,
          236,
          42,
          235,
          28,
          240,
          96
        ],
        [
          "test_diff_is_docstring_only",
          253,
          264,
          254,
          14,
          254,
          42,
          253,
          37,
          261,
          75
        ],
        [
          "test_get_diff",
          266,
          289,
          267,
          14,
          267,
          42,
          266,
          23,
          274,
          83
        ],
        [
          "test_get_module_dependencies",
          372,
          434,
          373,
          14,
          373,
          42,
          372,
          38,
          383,
          96
        ],
        [
          "test_create_reverse_dependency_tree",
          436,
          463,
          437,
          14,
          437,
          42,
          436,
          45,
          449,
          97
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          605,
          14,
          605,
          42,
          604,
          33,
          623,
          76
        ],
        [
          "test_infer_tests_to_run_with_test_modifs",
          686,
          703,
          687,
          14,
          687,
          42,
          686,
          50,
          703,
          76
        ],
        [
          "test_infer_tests_to_run_with_examples_modifs",
          706,
          739,
          707,
          14,
          707,
          42,
          706,
          54,
          724,
          86
        ]
      ],
      "transformers/tests/tensor_parallel/test_tensor_parallel.py": [
        [
          "test_model_save",
          176,
          215,
          179,
          14,
          179,
          42,
          176,
          25,
          180,
          44
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          125,
          14,
          125,
          42,
          118,
          39,
          130,
          63
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          110,
          14,
          110,
          42,
          103,
          34,
          115,
          59
        ],
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          326,
          14,
          326,
          42,
          306,
          48,
          331,
          36
        ],
        [
          "test_tokenizer_from_type",
          103,
          115,
          104,
          14,
          104,
          42,
          103,
          34,
          115,
          59
        ],
        [
          "test_tokenizer_from_type_fast",
          118,
          130,
          119,
          14,
          119,
          42,
          118,
          39,
          130,
          63
        ],
        [
          "test_auto_tokenizer_from_local_folder",
          205,
          213,
          208,
          14,
          208,
          42,
          205,
          47,
          213,
          51
        ],
        [
          "test_get_tokenizer_config",
          220,
          238,
          233,
          14,
          233,
          42,
          220,
          35,
          238,
          68
        ],
        [
          "test_new_tokenizer_registration",
          240,
          260,
          250,
          18,
          250,
          46,
          250,
          18,
          250,
          46
        ],
        [
          "test_new_tokenizer_fast_registration",
          263,
          304,
          286,
          18,
          286,
          46,
          286,
          18,
          286,
          46
        ],
        [
          "test_new_tokenizer_fast_registration",
          263,
          304,
          291,
          18,
          291,
          46,
          291,
          18,
          291,
          46
        ],
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          342,
          18,
          342,
          46,
          332,
          13,
          354,
          73
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          475,
          14,
          475,
          42,
          456,
          40,
          513,
          18
        ]
      ],
      "transformers/tests/models/camembert/test_tokenization_camembert.py": [
        [
          "test_rust_and_python_bpe_tokenizers",
          71,
          92,
          73,
          14,
          73,
          33,
          71,
          45,
          92,
          49
        ],
        [
          "test_added_tokens_serialization",
          137,
          217,
          159,
          22,
          159,
          50,
          150,
          13,
          168,
          60
        ],
        [
          "test_added_tokens_serialization",
          137,
          217,
          175,
          34,
          175,
          62,
          169,
          30,
          189,
          37
        ],
        [
          "test_added_tokens_serialization",
          137,
          217,
          207,
          30,
          207,
          58,
          193,
          42,
          217,
          33
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          209,
          18,
          209,
          46,
          208,
          13,
          255,
          17
        ],
        [
          "test_added_token_serializable",
          185,
          198,
          196,
          22,
          196,
          50,
          187,
          13,
          198,
          59
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_decode_single_bytes",
          277,
          291,
          286,
          18,
          286,
          46,
          285,
          13,
          291,
          62
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          222,
          18,
          222,
          46,
          221,
          13,
          275,
          17
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_conversion",
          375,
          393,
          379,
          14,
          379,
          42,
          375,
          25,
          393,
          60
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template",
          1114,
          1174,
          1146,
          22,
          1146,
          50,
          1123,
          13,
          1174,
          103
        ],
        [
          "test_chat_template",
          1114,
          1174,
          1158,
          22,
          1158,
          50,
          1123,
          13,
          1174,
          103
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1184,
          18,
          1184,
          46,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1195,
          18,
          1195,
          46,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_save_loading",
          1177,
          1217,
          1207,
          18,
          1207,
          46,
          1183,
          39,
          1217,
          110
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1708,
          26,
          1708,
          54,
          1706,
          21,
          1711,
          43
        ],
        [
          "test_chat_template_file_priority",
          1734,
          1747,
          1740,
          22,
          1740,
          50,
          1738,
          13,
          1747,
          78
        ],
        [
          "test_added_token_serializable",
          2837,
          2847,
          2845,
          22,
          2845,
          50,
          2840,
          13,
          2847,
          59
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4230,
          18,
          4230,
          46,
          4229,
          13,
          4272,
          17
        ],
        [
          "test_saving_tokenizer_trainer",
          4452,
          4470,
          4455,
          22,
          4455,
          50,
          4453,
          13,
          4470,
          100
        ],
        [
          "test_save_slow_from_fast_and_reload_fast",
          4481,
          4506,
          4488,
          22,
          4488,
          50,
          4486,
          13,
          4506,
          72
        ],
        [
          "test_save_slow_from_fast_and_reload_fast",
          4481,
          4506,
          4502,
          22,
          4502,
          50,
          4486,
          13,
          4506,
          72
        ],
        [
          "test_added_tokens_serialization",
          4565,
          4643,
          4585,
          22,
          4585,
          50,
          4576,
          13,
          4594,
          60
        ],
        [
          "test_added_tokens_serialization",
          4565,
          4643,
          4601,
          34,
          4601,
          62,
          4595,
          30,
          4615,
          37
        ],
        [
          "test_added_tokens_serialization",
          4565,
          4643,
          4633,
          30,
          4633,
          58,
          4619,
          42,
          4643,
          33
        ],
        [
          "test_special_token_addition",
          4645,
          4668,
          4652,
          22,
          4652,
          50,
          4646,
          13,
          4668,
          110
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_class_after_save_and_reload",
          173,
          206,
          177,
          14,
          177,
          42,
          173,
          42,
          206,
          13
        ],
        [
          "test_local_versioning",
          211,
          236,
          216,
          14,
          216,
          42,
          211,
          31,
          236,
          77
        ]
      ],
      "transformers/tests/models/gemma/test_tokenization_gemma.py": [
        [
          "test_conversion",
          236,
          254,
          240,
          14,
          240,
          42,
          236,
          25,
          254,
          60
        ],
        [
          "test_save_fast_load_slow",
          454,
          476,
          465,
          14,
          465,
          42,
          463,
          9,
          473,
          47
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_load_tokenizer_with_model_file_only",
          337,
          344,
          338,
          14,
          338,
          42,
          337,
          50,
          344,
          95
        ],
        [
          "test_conversion",
          413,
          431,
          417,
          14,
          417,
          42,
          413,
          25,
          431,
          60
        ]
      ],
      "transformers/tests/models/m2m_100/test_tokenization_m2m_100.py": [
        [
          "test_special_tokens_unaffacted_by_save_load",
          177,
          182,
          178,
          14,
          178,
          42,
          177,
          53,
          182,
          83
        ]
      ],
      "transformers/tests/models/nllb/test_tokenization_nllb.py": [
        [
          "test_new_language_codes",
          298,
          327,
          312,
          14,
          312,
          42,
          298,
          33,
          327,
          47
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          205,
          18,
          205,
          46,
          204,
          13,
          257,
          17
        ]
      ],
      "transformers/tests/test_tokenization_mistral_common.py": [
        [
          "test_save_pretrained",
          137,
          153,
          152,
          18,
          152,
          46,
          137,
          30,
          153,
          68
        ],
        [
          "test_save_pretrained",
          137,
          153,
          138,
          14,
          138,
          42,
          137,
          30,
          153,
          68
        ]
      ],
      "transformers/tests/models/rembert/test_tokenization_rembert.py": [
        [
          "test_added_tokens_serialization",
          168,
          248,
          191,
          22,
          191,
          50,
          180,
          13,
          200,
          60
        ],
        [
          "test_added_tokens_serialization",
          168,
          248,
          207,
          34,
          207,
          62,
          201,
          30,
          221,
          37
        ],
        [
          "test_added_tokens_serialization",
          168,
          248,
          238,
          30,
          238,
          58,
          225,
          42,
          248,
          33
        ]
      ],
      "transformers/tests/models/roformer/test_tokenization_roformer.py": [
        [
          "test_save_slow_from_fast_and_reload_fast",
          82,
          90,
          87,
          18,
          87,
          46,
          83,
          13,
          90,
          76
        ]
      ],
      "transformers/tests/models/siglip/test_tokenization_siglip.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          252,
          18,
          252,
          46,
          251,
          13,
          305,
          17
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_push_to_hub",
          122,
          132,
          124,
          18,
          124,
          46,
          122,
          26,
          132,
          70
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          134,
          146,
          136,
          18,
          136,
          46,
          134,
          46,
          146,
          70
        ],
        [
          "test_push_to_hub_in_organization",
          148,
          158,
          150,
          18,
          150,
          46,
          148,
          42,
          158,
          70
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          160,
          172,
          162,
          18,
          162,
          46,
          160,
          62,
          172,
          70
        ],
        [
          "test_push_to_hub_dynamic_tokenizer",
          175,
          189,
          178,
          18,
          178,
          46,
          175,
          44,
          189,
          77
        ],
        [
          "test_push_to_hub_dynamic_tokenizer_with_both_slow_and_fast_classes",
          192,
          215,
          199,
          18,
          199,
          46,
          192,
          76,
          215,
          77
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_utils.py": [
        [
          "test_extra_special_tokens_multimodal",
          227,
          273,
          258,
          14,
          258,
          42,
          227,
          46,
          273,
          102
        ],
        [
          "test_extra_special_tokens_multimodal",
          227,
          273,
          245,
          14,
          245,
          42,
          227,
          46,
          273,
          102
        ],
        [
          "test_instantiation_from_tokenizers_json_file",
          333,
          337,
          335,
          14,
          335,
          42,
          333,
          54,
          337,
          94
        ]
      ],
      "transformers/tests/models/t5/test_tokenization_t5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          303,
          18,
          303,
          46,
          302,
          13,
          356,
          17
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "test_nested_vocab",
          789,
          832,
          817,
          14,
          817,
          42,
          789,
          27,
          832,
          60
        ],
        [
          "test_nested_vocab",
          789,
          832,
          826,
          14,
          826,
          42,
          789,
          27,
          832,
          60
        ]
      ],
      "transformers/tests/quantization/torchao_integration/test_torchao.py": [
        [
          "check_serialization_expected_output",
          454,
          465,
          459,
          14,
          459,
          42,
          458,
          17,
          465,
          105
        ]
      ],
      "transformers/tests/test_training_args.py": [
        [
          "test_custom_output_dir",
          14,
          18,
          16,
          14,
          16,
          42,
          14,
          32,
          18,
          54
        ],
        [
          "test_output_dir_creation",
          20,
          40,
          22,
          14,
          22,
          42,
          20,
          34,
          40,
          56
        ]
      ],
      "transformers/tests/models/auto/test_video_processing_auto.py": [
        [
          "test_video_processor_from_local_file",
          116,
          128,
          117,
          14,
          117,
          42,
          116,
          46,
          128,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_key",
          49,
          63,
          50,
          14,
          50,
          42,
          49,
          60,
          63,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_preprocessor_key",
          65,
          80,
          67,
          14,
          67,
          42,
          65,
          73,
          80,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          83,
          14,
          83,
          42,
          82,
          63,
          114,
          67
        ],
        [
          "test_from_pretrained_dynamic_video_processor",
          150,
          175,
          172,
          14,
          172,
          42,
          150,
          54,
          175,
          90
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          185,
          18,
          185,
          46,
          185,
          18,
          185,
          46
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          200,
          18,
          200,
          46,
          200,
          18,
          200,
          46
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "setUp",
          742,
          755,
          747,
          14,
          747,
          42,
          742,
          15,
          755,
          40
        ],
        [
          "setUp",
          742,
          755,
          752,
          14,
          752,
          42,
          742,
          15,
          755,
          40
        ],
        [
          "test_reproducible_training",
          763,
          774,
          765,
          14,
          765,
          42,
          763,
          36,
          774,
          72
        ],
        [
          "test_reproducible_training",
          763,
          774,
          771,
          14,
          771,
          42,
          763,
          36,
          774,
          72
        ],
        [
          "test_trainer_with_datasets",
          776,
          803,
          784,
          14,
          784,
          42,
          776,
          36,
          803,
          51
        ],
        [
          "test_model_init",
          805,
          820,
          807,
          14,
          807,
          42,
          805,
          25,
          820,
          72
        ],
        [
          "test_gradient_accumulation_loss_alignment_with_model_loss",
          823,
          920,
          849,
          14,
          849,
          42,
          823,
          67,
          865,
          52
        ],
        [
          "test_gradient_accumulation_loss_alignment_with_loss_func",
          922,
          1021,
          960,
          14,
          960,
          42,
          922,
          66,
          1021,
          107
        ],
        [
          "test_gradient_accumulation_loss_alignment_with_loss_func",
          922,
          1021,
          976,
          14,
          976,
          42,
          922,
          66,
          1021,
          107
        ],
        [
          "test_gradient_accumulation",
          1023,
          1030,
          1025,
          14,
          1025,
          42,
          1023,
          36,
          1030,
          51
        ],
        [
          "test_gradient_checkpointing",
          1032,
          1050,
          1033,
          14,
          1033,
          42,
          1032,
          37,
          1046,
          56
        ],
        [
          "test_training_loss",
          1052,
          1073,
          1056,
          14,
          1056,
          42,
          1052,
          28,
          1073,
          72
        ],
        [
          "test_training_loss",
          1052,
          1073,
          1066,
          14,
          1066,
          42,
          1052,
          28,
          1073,
          72
        ],
        [
          "test_custom_optimizer",
          1075,
          1088,
          1077,
          14,
          1077,
          42,
          1075,
          31,
          1088,
          90
        ],
        [
          "test_lr_scheduler_kwargs",
          1090,
          1117,
          1096,
          14,
          1096,
          42,
          1090,
          34,
          1117,
          90
        ],
        [
          "test_cosine_with_min_lr_scheduler",
          1119,
          1142,
          1124,
          14,
          1124,
          42,
          1119,
          43,
          1140,
          37
        ],
        [
          "test_reduce_lr_on_plateau_args",
          1172,
          1198,
          1176,
          14,
          1176,
          42,
          1172,
          40,
          1198,
          62
        ],
        [
          "test_reduce_lr_on_plateau",
          1200,
          1246,
          1213,
          14,
          1213,
          42,
          1200,
          35,
          1233,
          46
        ],
        [
          "test_adafactor_lr_none",
          1248,
          1267,
          1254,
          14,
          1254,
          42,
          1248,
          32,
          1267,
          90
        ],
        [
          "test_mixed_fp16",
          1271,
          1279,
          1273,
          14,
          1273,
          42,
          1271,
          25,
          1279,
          60
        ],
        [
          "test_mixed_bf16",
          1283,
          1288,
          1285,
          14,
          1285,
          42,
          1283,
          25,
          1288,
          73
        ],
        [
          "test_tf32",
          1292,
          1297,
          1294,
          14,
          1294,
          42,
          1292,
          19,
          1297,
          51
        ],
        [
          "test_include_num_input_tokens_seen",
          1299,
          1395,
          1323,
          14,
          1323,
          42,
          1299,
          44,
          1395,
          79
        ],
        [
          "test_init_with_offloaded_model",
          1420,
          1436,
          1433,
          14,
          1433,
          42,
          1431,
          31,
          1436,
          13
        ],
        [
          "test_schedulefree_adam",
          2062,
          2080,
          2068,
          14,
          2068,
          42,
          2062,
          32,
          2080,
          13
        ],
        [
          "test_schedulefree_radam",
          2084,
          2102,
          2090,
          14,
          2090,
          42,
          2084,
          33,
          2102,
          9
        ],
        [
          "test_galore_adafactor",
          2294,
          2322,
          2305,
          14,
          2305,
          42,
          2294,
          31,
          2322,
          60
        ],
        [
          "test_galore_adafactor_attention_only",
          2326,
          2353,
          2337,
          14,
          2337,
          42,
          2326,
          46,
          2353,
          60
        ],
        [
          "test_galore_adafactor_all_linear",
          2357,
          2384,
          2368,
          14,
          2368,
          42,
          2357,
          42,
          2384,
          60
        ],
        [
          "test_evaluate",
          2774,
          2814,
          2775,
          14,
          2775,
          42,
          2774,
          23,
          2814,
          74
        ],
        [
          "test_evaluate_with_batch_eval_metrics",
          2816,
          2864,
          2817,
          14,
          2817,
          42,
          2816,
          47,
          2864,
          74
        ],
        [
          "test_evaluate_with_jit",
          2866,
          2914,
          2867,
          14,
          2867,
          42,
          2866,
          32,
          2914,
          74
        ],
        [
          "test_predict",
          2916,
          2949,
          2917,
          14,
          2917,
          42,
          2916,
          22,
          2949,
          82
        ],
        [
          "test_predict_with_batch_eval_metrics",
          2985,
          3047,
          2986,
          14,
          2986,
          42,
          2985,
          46,
          3047,
          82
        ],
        [
          "test_predict_with_jit",
          3049,
          3093,
          3050,
          14,
          3050,
          42,
          3049,
          31,
          3093,
          82
        ],
        [
          "test_dynamic_shapes",
          3095,
          3131,
          3098,
          14,
          3098,
          42,
          3095,
          29,
          3107,
          71
        ],
        [
          "test_dynamic_shapes",
          3095,
          3131,
          3116,
          14,
          3116,
          42,
          3116,
          14,
          3125,
          71
        ],
        [
          "test_log_level",
          3133,
          3162,
          3141,
          14,
          3141,
          42,
          3133,
          24,
          3145,
          22
        ],
        [
          "test_can_resume_training_lm",
          3380,
          3429,
          3384,
          14,
          3384,
          42,
          3380,
          37,
          3429,
          37
        ],
        [
          "test_auto_batch_size_finder",
          3493,
          3524,
          3503,
          14,
          3503,
          42,
          3497,
          19,
          3524,
          27
        ],
        [
          "test_resume_training_with_shard_checkpoint",
          3602,
          3624,
          3607,
          14,
          3607,
          42,
          3602,
          52,
          3624,
          64
        ],
        [
          "test_resume_training_with_safe_checkpoint",
          3627,
          3659,
          3634,
          22,
          3634,
          50,
          3633,
          17,
          3659,
          72
        ],
        [
          "test_resume_training_with_gradient_accumulation",
          3662,
          3697,
          3667,
          14,
          3667,
          42,
          3662,
          57,
          3697,
          64
        ],
        [
          "test_resume_training_with_frozen_params",
          3700,
          3737,
          3705,
          14,
          3705,
          42,
          3700,
          49,
          3737,
          64
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3741,
          14,
          3741,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3757,
          14,
          3757,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3775,
          14,
          3775,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_at_end",
          3739,
          3808,
          3795,
          14,
          3795,
          42,
          3739,
          37,
          3808,
          110
        ],
        [
          "test_load_best_model_from_safetensors",
          3810,
          3831,
          3813,
          18,
          3813,
          46,
          3812,
          13,
          3831,
          17
        ],
        [
          "test_trainer_eval_mrpc",
          3834,
          3847,
          3843,
          14,
          3843,
          42,
          3834,
          32,
          3847,
          53
        ],
        [
          "test_trainer_eval_multiple",
          3850,
          3878,
          3861,
          14,
          3861,
          42,
          3861,
          14,
          3878,
          52
        ],
        [
          "test_training_iterable_dataset",
          3891,
          3905,
          3897,
          14,
          3897,
          42,
          3891,
          40,
          3905,
          103
        ],
        [
          "test_evaluation_iterable_dataset",
          3907,
          3934,
          3913,
          14,
          3913,
          42,
          3907,
          42,
          3934,
          74
        ],
        [
          "test_predict_iterable_dataset",
          3936,
          3954,
          3941,
          14,
          3941,
          42,
          3936,
          39,
          3954,
          62
        ],
        [
          "test_num_train_epochs_in_training",
          3956,
          3976,
          3959,
          14,
          3959,
          42,
          3956,
          43,
          3976,
          74
        ],
        [
          "test_num_batches_in_training_with_gradient_accumulation",
          3979,
          4007,
          3980,
          14,
          3980,
          42,
          3979,
          65,
          3981,
          42
        ],
        [
          "test_early_stopping_callback",
          4009,
          4060,
          4011,
          14,
          4011,
          42,
          4009,
          38,
          4041,
          29
        ],
        [
          "test_early_stopping_callback",
          4009,
          4060,
          4028,
          14,
          4028,
          42,
          4009,
          38,
          4041,
          29
        ],
        [
          "test_early_stopping_callback",
          4009,
          4060,
          4046,
          14,
          4046,
          42,
          4046,
          14,
          4060,
          69
        ],
        [
          "test_flos_extraction",
          4062,
          4079,
          4063,
          14,
          4063,
          42,
          4062,
          30,
          4079,
          72
        ],
        [
          "test_checkpoint_rotation",
          4090,
          4112,
          4091,
          14,
          4091,
          42,
          4090,
          34,
          4112,
          69
        ],
        [
          "test_compare_trainer_and_checkpoint_args_logging",
          4114,
          4150,
          4117,
          14,
          4117,
          42,
          4114,
          58,
          4150,
          9
        ],
        [
          "test_mem_metrics",
          4170,
          4178,
          4171,
          14,
          4171,
          42,
          4170,
          26,
          4178,
          61
        ],
        [
          "test_fp16_full_eval",
          4182,
          4241,
          4188,
          14,
          4188,
          42,
          4182,
          29,
          4241,
          73
        ],
        [
          "test_torchdynamo_full_eval",
          4246,
          4289,
          4259,
          14,
          4259,
          42,
          4246,
          36,
          4289,
          31
        ],
        [
          "test_torchdynamo_memory",
          4293,
          4361,
          4337,
          14,
          4337,
          42,
          4327,
          9,
          4343,
          30
        ],
        [
          "test_bf16_full_eval",
          4365,
          4426,
          4380,
          14,
          4380,
          42,
          4365,
          29,
          4426,
          73
        ],
        [
          "test_no_wd_param_group",
          4428,
          4437,
          4430,
          14,
          4430,
          42,
          4428,
          32,
          4437,
          91
        ],
        [
          "test_end_to_end_example",
          4443,
          4485,
          4451,
          14,
          4451,
          42,
          4443,
          33,
          4485,
          45
        ],
        [
          "test_accelerator_config_empty",
          4488,
          4505,
          4490,
          14,
          4490,
          42,
          4488,
          39,
          4503,
          50
        ],
        [
          "test_accelerator_config_from_dict",
          4507,
          4530,
          4510,
          14,
          4510,
          42,
          4507,
          43,
          4521,
          50
        ],
        [
          "test_accelerator_config_from_yaml",
          4532,
          4555,
          4535,
          14,
          4535,
          42,
          4532,
          43,
          4555,
          77
        ],
        [
          "test_accelerator_config_from_dataclass",
          4557,
          4576,
          4570,
          14,
          4570,
          42,
          4557,
          48,
          4576,
          77
        ],
        [
          "test_accelerate_config_from_dataclass_grad_accum",
          4579,
          4602,
          4599,
          14,
          4599,
          42,
          4579,
          58,
          4602,
          74
        ],
        [
          "test_accelerator_config_from_partial",
          4604,
          4623,
          4607,
          14,
          4607,
          42,
          4604,
          46,
          4623,
          76
        ],
        [
          "test_accelerator_custom_state",
          4625,
          4633,
          4627,
          14,
          4627,
          42,
          4625,
          39,
          4633,
          63
        ],
        [
          "test_accelerator_config_from_dict_grad_accum_num_steps",
          4636,
          4671,
          4637,
          14,
          4637,
          42,
          4636,
          64,
          4671,
          105
        ],
        [
          "test_accelerator_config_not_instantiated",
          4673,
          4700,
          4676,
          14,
          4676,
          42,
          4673,
          50,
          4700,
          108
        ],
        [
          "test_accelerator_config_not_instantiated",
          4673,
          4700,
          4695,
          14,
          4695,
          42,
          4673,
          50,
          4700,
          108
        ],
        [
          "test_dtype_to_json",
          4702,
          4729,
          4724,
          18,
          4724,
          46,
          4709,
          13,
          4729,
          59
        ],
        [
          "test_eval_use_gather_object",
          4732,
          4741,
          4736,
          14,
          4736,
          42,
          4732,
          37,
          4741,
          13
        ],
        [
          "test_trainer_saves_tokenizer",
          4743,
          4764,
          4747,
          14,
          4747,
          42,
          4743,
          38,
          4764,
          9
        ],
        [
          "test_trainer_saves_image_processor",
          4767,
          4781,
          4771,
          14,
          4771,
          42,
          4767,
          44,
          4781,
          91
        ],
        [
          "test_trainer_saves_feature_extractor",
          4783,
          4798,
          4787,
          14,
          4787,
          42,
          4783,
          46,
          4798,
          95
        ],
        [
          "test_trainer_saves_processor",
          4801,
          4835,
          4807,
          14,
          4807,
          42,
          4801,
          38,
          4835,
          9
        ],
        [
          "test_save_best_checkpoint",
          4837,
          4903,
          4842,
          14,
          4842,
          42,
          4837,
          35,
          4903,
          17
        ],
        [
          "test_save_best_checkpoint",
          4837,
          4903,
          4874,
          14,
          4874,
          42,
          4837,
          35,
          4903,
          17
        ],
        [
          "test_metric_for_best_model_behavior",
          4905,
          4933,
          4908,
          14,
          4908,
          42,
          4905,
          45,
          4933,
          73
        ],
        [
          "test_metric_for_best_model_behavior",
          4905,
          4933,
          4923,
          14,
          4923,
          42,
          4905,
          45,
          4933,
          73
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4938,
          14,
          4938,
          42,
          4935,
          45,
          4949,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4956,
          14,
          4956,
          42,
          4951,
          13,
          4970,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          4980,
          14,
          4980,
          42,
          4976,
          13,
          5006,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5015,
          14,
          5015,
          42,
          5012,
          13,
          5042,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5052,
          14,
          5052,
          42,
          5048,
          13,
          5078,
          52
        ],
        [
          "test_best_model_checkpoint_behavior",
          4935,
          5118,
          5088,
          14,
          5088,
          42,
          5084,
          13,
          5113,
          52
        ],
        [
          "test_special_token_alignment",
          5120,
          5163,
          5142,
          14,
          5142,
          42,
          5120,
          38,
          5163,
          87
        ],
        [
          "test_trainer_works_without_model_config",
          5165,
          5197,
          5187,
          14,
          5187,
          42,
          5187,
          14,
          5197,
          27
        ],
        [
          "test_push_to_hub",
          5315,
          5335,
          5318,
          18,
          5318,
          46,
          5315,
          26,
          5335,
          68
        ],
        [
          "test_push_to_hub_in_organization",
          5337,
          5359,
          5339,
          18,
          5339,
          46,
          5337,
          42,
          5359,
          68
        ],
        [
          "test_push_to_hub_with_saves_each_epoch",
          5374,
          5395,
          5376,
          18,
          5376,
          46,
          5374,
          48,
          5395,
          114
        ],
        [
          "test_push_to_hub_with_saves_each_n_steps",
          5397,
          5433,
          5403,
          18,
          5403,
          46,
          5402,
          14,
          5433,
          93
        ],
        [
          "test_push_to_hub_with_tensorboard_logs",
          5436,
          5457,
          5438,
          18,
          5438,
          46,
          5436,
          48,
          5453,
          26
        ],
        [
          "test_push_to_hub_tags",
          5459,
          5484,
          5464,
          18,
          5464,
          46,
          5459,
          31,
          5484,
          72
        ],
        [
          "test_push_to_hub_with_revision",
          5486,
          5501,
          5489,
          18,
          5489,
          46,
          5486,
          40,
          5501,
          67
        ],
        [
          "test_hyperparameter_search",
          5512,
          5547,
          5533,
          14,
          5533,
          42,
          5512,
          36,
          5547,
          111
        ],
        [
          "test_hyperparameter_search",
          5558,
          5603,
          5582,
          14,
          5582,
          42,
          5558,
          36,
          5603,
          13
        ],
        [
          "test_hyperparameter_search",
          5609,
          5635,
          5624,
          14,
          5624,
          42,
          5609,
          36,
          5635,
          13
        ],
        [
          "ray_hyperparameter_search",
          5646,
          5688,
          5672,
          14,
          5672,
          42,
          5646,
          35,
          5688,
          13
        ],
        [
          "test_hyperparameter_search",
          5711,
          5751,
          5735,
          14,
          5735,
          42,
          5711,
          36,
          5751,
          13
        ],
        [
          "test_optim_supported",
          5940,
          5946,
          5941,
          14,
          5941,
          42,
          5940,
          30,
          5946,
          27
        ],
        [
          "test_fused_adam",
          5948,
          5965,
          5959,
          14,
          5959,
          42,
          5948,
          25,
          5965,
          17
        ],
        [
          "test_fused_adam_no_apex",
          5967,
          5975,
          5968,
          14,
          5968,
          42,
          5967,
          33,
          5975,
          62
        ],
        [
          "test_bnb_adam8bit",
          5977,
          5994,
          5988,
          14,
          5988,
          42,
          5977,
          27,
          5994,
          17
        ],
        [
          "test_bnb_paged_adam8bit_alias",
          5996,
          6009,
          6003,
          14,
          6003,
          42,
          5996,
          39,
          6009,
          17
        ],
        [
          "test_bnb_paged_adam",
          6011,
          6024,
          6018,
          14,
          6018,
          42,
          6011,
          29,
          6024,
          17
        ],
        [
          "test_bnb_paged_adam8bit",
          6026,
          6039,
          6033,
          14,
          6033,
          42,
          6026,
          33,
          6039,
          17
        ],
        [
          "test_bnb_ademamix",
          6041,
          6054,
          6048,
          14,
          6048,
          42,
          6041,
          27,
          6054,
          17
        ],
        [
          "test_bnb_ademamix8bit",
          6056,
          6069,
          6063,
          14,
          6063,
          42,
          6056,
          31,
          6069,
          17
        ],
        [
          "test_bnb_paged_ademamix",
          6071,
          6084,
          6078,
          14,
          6078,
          42,
          6071,
          33,
          6084,
          17
        ],
        [
          "test_bnb_paged_ademamix8bit",
          6086,
          6099,
          6093,
          14,
          6093,
          42,
          6086,
          37,
          6099,
          17
        ],
        [
          "test_bnb_lion",
          6101,
          6114,
          6108,
          14,
          6108,
          42,
          6101,
          23,
          6114,
          17
        ],
        [
          "test_bnb_lion8bit",
          6116,
          6129,
          6123,
          14,
          6123,
          42,
          6116,
          27,
          6129,
          17
        ],
        [
          "test_bnb_paged_lion8bit",
          6131,
          6144,
          6138,
          14,
          6138,
          42,
          6131,
          33,
          6144,
          17
        ],
        [
          "test_bnb_paged_lion",
          6146,
          6159,
          6153,
          14,
          6153,
          42,
          6146,
          29,
          6159,
          17
        ],
        [
          "test_bnb_adam8bit_no_bnb",
          6161,
          6169,
          6162,
          14,
          6162,
          42,
          6161,
          34,
          6169,
          62
        ],
        [
          "test_bnb_paged_adam_no_bnb",
          6171,
          6179,
          6172,
          14,
          6172,
          42,
          6171,
          36,
          6179,
          62
        ],
        [
          "test_bnb_paged_adam8bit_no_bnb",
          6181,
          6189,
          6182,
          14,
          6182,
          42,
          6181,
          40,
          6189,
          62
        ],
        [
          "test_bnb_ademamix_no_bnb",
          6191,
          6199,
          6192,
          14,
          6192,
          42,
          6191,
          34,
          6199,
          62
        ],
        [
          "test_bnb_ademamix8bit_no_bnb",
          6201,
          6209,
          6202,
          14,
          6202,
          42,
          6201,
          38,
          6209,
          62
        ],
        [
          "test_bnb_paged_ademamix_no_bnb",
          6211,
          6219,
          6212,
          14,
          6212,
          42,
          6211,
          40,
          6219,
          62
        ],
        [
          "test_bnb_paged_ademamix8bit_no_bnb",
          6221,
          6229,
          6222,
          14,
          6222,
          42,
          6221,
          44,
          6229,
          62
        ],
        [
          "test_bnb_paged_lion_no_bnb",
          6231,
          6239,
          6232,
          14,
          6232,
          42,
          6231,
          36,
          6239,
          62
        ],
        [
          "test_bnb_paged_lion8bit_no_bnb",
          6241,
          6249,
          6242,
          14,
          6242,
          42,
          6241,
          40,
          6249,
          62
        ],
        [
          "test_anyprecision_adamw",
          6251,
          6268,
          6262,
          14,
          6262,
          42,
          6251,
          33,
          6268,
          17
        ],
        [
          "test_no_torchdistx_anyprecision_adamw",
          6270,
          6278,
          6271,
          14,
          6271,
          42,
          6270,
          47,
          6278,
          62
        ],
        [
          "test_hyperparameter_search",
          6289,
          6349,
          6311,
          14,
          6311,
          42,
          6289,
          36,
          6349,
          85
        ],
        [
          "test_get_num_trainable_parameters",
          6362,
          6373,
          6367,
          14,
          6367,
          42,
          6362,
          43,
          6371,
          47
        ],
        [
          "test_get_learning_rates",
          6375,
          6382,
          6377,
          14,
          6377,
          42,
          6375,
          33,
          6382,
          74
        ],
        [
          "test_get_optimizer_group",
          6384,
          6398,
          6386,
          14,
          6386,
          42,
          6384,
          34,
          6398,
          49
        ],
        [
          "test_bnb_8bit_optimizer_skip_embedding",
          6401,
          6417,
          6403,
          14,
          6403,
          42,
          6401,
          48,
          6404,
          64
        ]
      ],
      "transformers/tests/test_video_processing_common.py": [
        [
          "test_video_processor_from_and_save_pretrained",
          141,
          150,
          145,
          18,
          145,
          46,
          142,
          13,
          150,
          95
        ],
        [
          "test_video_processor_to_json_file",
          121,
          130,
          125,
          18,
          125,
          46,
          122,
          13,
          130,
          95
        ],
        [
          "test_video_processor_save_load_with_autovideoprocessor",
          152,
          163,
          156,
          18,
          156,
          46,
          153,
          13,
          163,
          95
        ]
      ],
      "transformers/tests/generation/test_utils.py": [
        [
          "test_model_parallel_beam_search",
          540,
          560,
          552,
          18,
          552,
          46,
          549,
          35,
          560,
          17
        ],
        [
          "_test_attention_implementation",
          1858,
          1944,
          1911,
          18,
          1911,
          46,
          1911,
          18,
          1944,
          104
        ],
        [
          "test_flash_attention_2_continue_generate_with_position_ids",
          1971,
          2054,
          2003,
          18,
          2003,
          46,
          2003,
          18,
          2022,
          50
        ],
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          2056,
          2162,
          2106,
          18,
          2106,
          46,
          2106,
          18,
          2113,
          60
        ],
        [
          "test_custom_generate_local_directory",
          4625,
          4644,
          4627,
          14,
          4627,
          42,
          4625,
          46,
          4644,
          37
        ]
      ],
      "transformers/tests/quantization/vptq_integration/test_vptq.py": [
        [
          "test_save_pretrained",
          97,
          108,
          101,
          14,
          101,
          42,
          97,
          30,
          108,
          110
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "__init__",
          1841,
          1847,
          1843,
          14,
          1843,
          42,
          1841,
          18,
          1845,
          36
        ]
      ],
      "transformers/utils/update_metadata.py": [
        [
          "update_metadata",
          232,
          312,
          282,
          10,
          282,
          38,
          232,
          21,
          294,
          27
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_report_to_hp_search",
          1867,
          1889,
          1883,
          18,
          1883,
          46,
          1881,
          20,
          1885,
          43
        ]
      ],
      "transformers/tests/causal_lm_tester.py": [
        [
          "test_causal_lm_can_accept_training_kwargs",
          558,
          572,
          564,
          14,
          564,
          42,
          562,
          31,
          572,
          13
        ],
        [
          "test_flash_attn_2_equivalence",
          531,
          556,
          539,
          18,
          539,
          46,
          536,
          35,
          556,
          83
        ]
      ],
      "transformers/src/transformers/models/esm/convert_esm.py": [
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          310,
          14,
          310,
          33,
          287,
          5,
          319,
          77
        ],
        [
          "get_esmfold_tokenizer",
          77,
          84,
          78,
          10,
          78,
          29,
          78,
          10,
          84,
          23
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_FastSpeech2ConformerModel_checkpoint",
          155,
          188,
          175,
          10,
          175,
          29,
          156,
          5,
          185,
          14
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "write_model",
          184,
          433,
          224,
          10,
          224,
          38,
          221,
          34,
          227,
          26
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "convert_tiktoken_to_hf",
          291,
          327,
          312,
          10,
          312,
          38,
          295,
          43,
          320,
          36
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "write_model",
          195,
          436,
          230,
          10,
          230,
          38,
          227,
          34,
          255,
          38
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "convert_processors",
          509,
          736,
          629,
          18,
          629,
          46,
          629,
          18,
          629,
          46
        ],
        [
          "convert_processors",
          509,
          736,
          671,
          14,
          671,
          42,
          671,
          14,
          673,
          46
        ],
        [
          "convert_processors",
          509,
          736,
          685,
          14,
          685,
          42,
          685,
          14,
          687,
          46
        ],
        [
          "upload_model",
          784,
          831,
          808,
          10,
          808,
          38,
          808,
          10,
          813,
          21
        ],
        [
          "build_composite_models",
          834,
          956,
          896,
          10,
          896,
          38,
          896,
          10,
          900,
          35
        ]
      ],
      "transformers/utils/get_test_reports.py": [
        [
          "run_pytest",
          48,
          79,
          69,
          19,
          69,
          63,
          69,
          19,
          69,
          63
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "working_or_temp_dir",
          488,
          493,
          490,
          14,
          490,
          42,
          490,
          14,
          491,
          25
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "_objective",
          318,
          354,
          351,
          18,
          351,
          46,
          346,
          23,
          354,
          64
        ],
        [
          "setup",
          822,
          946,
          916,
          22,
          916,
          50,
          916,
          22,
          919,
          49
        ],
        [
          "on_train_end",
          959,
          1001,
          971,
          18,
          971,
          46,
          963,
          18,
          979,
          54
        ],
        [
          "on_init_end",
          1797,
          1803,
          1800,
          46,
          1800,
          74,
          1800,
          46,
          1800,
          42
        ]
      ],
      "transformers/tests/quantization/aqlm_integration/test_aqlm.py": [
        [
          "test_save_pretrained",
          167,
          178,
          171,
          14,
          171,
          42,
          167,
          30,
          178,
          110
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "setUpClass",
          35,
          76,
          39,
          25,
          39,
          53,
          35,
          20,
          56,
          35
        ]
      ],
      "transformers/tests/quantization/autoround/test_auto_round.py": [
        [
          "test_mixed_bits",
          196,
          217,
          212,
          14,
          212,
          42,
          196,
          25,
          217,
          75
        ],
        [
          "test_save_pretrained",
          121,
          143,
          127,
          14,
          127,
          42,
          121,
          30,
          143,
          63
        ]
      ],
      "transformers/tests/test_backbone_common.py": [
        [
          "test_config_save_pretrained",
          75,
          83,
          79,
          14,
          79,
          42,
          75,
          37,
          83,
          73
        ]
      ],
      "transformers/tests/quantization/autoawq/test_awq.py": [
        [
          "test_save_pretrained",
          242,
          253,
          246,
          14,
          246,
          42,
          242,
          30,
          253,
          107
        ],
        [
          "test_raise_save_pretrained",
          332,
          347,
          346,
          45,
          346,
          73,
          332,
          36,
          347,
          45
        ]
      ],
      "transformers/tests/quantization/bnb/test_4bit.py": [
        [
          "test_serialization",
          686,
          764,
          706,
          14,
          706,
          42,
          686,
          28,
          728,
          19
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "test_find_code_in_transformers",
          299,
          308,
          300,
          14,
          300,
          42,
          299,
          40,
          308,
          46
        ],
        [
          "test_is_copy_consistent_with_ignored_match",
          334,
          342,
          336,
          14,
          336,
          42,
          334,
          52,
          342,
          43
        ],
        [
          "test_is_copy_consistent",
          310,
          332,
          312,
          14,
          312,
          42,
          310,
          33,
          332,
          67
        ],
        [
          "test_is_copy_consistent_with_ignored_no_match",
          344,
          368,
          352,
          14,
          352,
          42,
          344,
          55,
          368,
          70
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_from_pretrained_dynamic_config",
          106,
          128,
          122,
          14,
          122,
          42,
          106,
          45,
          128,
          78
        ],
        [
          "test_pattern_matching_fallback",
          63,
          71,
          64,
          14,
          64,
          42,
          63,
          40,
          71,
          57
        ],
        [
          "test_new_config_registration",
          73,
          92,
          85,
          18,
          85,
          46,
          85,
          18,
          85,
          46
        ]
      ],
      "transformers/tests/models/llava/test_configuration_llava.py": [
        [
          "test_arbitrary_reload",
          57,
          70,
          65,
          14,
          65,
          42,
          57,
          31,
          70,
          70
        ],
        [
          "test_pixtral_reload",
          19,
          55,
          50,
          14,
          50,
          42,
          19,
          29,
          55,
          57
        ],
        [
          "test_llava_reload",
          8,
          17,
          12,
          14,
          12,
          42,
          8,
          27,
          17,
          57
        ]
      ],
      "transformers/tests/test_configuration_common.py": [
        [
          "create_and_test_config_from_and_save_pretrained_composite",
          118,
          155,
          126,
          14,
          126,
          42,
          118,
          67,
          133,
          64
        ],
        [
          "create_and_test_config_to_json_file",
          85,
          93,
          88,
          14,
          88,
          42,
          85,
          45,
          93,
          80
        ],
        [
          "create_and_test_config_from_and_save_pretrained",
          95,
          105,
          98,
          14,
          98,
          42,
          95,
          57,
          105,
          63
        ],
        [
          "create_and_test_config_from_and_save_pretrained_subfolder",
          107,
          116,
          111,
          14,
          111,
          42,
          107,
          67,
          116,
          80
        ],
        [
          "create_and_test_config_from_and_save_pretrained_composite",
          118,
          155,
          152,
          22,
          152,
          50,
          142,
          42,
          155,
          103
        ],
        [
          "create_and_test_config_from_pretrained_custom_kwargs",
          157,
          190,
          181,
          14,
          181,
          42,
          180,
          27,
          190,
          93
        ]
      ],
      "transformers/tests/utils/test_configuration_utils.py": [
        [
          "test_bc_torch_dtype",
          335,
          358,
          348,
          14,
          348,
          42,
          335,
          29,
          358,
          53
        ],
        [
          "test_local_versioning",
          237,
          257,
          241,
          14,
          241,
          42,
          237,
          31,
          257,
          64
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          134,
          146,
          140,
          18,
          140,
          46,
          134,
          62,
          144,
          48
        ],
        [
          "test_saving_config_with_custom_generation_kwargs_raises_warning",
          280,
          285,
          282,
          14,
          282,
          42,
          280,
          73,
          285,
          56
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          108,
          120,
          114,
          18,
          114,
          46,
          108,
          46,
          118,
          48
        ]
      ],
      "transformers/tests/generation/test_configuration_utils.py": [
        [
          "test_refuse_to_save",
          233,
          273,
          240,
          14,
          240,
          42,
          233,
          29,
          273,
          57
        ],
        [
          "test_save_load_config",
          71,
          91,
          78,
          14,
          78,
          42,
          71,
          31,
          91,
          54
        ],
        [
          "test_refuse_to_save",
          233,
          273,
          251,
          14,
          251,
          42,
          233,
          29,
          273,
          57
        ],
        [
          "test_kwarg_init",
          123,
          146,
          140,
          14,
          140,
          42,
          123,
          25,
          146,
          52
        ],
        [
          "test_refuse_to_save",
          233,
          273,
          263,
          14,
          263,
          42,
          233,
          29,
          273,
          57
        ],
        [
          "test_serialize_generation_sequence_bias",
          301,
          313,
          306,
          14,
          306,
          66,
          301,
          49,
          313,
          89
        ],
        [
          "test_serialize_generation_min_length_eos_token",
          315,
          331,
          321,
          14,
          321,
          66,
          315,
          56,
          331,
          71
        ],
        [
          "test_serialize_generation_min_new_tokens",
          333,
          350,
          340,
          14,
          340,
          66,
          333,
          50,
          350,
          81
        ],
        [
          "test_serialize_generation_temperature",
          352,
          363,
          357,
          14,
          357,
          66,
          352,
          47,
          363,
          76
        ],
        [
          "test_serialize_generation_repetition_penalty",
          365,
          376,
          370,
          14,
          370,
          66,
          365,
          54,
          376,
          59
        ],
        [
          "test_serialize_generation_encoder_repetition_penalty",
          378,
          393,
          384,
          14,
          384,
          66,
          378,
          62,
          393,
          81
        ],
        [
          "test_serialize_generation_top_p",
          395,
          406,
          400,
          14,
          400,
          66,
          395,
          41,
          406,
          55
        ],
        [
          "test_serialize_generation_top_k",
          408,
          419,
          413,
          14,
          413,
          66,
          408,
          41,
          419,
          56
        ],
        [
          "test_serialize_generation_min_p",
          421,
          432,
          426,
          14,
          426,
          66,
          421,
          41,
          432,
          56
        ],
        [
          "test_serialize_generation_typical_p",
          434,
          445,
          439,
          14,
          439,
          66,
          434,
          45,
          445,
          58
        ],
        [
          "test_serialize_generation_epsilon_cutoff",
          447,
          458,
          452,
          14,
          452,
          66,
          447,
          50,
          458,
          62
        ],
        [
          "test_serialize_generation_eta_cutoff",
          460,
          471,
          465,
          14,
          465,
          66,
          460,
          46,
          471,
          58
        ],
        [
          "test_serialize_generation_ngram_size",
          473,
          484,
          478,
          14,
          478,
          66,
          473,
          46,
          484,
          69
        ],
        [
          "test_serialize_generation_encoder_ngram_size",
          486,
          500,
          492,
          14,
          492,
          66,
          486,
          54,
          500,
          77
        ],
        [
          "test_serialize_generation_bad_words_ids",
          502,
          513,
          507,
          14,
          507,
          66,
          502,
          49,
          513,
          86
        ],
        [
          "test_serialize_generation_num_beams",
          515,
          531,
          523,
          14,
          523,
          66,
          515,
          45,
          531,
          78
        ],
        [
          "test_serialize_generation_bos_token_id",
          533,
          544,
          538,
          14,
          538,
          66,
          533,
          48,
          544,
          69
        ],
        [
          "test_serialize_generation_eos_token_id",
          546,
          560,
          552,
          14,
          552,
          66,
          546,
          48,
          560,
          69
        ],
        [
          "test_serialize_generation_exponential_decay_length_penalty",
          562,
          584,
          571,
          14,
          571,
          66,
          562,
          68,
          584,
          108
        ],
        [
          "test_serialize_generation_begin_suppress_tokens",
          586,
          601,
          592,
          14,
          592,
          66,
          586,
          57,
          601,
          69
        ],
        [
          "test_serialize_generation_suppress_tokens",
          603,
          614,
          608,
          14,
          608,
          66,
          603,
          51,
          614,
          85
        ],
        [
          "test_serialize_generation_guidance_scale",
          616,
          626,
          620,
          14,
          620,
          66,
          616,
          50,
          626,
          77
        ],
        [
          "test_serialize_generation_guidance_scale_unbatched",
          628,
          641,
          635,
          14,
          635,
          66,
          628,
          60,
          641,
          60
        ],
        [
          "test_serialize_generation_watermarking_config",
          643,
          683,
          661,
          14,
          661,
          66,
          643,
          55,
          683,
          64
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          706,
          720,
          714,
          18,
          714,
          46,
          706,
          46,
          718,
          48
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          736,
          750,
          744,
          18,
          744,
          46,
          736,
          62,
          748,
          48
        ]
      ],
      "transformers/tests/quantization/eetq_integration/test_eetq.py": [
        [
          "test_save_pretrained",
          143,
          155,
          147,
          14,
          147,
          42,
          143,
          30,
          155,
          110
        ]
      ],
      "transformers/tests/models/auto/test_feature_extraction_auto.py": [
        [
          "test_new_feature_extractor_registration",
          135,
          154,
          145,
          18,
          145,
          46,
          145,
          18,
          145,
          46
        ],
        [
          "test_from_pretrained_dynamic_feature_extractor",
          102,
          133,
          126,
          14,
          126,
          42,
          102,
          56,
          133,
          94
        ],
        [
          "test_feature_extractor_from_local_directory_from_config",
          57,
          77,
          58,
          14,
          58,
          42,
          57,
          65,
          77,
          63
        ]
      ],
      "transformers/tests/models/audio_spectrogram_transformer/test_feature_extraction_audio_spectrogram_transformer.py": [
        [
          "test_feat_extract_to_json_file",
          190,
          200,
          193,
          14,
          193,
          42,
          190,
          40,
          200,
          49
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          178,
          188,
          181,
          14,
          181,
          42,
          178,
          52,
          188,
          53
        ]
      ],
      "transformers/tests/quantization/fbgemm_fp8/test_fbgemm_fp8.py": [
        [
          "test_save_pretrained_offload",
          243,
          254,
          247,
          14,
          247,
          42,
          243,
          38,
          254,
          110
        ],
        [
          "test_change_loading_attributes",
          194,
          212,
          198,
          14,
          198,
          42,
          194,
          40,
          212,
          110
        ],
        [
          "test_save_pretrained",
          180,
          192,
          184,
          14,
          184,
          42,
          180,
          30,
          192,
          110
        ],
        [
          "test_save_pretrained_multi_gpu",
          257,
          270,
          261,
          14,
          261,
          42,
          257,
          40,
          270,
          110
        ]
      ],
      "transformers/tests/models/clvp/test_feature_extraction_clvp.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          126,
          139,
          129,
          14,
          129,
          42,
          126,
          52,
          139,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          142,
          155,
          145,
          14,
          145,
          42,
          142,
          40,
          155,
          49
        ]
      ],
      "transformers/tests/test_feature_extraction_common.py": [
        [
          "test_feat_extract_to_json_file",
          32,
          40,
          35,
          14,
          35,
          42,
          32,
          40,
          40,
          85
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          42,
          50,
          45,
          14,
          45,
          42,
          42,
          52,
          50,
          85
        ]
      ],
      "transformers/tests/models/gemma3n/test_feature_extraction_gemma3n.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          148,
          161,
          151,
          14,
          151,
          42,
          148,
          52,
          161,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          163,
          176,
          166,
          14,
          166,
          42,
          163,
          40,
          176,
          49
        ],
        [
          "test_feat_extract_from_pretrained_kwargs",
          178,
          190,
          181,
          14,
          181,
          42,
          178,
          50,
          190,
          61
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_feature_extraction_musicgen_melody.py": [
        [
          "test_feat_extract_to_json_file",
          142,
          152,
          145,
          14,
          145,
          42,
          142,
          40,
          152,
          49
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          129,
          139,
          132,
          14,
          132,
          42,
          129,
          52,
          139,
          53
        ]
      ],
      "transformers/tests/models/pop2piano/test_feature_extraction_pop2piano.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          95,
          108,
          98,
          14,
          98,
          42,
          95,
          52,
          108,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          110,
          123,
          113,
          14,
          113,
          42,
          110,
          40,
          123,
          49
        ]
      ],
      "transformers/tests/models/phi4_multimodal/test_feature_extraction_phi4_multimodal.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          114,
          127,
          117,
          14,
          117,
          42,
          114,
          52,
          127,
          49
        ],
        [
          "test_feat_extract_from_pretrained_kwargs",
          144,
          156,
          147,
          14,
          147,
          42,
          144,
          50,
          156,
          61
        ],
        [
          "test_feat_extract_to_json_file",
          129,
          142,
          132,
          14,
          132,
          42,
          129,
          40,
          142,
          49
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_feature_extraction_seamless_m4t.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          117,
          127,
          120,
          14,
          120,
          42,
          117,
          52,
          127,
          53
        ],
        [
          "test_feat_extract_to_json_file",
          129,
          139,
          132,
          14,
          132,
          42,
          129,
          40,
          139,
          49
        ]
      ],
      "transformers/tests/models/speech_to_text/test_feature_extraction_speech_to_text.py": [
        [
          "test_feat_extract_from_and_save_pretrained",
          316,
          326,
          319,
          14,
          319,
          42,
          316,
          52,
          326,
          53
        ],
        [
          "test_feat_extract_to_json_file",
          328,
          338,
          331,
          14,
          331,
          42,
          328,
          40,
          338,
          49
        ]
      ],
      "transformers/tests/utils/test_feature_extraction_utils.py": [
        [
          "test_push_to_hub_via_save_pretrained",
          71,
          82,
          75,
          18,
          75,
          46,
          71,
          46,
          81,
          58
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          93,
          104,
          97,
          18,
          97,
          46,
          93,
          62,
          103,
          58
        ]
      ],
      "transformers/tests/models/whisper/test_feature_extraction_whisper.py": [
        [
          "test_feat_extract_from_pretrained_kwargs",
          148,
          160,
          151,
          14,
          151,
          42,
          148,
          50,
          160,
          61
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          118,
          131,
          121,
          14,
          121,
          42,
          118,
          52,
          131,
          49
        ],
        [
          "test_feat_extract_to_json_file",
          133,
          146,
          136,
          14,
          136,
          42,
          133,
          40,
          146,
          49
        ]
      ],
      "transformers/tests/quantization/finegrained_fp8/test_fp8.py": [
        [
          "test_save_pretrained",
          160,
          172,
          164,
          14,
          164,
          42,
          160,
          30,
          172,
          110
        ],
        [
          "test_save_pretrained_multi_accelerators",
          213,
          226,
          217,
          14,
          217,
          42,
          213,
          49,
          226,
          110
        ],
        [
          "test_save_pretrained_offload",
          239,
          250,
          243,
          14,
          243,
          42,
          239,
          38,
          250,
          110
        ]
      ],
      "transformers/tests/models/univnet/test_feature_extraction_univnet.py": [
        [
          "test_feat_extract_to_json_file",
          174,
          187,
          177,
          14,
          177,
          42,
          174,
          40,
          187,
          49
        ],
        [
          "test_feat_extract_from_and_save_pretrained",
          158,
          171,
          161,
          14,
          161,
          42,
          158,
          52,
          171,
          49
        ]
      ],
      "transformers/tests/quantization/fp_quant_integration/test_fp_quant.py": [
        [
          "test_save_pretrained",
          100,
          112,
          104,
          14,
          104,
          42,
          100,
          30,
          112,
          110
        ],
        [
          "test_save_pretrained_multi_gpu",
          131,
          144,
          135,
          14,
          135,
          42,
          131,
          40,
          144,
          110
        ]
      ],
      "transformers/tests/quantization/hqq/test_hqq.py": [
        [
          "test_save_and_load_quantized_model",
          206,
          237,
          224,
          14,
          224,
          42,
          206,
          44,
          237,
          81
        ]
      ],
      "transformers/tests/quantization/higgs/test_higgs.py": [
        [
          "test_save_pretrained_multi_gpu",
          172,
          185,
          176,
          14,
          176,
          42,
          172,
          40,
          185,
          110
        ],
        [
          "test_save_pretrained",
          141,
          153,
          145,
          14,
          145,
          42,
          141,
          30,
          153,
          110
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_has_file_in_cache",
          103,
          112,
          104,
          14,
          104,
          42,
          103,
          32,
          106,
          106
        ],
        [
          "test_get_file_from_repo_local",
          158,
          181,
          159,
          14,
          159,
          42,
          158,
          39,
          181,
          13
        ]
      ],
      "transformers/tests/quantization/gptq/test_gptq.py": [
        [
          "test_change_loading_attributes",
          289,
          303,
          293,
          14,
          293,
          42,
          289,
          40,
          295,
          39
        ],
        [
          "test_serialization",
          241,
          271,
          245,
          14,
          245,
          42,
          241,
          28,
          247,
          39
        ],
        [
          "test_serialization_big_model_inference",
          274,
          282,
          278,
          14,
          278,
          42,
          274,
          48,
          280,
          40
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_image_processor_from_local_file",
          123,
          132,
          124,
          14,
          124,
          42,
          123,
          46,
          132,
          61
        ],
        [
          "test_image_processor_from_new_filename",
          79,
          90,
          80,
          14,
          80,
          42,
          79,
          48,
          90,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          93,
          14,
          93,
          42,
          92,
          63,
          121,
          57
        ],
        [
          "test_from_pretrained_dynamic_image_processor",
          171,
          206,
          193,
          14,
          193,
          42,
          171,
          54,
          206,
          87
        ],
        [
          "test_image_processor_from_local_directory_from_feature_extractor_key",
          63,
          77,
          67,
          14,
          67,
          42,
          63,
          78,
          77,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_key",
          50,
          61,
          51,
          14,
          51,
          42,
          50,
          60,
          61,
          61
        ],
        [
          "test_new_image_processor_registration",
          208,
          237,
          228,
          18,
          228,
          46,
          228,
          18,
          228,
          46
        ],
        [
          "test_new_image_processor_registration",
          208,
          237,
          216,
          18,
          216,
          46,
          216,
          18,
          216,
          46
        ]
      ],
      "transformers/tests/utils/test_hf_argparser.py": [
        [
          "test_11_parse_json",
          378,
          395,
          387,
          14,
          387,
          42,
          378,
          28,
          395,
          43
        ],
        [
          "test_14_valid_dict_input_parsing",
          474,
          481,
          475,
          14,
          475,
          42,
          474,
          42,
          481,
          98
        ],
        [
          "test_12_parse_yaml",
          397,
          413,
          406,
          14,
          406,
          42,
          397,
          28,
          413,
          43
        ]
      ],
      "transformers/tests/quantization/ggml/test_ggml.py": [
        [
          "test_llama3_q4_0_tokenizer",
          433,
          440,
          435,
          14,
          435,
          42,
          433,
          36,
          440,
          84
        ],
        [
          "test_q2_k_serialization",
          189,
          210,
          200,
          14,
          200,
          42,
          189,
          33,
          210,
          91
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_image_processor_from_and_save_pretrained",
          277,
          286,
          281,
          18,
          281,
          46,
          278,
          13,
          286,
          95
        ],
        [
          "test_save_load_fast_slow",
          301,
          349,
          317,
          14,
          317,
          42,
          306,
          32,
          349,
          50
        ],
        [
          "test_save_load_fast_slow_auto",
          351,
          399,
          360,
          14,
          360,
          42,
          356,
          32,
          399,
          50
        ],
        [
          "test_image_processor_to_json_file",
          266,
          275,
          270,
          18,
          270,
          46,
          267,
          13,
          275,
          95
        ],
        [
          "test_image_processor_save_load_with_autoimageprocessor",
          288,
          299,
          292,
          18,
          292,
          46,
          289,
          13,
          296,
          33
        ],
        [
          "test_save_load_fast_slow",
          301,
          349,
          310,
          14,
          310,
          42,
          306,
          32,
          349,
          50
        ],
        [
          "test_save_load_fast_slow_auto",
          351,
          399,
          367,
          14,
          367,
          42,
          356,
          32,
          399,
          50
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          759,
          22,
          759,
          50,
          754,
          13,
          772,
          57
        ]
      ],
      "transformers/tests/models/imagegpt/test_image_processing_imagegpt.py": [
        [
          "test_image_processor_to_json_file",
          146,
          160,
          150,
          18,
          150,
          46,
          147,
          13,
          156,
          59
        ],
        [
          "test_image_processor_from_and_save_pretrained",
          162,
          175,
          166,
          18,
          166,
          46,
          163,
          13,
          171,
          59
        ],
        [
          "test_image_processor_save_load_with_autoimageprocessor",
          177,
          194,
          181,
          18,
          181,
          46,
          178,
          13,
          190,
          59
        ]
      ],
      "transformers/tests/models/oneformer/test_image_processing_oneformer.py": [
        [
          "test_can_load_with_local_metadata",
          359,
          378,
          368,
          18,
          368,
          46,
          367,
          13,
          378,
          64
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_image_processing_qwen2_vl.py": [
        [
          "test_custom_image_size",
          302,
          314,
          305,
          18,
          305,
          46,
          303,
          13,
          314,
          99
        ]
      ],
      "transformers/tests/utils/test_image_processing_utils.py": [
        [
          "test_push_to_hub_via_save_pretrained_fast",
          105,
          114,
          109,
          18,
          109,
          46,
          105,
          51,
          113,
          56
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          94,
          103,
          98,
          18,
          98,
          46,
          94,
          46,
          102,
          56
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          134,
          143,
          138,
          18,
          138,
          46,
          134,
          62,
          142,
          56
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained_fast",
          145,
          154,
          149,
          18,
          149,
          46,
          145,
          67,
          153,
          56
        ]
      ],
      "transformers/tests/models/timm_wrapper/test_image_processing_timm_wrapper.py": [
        [
          "setUp",
          39,
          43,
          41,
          25,
          41,
          53,
          39,
          15,
          43,
          50
        ]
      ],
      "transformers/tests/utils/test_model_card.py": [
        [
          "test_model_card_to_json_file",
          66,
          74,
          69,
          14,
          69,
          42,
          66,
          38,
          74,
          81
        ],
        [
          "test_model_card_from_and_save_pretrained",
          76,
          83,
          79,
          14,
          79,
          42,
          76,
          50,
          83,
          81
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_layer_pruning_behavior",
          96,
          122,
          113,
          18,
          113,
          46,
          113,
          18,
          122,
          99
        ],
        [
          "test_layer_pruning_behavior",
          96,
          122,
          98,
          18,
          98,
          46,
          96,
          41,
          106,
          43
        ],
        [
          "test_debugger_outputs",
          52,
          63,
          53,
          18,
          53,
          46,
          52,
          35,
          60,
          55
        ]
      ],
      "transformers/tests/quantization/bnb/test_mixed_int8.py": [
        [
          "test_inference_with_keep_in_fp32_serialized",
          542,
          571,
          555,
          14,
          555,
          42,
          542,
          53,
          571,
          13
        ],
        [
          "test_int8_serialization",
          370,
          395,
          376,
          14,
          376,
          42,
          370,
          33,
          395,
          114
        ],
        [
          "test_int8_serialization_regression",
          397,
          422,
          403,
          14,
          403,
          42,
          397,
          44,
          422,
          114
        ],
        [
          "test_int8_serialization_sharded",
          424,
          449,
          430,
          14,
          430,
          42,
          424,
          41,
          449,
          118
        ],
        [
          "test_cpu_accelerator_disk_loading_custom_device_map",
          812,
          837,
          825,
          14,
          825,
          42,
          812,
          61,
          837,
          56
        ],
        [
          "test_cpu_accelerator_disk_loading_custom_device_map_kwargs",
          839,
          864,
          851,
          14,
          851,
          42,
          839,
          68,
          864,
          56
        ]
      ],
      "transformers/tests/models/aimv2/test_modeling_aimv2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          144,
          171,
          149,
          18,
          149,
          46,
          145,
          13,
          162,
          50
        ],
        [
          "test_load_vision_text_config",
          429,
          442,
          433,
          14,
          433,
          42,
          429,
          38,
          442,
          85
        ],
        [
          "test_load_vision_text_config",
          429,
          442,
          439,
          14,
          439,
          42,
          429,
          38,
          442,
          85
        ]
      ],
      "transformers/tests/models/align/test_modeling_align.py": [
        [
          "_create_and_check_torchscript",
          491,
          560,
          510,
          18,
          510,
          46,
          510,
          18,
          514,
          25
        ],
        [
          "test_load_vision_text_config",
          562,
          575,
          572,
          14,
          572,
          42,
          562,
          38,
          575,
          85
        ],
        [
          "test_load_vision_text_config",
          562,
          575,
          566,
          14,
          566,
          42,
          562,
          38,
          575,
          85
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "_create_and_check_torchscript",
          467,
          536,
          486,
          18,
          486,
          46,
          486,
          18,
          490,
          25
        ]
      ],
      "transformers/tests/models/autoformer/test_modeling_autoformer.py": [
        [
          "check_encoder_decoder_model_standalone",
          144,
          202,
          151,
          14,
          151,
          42,
          144,
          48,
          202,
          99
        ],
        [
          "test_save_load_strict",
          228,
          236,
          233,
          18,
          233,
          46,
          230,
          13,
          236,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          144,
          202,
          191,
          14,
          191,
          42,
          144,
          48,
          202,
          99
        ]
      ],
      "transformers/tests/models/auto/test_modeling_auto.py": [
        [
          "test_from_pretrained_dynamic_model_distant",
          310,
          363,
          326,
          14,
          326,
          42,
          310,
          52,
          331,
          74
        ],
        [
          "test_from_pretrained_dynamic_model_distant_with_ref",
          365,
          391,
          385,
          14,
          385,
          42,
          379,
          17,
          390,
          74
        ],
        [
          "test_from_pretrained_with_tuple_values",
          274,
          287,
          284,
          14,
          284,
          42,
          274,
          48,
          287,
          57
        ],
        [
          "test_from_pretrained_dynamic_model_local",
          289,
          308,
          297,
          18,
          297,
          46,
          297,
          18,
          297,
          46
        ],
        [
          "test_from_pretrained_dynamic_model_distant",
          310,
          363,
          351,
          14,
          351,
          42,
          335,
          26,
          356,
          74
        ],
        [
          "test_from_pretrained_dynamic_model_distant_with_ref",
          365,
          391,
          370,
          14,
          370,
          42,
          365,
          61,
          375,
          74
        ],
        [
          "test_from_pretrained_dynamic_model_with_period",
          393,
          412,
          408,
          14,
          408,
          42,
          393,
          56,
          412,
          66
        ],
        [
          "test_new_model_registration",
          414,
          463,
          444,
          26,
          444,
          54,
          444,
          26,
          444,
          54
        ]
      ],
      "transformers/tests/models/bart/test_modeling_bart.py": [
        [
          "check_encoder_decoder_model_standalone",
          187,
          217,
          205,
          14,
          205,
          42,
          187,
          48,
          217,
          99
        ],
        [
          "test_save_load_strict",
          434,
          442,
          439,
          18,
          439,
          46,
          436,
          13,
          442,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          187,
          217,
          194,
          14,
          194,
          42,
          187,
          48,
          217,
          99
        ]
      ],
      "transformers/tests/models/bamba/test_modeling_bamba.py": [
        [
          "test_flash_attention_2_padding_matches_padding_free_with_position_ids_seq_idx_and_fa_kwargs",
          434,
          514,
          460,
          18,
          460,
          46,
          460,
          18,
          464,
          60
        ]
      ],
      "transformers/tests/models/bark/test_modeling_bark.py": [
        [
          "test_save_load_strict",
          536,
          544,
          541,
          18,
          541,
          46,
          538,
          13,
          544,
          54
        ],
        [
          "test_save_load_strict",
          623,
          631,
          628,
          18,
          628,
          46,
          625,
          13,
          631,
          54
        ],
        [
          "test_save_load_strict",
          710,
          718,
          715,
          18,
          715,
          46,
          712,
          13,
          718,
          54
        ]
      ],
      "transformers/tests/models/bert_generation/test_modeling_bert_generation.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          313,
          425,
          362,
          18,
          362,
          46,
          362,
          18,
          369,
          60
        ]
      ],
      "transformers/tests/models/bert/test_modeling_bert.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          614,
          726,
          663,
          18,
          663,
          46,
          663,
          18,
          670,
          60
        ]
      ],
      "transformers/tests/models/bigbird_pegasus/test_modeling_bigbird_pegasus.py": [
        [
          "check_encoder_decoder_model_standalone",
          200,
          230,
          207,
          14,
          207,
          42,
          200,
          48,
          230,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          200,
          230,
          218,
          14,
          218,
          42,
          200,
          48,
          230,
          99
        ],
        [
          "test_save_load_strict",
          297,
          305,
          302,
          18,
          302,
          46,
          299,
          13,
          305,
          54
        ]
      ],
      "transformers/tests/models/blenderbot/test_modeling_blenderbot.py": [
        [
          "check_encoder_decoder_model_standalone",
          179,
          209,
          186,
          14,
          186,
          42,
          179,
          48,
          209,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          179,
          209,
          197,
          14,
          197,
          42,
          179,
          48,
          209,
          99
        ],
        [
          "test_save_load_strict",
          238,
          246,
          243,
          18,
          243,
          46,
          240,
          13,
          246,
          54
        ]
      ],
      "transformers/tests/models/blenderbot_small/test_modeling_blenderbot_small.py": [
        [
          "check_encoder_decoder_model_standalone",
          171,
          201,
          178,
          14,
          178,
          42,
          171,
          48,
          201,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          171,
          201,
          189,
          14,
          189,
          42,
          171,
          48,
          201,
          99
        ],
        [
          "test_save_load_strict",
          243,
          251,
          248,
          18,
          248,
          46,
          245,
          13,
          251,
          54
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip.py": [
        [
          "test_load_vision_text_config",
          530,
          543,
          534,
          14,
          534,
          42,
          530,
          38,
          543,
          85
        ],
        [
          "test_load_vision_text_config",
          1209,
          1222,
          1213,
          14,
          1213,
          42,
          1209,
          38,
          1222,
          85
        ],
        [
          "_create_and_check_torchscript",
          1138,
          1207,
          1157,
          18,
          1157,
          46,
          1157,
          18,
          1161,
          25
        ],
        [
          "_create_and_check_torchscript",
          459,
          528,
          478,
          18,
          478,
          46,
          478,
          18,
          482,
          25
        ],
        [
          "test_load_vision_text_config",
          530,
          543,
          540,
          14,
          540,
          42,
          530,
          38,
          543,
          85
        ],
        [
          "_create_and_check_torchscript",
          949,
          1018,
          968,
          18,
          968,
          46,
          968,
          18,
          972,
          25
        ],
        [
          "test_load_vision_text_config",
          1020,
          1033,
          1024,
          14,
          1024,
          42,
          1020,
          38,
          1033,
          85
        ],
        [
          "test_load_vision_text_config",
          1020,
          1033,
          1030,
          14,
          1030,
          42,
          1020,
          38,
          1033,
          85
        ],
        [
          "test_load_vision_text_config",
          1209,
          1222,
          1219,
          14,
          1219,
          42,
          1209,
          38,
          1222,
          85
        ]
      ],
      "transformers/tests/models/blip_2/test_modeling_blip_2.py": [
        [
          "test_load_vision_qformer_text_config",
          567,
          580,
          571,
          14,
          571,
          42,
          567,
          46,
          580,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          918,
          931,
          922,
          14,
          922,
          42,
          918,
          46,
          931,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          567,
          580,
          577,
          14,
          577,
          42,
          567,
          46,
          580,
          91
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          507,
          553,
          528,
          18,
          528,
          46,
          524,
          13,
          546,
          66
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          859,
          905,
          880,
          18,
          880,
          46,
          876,
          13,
          898,
          66
        ],
        [
          "test_load_vision_qformer_text_config",
          918,
          931,
          928,
          14,
          928,
          42,
          918,
          46,
          931,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          1432,
          1445,
          1436,
          14,
          1436,
          42,
          1432,
          46,
          1445,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          1432,
          1445,
          1442,
          14,
          1442,
          42,
          1432,
          46,
          1445,
          91
        ]
      ],
      "transformers/tests/models/chinese_clip/test_modeling_chinese_clip.py": [
        [
          "_create_and_check_torchscript",
          574,
          643,
          593,
          18,
          593,
          46,
          593,
          18,
          597,
          25
        ]
      ],
      "transformers/tests/models/clap/test_modeling_clap.py": [
        [
          "_create_and_check_torchscript",
          528,
          597,
          547,
          18,
          547,
          46,
          547,
          18,
          551,
          25
        ],
        [
          "test_load_audio_text_config",
          599,
          612,
          603,
          14,
          603,
          42,
          599,
          37,
          612,
          85
        ],
        [
          "test_load_audio_text_config",
          599,
          612,
          609,
          14,
          609,
          42,
          599,
          37,
          612,
          85
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "_create_and_check_torchscript",
          493,
          562,
          512,
          18,
          512,
          46,
          512,
          18,
          516,
          25
        ],
        [
          "test_load_vision_text_config",
          564,
          577,
          568,
          14,
          568,
          42,
          564,
          38,
          577,
          85
        ],
        [
          "test_load_vision_text_config",
          564,
          577,
          574,
          14,
          574,
          42,
          564,
          38,
          577,
          85
        ]
      ],
      "transformers/tests/models/clip/test_modeling_clip.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          174,
          202,
          179,
          18,
          179,
          46,
          175,
          13,
          193,
          50
        ],
        [
          "_create_and_check_torchscript",
          565,
          634,
          584,
          18,
          584,
          46,
          584,
          18,
          588,
          25
        ],
        [
          "test_load_vision_text_config",
          636,
          649,
          640,
          14,
          640,
          42,
          636,
          38,
          649,
          85
        ],
        [
          "test_load_vision_text_config",
          636,
          649,
          646,
          14,
          646,
          42,
          636,
          38,
          649,
          85
        ]
      ],
      "transformers/tests/models/clvp/test_modeling_clvp.py": [
        [
          "test_load_speech_text_decoder_config",
          501,
          514,
          511,
          14,
          511,
          42,
          501,
          46,
          514,
          91
        ],
        [
          "test_load_speech_text_decoder_config",
          501,
          514,
          505,
          14,
          505,
          42,
          501,
          46,
          514,
          91
        ]
      ],
      "transformers/tests/models/data2vec/test_modeling_data2vec_text.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          507,
          619,
          556,
          18,
          556,
          46,
          556,
          18,
          563,
          60
        ]
      ],
      "transformers/tests/models/d_fine/test_modeling_d_fine.py": [
        [
          "test_inference_equivalence_for_static_and_dynamic_anchors",
          656,
          690,
          672,
          18,
          672,
          46,
          671,
          13,
          690,
          13
        ]
      ],
      "transformers/tests/models/dac/test_modeling_dac.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          207,
          18,
          207,
          46,
          207,
          18,
          211,
          25
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "_test_eager_matches_sdpa_inference",
          152,
          504,
          250,
          14,
          250,
          42,
          250,
          14,
          257,
          48
        ],
        [
          "test_save_load",
          710,
          755,
          731,
          18,
          731,
          46,
          723,
          13,
          751,
          39
        ],
        [
          "test_keep_in_fp32_modules",
          769,
          785,
          776,
          18,
          776,
          46,
          775,
          21,
          781,
          59
        ],
        [
          "test_save_load_keys_to_ignore_on_save",
          787,
          817,
          801,
          18,
          801,
          46,
          801,
          18,
          806,
          48
        ],
        [
          "test_torch_save_load",
          975,
          1022,
          1017,
          18,
          1017,
          46,
          991,
          29,
          1022,
          64
        ],
        [
          "_create_and_check_torchscript",
          1385,
          1521,
          1466,
          22,
          1466,
          50,
          1466,
          22,
          1470,
          29
        ],
        [
          "test_head_pruning_save_load_from_pretrained",
          1725,
          1759,
          1748,
          18,
          1748,
          46,
          1729,
          13,
          1759,
          97
        ],
        [
          "test_head_pruning_integration",
          1795,
          1846,
          1824,
          18,
          1824,
          46,
          1799,
          13,
          1846,
          80
        ],
        [
          "test_correct_missing_keys",
          2380,
          2404,
          2401,
          22,
          2401,
          50,
          2401,
          22,
          2404,
          102
        ],
        [
          "test_can_use_safetensors",
          2438,
          2472,
          2442,
          18,
          2442,
          46,
          2439,
          13,
          2444,
          46
        ],
        [
          "test_load_save_without_tied_weights",
          2474,
          2491,
          2479,
          18,
          2479,
          46,
          2475,
          13,
          2485,
          54
        ],
        [
          "test_model_weights_reload_no_missing_tied_weights",
          2530,
          2586,
          2534,
          18,
          2534,
          46,
          2531,
          13,
          2553,
          71
        ],
        [
          "test_disk_offload_bin",
          2783,
          2822,
          2797,
          18,
          2797,
          46,
          2790,
          33,
          2816,
          52
        ],
        [
          "test_disk_offload_safetensors",
          2827,
          2860,
          2841,
          18,
          2841,
          46,
          2834,
          33,
          2854,
          52
        ],
        [
          "test_cpu_offload",
          2865,
          2902,
          2882,
          18,
          2882,
          46,
          2872,
          33,
          2885,
          45
        ],
        [
          "test_model_parallelism",
          2908,
          2944,
          2925,
          18,
          2925,
          46,
          2915,
          33,
          2928,
          45
        ],
        [
          "test_load_with_mismatched_shapes",
          2992,
          3034,
          3002,
          22,
          3002,
          50,
          3001,
          18,
          3031,
          46
        ],
        [
          "test_can_load_ignoring_mismatched_shapes",
          3036,
          3118,
          3057,
          22,
          3057,
          50,
          3056,
          18,
          3076,
          51
        ],
        [
          "flash_attn_inference_equivalence",
          3131,
          3281,
          3166,
          18,
          3166,
          46,
          3165,
          43,
          3173,
          55
        ],
        [
          "test_attn_implementation_composite_models",
          3333,
          3389,
          3379,
          18,
          3379,
          46,
          3372,
          43,
          3383,
          52
        ],
        [
          "test_sdpa_can_dispatch_non_composite_models",
          3391,
          3426,
          3406,
          18,
          3406,
          46,
          3402,
          13,
          3417,
          66
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          3428,
          3481,
          3449,
          18,
          3449,
          46,
          3445,
          13,
          3461,
          72
        ],
        [
          "test_sdpa_can_dispatch_on_flash",
          3493,
          3570,
          3557,
          18,
          3557,
          46,
          3557,
          18,
          3565,
          52
        ],
        [
          "test_sdpa_can_compile_dynamic",
          3575,
          3635,
          3618,
          18,
          3618,
          46,
          3618,
          18,
          3629,
          52
        ],
        [
          "flash_attn_can_dispatch_composite_models",
          3637,
          3697,
          3658,
          18,
          3658,
          46,
          3658,
          18,
          3668,
          86
        ],
        [
          "test_flash_attn_2_fp32_ln",
          3716,
          3765,
          3725,
          18,
          3725,
          46,
          3723,
          35,
          3735,
          35
        ],
        [
          "flash_attn_from_config",
          3806,
          3844,
          3841,
          18,
          3841,
          46,
          3841,
          18,
          3844,
          105
        ],
        [
          "test_can_load_with_device_context_manager",
          4176,
          4196,
          4185,
          18,
          4185,
          46,
          4180,
          13,
          4196,
          13
        ],
        [
          "test_can_load_with_global_device_set",
          4203,
          4229,
          4216,
          18,
          4216,
          46,
          4208,
          13,
          4229,
          13
        ],
        [
          "test_cannot_load_with_meta_device_context_manager",
          4231,
          4244,
          4238,
          18,
          4238,
          46,
          4233,
          13,
          4244,
          25
        ],
        [
          "test_bc_torch_dtype",
          4379,
          4401,
          4389,
          18,
          4389,
          46,
          4388,
          21,
          4393,
          117
        ]
      ],
      "transformers/tests/models/deepseek_vl/test_modeling_deepseek_vl.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          190,
          229,
          195,
          18,
          195,
          46,
          191,
          13,
          210,
          72
        ]
      ],
      "transformers/tests/models/deepseek_vl_hybrid/test_modeling_deepseek_vl_hybrid.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          220,
          272,
          225,
          18,
          225,
          46,
          221,
          13,
          246,
          51
        ]
      ],
      "transformers/tests/models/dia/test_modeling_dia.py": [
        [
          "check_encoder_decoder_model_standalone",
          183,
          212,
          190,
          14,
          190,
          42,
          183,
          48,
          212,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          183,
          212,
          201,
          14,
          201,
          42,
          183,
          48,
          212,
          99
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          412,
          443,
          420,
          18,
          420,
          46,
          416,
          13,
          431,
          58
        ]
      ],
      "transformers/tests/models/diffllama/test_modeling_diffllama.py": [
        [
          "test_use_flash_attention_2_true",
          472,
          494,
          478,
          18,
          478,
          46,
          477,
          13,
          489,
          64
        ]
      ],
      "transformers/tests/models/distilbert/test_modeling_distilbert.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          282,
          327,
          306,
          18,
          306,
          46,
          285,
          13,
          327,
          91
        ],
        [
          "test_flash_attn_2_inference_equivalence_right_padding",
          334,
          382,
          358,
          18,
          358,
          46,
          337,
          13,
          382,
          93
        ]
      ],
      "transformers/tests/models/dpr/test_modeling_dpr.py": [
        [
          "test_init_changed_config",
          211,
          222,
          218,
          14,
          218,
          42,
          211,
          34,
          222,
          35
        ]
      ],
      "transformers/tests/models/edgetam/test_modeling_edgetam.py": [
        [
          "flash_attn_inference_equivalence",
          266,
          352,
          283,
          18,
          283,
          46,
          280,
          35,
          294,
          70
        ]
      ],
      "transformers/tests/models/electra/test_modeling_electra.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          476,
          588,
          525,
          18,
          525,
          46,
          525,
          18,
          532,
          60
        ]
      ],
      "transformers/tests/models/encoder_decoder/test_modeling_encoder_decoder.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          511,
          591,
          567,
          14,
          567,
          42,
          512,
          9,
          591,
          13
        ],
        [
          "test_real_model_save_load_from_pretrained",
          668,
          696,
          683,
          18,
          683,
          46,
          668,
          51,
          696,
          52
        ],
        [
          "check_encoder_decoder_model_from_pretrained_using_model_paths",
          169,
          212,
          183,
          13,
          183,
          41,
          170,
          9,
          190,
          65
        ],
        [
          "check_save_and_load",
          245,
          284,
          270,
          18,
          270,
          46,
          246,
          9,
          284,
          52
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          286,
          332,
          313,
          17,
          313,
          45,
          287,
          9,
          332,
          52
        ],
        [
          "check_encoder_decoder_model_from_pretrained_using_model_paths",
          169,
          212,
          182,
          13,
          182,
          41,
          170,
          9,
          190,
          65
        ],
        [
          "check_save_and_load_encoder_decoder_model",
          286,
          332,
          312,
          17,
          312,
          45,
          287,
          9,
          332,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          698,
          747,
          709,
          14,
          709,
          42,
          702,
          23,
          716,
          65
        ]
      ],
      "transformers/tests/models/encodec/test_modeling_encodec.py": [
        [
          "_create_and_check_torchscript",
          212,
          300,
          234,
          18,
          234,
          46,
          234,
          18,
          238,
          25
        ]
      ],
      "transformers/tests/models/ernie4_5_moe/test_modeling_ernie4_5_moe.py": [
        [
          "test_flash_attn_2_equivalence",
          72,
          99,
          80,
          18,
          80,
          46,
          77,
          35,
          99,
          78
        ]
      ],
      "transformers/tests/models/esm/test_modeling_esm.py": [
        [
          "test_flash_attn_2_equivalence",
          313,
          339,
          321,
          18,
          321,
          46,
          318,
          35,
          339,
          83
        ]
      ],
      "transformers/tests/models/ernie/test_modeling_ernie.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          568,
          680,
          617,
          18,
          617,
          46,
          617,
          18,
          624,
          60
        ]
      ],
      "transformers/tests/models/fsmt/test_modeling_fsmt.py": [
        [
          "get_model",
          464,
          478,
          472,
          18,
          472,
          46,
          471,
          21,
          476,
          37
        ],
        [
          "test_save_load_missing_keys",
          242,
          251,
          248,
          18,
          248,
          46,
          245,
          13,
          251,
          54
        ]
      ],
      "transformers/tests/models/fastspeech2_conformer/test_modeling_fastspeech2_conformer.py": [
        [
          "test_save_load_strict",
          197,
          204,
          201,
          14,
          201,
          42,
          197,
          31,
          204,
          50
        ],
        [
          "test_save_load_strict",
          616,
          623,
          620,
          14,
          620,
          42,
          616,
          31,
          623,
          50
        ]
      ],
      "transformers/tests/models/flava/test_modeling_flava.py": [
        [
          "_create_and_check_torchscript",
          920,
          999,
          947,
          18,
          947,
          46,
          947,
          18,
          951,
          25
        ],
        [
          "test_load_image_text_config",
          1001,
          1020,
          1005,
          14,
          1005,
          42,
          1001,
          37,
          1020,
          97
        ],
        [
          "test_load_image_text_config",
          1001,
          1020,
          1011,
          14,
          1011,
          42,
          1001,
          37,
          1020,
          97
        ],
        [
          "test_load_image_text_config",
          1001,
          1020,
          1017,
          14,
          1017,
          42,
          1001,
          37,
          1020,
          97
        ]
      ],
      "transformers/tests/models/gemma3/test_modeling_gemma3.py": [
        [
          "test_automodelforcausallm",
          342,
          352,
          349,
          14,
          349,
          42,
          342,
          35,
          352,
          80
        ]
      ],
      "transformers/tests/models/gemma3n/test_modeling_gemma3n.py": [
        [
          "test_automodelforcausallm",
          716,
          726,
          723,
          14,
          723,
          42,
          716,
          35,
          726,
          68
        ]
      ],
      "transformers/tests/models/granite_speech/test_modeling_granite_speech.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          252,
          287,
          267,
          18,
          267,
          46,
          260,
          13,
          272,
          73
        ]
      ],
      "transformers/tests/models/groupvit/test_modeling_groupvit.py": [
        [
          "_create_and_check_torchscript",
          569,
          638,
          588,
          18,
          588,
          46,
          588,
          18,
          592,
          25
        ],
        [
          "test_load_vision_text_config",
          640,
          653,
          644,
          14,
          644,
          42,
          640,
          38,
          653,
          85
        ],
        [
          "test_load_vision_text_config",
          640,
          653,
          650,
          14,
          650,
          42,
          640,
          38,
          653,
          85
        ]
      ],
      "transformers/tests/models/idefics2/test_modeling_idefics2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          337,
          360,
          342,
          18,
          342,
          46,
          338,
          13,
          357,
          66
        ]
      ],
      "transformers/tests/models/hubert/test_modeling_hubert.py": [
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          505,
          18,
          505,
          46,
          505,
          18,
          508,
          50
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_modeling_instructblipvideo.py": [
        [
          "test_load_vision_qformer_text_config",
          550,
          563,
          560,
          14,
          560,
          42,
          550,
          46,
          563,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          550,
          563,
          554,
          14,
          554,
          42,
          550,
          46,
          563,
          91
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          578,
          624,
          599,
          18,
          599,
          46,
          595,
          13,
          617,
          66
        ]
      ],
      "transformers/tests/models/informer/test_modeling_informer.py": [
        [
          "test_save_load_strict",
          214,
          222,
          219,
          18,
          219,
          46,
          216,
          13,
          222,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          151,
          189,
          179,
          14,
          179,
          42,
          151,
          48,
          189,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          151,
          189,
          158,
          14,
          158,
          42,
          151,
          48,
          189,
          99
        ]
      ],
      "transformers/tests/models/jamba/test_modeling_jamba.py": [
        [
          "test_flash_attn_2_fp32_ln",
          503,
          534,
          512,
          18,
          512,
          46,
          508,
          13,
          527,
          56
        ]
      ],
      "transformers/tests/models/janus/test_modeling_janus.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          204,
          243,
          209,
          18,
          209,
          46,
          205,
          13,
          224,
          72
        ]
      ],
      "transformers/tests/models/instructblip/test_modeling_instructblip.py": [
        [
          "test_load_vision_qformer_text_config",
          538,
          551,
          542,
          14,
          542,
          42,
          538,
          46,
          551,
          91
        ],
        [
          "test_load_vision_qformer_text_config",
          538,
          551,
          548,
          14,
          548,
          42,
          538,
          46,
          551,
          91
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          566,
          612,
          587,
          18,
          587,
          46,
          583,
          13,
          605,
          66
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_modeling_kosmos2_5.py": [
        [
          "test_load_save_without_tied_weights",
          396,
          415,
          401,
          18,
          401,
          46,
          399,
          13,
          407,
          54
        ]
      ],
      "transformers/tests/models/kyutai_speech_to_text/test_modeling_kyutai_speech_to_text.py": [
        [
          "_test_attention_implementation",
          443,
          517,
          486,
          18,
          486,
          46,
          484,
          21,
          517,
          104
        ]
      ],
      "transformers/tests/models/kosmos2/test_modeling_kosmos2.py": [
        [
          "test_load_save_without_tied_weights",
          334,
          351,
          339,
          18,
          339,
          46,
          337,
          13,
          345,
          54
        ],
        [
          "_create_and_check_torchscript",
          490,
          568,
          513,
          18,
          513,
          46,
          513,
          18,
          517,
          25
        ]
      ],
      "transformers/tests/models/led/test_modeling_led.py": [
        [
          "check_encoder_decoder_model_standalone",
          205,
          237,
          212,
          14,
          212,
          42,
          205,
          48,
          237,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          205,
          237,
          225,
          14,
          225,
          42,
          205,
          48,
          237,
          99
        ],
        [
          "test_save_load_strict",
          312,
          320,
          317,
          18,
          317,
          46,
          314,
          13,
          320,
          54
        ]
      ],
      "transformers/tests/models/longcat_flash/test_modeling_longcat_flash.py": [
        [
          "test_flash_attn_2_fp32_ln",
          352,
          398,
          361,
          18,
          361,
          46,
          359,
          35,
          371,
          35
        ]
      ],
      "transformers/tests/models/m2m_100/test_modeling_m2m_100.py": [
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          193,
          14,
          193,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          204,
          14,
          204,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "test_save_load_strict",
          269,
          277,
          274,
          18,
          274,
          46,
          271,
          13,
          277,
          54
        ]
      ],
      "transformers/tests/models/longt5/test_modeling_longt5.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          404,
          478,
          452,
          18,
          452,
          46,
          413,
          13,
          478,
          17
        ]
      ],
      "transformers/tests/models/marian/test_modeling_marian.py": [
        [
          "check_encoder_decoder_model_standalone",
          184,
          214,
          202,
          14,
          202,
          42,
          184,
          48,
          214,
          99
        ],
        [
          "test_share_encoder_decoder_embeddings",
          271,
          295,
          291,
          18,
          291,
          46,
          289,
          13,
          295,
          114
        ],
        [
          "check_encoder_decoder_model_standalone",
          184,
          214,
          191,
          14,
          191,
          42,
          184,
          48,
          214,
          99
        ],
        [
          "test_save_load_strict",
          243,
          251,
          248,
          18,
          248,
          46,
          245,
          13,
          251,
          54
        ]
      ],
      "transformers/tests/models/mbart/test_modeling_mbart.py": [
        [
          "test_save_load_strict",
          261,
          269,
          266,
          18,
          266,
          46,
          263,
          13,
          269,
          54
        ],
        [
          "check_encoder_decoder_model_standalone",
          178,
          208,
          185,
          14,
          185,
          42,
          178,
          48,
          208,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          178,
          208,
          196,
          14,
          196,
          42,
          178,
          48,
          208,
          99
        ]
      ],
      "transformers/tests/models/metaclip_2/test_modeling_metaclip_2.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          173,
          201,
          178,
          18,
          178,
          46,
          174,
          13,
          192,
          50
        ],
        [
          "test_load_vision_text_config",
          646,
          659,
          650,
          14,
          650,
          42,
          646,
          38,
          659,
          85
        ],
        [
          "_create_and_check_torchscript",
          575,
          644,
          594,
          18,
          594,
          46,
          594,
          18,
          598,
          25
        ],
        [
          "test_load_vision_text_config",
          646,
          659,
          656,
          14,
          656,
          42,
          646,
          38,
          659,
          85
        ]
      ],
      "transformers/tests/models/mimi/test_modeling_mimi.py": [
        [
          "_create_and_check_torchscript",
          225,
          313,
          247,
          18,
          247,
          46,
          247,
          18,
          251,
          25
        ],
        [
          "test_flash_attn_2_inference_equivalence",
          399,
          424,
          404,
          18,
          404,
          46,
          400,
          13,
          415,
          70
        ]
      ],
      "transformers/tests/models/modernbert/test_modeling_modernbert.py": [
        [
          "test_saved_config_excludes_reference_compile",
          363,
          369,
          365,
          14,
          365,
          42,
          363,
          54,
          369,
          62
        ],
        [
          "flash_attn_inference_equivalence",
          383,
          510,
          418,
          18,
          418,
          46,
          417,
          43,
          425,
          55
        ]
      ],
      "transformers/tests/models/mvp/test_modeling_mvp.py": [
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          193,
          14,
          193,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          186,
          216,
          204,
          14,
          204,
          42,
          186,
          48,
          216,
          99
        ],
        [
          "test_save_load_strict",
          458,
          466,
          463,
          18,
          463,
          46,
          460,
          13,
          466,
          54
        ]
      ],
      "transformers/tests/models/mt5/test_modeling_mt5.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          434,
          508,
          482,
          18,
          482,
          46,
          443,
          13,
          508,
          17
        ],
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          685,
          18,
          685,
          46,
          685,
          18,
          688,
          50
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_modeling_musicgen_melody.py": [
        [
          "test_flash_attn_2_inference_equivalence",
          302,
          377,
          310,
          18,
          310,
          46,
          307,
          35,
          324,
          70
        ],
        [
          "test_flash_attn_2_inference_equivalence_right_padding",
          384,
          458,
          392,
          18,
          392,
          46,
          389,
          35,
          406,
          70
        ],
        [
          "test_sdpa_can_dispatch_on_flash",
          924,
          973,
          956,
          18,
          956,
          46,
          954,
          21,
          968,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          975,
          1007,
          986,
          18,
          986,
          46,
          982,
          13,
          991,
          81
        ]
      ],
      "transformers/tests/models/moshi/test_modeling_moshi.py": [
        [
          "test_eager_matches_sdpa_generate",
          642,
          713,
          665,
          18,
          665,
          46,
          663,
          21,
          683,
          66
        ]
      ],
      "transformers/tests/models/nllb_moe/test_modeling_nllb_moe.py": [
        [
          "check_encoder_decoder_model_standalone",
          198,
          228,
          205,
          14,
          205,
          42,
          198,
          48,
          228,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          198,
          228,
          216,
          14,
          216,
          42,
          198,
          48,
          228,
          99
        ],
        [
          "test_save_load_strict",
          271,
          279,
          276,
          18,
          276,
          46,
          273,
          13,
          279,
          54
        ]
      ],
      "transformers/tests/models/musicgen/test_modeling_musicgen.py": [
        [
          "test_flash_attn_2_inference_equivalence_right_padding",
          373,
          445,
          381,
          18,
          381,
          46,
          378,
          35,
          393,
          70
        ],
        [
          "test_flash_attn_2_inference_equivalence",
          293,
          366,
          301,
          18,
          301,
          46,
          298,
          35,
          313,
          70
        ],
        [
          "test_sdpa_can_dispatch_on_flash",
          921,
          970,
          953,
          18,
          953,
          46,
          951,
          21,
          965,
          52
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          972,
          1004,
          983,
          18,
          983,
          46,
          979,
          13,
          988,
          81
        ]
      ],
      "transformers/tests/models/opt/test_modeling_opt.py": [
        [
          "test_save_load_strict",
          252,
          260,
          257,
          18,
          257,
          46,
          254,
          13,
          260,
          54
        ]
      ],
      "transformers/tests/models/owlv2/test_modeling_owlv2.py": [
        [
          "test_load_vision_text_config",
          529,
          542,
          533,
          14,
          533,
          42,
          529,
          38,
          542,
          85
        ],
        [
          "_create_and_check_torchscript",
          462,
          527,
          480,
          18,
          480,
          46,
          480,
          18,
          484,
          25
        ],
        [
          "test_load_vision_text_config",
          529,
          542,
          539,
          14,
          539,
          42,
          529,
          38,
          542,
          85
        ],
        [
          "_create_and_check_torchscript",
          671,
          736,
          689,
          18,
          689,
          46,
          689,
          18,
          693,
          25
        ]
      ],
      "transformers/tests/models/owlvit/test_modeling_owlvit.py": [
        [
          "test_load_vision_text_config",
          524,
          537,
          534,
          14,
          534,
          42,
          524,
          38,
          537,
          85
        ],
        [
          "test_load_vision_text_config",
          524,
          537,
          528,
          14,
          528,
          42,
          524,
          38,
          537,
          85
        ],
        [
          "_create_and_check_torchscript",
          457,
          522,
          475,
          18,
          475,
          46,
          475,
          18,
          479,
          25
        ],
        [
          "_create_and_check_torchscript",
          664,
          729,
          682,
          18,
          682,
          46,
          682,
          18,
          686,
          25
        ]
      ],
      "transformers/tests/models/parakeet/test_modeling_parakeet.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          275,
          298,
          286,
          18,
          286,
          46,
          282,
          13,
          295,
          66
        ]
      ],
      "transformers/tests/models/patchtst/test_modeling_patchtst.py": [
        [
          "test_save_load_strict",
          204,
          212,
          209,
          18,
          209,
          46,
          206,
          13,
          212,
          54
        ]
      ],
      "transformers/tests/models/pegasus/test_modeling_pegasus.py": [
        [
          "check_encoder_decoder_model_standalone",
          189,
          219,
          207,
          14,
          207,
          42,
          189,
          48,
          219,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          189,
          219,
          196,
          14,
          196,
          42,
          189,
          48,
          219,
          99
        ],
        [
          "test_save_load_strict",
          249,
          257,
          254,
          18,
          254,
          46,
          251,
          13,
          257,
          54
        ]
      ],
      "transformers/tests/models/pegasus_x/test_modeling_pegasus_x.py": [
        [
          "check_encoder_decoder_model_standalone",
          169,
          199,
          176,
          14,
          176,
          42,
          169,
          48,
          199,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          169,
          199,
          187,
          14,
          187,
          42,
          169,
          48,
          199,
          99
        ],
        [
          "test_save_load_strict",
          232,
          240,
          237,
          18,
          237,
          46,
          234,
          13,
          240,
          54
        ]
      ],
      "transformers/tests/models/patchtsmixer/test_modeling_patchtsmixer.py": [
        [
          "test_save_load_strict",
          273,
          281,
          278,
          18,
          278,
          46,
          275,
          13,
          281,
          54
        ]
      ],
      "transformers/tests/models/plbart/test_modeling_plbart.py": [
        [
          "check_encoder_decoder_model_standalone",
          176,
          206,
          194,
          14,
          194,
          42,
          176,
          48,
          206,
          99
        ],
        [
          "check_encoder_decoder_model_standalone",
          176,
          206,
          183,
          14,
          183,
          42,
          176,
          48,
          206,
          99
        ],
        [
          "test_save_load_strict",
          257,
          265,
          262,
          18,
          262,
          46,
          259,
          13,
          265,
          54
        ]
      ],
      "transformers/tests/models/perceiver/test_modeling_perceiver.py": [
        [
          "test_save_load",
          686,
          729,
          701,
          26,
          701,
          54,
          697,
          21,
          712,
          60
        ],
        [
          "test_save_load",
          686,
          729,
          718,
          22,
          718,
          50,
          715,
          25,
          729,
          56
        ],
        [
          "test_correct_missing_keys",
          731,
          757,
          753,
          22,
          753,
          50,
          753,
          22,
          757,
          80
        ]
      ],
      "transformers/tests/models/pix2struct/test_modeling_pix2struct.py": [
        [
          "test_load_vision_text_config",
          694,
          707,
          698,
          14,
          698,
          42,
          694,
          38,
          707,
          85
        ],
        [
          "_create_and_check_torchscript",
          623,
          692,
          642,
          18,
          642,
          46,
          642,
          18,
          646,
          25
        ],
        [
          "test_load_vision_text_config",
          694,
          707,
          704,
          14,
          704,
          42,
          694,
          38,
          707,
          85
        ]
      ],
      "transformers/tests/models/pop2piano/test_modeling_pop2piano.py": [
        [
          "create_and_check_encoder_decoder_shared_weights",
          375,
          449,
          423,
          18,
          423,
          46,
          384,
          13,
          449,
          17
        ]
      ],
      "transformers/tests/models/pvt_v2/test_modeling_pvt_v2.py": [
        [
          "test_config_save_pretrained",
          371,
          383,
          375,
          14,
          375,
          42,
          371,
          37,
          380,
          53
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          296,
          333,
          308,
          18,
          308,
          46,
          304,
          13,
          313,
          64
        ],
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          335,
          418,
          352,
          18,
          352,
          46,
          350,
          21,
          355,
          60
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          335,
          415,
          352,
          18,
          352,
          46,
          350,
          21,
          355,
          60
        ]
      ],
      "transformers/tests/models/prophetnet/test_modeling_prophetnet.py": [
        [
          "check_causal_lm_from_pretrained",
          489,
          512,
          494,
          14,
          494,
          42,
          490,
          9,
          512,
          9
        ],
        [
          "create_and_check_encoder_decoder_shared_weights",
          336,
          414,
          388,
          18,
          388,
          46,
          355,
          13,
          414,
          17
        ],
        [
          "test_config_save",
          968,
          975,
          971,
          14,
          971,
          42,
          968,
          26,
          975,
          52
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_modeling_qwen2_audio.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          159,
          194,
          171,
          18,
          171,
          46,
          167,
          13,
          176,
          73
        ]
      ],
      "transformers/tests/models/qwen3_next/test_modeling_qwen3_next.py": [
        [
          "test_can_use_device_map",
          311,
          343,
          324,
          18,
          324,
          46,
          316,
          13,
          343,
          17
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_modeling_qwen2_vl.py": [
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          277,
          358,
          294,
          18,
          294,
          46,
          292,
          21,
          297,
          60
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_modeling_qwen3_omni_moe.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          307,
          344,
          319,
          18,
          319,
          46,
          315,
          13,
          324,
          64
        ],
        [
          "attention_mask_padding_matches_padding_free_with_position_ids",
          346,
          429,
          363,
          18,
          363,
          46,
          361,
          21,
          366,
          60
        ]
      ]
    },
    "open": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUpClass",
          1066,
          1077,
          1076,
          14,
          1076,
          39,
          1066,
          20,
          1077,
          38
        ],
        [
          "setUp",
          113,
          178,
          137,
          14,
          137,
          57,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          171,
          14,
          171,
          57,
          113,
          15,
          178,
          55
        ],
        [
          "setUp",
          113,
          178,
          173,
          14,
          173,
          58,
          113,
          15,
          178,
          55
        ],
        [
          "setUpClass",
          685,
          696,
          695,
          14,
          695,
          39,
          685,
          20,
          696,
          38
        ]
      ],
      "transformers/tests/models/t5/test_modeling_t5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          696,
          26,
          696,
          50,
          693,
          18,
          696,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          698,
          26,
          698,
          50,
          698,
          26,
          698,
          50
        ]
      ],
      "transformers/tests/models/umt5/test_modeling_umt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          384,
          26,
          384,
          50,
          381,
          18,
          384,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          386,
          26,
          386,
          50,
          386,
          26,
          386,
          50
        ]
      ],
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "remove_dtype",
          654,
          660,
          656,
          18,
          656,
          45,
          654,
          26,
          660,
          31
        ],
        [
          "remove_dtype",
          654,
          660,
          659,
          18,
          659,
          50,
          654,
          26,
          660,
          31
        ],
        [
          "test_model_from_pretrained_dtype",
          641,
          726,
          688,
          14,
          688,
          46,
          641,
          42,
          726,
          53
        ],
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          815,
          22,
          815,
          55,
          815,
          22,
          824,
          77
        ],
        [
          "test_use_safetensors",
          1275,
          1329,
          1322,
          22,
          1322,
          68,
          1275,
          30,
          1329,
          9
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          1998,
          18,
          1998,
          62,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2024,
          18,
          2024,
          62,
          2006,
          66,
          2030,
          85
        ],
        [
          "test_device_map_works_with_unexpected_keys_sharded",
          2109,
          2147,
          2133,
          14,
          2133,
          83,
          2109,
          60,
          2139,
          54
        ]
      ],
      "transformers/tests/models/wav2vec2/test_modeling_wav2vec2.py": [
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          762,
          26,
          762,
          50,
          759,
          18,
          762,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          764,
          26,
          764,
          50,
          764,
          26,
          764,
          50
        ]
      ],
      "transformers/tests/sagemaker/test_multi_node_data_parallel.py": [
        [
          "test_script",
          74,
          99,
          98,
          14,
          98,
          68,
          95,
          9,
          99,
          117
        ]
      ],
      "transformers/tests/sagemaker/test_multi_node_model_parallel.py": [
        [
          "test_scripz",
          94,
          119,
          118,
          14,
          118,
          68,
          115,
          9,
          119,
          117
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_common.py": [
        [
          "test_push_to_hub_dynamic_pipeline",
          886,
          964,
          902,
          18,
          902,
          56,
          886,
          43,
          964,
          9
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_text_to_text.py": [
        [
          "test_model_pt_chat_template_image_url_base64",
          370,
          388,
          371,
          14,
          371,
          79,
          370,
          54,
          388,
          82
        ]
      ],
      "transformers/tests/models/align/test_processing_align.py": [
        [
          "setUp",
          39,
          72,
          60,
          14,
          60,
          57,
          39,
          15,
          72,
          46
        ],
        [
          "setUp",
          39,
          72,
          71,
          14,
          71,
          67,
          39,
          15,
          72,
          46
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "setUpClass",
          40,
          84,
          64,
          14,
          64,
          56,
          40,
          20,
          84,
          49
        ],
        [
          "setUpClass",
          40,
          84,
          78,
          14,
          78,
          66,
          40,
          20,
          84,
          49
        ]
      ],
      "transformers/tests/models/clipseg/test_processing_clipseg.py": [
        [
          "setUp",
          39,
          65,
          49,
          14,
          49,
          57,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          51,
          14,
          51,
          58,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          64,
          14,
          64,
          67,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/flava/test_processing_flava.py": [
        [
          "setUp",
          46,
          81,
          52,
          14,
          52,
          57,
          46,
          15,
          81,
          46
        ],
        [
          "setUp",
          46,
          81,
          80,
          14,
          80,
          67,
          46,
          15,
          81,
          46
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "setUpClass",
          48,
          80,
          53,
          14,
          53,
          56,
          48,
          20,
          80,
          22
        ],
        [
          "setUpClass",
          48,
          80,
          67,
          14,
          67,
          66,
          48,
          20,
          80,
          22
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "setUpClass",
          49,
          67,
          58,
          14,
          58,
          69,
          49,
          20,
          67,
          49
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_processing_layoutlmv2.py": [
        [
          "setUp",
          42,
          73,
          69,
          14,
          69,
          57,
          42,
          15,
          73,
          60
        ],
        [
          "setUp",
          42,
          73,
          72,
          14,
          72,
          68,
          42,
          15,
          73,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_processing_layoutlmv3.py": [
        [
          "setUp",
          42,
          86,
          73,
          14,
          73,
          57,
          42,
          15,
          86,
          60
        ],
        [
          "setUp",
          42,
          86,
          75,
          14,
          75,
          58,
          42,
          15,
          86,
          60
        ],
        [
          "setUp",
          42,
          86,
          85,
          14,
          85,
          70,
          42,
          15,
          86,
          60
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "setUp",
          50,
          70,
          58,
          14,
          58,
          57,
          50,
          15,
          70,
          46
        ],
        [
          "setUp",
          50,
          70,
          69,
          14,
          69,
          67,
          50,
          15,
          70,
          46
        ]
      ],
      "transformers/tests/models/markuplm/test_processing_markuplm.py": [
        [
          "setUp",
          47,
          70,
          60,
          14,
          60,
          57,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          62,
          14,
          62,
          58,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          64,
          14,
          64,
          68,
          47,
          15,
          70,
          62
        ],
        [
          "setUp",
          47,
          70,
          69,
          14,
          69,
          70,
          47,
          15,
          70,
          62
        ]
      ],
      "transformers/tests/models/owlvit/test_processing_owlvit.py": [
        [
          "setUp",
          39,
          65,
          49,
          14,
          49,
          57,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          51,
          14,
          51,
          58,
          39,
          15,
          65,
          46
        ],
        [
          "setUp",
          39,
          65,
          64,
          14,
          64,
          67,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/oneformer/test_processing_oneformer.py": [
        [
          "prepare_metadata",
          43,
          58,
          44,
          10,
          44,
          79,
          43,
          22,
          50,
          39
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_processing_shieldgemma2.py": [
        [
          "test_policy_definitions_saved_in_config",
          102,
          110,
          105,
          14,
          105,
          46,
          102,
          49,
          110,
          62
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "setUpClass",
          31,
          42,
          36,
          14,
          36,
          56,
          31,
          20,
          42,
          49
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "setUpClass",
          41,
          65,
          64,
          14,
          64,
          69,
          41,
          20,
          65,
          62
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "setUpClass",
          39,
          61,
          44,
          14,
          44,
          56,
          39,
          20,
          61,
          49
        ],
        [
          "setUpClass",
          39,
          61,
          55,
          14,
          55,
          66,
          39,
          20,
          61,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "setUpClass",
          35,
          63,
          56,
          14,
          56,
          56,
          35,
          20,
          63,
          49
        ],
        [
          "setUpClass",
          35,
          63,
          59,
          14,
          59,
          69,
          35,
          20,
          63,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "setUpClass",
          36,
          64,
          57,
          14,
          57,
          56,
          36,
          20,
          64,
          49
        ],
        [
          "setUpClass",
          36,
          64,
          60,
          14,
          60,
          69,
          36,
          20,
          64,
          49
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_processor_from_processor_class",
          97,
          123,
          110,
          22,
          110,
          72,
          109,
          32,
          111,
          46
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          114,
          18,
          114,
          70,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_processor_class",
          97,
          123,
          118,
          18,
          118,
          75,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          137,
          22,
          137,
          67,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          141,
          22,
          141,
          72,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          145,
          18,
          145,
          70,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          149,
          18,
          149,
          75,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          168,
          22,
          168,
          67,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          172,
          22,
          172,
          72,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          176,
          18,
          176,
          71,
          176,
          18,
          185,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          180,
          18,
          180,
          76,
          176,
          18,
          185,
          59
        ],
        [
          "test_processor_from_local_directory_from_model_config",
          187,
          199,
          194,
          18,
          194,
          76,
          187,
          63,
          199,
          59
        ],
        [
          "test_new_processor_registration",
          234,
          270,
          249,
          22,
          249,
          60,
          248,
          17,
          249,
          60
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          466,
          22,
          466,
          60,
          456,
          44,
          505,
          85
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          486,
          22,
          486,
          73,
          456,
          44,
          505,
          85
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "setUp",
          50,
          77,
          70,
          14,
          70,
          57,
          50,
          15,
          77,
          25
        ],
        [
          "setUp",
          50,
          77,
          73,
          14,
          73,
          70,
          50,
          15,
          77,
          25
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "setUp",
          43,
          105,
          68,
          14,
          68,
          57,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          102,
          14,
          102,
          57,
          43,
          15,
          105,
          39
        ],
        [
          "setUp",
          43,
          105,
          104,
          14,
          104,
          58,
          43,
          15,
          105,
          39
        ]
      ],
      "transformers/tests/sagemaker/test_single_node_gpu.py": [
        [
          "test_glue",
          61,
          86,
          85,
          14,
          85,
          68,
          82,
          9,
          86,
          117
        ]
      ],
      "transformers/examples/pytorch/test_pytorch_examples.py": [
        [
          "get_results",
          85,
          93,
          89,
          14,
          89,
          23,
          89,
          14,
          93,
          18
        ]
      ],
      "transformers/tests/repo_utils/test_tests_fetcher.py": [
        [
          "create_tmp_repo",
          85,
          168,
          102,
          10,
          102,
          52,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          108,
          10,
          108,
          63,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          110,
          10,
          110,
          58,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          115,
          10,
          115,
          45,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          117,
          10,
          117,
          40,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          119,
          10,
          119,
          44,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          124,
          10,
          124,
          45,
          98,
          62,
          127,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          130,
          14,
          130,
          49,
          127,
          9,
          136,
          34
        ],
        [
          "create_tmp_repo",
          85,
          168,
          132,
          14,
          132,
          63,
          127,
          9,
          136,
          34
        ],
        [
          "create_tmp_repo",
          85,
          168,
          134,
          14,
          134,
          58,
          127,
          9,
          136,
          34
        ],
        [
          "create_tmp_repo",
          85,
          168,
          140,
          10,
          140,
          56,
          138,
          16,
          143,
          46
        ],
        [
          "create_tmp_repo",
          85,
          168,
          147,
          14,
          147,
          68,
          143,
          9,
          150,
          13
        ],
        [
          "create_tmp_repo",
          85,
          168,
          156,
          10,
          156,
          62,
          152,
          19,
          168,
          15
        ],
        [
          "create_tmp_repo",
          85,
          168,
          160,
          10,
          160,
          44,
          152,
          19,
          168,
          15
        ],
        [
          "commit_changes",
          190,
          205,
          201,
          14,
          201,
          41,
          200,
          9,
          202,
          28
        ],
        [
          "test_checkout_commit",
          209,
          224,
          219,
          22,
          219,
          58,
          218,
          17,
          220,
          54
        ],
        [
          "test_checkout_commit",
          209,
          224,
          223,
          18,
          223,
          54,
          222,
          13,
          224,
          64
        ],
        [
          "test_extract_imports_relative",
          291,
          330,
          309,
          18,
          309,
          59,
          307,
          17,
          318,
          83
        ],
        [
          "test_extract_imports_relative",
          291,
          330,
          321,
          18,
          321,
          59,
          318,
          17,
          330,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          337,
          18,
          337,
          59,
          332,
          39,
          346,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          349,
          18,
          349,
          59,
          346,
          17,
          358,
          83
        ],
        [
          "test_extract_imports_absolute",
          332,
          370,
          361,
          18,
          361,
          59,
          358,
          17,
          370,
          83
        ],
        [
          "test_get_module_dependencies",
          372,
          434,
          399,
          18,
          399,
          59,
          392,
          17,
          409,
          96
        ],
        [
          "test_get_module_dependencies",
          372,
          434,
          413,
          18,
          413,
          59,
          409,
          17,
          423,
          96
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          618,
          22,
          618,
          57,
          604,
          33,
          623,
          76
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          620,
          22,
          620,
          64,
          604,
          33,
          623,
          76
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          632,
          18,
          632,
          71,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          638,
          18,
          638,
          53,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          640,
          18,
          640,
          61,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          642,
          18,
          642,
          56,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          649,
          18,
          649,
          60,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          659,
          22,
          659,
          57,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          661,
          22,
          661,
          64,
          624,
          13,
          670,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          675,
          22,
          675,
          57,
          671,
          13,
          682,
          65
        ],
        [
          "test_infer_tests_to_run",
          604,
          683,
          677,
          22,
          677,
          64,
          671,
          13,
          682,
          65
        ],
        [
          "test_infer_tests_to_run_with_test_modifs",
          686,
          703,
          700,
          22,
          700,
          57,
          686,
          50,
          703,
          76
        ],
        [
          "test_infer_tests_to_run_with_examples_modifs",
          706,
          739,
          721,
          22,
          721,
          64,
          706,
          54,
          724,
          86
        ],
        [
          "test_infer_tests_to_run_with_examples_modifs",
          706,
          739,
          736,
          22,
          736,
          64,
          724,
          13,
          739,
          86
        ]
      ],
      "transformers/tests/models/bart/test_tokenization_bart.py": [
        [
          "setUpClass",
          36,
          70,
          69,
          14,
          69,
          57,
          36,
          20,
          70,
          39
        ],
        [
          "setUpClass",
          36,
          70,
          67,
          14,
          67,
          56,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/models/bartpho/test_tokenization_bartpho.py": [
        [
          "setUpClass",
          34,
          47,
          42,
          14,
          42,
          68,
          34,
          20,
          43,
          37
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          349,
          22,
          349,
          78,
          332,
          13,
          354,
          73
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          481,
          18,
          481,
          46,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          485,
          18,
          485,
          49,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          494,
          18,
          494,
          39,
          456,
          40,
          513,
          18
        ],
        [
          "test_init_tokenizer_with_trust",
          456,
          524,
          507,
          18,
          507,
          49,
          456,
          40,
          513,
          18
        ]
      ],
      "transformers/tests/models/bertweet/test_tokenization_bertweet.py": [
        [
          "setUpClass",
          29,
          44,
          40,
          14,
          40,
          56,
          29,
          20,
          41,
          37
        ],
        [
          "setUpClass",
          29,
          44,
          43,
          14,
          43,
          57,
          43,
          14,
          44,
          39
        ]
      ],
      "transformers/tests/models/biogpt/test_tokenization_biogpt.py": [
        [
          "setUpClass",
          33,
          68,
          65,
          14,
          65,
          38,
          33,
          20,
          68,
          39
        ],
        [
          "setUpClass",
          33,
          68,
          67,
          14,
          67,
          39,
          33,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/bert/test_tokenization_bert.py": [
        [
          "setUpClass",
          44,
          66,
          65,
          14,
          65,
          56,
          44,
          20,
          66,
          73
        ]
      ],
      "transformers/tests/models/blenderbot_small/test_tokenization_blenderbot_small.py": [
        [
          "setUpClass",
          35,
          49,
          46,
          14,
          46,
          56,
          35,
          20,
          49,
          39
        ],
        [
          "setUpClass",
          35,
          49,
          48,
          14,
          48,
          57,
          35,
          20,
          49,
          39
        ]
      ],
      "transformers/tests/models/bert_japanese/test_tokenization_bert_japanese.py": [
        [
          "setUpClass",
          44,
          77,
          76,
          14,
          76,
          56,
          44,
          20,
          77,
          73
        ],
        [
          "test_pickle_mecab_tokenizer",
          106,
          124,
          116,
          14,
          116,
          33,
          106,
          37,
          124,
          51
        ],
        [
          "test_pickle_mecab_tokenizer",
          106,
          124,
          119,
          14,
          119,
          33,
          106,
          37,
          124,
          51
        ],
        [
          "test_pickle_sudachi_tokenizer",
          202,
          220,
          212,
          14,
          212,
          33,
          202,
          39,
          220,
          51
        ],
        [
          "test_pickle_sudachi_tokenizer",
          202,
          220,
          215,
          14,
          215,
          33,
          202,
          39,
          220,
          51
        ],
        [
          "test_pickle_jumanpp_tokenizer",
          297,
          315,
          307,
          14,
          307,
          33,
          297,
          39,
          315,
          51
        ],
        [
          "test_pickle_jumanpp_tokenizer",
          297,
          315,
          310,
          14,
          310,
          33,
          297,
          39,
          315,
          51
        ],
        [
          "setUpClass",
          412,
          419,
          418,
          14,
          418,
          56,
          412,
          20,
          419,
          73
        ]
      ],
      "transformers/tests/models/clip/test_tokenization_clip.py": [
        [
          "setUpClass",
          37,
          50,
          49,
          14,
          49,
          57,
          37,
          20,
          50,
          39
        ],
        [
          "setUpClass",
          37,
          50,
          47,
          14,
          47,
          56,
          37,
          20,
          50,
          39
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          212,
          22,
          212,
          93,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          215,
          22,
          215,
          91,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          225,
          22,
          225,
          98,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          227,
          22,
          227,
          96,
          208,
          13,
          255,
          17
        ]
      ],
      "transformers/tests/models/clvp/test_tokenization_clvp.py": [
        [
          "setUpClass",
          34,
          71,
          70,
          14,
          70,
          57,
          34,
          20,
          71,
          39
        ],
        [
          "setUpClass",
          34,
          71,
          68,
          14,
          68,
          56,
          34,
          20,
          71,
          39
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          225,
          22,
          225,
          93,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          228,
          22,
          228,
          91,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          240,
          22,
          240,
          98,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          242,
          22,
          242,
          96,
          221,
          13,
          275,
          17
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_conversion",
          375,
          393,
          382,
          18,
          382,
          62,
          375,
          25,
          393,
          60
        ],
        [
          "test_conversion",
          375,
          393,
          389,
          30,
          389,
          41,
          375,
          25,
          393,
          60
        ],
        [
          "test_conversion",
          375,
          393,
          390,
          18,
          390,
          48,
          375,
          25,
          393,
          60
        ]
      ],
      "transformers/tests/models/cpmant/test_tokenization_cpmant.py": [
        [
          "setUpClass",
          31,
          54,
          53,
          14,
          53,
          56,
          31,
          20,
          54,
          73
        ]
      ],
      "transformers/tests/models/ctrl/test_tokenization_ctrl.py": [
        [
          "setUpClass",
          31,
          45,
          42,
          14,
          42,
          56,
          31,
          20,
          45,
          39
        ],
        [
          "setUpClass",
          31,
          45,
          44,
          14,
          44,
          57,
          31,
          20,
          45,
          39
        ]
      ],
      "transformers/tests/models/deberta/test_tokenization_deberta.py": [
        [
          "setUpClass",
          34,
          69,
          68,
          14,
          68,
          57,
          34,
          20,
          69,
          39
        ],
        [
          "setUpClass",
          34,
          69,
          66,
          14,
          66,
          56,
          34,
          20,
          69,
          39
        ]
      ],
      "transformers/tests/models/codegen/test_tokenization_codegen.py": [
        [
          "setUpClass",
          38,
          74,
          73,
          14,
          73,
          57,
          38,
          20,
          74,
          39
        ],
        [
          "setUpClass",
          38,
          74,
          71,
          14,
          71,
          56,
          38,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/electra/test_tokenization_electra.py": [
        [
          "setUpClass",
          43,
          65,
          64,
          14,
          64,
          56,
          43,
          20,
          65,
          73
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "setUpClass",
          233,
          255,
          252,
          14,
          252,
          82,
          252,
          14,
          255,
          22
        ],
        [
          "test_pickle_tokenizer",
          830,
          849,
          841,
          22,
          841,
          41,
          833,
          13,
          849,
          63
        ],
        [
          "test_pickle_tokenizer",
          830,
          849,
          844,
          22,
          844,
          41,
          833,
          13,
          849,
          63
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1712,
          53,
          1712,
          109,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1719,
          53,
          1719,
          109,
          1719,
          43,
          1728,
          111
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4234,
          22,
          4234,
          82,
          4229,
          13,
          4272,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4239,
          22,
          4239,
          87,
          4229,
          13,
          4272,
          17
        ]
      ],
      "transformers/tests/models/esm/test_tokenization_esm.py": [
        [
          "setUpClass",
          31,
          38,
          37,
          14,
          37,
          56,
          31,
          20,
          38,
          73
        ]
      ],
      "transformers/tests/models/flaubert/test_tokenization_flaubert.py": [
        [
          "setUpClass",
          33,
          47,
          44,
          14,
          44,
          56,
          33,
          20,
          47,
          39
        ],
        [
          "setUpClass",
          33,
          47,
          46,
          14,
          46,
          57,
          33,
          20,
          47,
          39
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_local_versioning",
          211,
          236,
          220,
          39,
          220,
          94,
          211,
          31,
          236,
          77
        ]
      ],
      "transformers/tests/models/funnel/test_tokenization_funnel.py": [
        [
          "setUpClass",
          35,
          55,
          54,
          14,
          54,
          56,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/gpt_neox_japanese/test_tokenization_gpt_neox_japanese.py": [
        [
          "setUpClass",
          37,
          72,
          69,
          14,
          69,
          56,
          37,
          20,
          72,
          56
        ],
        [
          "setUpClass",
          37,
          72,
          71,
          14,
          71,
          38,
          37,
          20,
          72,
          56
        ]
      ],
      "transformers/tests/models/gpt2/test_tokenization_gpt2.py": [
        [
          "setUpClass",
          37,
          73,
          70,
          14,
          70,
          56,
          37,
          20,
          73,
          39
        ],
        [
          "setUpClass",
          37,
          73,
          72,
          14,
          72,
          57,
          37,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/layoutlm/test_tokenization_layoutlm.py": [
        [
          "setUpClass",
          35,
          55,
          54,
          14,
          54,
          56,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/herbert/test_tokenization_herbert.py": [
        [
          "setUpClass",
          36,
          77,
          40,
          14,
          40,
          93,
          36,
          20,
          77,
          39
        ],
        [
          "setUpClass",
          36,
          77,
          74,
          14,
          74,
          38,
          36,
          20,
          77,
          39
        ],
        [
          "setUpClass",
          36,
          77,
          76,
          14,
          76,
          39,
          36,
          20,
          77,
          39
        ]
      ],
      "transformers/tests/models/fsmt/test_tokenization_fsmt.py": [
        [
          "setUpClass",
          37,
          85,
          78,
          14,
          78,
          42,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          80,
          14,
          80,
          42,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          82,
          14,
          82,
          39,
          37,
          20,
          85,
          40
        ],
        [
          "setUpClass",
          37,
          85,
          84,
          14,
          84,
          35,
          37,
          20,
          85,
          40
        ]
      ],
      "transformers/tests/models/led/test_tokenization_led.py": [
        [
          "setUpClass",
          34,
          68,
          65,
          14,
          65,
          56,
          34,
          20,
          68,
          39
        ],
        [
          "setUpClass",
          34,
          68,
          67,
          14,
          67,
          57,
          34,
          20,
          68,
          39
        ]
      ],
      "transformers/tests/models/gemma/test_tokenization_gemma.py": [
        [
          "test_conversion",
          236,
          254,
          243,
          18,
          243,
          62,
          236,
          25,
          254,
          60
        ],
        [
          "test_conversion",
          236,
          254,
          250,
          30,
          250,
          41,
          236,
          25,
          254,
          60
        ],
        [
          "test_conversion",
          236,
          254,
          251,
          18,
          251,
          48,
          236,
          25,
          254,
          60
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_conversion",
          413,
          431,
          420,
          18,
          420,
          62,
          413,
          25,
          431,
          60
        ],
        [
          "test_conversion",
          413,
          431,
          427,
          30,
          427,
          41,
          413,
          25,
          431,
          60
        ],
        [
          "test_conversion",
          413,
          431,
          428,
          18,
          428,
          48,
          413,
          25,
          431,
          60
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "setUpClass",
          128,
          163,
          160,
          14,
          160,
          56,
          128,
          20,
          163,
          39
        ],
        [
          "setUpClass",
          128,
          163,
          162,
          14,
          162,
          57,
          128,
          20,
          163,
          39
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py": [
        [
          "setUpClass",
          136,
          158,
          157,
          14,
          157,
          56,
          136,
          20,
          158,
          73
        ]
      ],
      "transformers/tests/models/longformer/test_tokenization_longformer.py": [
        [
          "setUpClass",
          39,
          74,
          73,
          14,
          73,
          57,
          39,
          20,
          74,
          39
        ],
        [
          "setUpClass",
          39,
          74,
          71,
          14,
          71,
          56,
          39,
          20,
          74,
          39
        ]
      ],
      "transformers/tests/models/lxmert/test_tokenization_lxmert.py": [
        [
          "setUpClass",
          35,
          55,
          54,
          14,
          54,
          56,
          35,
          20,
          55,
          73
        ]
      ],
      "transformers/tests/models/mgp_str/test_tokenization_mgp_str.py": [
        [
          "setUpClass",
          36,
          44,
          43,
          14,
          43,
          56,
          36,
          20,
          44,
          53
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "setUpClass",
          52,
          71,
          68,
          14,
          68,
          57,
          52,
          20,
          71,
          62
        ],
        [
          "setUpClass",
          52,
          71,
          66,
          14,
          66,
          56,
          52,
          20,
          71,
          62
        ],
        [
          "setUpClass",
          52,
          71,
          70,
          14,
          70,
          67,
          52,
          20,
          71,
          62
        ]
      ],
      "transformers/tests/models/mobilebert/test_tokenization_mobilebert.py": [
        [
          "setUpClass",
          44,
          71,
          65,
          14,
          65,
          56,
          44,
          20,
          68,
          27
        ]
      ],
      "transformers/tests/models/mpnet/test_tokenization_mpnet.py": [
        [
          "setUpClass",
          35,
          57,
          56,
          14,
          56,
          56,
          35,
          20,
          57,
          73
        ]
      ],
      "transformers/tests/models/mvp/test_tokenization_mvp.py": [
        [
          "setUpClass",
          36,
          70,
          69,
          14,
          69,
          57,
          36,
          20,
          70,
          39
        ],
        [
          "setUpClass",
          36,
          70,
          67,
          14,
          67,
          56,
          36,
          20,
          70,
          39
        ]
      ],
      "transformers/tests/models/openai/test_tokenization_openai.py": [
        [
          "setUpClass",
          38,
          73,
          70,
          14,
          70,
          38,
          38,
          20,
          73,
          39
        ],
        [
          "setUpClass",
          38,
          73,
          72,
          14,
          72,
          39,
          38,
          20,
          73,
          39
        ]
      ],
      "transformers/tests/models/phobert/test_tokenization_phobert.py": [
        [
          "setUpClass",
          29,
          45,
          44,
          14,
          44,
          57,
          44,
          14,
          45,
          39
        ],
        [
          "setUpClass",
          29,
          45,
          41,
          14,
          41,
          56,
          29,
          20,
          42,
          37
        ]
      ],
      "transformers/tests/models/prophetnet/test_tokenization_prophetnet.py": [
        [
          "setUpClass",
          39,
          61,
          60,
          14,
          60,
          56,
          39,
          20,
          61,
          73
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          208,
          22,
          208,
          93,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          211,
          22,
          211,
          91,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          223,
          22,
          223,
          98,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          225,
          22,
          225,
          96,
          204,
          13,
          257,
          17
        ]
      ],
      "transformers/tests/models/pop2piano/test_tokenization_pop2piano.py": [
        [
          "test_pickle_tokenizer",
          227,
          242,
          234,
          14,
          234,
          33,
          227,
          31,
          242,
          55
        ],
        [
          "test_pickle_tokenizer",
          227,
          242,
          237,
          14,
          237,
          33,
          227,
          31,
          242,
          55
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "setUp",
          38,
          100,
          63,
          14,
          63,
          57,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          97,
          14,
          97,
          57,
          38,
          15,
          100,
          39
        ],
        [
          "setUp",
          38,
          100,
          99,
          14,
          99,
          58,
          38,
          15,
          100,
          39
        ]
      ],
      "transformers/tests/models/qwen2/test_tokenization_qwen2.py": [
        [
          "setUpClass",
          40,
          92,
          89,
          14,
          89,
          56,
          40,
          20,
          92,
          39
        ],
        [
          "setUpClass",
          40,
          92,
          91,
          14,
          91,
          57,
          40,
          20,
          92,
          39
        ]
      ],
      "transformers/tests/models/roberta/test_tokenization_roberta.py": [
        [
          "setUpClass",
          37,
          72,
          69,
          14,
          69,
          56,
          37,
          20,
          72,
          39
        ],
        [
          "setUpClass",
          37,
          72,
          71,
          14,
          71,
          57,
          37,
          20,
          72,
          39
        ]
      ],
      "transformers/tests/models/roc_bert/test_tokenization_roc_bert.py": [
        [
          "setUpClass",
          44,
          61,
          56,
          14,
          56,
          56,
          53,
          26,
          61,
          88
        ],
        [
          "setUpClass",
          44,
          61,
          60,
          14,
          60,
          69,
          53,
          26,
          61,
          88
        ],
        [
          "setUpClass",
          44,
          61,
          58,
          14,
          58,
          61,
          53,
          26,
          61,
          88
        ]
      ],
      "transformers/tests/models/siglip/test_tokenization_siglip.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          255,
          22,
          255,
          93,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          258,
          22,
          258,
          91,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          270,
          22,
          270,
          98,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          272,
          22,
          272,
          96,
          251,
          13,
          305,
          17
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          103,
          18,
          103,
          45,
          102,
          9,
          103,
          45
        ],
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          90,
          18,
          90,
          37,
          89,
          13,
          90,
          37
        ],
        [
          "test_push_to_hub",
          122,
          132,
          126,
          22,
          126,
          60,
          122,
          26,
          132,
          70
        ],
        [
          "test_push_to_hub_via_save_pretrained",
          134,
          146,
          138,
          22,
          138,
          60,
          134,
          46,
          146,
          70
        ],
        [
          "test_push_to_hub_in_organization",
          148,
          158,
          152,
          22,
          152,
          60,
          148,
          42,
          158,
          70
        ],
        [
          "test_push_to_hub_in_organization_via_save_pretrained",
          160,
          172,
          164,
          22,
          164,
          60,
          160,
          62,
          172,
          70
        ],
        [
          "test_push_to_hub_dynamic_tokenizer",
          175,
          189,
          180,
          22,
          180,
          60,
          175,
          44,
          189,
          77
        ],
        [
          "test_push_to_hub_dynamic_tokenizer_with_both_slow_and_fast_classes",
          192,
          215,
          201,
          22,
          201,
          60,
          192,
          76,
          215,
          77
        ]
      ],
      "transformers/tests/models/vits/test_tokenization_vits.py": [
        [
          "setUpClass",
          35,
          52,
          51,
          14,
          51,
          56,
          35,
          20,
          52,
          53
        ]
      ],
      "transformers/tests/models/t5/test_tokenization_t5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          306,
          22,
          306,
          93,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          309,
          22,
          309,
          91,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          321,
          22,
          321,
          98,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          323,
          22,
          323,
          96,
          302,
          13,
          356,
          17
        ]
      ],
      "transformers/tests/models/wav2vec2_phoneme/test_tokenization_wav2vec2_phoneme.py": [
        [
          "setUpClass",
          35,
          59,
          58,
          14,
          58,
          56,
          35,
          20,
          59,
          53
        ]
      ],
      "transformers/tests/models/tapas/test_tokenization_tapas.py": [
        [
          "setUpClass",
          113,
          135,
          134,
          14,
          134,
          56,
          113,
          20,
          135,
          73
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "setUpClass",
          60,
          71,
          70,
          14,
          70,
          56,
          60,
          20,
          71,
          53
        ],
        [
          "setUpClass",
          379,
          390,
          389,
          14,
          389,
          56,
          379,
          20,
          390,
          53
        ],
        [
          "test_special_characters_in_vocab",
          478,
          496,
          484,
          14,
          484,
          34,
          478,
          42,
          496,
          45
        ],
        [
          "test_nested_vocab",
          789,
          832,
          819,
          18,
          819,
          41,
          789,
          27,
          832,
          60
        ]
      ],
      "transformers/tests/models/xlm/test_tokenization_xlm.py": [
        [
          "setUpClass",
          32,
          67,
          64,
          14,
          64,
          38,
          32,
          20,
          67,
          39
        ],
        [
          "setUpClass",
          32,
          67,
          66,
          14,
          66,
          39,
          32,
          20,
          67,
          39
        ]
      ],
      "transformers/tests/trainer/test_trainer_distributed_loss.py": [
        [
          "test_trainer",
          29,
          61,
          45,
          14,
          45,
          51,
          45,
          14,
          61,
          45
        ],
        [
          "test_trainer",
          29,
          61,
          47,
          14,
          47,
          53,
          45,
          14,
          61,
          45
        ],
        [
          "test_trainer",
          29,
          61,
          49,
          14,
          49,
          52,
          45,
          14,
          61,
          45
        ],
        [
          "run_distributed_training",
          64,
          101,
          100,
          10,
          100,
          61,
          64,
          30,
          101,
          42
        ]
      ],
      "transformers/tests/models/auto/test_video_processing_auto.py": [
        [
          "test_video_processor_from_local_directory_from_key",
          49,
          63,
          58,
          17,
          58,
          44,
          49,
          60,
          63,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_key",
          49,
          63,
          60,
          58,
          60,
          82,
          49,
          60,
          63,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_preprocessor_key",
          65,
          80,
          75,
          17,
          75,
          44,
          65,
          73,
          80,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_preprocessor_key",
          65,
          80,
          77,
          58,
          77,
          82,
          65,
          73,
          80,
          71
        ],
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          94,
          17,
          94,
          44,
          82,
          63,
          114,
          67
        ],
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          96,
          58,
          96,
          82,
          82,
          63,
          114,
          67
        ],
        [
          "test_video_processor_from_local_file",
          116,
          128,
          124,
          17,
          124,
          44,
          116,
          46,
          128,
          71
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          193,
          21,
          193,
          48,
          190,
          25,
          193,
          48
        ],
        [
          "test_new_video_processor_registration",
          177,
          209,
          195,
          62,
          195,
          86,
          195,
          28,
          195,
          86
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          723,
          14,
          723,
          52,
          712,
          22,
          727,
          60
        ],
        [
          "test_accelerator_config_from_yaml",
          4532,
          4555,
          4537,
          18,
          4537,
          37,
          4532,
          43,
          4555,
          77
        ]
      ],
      "transformers/tests/generation/test_utils.py": [
        [
          "test_custom_generate_local_directory",
          4625,
          4644,
          4630,
          18,
          4630,
          63,
          4625,
          46,
          4644,
          37
        ],
        [
          "test_custom_generate_local_directory",
          4625,
          4644,
          4632,
          18,
          4632,
          61,
          4625,
          46,
          4644,
          37
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "diff_is_docstring_only",
          185,
          208,
          199,
          14,
          199,
          59,
          185,
          28,
          208,
          49
        ],
        [
          "diff_is_docstring_only",
          185,
          208,
          202,
          10,
          202,
          55,
          185,
          28,
          208,
          49
        ],
        [
          "diff_contains_doc_examples",
          211,
          234,
          225,
          14,
          225,
          59,
          211,
          32,
          234,
          49
        ],
        [
          "diff_contains_doc_examples",
          211,
          234,
          228,
          10,
          228,
          55,
          211,
          32,
          234,
          49
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          270,
          18,
          270,
          92,
          268,
          9,
          287,
          30
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          273,
          14,
          273,
          88,
          268,
          9,
          287,
          30
        ],
        [
          "get_all_doctest_files",
          429,
          459,
          453,
          10,
          453,
          40,
          430,
          5,
          459,
          36
        ],
        [
          "get_new_doctest_files",
          462,
          486,
          477,
          18,
          477,
          80,
          475,
          18,
          485,
          38
        ],
        [
          "get_new_doctest_files",
          462,
          486,
          479,
          14,
          479,
          76,
          475,
          18,
          485,
          38
        ],
        [
          "get_doctest_files",
          489,
          534,
          525,
          10,
          525,
          51,
          518,
          29,
          534,
          36
        ],
        [
          "extract_imports",
          558,
          637,
          577,
          10,
          577,
          65,
          577,
          10,
          597,
          43
        ],
        [
          "init_test_examples_dependencies",
          798,
          827,
          819,
          14,
          819,
          51,
          818,
          9,
          826,
          116
        ],
        [
          "infer_tests_to_run",
          956,
          1038,
          1037,
          14,
          1037,
          54,
          1036,
          24,
          1038,
          43
        ],
        [
          "filter_tests",
          1041,
          1065,
          1052,
          10,
          1052,
          49,
          1052,
          10,
          1055,
          27
        ],
        [
          "filter_tests",
          1041,
          1065,
          1064,
          10,
          1064,
          49,
          1064,
          10,
          1065,
          37
        ],
        [
          "create_test_list_from_filter",
          1109,
          1121,
          1120,
          18,
          1120,
          37,
          1120,
          18,
          1121,
          49
        ]
      ],
      "transformers/src/transformers/models/albert/tokenization_albert.py": [
        [
          "save_vocabulary",
          302,
          317,
          313,
          18,
          313,
          43,
          313,
          18,
          315,
          46
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "__init__",
          155,
          207,
          180,
          14,
          180,
          47,
          178,
          22,
          207,
          9
        ],
        [
          "__init__",
          155,
          207,
          186,
          14,
          186,
          48,
          178,
          22,
          207,
          9
        ],
        [
          "save_vocabulary",
          282,
          309,
          293,
          14,
          293,
          52,
          290,
          30,
          299,
          95
        ],
        [
          "save_vocabulary",
          282,
          309,
          297,
          14,
          297,
          52,
          290,
          30,
          299,
          95
        ]
      ],
      "transformers/src/transformers/models/barthez/tokenization_barthez.py": [
        [
          "save_vocabulary",
          273,
          288,
          284,
          18,
          284,
          43,
          284,
          18,
          286,
          46
        ]
      ],
      "transformers/src/transformers/models/bartpho/tokenization_bartpho.py": [
        [
          "__init__",
          109,
          161,
          142,
          14,
          142,
          64,
          142,
          14,
          143,
          37
        ],
        [
          "save_vocabulary",
          286,
          315,
          301,
          18,
          301,
          43,
          301,
          18,
          303,
          46
        ],
        [
          "save_vocabulary",
          286,
          315,
          310,
          18,
          310,
          72,
          310,
          18,
          311,
          55
        ]
      ],
      "transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py": [
        [
          "save_vocabulary",
          159,
          174,
          170,
          18,
          170,
          43,
          170,
          18,
          172,
          46
        ]
      ],
      "transformers/src/transformers/models/bert/tokenization_bert.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          239,
          257,
          247,
          14,
          247,
          52,
          247,
          14,
          248,
          86
        ]
      ],
      "transformers/src/transformers/models/bert_japanese/tokenization_bert_japanese.py": [
        [
          "load_vocab",
          40,
          48,
          43,
          10,
          43,
          48,
          40,
          16,
          45,
          41
        ],
        [
          "save_vocabulary",
          312,
          342,
          327,
          18,
          327,
          39,
          327,
          18,
          329,
          50
        ],
        [
          "save_vocabulary",
          312,
          342,
          331,
          18,
          331,
          56,
          331,
          18,
          333,
          90
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "save_vocabulary",
          233,
          248,
          244,
          18,
          244,
          43,
          244,
          18,
          246,
          46
        ]
      ],
      "transformers/src/transformers/models/biogpt/tokenization_biogpt.py": [
        [
          "__init__",
          92,
          134,
          118,
          14,
          118,
          47,
          104,
          20,
          134,
          9
        ],
        [
          "__init__",
          92,
          134,
          121,
          14,
          121,
          48,
          104,
          20,
          134,
          9
        ],
        [
          "save_vocabulary",
          284,
          310,
          295,
          14,
          295,
          52,
          292,
          30,
          300,
          95
        ],
        [
          "save_vocabulary",
          284,
          310,
          299,
          14,
          299,
          52,
          292,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/auto/tokenization_auto.py": [
        [
          "get_tokenizer_config",
          821,
          924,
          921,
          10,
          921,
          53,
          919,
          19,
          924,
          17
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "__init__",
          107,
          165,
          145,
          14,
          145,
          48,
          132,
          27,
          165,
          9
        ],
        [
          "save_vocabulary",
          373,
          394,
          387,
          18,
          387,
          43,
          387,
          18,
          389,
          46
        ],
        [
          "add_from_file",
          402,
          423,
          408,
          22,
          408,
          51,
          407,
          13,
          408,
          51
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2286,
          14,
          2286,
          49,
          2285,
          9,
          2289,
          42
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2316,
          10,
          2316,
          49,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2321,
          10,
          2321,
          50,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2326,
          10,
          2326,
          49,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2330,
          10,
          2330,
          42,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2334,
          10,
          2334,
          44,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2348,
          10,
          2348,
          49,
          2295,
          5,
          2359,
          25
        ],
        [
          "pytest_terminal_summary_main",
          2229,
          2359,
          2352,
          10,
          2352,
          41,
          2295,
          5,
          2359,
          25
        ],
        [
          "check_json_file_has_correct_format",
          2496,
          2510,
          2497,
          10,
          2497,
          24,
          2496,
          40,
          2499,
          26
        ],
        [
          "_get_test_info",
          3345,
          3459,
          3432,
          10,
          3432,
          31,
          3424,
          19,
          3459,
          5
        ],
        [
          "_get_test_info",
          3345,
          3459,
          3438,
          10,
          3438,
          26,
          3424,
          19,
          3459,
          5
        ],
        [
          "_prepare_debugging_info",
          3522,
          3531,
          3528,
          10,
          3528,
          21,
          3522,
          29,
          3531,
          15
        ]
      ],
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "__init__",
          81,
          99,
          91,
          14,
          91,
          47,
          82,
          9,
          99,
          118
        ],
        [
          "__init__",
          81,
          99,
          94,
          14,
          94,
          48,
          82,
          9,
          99,
          118
        ],
        [
          "save_vocabulary",
          192,
          219,
          203,
          14,
          203,
          52,
          200,
          30,
          209,
          95
        ],
        [
          "save_vocabulary",
          192,
          219,
          207,
          14,
          207,
          52,
          200,
          30,
          209,
          95
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "__init__",
          162,
          220,
          193,
          14,
          193,
          47,
          186,
          13,
          220,
          9
        ],
        [
          "__init__",
          162,
          220,
          199,
          14,
          199,
          48,
          186,
          13,
          220,
          9
        ],
        [
          "save_vocabulary",
          305,
          332,
          316,
          14,
          316,
          52,
          313,
          30,
          322,
          95
        ],
        [
          "save_vocabulary",
          305,
          332,
          320,
          14,
          320,
          52,
          313,
          30,
          322,
          95
        ]
      ],
      "transformers/src/transformers/models/camembert/tokenization_camembert.py": [
        [
          "save_vocabulary",
          229,
          244,
          240,
          18,
          240,
          43,
          240,
          18,
          242,
          46
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "__init__",
          283,
          330,
          306,
          14,
          306,
          47,
          306,
          14,
          330,
          9
        ],
        [
          "__init__",
          283,
          330,
          312,
          14,
          312,
          48,
          306,
          14,
          330,
          9
        ],
        [
          "save_vocabulary",
          489,
          516,
          500,
          14,
          500,
          52,
          497,
          30,
          506,
          95
        ],
        [
          "save_vocabulary",
          489,
          516,
          504,
          14,
          504,
          52,
          497,
          30,
          506,
          95
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "__init__",
          140,
          189,
          163,
          14,
          163,
          47,
          157,
          21,
          189,
          9
        ],
        [
          "__init__",
          140,
          189,
          169,
          14,
          169,
          48,
          157,
          21,
          189,
          9
        ],
        [
          "save_vocabulary",
          337,
          364,
          348,
          14,
          348,
          52,
          345,
          30,
          354,
          95
        ],
        [
          "save_vocabulary",
          337,
          364,
          352,
          14,
          352,
          52,
          345,
          30,
          354,
          95
        ]
      ],
      "transformers/src/transformers/models/code_llama/tokenization_code_llama.py": [
        [
          "get_spm_processor",
          186,
          197,
          188,
          14,
          188,
          40,
          186,
          27,
          197,
          24
        ],
        [
          "save_vocabulary",
          331,
          356,
          352,
          18,
          352,
          43,
          352,
          18,
          354,
          46
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "__init__",
          140,
          188,
          163,
          14,
          163,
          47,
          163,
          14,
          188,
          9
        ],
        [
          "__init__",
          140,
          188,
          169,
          14,
          169,
          48,
          163,
          14,
          188,
          9
        ],
        [
          "save_vocabulary",
          276,
          303,
          287,
          14,
          287,
          52,
          284,
          30,
          293,
          95
        ],
        [
          "save_vocabulary",
          276,
          303,
          291,
          14,
          291,
          52,
          284,
          30,
          293,
          95
        ]
      ],
      "transformers/src/transformers/models/convbert/tokenization_convbert.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          242,
          260,
          250,
          14,
          250,
          52,
          250,
          14,
          251,
          86
        ]
      ],
      "transformers/src/transformers/models/cpm/tokenization_cpm.py": [
        [
          "save_vocabulary",
          327,
          342,
          338,
          18,
          338,
          43,
          338,
          18,
          340,
          46
        ]
      ],
      "transformers/src/transformers/models/cpmant/tokenization_cpmant.py": [
        [
          "load_vocab",
          36,
          44,
          39,
          10,
          39,
          48,
          36,
          16,
          41,
          41
        ],
        [
          "save_vocabulary",
          198,
          223,
          213,
          14,
          213,
          52,
          212,
          24,
          214,
          58
        ]
      ],
      "transformers/src/transformers/models/ctrl/tokenization_ctrl.py": [
        [
          "__init__",
          130,
          139,
          134,
          14,
          134,
          48,
          130,
          18,
          139,
          55
        ],
        [
          "__init__",
          130,
          139,
          131,
          14,
          131,
          47,
          130,
          18,
          139,
          55
        ],
        [
          "save_vocabulary",
          215,
          242,
          226,
          14,
          226,
          52,
          223,
          30,
          232,
          95
        ],
        [
          "save_vocabulary",
          215,
          242,
          230,
          14,
          230,
          52,
          223,
          30,
          232,
          95
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "__init__",
          140,
          195,
          167,
          14,
          167,
          47,
          164,
          22,
          195,
          9
        ],
        [
          "__init__",
          140,
          195,
          173,
          14,
          173,
          48,
          164,
          22,
          195,
          9
        ],
        [
          "save_vocabulary",
          330,
          357,
          341,
          14,
          341,
          52,
          338,
          30,
          347,
          95
        ],
        [
          "save_vocabulary",
          330,
          357,
          345,
          14,
          345,
          52,
          338,
          30,
          347,
          95
        ]
      ],
      "transformers/src/transformers/models/deberta_v2/tokenization_deberta_v2.py": [
        [
          "save_pretrained",
          440,
          447,
          445,
          14,
          445,
          34,
          444,
          21,
          447,
          27
        ]
      ],
      "transformers/src/transformers/models/distilbert/tokenization_distilbert.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          251,
          269,
          259,
          14,
          259,
          52,
          259,
          14,
          260,
          86
        ]
      ],
      "transformers/src/transformers/models/electra/tokenization_electra.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          241,
          259,
          249,
          14,
          249,
          52,
          249,
          14,
          250,
          86
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": [
        [
          "__init__",
          55,
          85,
          67,
          14,
          67,
          47,
          56,
          9,
          85,
          32
        ],
        [
          "save_vocabulary",
          146,
          167,
          164,
          14,
          164,
          52,
          161,
          30,
          167,
          28
        ]
      ],
      "transformers/src/transformers/models/deprecated/ernie_m/tokenization_ernie_m.py": [
        [
          "load_vocab",
          373,
          380,
          375,
          14,
          375,
          50,
          373,
          20,
          376,
          43
        ],
        [
          "save_vocabulary",
          382,
          406,
          390,
          14,
          390,
          52,
          390,
          14,
          391,
          86
        ],
        [
          "save_vocabulary",
          382,
          406,
          402,
          14,
          402,
          45,
          401,
          32,
          406,
          28
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "save_vocabulary",
          489,
          515,
          500,
          14,
          500,
          52,
          497,
          30,
          505,
          95
        ],
        [
          "save_vocabulary",
          489,
          515,
          504,
          14,
          504,
          52,
          497,
          30,
          505,
          95
        ],
        [
          "__init__",
          178,
          260,
          239,
          14,
          239,
          47,
          236,
          34,
          260,
          9
        ],
        [
          "__init__",
          178,
          260,
          242,
          14,
          242,
          48,
          236,
          34,
          260,
          9
        ]
      ],
      "transformers/src/transformers/models/fnet/tokenization_fnet.py": [
        [
          "save_vocabulary",
          296,
          311,
          307,
          18,
          307,
          43,
          307,
          18,
          309,
          46
        ]
      ],
      "transformers/src/transformers/models/esm/tokenization_esm.py": [
        [
          "load_vocab_file",
          29,
          32,
          30,
          10,
          30,
          30,
          29,
          21,
          32,
          41
        ],
        [
          "save_vocabulary",
          136,
          140,
          138,
          14,
          138,
          34,
          137,
          52,
          140,
          28
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "__init__",
          163,
          227,
          206,
          14,
          206,
          51,
          198,
          44,
          227,
          9
        ],
        [
          "__init__",
          163,
          227,
          208,
          14,
          208,
          51,
          198,
          44,
          227,
          9
        ],
        [
          "__init__",
          163,
          227,
          211,
          14,
          211,
          48,
          198,
          44,
          227,
          9
        ],
        [
          "save_vocabulary",
          433,
          467,
          448,
          14,
          448,
          56,
          445,
          30,
          457,
          95
        ],
        [
          "save_vocabulary",
          433,
          467,
          451,
          14,
          451,
          56,
          445,
          30,
          457,
          95
        ],
        [
          "save_vocabulary",
          433,
          467,
          456,
          14,
          456,
          53,
          445,
          30,
          457,
          95
        ]
      ],
      "transformers/src/transformers/models/funnel/tokenization_funnel.py": [
        [
          "load_vocab",
          45,
          53,
          48,
          10,
          48,
          48,
          45,
          16,
          50,
          41
        ],
        [
          "save_vocabulary",
          301,
          319,
          309,
          14,
          309,
          52,
          309,
          14,
          310,
          86
        ]
      ],
      "transformers/src/transformers/models/gemma/tokenization_gemma.py": [
        [
          "save_vocabulary",
          197,
          222,
          218,
          18,
          218,
          43,
          218,
          18,
          220,
          46
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "save_vocabulary",
          298,
          325,
          309,
          14,
          309,
          52,
          306,
          30,
          315,
          95
        ],
        [
          "__init__",
          133,
          178,
          153,
          14,
          153,
          47,
          149,
          21,
          178,
          9
        ],
        [
          "__init__",
          133,
          178,
          159,
          14,
          159,
          48,
          149,
          21,
          178,
          9
        ],
        [
          "save_vocabulary",
          298,
          325,
          313,
          14,
          313,
          52,
          306,
          30,
          315,
          95
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "save_vocabulary",
          236,
          251,
          247,
          18,
          247,
          43,
          247,
          18,
          249,
          46
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "load_vocab_and_emoji",
          35,
          52,
          43,
          10,
          43,
          48,
          35,
          26,
          46,
          34
        ],
        [
          "load_vocab_and_emoji",
          35,
          52,
          37,
          10,
          37,
          48,
          35,
          26,
          46,
          34
        ],
        [
          "save_vocabulary",
          165,
          193,
          181,
          14,
          181,
          52,
          181,
          14,
          182,
          64
        ],
        [
          "save_vocabulary",
          165,
          193,
          191,
          14,
          191,
          52,
          191,
          14,
          193,
          37
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "save_vocabulary",
          240,
          268,
          266,
          14,
          266,
          52,
          266,
          14,
          268,
          37
        ],
        [
          "load_vocab_and_emoji",
          43,
          60,
          45,
          10,
          45,
          48,
          43,
          26,
          54,
          34
        ],
        [
          "load_vocab_and_emoji",
          43,
          60,
          51,
          10,
          51,
          48,
          43,
          26,
          54,
          34
        ],
        [
          "save_vocabulary",
          240,
          268,
          256,
          14,
          256,
          52,
          256,
          14,
          257,
          64
        ]
      ],
      "transformers/src/transformers/models/layoutlm/tokenization_layoutlm.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          242,
          260,
          250,
          14,
          250,
          52,
          250,
          14,
          251,
          86
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "__init__",
          294,
          376,
          347,
          14,
          347,
          47,
          344,
          34,
          371,
          31
        ],
        [
          "__init__",
          294,
          376,
          350,
          14,
          350,
          48,
          344,
          34,
          371,
          31
        ],
        [
          "save_vocabulary",
          568,
          594,
          579,
          14,
          579,
          52,
          576,
          30,
          584,
          95
        ],
        [
          "save_vocabulary",
          568,
          594,
          583,
          14,
          583,
          52,
          576,
          30,
          584,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "__init__",
          100,
          141,
          123,
          14,
          123,
          48,
          111,
          21,
          128,
          41
        ],
        [
          "__init__",
          100,
          141,
          117,
          14,
          117,
          49,
          111,
          21,
          128,
          41
        ],
        [
          "__init__",
          100,
          141,
          120,
          14,
          120,
          48,
          111,
          21,
          128,
          41
        ],
        [
          "save_vocabulary",
          336,
          370,
          355,
          14,
          355,
          54,
          353,
          30,
          359,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          361,
          14,
          361,
          53,
          359,
          30,
          365,
          69
        ],
        [
          "save_vocabulary",
          336,
          370,
          367,
          14,
          367,
          53,
          365,
          30,
          370,
          55
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py": [
        [
          "load_vocab",
          146,
          154,
          149,
          10,
          149,
          48,
          146,
          16,
          151,
          41
        ],
        [
          "save_vocabulary",
          360,
          378,
          368,
          14,
          368,
          52,
          368,
          14,
          369,
          86
        ]
      ],
      "transformers/src/transformers/models/layoutxlm/tokenization_layoutxlm.py": [
        [
          "save_vocabulary",
          421,
          436,
          432,
          18,
          432,
          43,
          432,
          18,
          434,
          46
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "__init__",
          257,
          326,
          287,
          14,
          287,
          47,
          285,
          22,
          326,
          9
        ],
        [
          "__init__",
          257,
          326,
          293,
          14,
          293,
          48,
          285,
          22,
          326,
          9
        ],
        [
          "save_vocabulary",
          411,
          438,
          422,
          14,
          422,
          52,
          419,
          30,
          428,
          95
        ],
        [
          "save_vocabulary",
          411,
          438,
          426,
          14,
          426,
          52,
          419,
          30,
          428,
          95
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "__init__",
          160,
          212,
          185,
          14,
          185,
          47,
          183,
          22,
          212,
          9
        ],
        [
          "__init__",
          160,
          212,
          191,
          14,
          191,
          48,
          183,
          22,
          212,
          9
        ],
        [
          "save_vocabulary",
          295,
          322,
          306,
          14,
          306,
          52,
          303,
          30,
          312,
          95
        ],
        [
          "save_vocabulary",
          295,
          322,
          310,
          14,
          310,
          52,
          303,
          30,
          312,
          95
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "__init__",
          156,
          214,
          193,
          14,
          193,
          48,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          306,
          14,
          306,
          52,
          299,
          30,
          308,
          95
        ],
        [
          "__init__",
          156,
          214,
          187,
          14,
          187,
          47,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          302,
          14,
          302,
          52,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/lxmert/tokenization_lxmert.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          241,
          259,
          249,
          14,
          249,
          52,
          249,
          14,
          250,
          86
        ]
      ],
      "transformers/src/transformers/models/llama/tokenization_llama.py": [
        [
          "get_spm_processor",
          195,
          210,
          201,
          14,
          201,
          40,
          201,
          14,
          210,
          24
        ],
        [
          "save_vocabulary",
          306,
          331,
          327,
          18,
          327,
          43,
          327,
          18,
          329,
          46
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "save_vocabulary",
          287,
          330,
          325,
          22,
          325,
          46,
          325,
          22,
          328,
          49
        ],
        [
          "save_json",
          386,
          388,
          387,
          10,
          387,
          24,
          386,
          15,
          388,
          36
        ],
        [
          "load_json",
          391,
          393,
          392,
          10,
          392,
          24,
          391,
          15,
          393,
          27
        ]
      ],
      "transformers/src/transformers/models/mbart/tokenization_mbart.py": [
        [
          "save_vocabulary",
          294,
          309,
          305,
          18,
          305,
          43,
          305,
          18,
          307,
          46
        ]
      ],
      "transformers/src/transformers/models/mbart50/tokenization_mbart50.py": [
        [
          "save_vocabulary",
          242,
          257,
          253,
          18,
          253,
          43,
          253,
          18,
          255,
          46
        ]
      ],
      "transformers/src/transformers/models/m2m_100/tokenization_m2m_100.py": [
        [
          "save_vocabulary",
          295,
          315,
          311,
          18,
          311,
          42,
          311,
          18,
          313,
          46
        ],
        [
          "load_json",
          374,
          376,
          375,
          10,
          375,
          24,
          374,
          15,
          376,
          27
        ],
        [
          "save_json",
          379,
          381,
          380,
          10,
          380,
          24,
          379,
          15,
          381,
          36
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "__init__",
          184,
          264,
          215,
          14,
          215,
          47,
          213,
          22,
          264,
          37
        ],
        [
          "__init__",
          184,
          264,
          223,
          14,
          223,
          48,
          213,
          22,
          264,
          37
        ],
        [
          "save_vocabulary",
          369,
          398,
          381,
          14,
          381,
          52,
          377,
          30,
          388,
          95
        ],
        [
          "save_vocabulary",
          369,
          398,
          386,
          14,
          386,
          52,
          377,
          30,
          388,
          95
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "__init__",
          273,
          387,
          308,
          14,
          308,
          47,
          306,
          22,
          328,
          46
        ],
        [
          "__init__",
          273,
          387,
          314,
          14,
          314,
          48,
          306,
          22,
          328,
          46
        ],
        [
          "__init__",
          273,
          387,
          339,
          14,
          339,
          54,
          332,
          13,
          341,
          111
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1702,
          14,
          1702,
          52,
          1699,
          30,
          1708,
          95
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1706,
          14,
          1706,
          52,
          1699,
          30,
          1708,
          95
        ],
        [
          "save_vocabulary",
          1691,
          1725,
          1722,
          14,
          1722,
          59,
          1719,
          30,
          1725,
          56
        ]
      ],
      "transformers/src/transformers/models/mgp_str/tokenization_mgp_str.py": [
        [
          "__init__",
          54,
          64,
          55,
          14,
          55,
          47,
          54,
          18,
          64,
          9
        ],
        [
          "save_vocabulary",
          90,
          101,
          98,
          14,
          98,
          52,
          95,
          30,
          101,
          28
        ]
      ],
      "transformers/src/transformers/models/mobilebert/tokenization_mobilebert.py": [
        [
          "load_vocab",
          33,
          41,
          36,
          10,
          36,
          48,
          33,
          16,
          38,
          41
        ],
        [
          "save_vocabulary",
          243,
          261,
          251,
          14,
          251,
          52,
          251,
          14,
          252,
          86
        ]
      ],
      "transformers/src/transformers/models/mpnet/tokenization_mpnet.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          296,
          314,
          304,
          14,
          304,
          52,
          304,
          14,
          305,
          86
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "__init__",
          221,
          331,
          283,
          14,
          283,
          54,
          262,
          32,
          285,
          111
        ],
        [
          "save_vocabulary",
          1530,
          1553,
          1542,
          18,
          1542,
          43,
          1542,
          18,
          1544,
          46
        ],
        [
          "save_vocabulary",
          1530,
          1553,
          1550,
          14,
          1550,
          59,
          1547,
          30,
          1553,
          48
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "__init__",
          155,
          206,
          179,
          14,
          179,
          47,
          178,
          22,
          206,
          9
        ],
        [
          "__init__",
          155,
          206,
          185,
          14,
          185,
          48,
          178,
          22,
          206,
          9
        ],
        [
          "save_vocabulary",
          283,
          310,
          294,
          14,
          294,
          52,
          291,
          30,
          300,
          95
        ],
        [
          "save_vocabulary",
          283,
          310,
          298,
          14,
          298,
          52,
          291,
          30,
          300,
          95
        ]
      ],
      "transformers/src/transformers/models/myt5/tokenization_myt5.py": [
        [
          "__init__",
          46,
          57,
          48,
          18,
          48,
          43,
          48,
          18,
          49,
          31
        ],
        [
          "__init__",
          165,
          209,
          197,
          36,
          197,
          56,
          190,
          21,
          209,
          9
        ],
        [
          "save_vocabulary",
          368,
          377,
          375,
          14,
          375,
          52,
          375,
          14,
          377,
          28
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "save_vocabulary",
          366,
          393,
          381,
          14,
          381,
          52,
          374,
          30,
          383,
          95
        ],
        [
          "__init__",
          259,
          281,
          272,
          14,
          272,
          47,
          272,
          14,
          281,
          55
        ],
        [
          "__init__",
          259,
          281,
          275,
          14,
          275,
          48,
          272,
          14,
          281,
          55
        ],
        [
          "save_vocabulary",
          366,
          393,
          377,
          14,
          377,
          52,
          374,
          30,
          383,
          95
        ]
      ],
      "transformers/src/transformers/models/nllb/tokenization_nllb.py": [
        [
          "save_vocabulary",
          332,
          347,
          343,
          18,
          343,
          43,
          343,
          18,
          345,
          46
        ]
      ],
      "transformers/src/transformers/models/pegasus/tokenization_pegasus.py": [
        [
          "save_vocabulary",
          274,
          289,
          285,
          18,
          285,
          43,
          285,
          18,
          287,
          46
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "__init__",
          102,
          144,
          128,
          14,
          128,
          48,
          103,
          9,
          144,
          9
        ],
        [
          "save_vocabulary",
          298,
          319,
          312,
          18,
          312,
          43,
          312,
          18,
          314,
          46
        ],
        [
          "add_from_file",
          327,
          348,
          333,
          22,
          333,
          51,
          332,
          13,
          333,
          51
        ]
      ],
      "transformers/src/transformers/models/plbart/tokenization_plbart.py": [
        [
          "save_vocabulary",
          370,
          385,
          381,
          18,
          381,
          43,
          381,
          18,
          383,
          46
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "__init__",
          137,
          208,
          172,
          14,
          172,
          47,
          167,
          13,
          180,
          51
        ],
        [
          "__init__",
          137,
          208,
          179,
          14,
          179,
          48,
          167,
          13,
          180,
          51
        ],
        [
          "save_vocabulary",
          308,
          335,
          319,
          14,
          319,
          52,
          316,
          30,
          325,
          95
        ],
        [
          "save_vocabulary",
          308,
          335,
          323,
          14,
          323,
          52,
          316,
          30,
          325,
          95
        ]
      ],
      "transformers/src/transformers/models/prophetnet/tokenization_prophetnet.py": [
        [
          "load_vocab",
          261,
          269,
          264,
          10,
          264,
          48,
          261,
          16,
          266,
          41
        ],
        [
          "save_vocabulary",
          435,
          453,
          443,
          14,
          443,
          52,
          443,
          14,
          444,
          86
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/tokenization_realm.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          307,
          325,
          315,
          14,
          315,
          52,
          315,
          14,
          316,
          86
        ]
      ],
      "transformers/src/transformers/models/pop2piano/tokenization_pop2piano.py": [
        [
          "__init__",
          93,
          125,
          113,
          14,
          113,
          30,
          107,
          21,
          125,
          9
        ],
        [
          "save_vocabulary",
          344,
          365,
          362,
          14,
          362,
          38,
          360,
          30,
          365,
          32
        ]
      ],
      "transformers/src/transformers/models/reformer/tokenization_reformer.py": [
        [
          "save_vocabulary",
          158,
          173,
          169,
          18,
          169,
          43,
          169,
          18,
          171,
          46
        ]
      ],
      "transformers/src/transformers/models/rembert/tokenization_rembert.py": [
        [
          "save_vocabulary",
          219,
          234,
          230,
          18,
          230,
          43,
          230,
          18,
          232,
          46
        ]
      ],
      "transformers/src/transformers/models/deprecated/retribert/tokenization_retribert.py": [
        [
          "load_vocab",
          31,
          39,
          34,
          10,
          34,
          48,
          31,
          16,
          36,
          41
        ],
        [
          "save_vocabulary",
          236,
          254,
          244,
          14,
          244,
          52,
          244,
          14,
          245,
          86
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "__init__",
          156,
          214,
          193,
          14,
          193,
          48,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          306,
          14,
          306,
          52,
          299,
          30,
          308,
          95
        ],
        [
          "__init__",
          156,
          214,
          187,
          14,
          187,
          47,
          180,
          13,
          214,
          9
        ],
        [
          "save_vocabulary",
          291,
          318,
          302,
          14,
          302,
          52,
          299,
          30,
          308,
          95
        ]
      ],
      "transformers/src/transformers/models/roformer/tokenization_roformer.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          490,
          508,
          498,
          14,
          498,
          52,
          498,
          14,
          499,
          86
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "get_spm_processor",
          139,
          150,
          141,
          14,
          141,
          40,
          139,
          27,
          150,
          24
        ],
        [
          "save_vocabulary",
          362,
          377,
          373,
          18,
          373,
          43,
          373,
          18,
          375,
          46
        ]
      ],
      "transformers/src/transformers/models/seamless_m4t/tokenization_seamless_m4t.py": [
        [
          "get_spm_processor",
          421,
          436,
          427,
          14,
          427,
          40,
          427,
          14,
          436,
          24
        ],
        [
          "save_vocabulary",
          497,
          512,
          508,
          18,
          508,
          43,
          508,
          18,
          510,
          46
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/tokenization_speech_to_text.py": [
        [
          "save_vocabulary",
          257,
          276,
          272,
          18,
          272,
          42,
          272,
          18,
          274,
          46
        ],
        [
          "load_json",
          285,
          287,
          286,
          10,
          286,
          24,
          285,
          15,
          287,
          27
        ],
        [
          "save_json",
          290,
          292,
          291,
          10,
          291,
          24,
          290,
          15,
          292,
          36
        ]
      ],
      "transformers/src/transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py": [
        [
          "__init__",
          82,
          118,
          95,
          14,
          95,
          47,
          83,
          9,
          99,
          30
        ],
        [
          "__init__",
          82,
          118,
          105,
          18,
          105,
          52,
          105,
          18,
          110,
          22
        ],
        [
          "save_vocabulary",
          220,
          249,
          231,
          14,
          231,
          52,
          228,
          30,
          235,
          33
        ],
        [
          "save_vocabulary",
          220,
          249,
          238,
          14,
          238,
          53,
          238,
          14,
          239,
          95
        ]
      ],
      "transformers/src/transformers/models/splinter/tokenization_splinter.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          280,
          298,
          288,
          14,
          288,
          52,
          288,
          14,
          289,
          86
        ]
      ],
      "transformers/src/transformers/models/speecht5/tokenization_speecht5.py": [
        [
          "save_vocabulary",
          205,
          220,
          216,
          18,
          216,
          43,
          216,
          18,
          218,
          46
        ]
      ],
      "transformers/src/transformers/models/squeezebert/tokenization_squeezebert.py": [
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ],
        [
          "save_vocabulary",
          242,
          260,
          250,
          14,
          250,
          52,
          250,
          14,
          251,
          86
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "get_spm_processor",
          200,
          215,
          206,
          14,
          206,
          40,
          206,
          14,
          215,
          24
        ],
        [
          "save_vocabulary",
          430,
          445,
          441,
          18,
          441,
          43,
          441,
          18,
          443,
          46
        ]
      ],
      "transformers/src/transformers/models/roc_bert/tokenization_roc_bert.py": [
        [
          "load_vocab",
          52,
          60,
          55,
          10,
          55,
          48,
          52,
          16,
          57,
          41
        ],
        [
          "__init__",
          117,
          172,
          143,
          14,
          143,
          56,
          141,
          22,
          152,
          28
        ],
        [
          "__init__",
          117,
          172,
          146,
          14,
          146,
          64,
          141,
          22,
          152,
          28
        ],
        [
          "save_vocabulary",
          827,
          869,
          848,
          14,
          848,
          52,
          840,
          18,
          849,
          86
        ],
        [
          "save_vocabulary",
          827,
          869,
          859,
          14,
          859,
          56,
          859,
          14,
          869,
          9
        ],
        [
          "save_vocabulary",
          827,
          869,
          862,
          14,
          862,
          64,
          859,
          14,
          869,
          9
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "save_vocabulary",
          465,
          492,
          476,
          14,
          476,
          52,
          473,
          30,
          482,
          95
        ],
        [
          "__init__",
          251,
          315,
          278,
          14,
          278,
          47,
          276,
          22,
          315,
          28
        ],
        [
          "__init__",
          251,
          315,
          284,
          14,
          284,
          48,
          276,
          22,
          315,
          28
        ],
        [
          "save_vocabulary",
          465,
          492,
          480,
          14,
          480,
          52,
          473,
          30,
          482,
          95
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "save_vocabulary",
          491,
          506,
          502,
          18,
          502,
          43,
          502,
          18,
          504,
          46
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "_build_from_file",
          302,
          315,
          306,
          14,
          306,
          52,
          302,
          26,
          307,
          25
        ],
        [
          "__init__",
          158,
          264,
          212,
          22,
          212,
          54,
          212,
          22,
          212,
          54
        ],
        [
          "count_file",
          275,
          289,
          281,
          14,
          281,
          46,
          278,
          9,
          282,
          41
        ],
        [
          "save_vocabulary",
          317,
          327,
          325,
          14,
          325,
          35,
          325,
          14,
          327,
          28
        ],
        [
          "encode_file",
          350,
          365,
          355,
          14,
          355,
          46,
          353,
          9,
          356,
          41
        ],
        [
          "get_lm_corpus",
          784,
          821,
          800,
          14,
          800,
          27,
          800,
          14,
          801,
          18
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "load_vocab",
          89,
          97,
          92,
          10,
          92,
          48,
          89,
          16,
          94,
          41
        ],
        [
          "save_vocabulary",
          372,
          390,
          380,
          14,
          380,
          52,
          380,
          14,
          381,
          86
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "__init__",
          72,
          104,
          84,
          14,
          84,
          47,
          73,
          9,
          104,
          9
        ],
        [
          "save_vocabulary",
          231,
          243,
          240,
          14,
          240,
          52,
          237,
          30,
          243,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        [
          "__init__",
          107,
          145,
          130,
          14,
          130,
          47,
          130,
          14,
          145,
          9
        ],
        [
          "save_vocabulary",
          558,
          569,
          566,
          14,
          566,
          52,
          563,
          30,
          569,
          28
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py": [
        [
          "__init__",
          140,
          187,
          159,
          14,
          159,
          47,
          141,
          9,
          164,
          34
        ],
        [
          "save_vocabulary",
          624,
          635,
          632,
          14,
          632,
          52,
          629,
          30,
          635,
          28
        ],
        [
          "__init__",
          698,
          738,
          723,
          14,
          723,
          47,
          699,
          9,
          738,
          9
        ],
        [
          "save_vocabulary",
          901,
          912,
          909,
          14,
          909,
          52,
          906,
          30,
          912,
          28
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "__init__",
          87,
          141,
          132,
          18,
          132,
          56,
          132,
          18,
          133,
          48
        ],
        [
          "save_vocabulary",
          439,
          452,
          447,
          18,
          447,
          61,
          447,
          18,
          450,
          17
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "_save_pretrained",
          695,
          742,
          728,
          22,
          728,
          67,
          728,
          22,
          730,
          36
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "from_pretrained",
          1859,
          2128,
          2042,
          30,
          2042,
          73,
          2042,
          30,
          2044,
          73
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2172,
          18,
          2172,
          62,
          2172,
          18,
          2177,
          37
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2191,
          18,
          2191,
          59,
          2191,
          18,
          2192,
          41
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2198,
          18,
          2198,
          53,
          2197,
          29,
          2199,
          45
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2296,
          22,
          2296,
          68,
          2296,
          22,
          2298,
          64
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2328,
          22,
          2328,
          62,
          2328,
          22,
          2330,
          65
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2342,
          22,
          2342,
          59,
          2342,
          22,
          2345,
          53
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2438,
          18,
          2438,
          64,
          2438,
          18,
          2442,
          50
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2449,
          26,
          2449,
          72,
          2449,
          26,
          2452,
          76
        ],
        [
          "save_chat_templates",
          2416,
          2469,
          2456,
          26,
          2456,
          71,
          2454,
          21,
          2459,
          75
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2606,
          14,
          2606,
          63,
          2606,
          14,
          2638,
          25
        ],
        [
          "save_pretrained",
          2471,
          2638,
          2615,
          14,
          2615,
          65,
          2606,
          14,
          2638,
          25
        ],
        [
          "_save_pretrained",
          2640,
          2673,
          2666,
          18,
          2666,
          63,
          2666,
          18,
          2669,
          78
        ]
      ],
      "transformers/src/transformers/models/xglm/tokenization_xglm.py": [
        [
          "save_vocabulary",
          284,
          299,
          295,
          18,
          295,
          43,
          295,
          18,
          297,
          46
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "__init__",
          254,
          326,
          305,
          18,
          305,
          56,
          305,
          18,
          306,
          48
        ],
        [
          "__init__",
          254,
          326,
          291,
          14,
          291,
          47,
          286,
          13,
          304,
          38
        ],
        [
          "__init__",
          254,
          326,
          297,
          14,
          297,
          48,
          286,
          13,
          304,
          38
        ],
        [
          "save_vocabulary",
          801,
          837,
          815,
          14,
          815,
          52,
          812,
          30,
          821,
          95
        ],
        [
          "save_vocabulary",
          801,
          837,
          819,
          14,
          819,
          52,
          812,
          30,
          821,
          95
        ],
        [
          "save_vocabulary",
          801,
          837,
          832,
          18,
          832,
          61,
          832,
          18,
          835,
          17
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "__init__",
          194,
          266,
          246,
          14,
          246,
          47,
          243,
          34,
          266,
          9
        ],
        [
          "__init__",
          194,
          266,
          249,
          14,
          249,
          48,
          243,
          34,
          266,
          9
        ],
        [
          "save_vocabulary",
          532,
          558,
          543,
          14,
          543,
          52,
          540,
          30,
          548,
          95
        ],
        [
          "save_vocabulary",
          532,
          558,
          547,
          14,
          547,
          52,
          540,
          30,
          548,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": [
        [
          "save_vocabulary",
          279,
          294,
          290,
          18,
          290,
          43,
          290,
          18,
          292,
          46
        ],
        [
          "load_vocab",
          32,
          40,
          35,
          10,
          35,
          48,
          32,
          16,
          37,
          41
        ]
      ],
      "transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py": [
        [
          "save_vocabulary",
          283,
          298,
          294,
          18,
          294,
          43,
          294,
          18,
          296,
          46
        ]
      ],
      "transformers/scripts/distributed/torch-distributed-gpu-test.py": [
        [
          "printflock",
          53,
          60,
          55,
          10,
          55,
          28,
          53,
          17,
          58,
          23
        ]
      ],
      "transformers/src/transformers/models/xlnet/tokenization_xlnet.py": [
        [
          "save_vocabulary",
          369,
          384,
          380,
          18,
          380,
          43,
          380,
          18,
          382,
          46
        ]
      ],
      "transformers/src/transformers/trainer_callback.py": [
        [
          "save_to_json",
          144,
          148,
          147,
          14,
          147,
          51,
          144,
          22,
          148,
          32
        ],
        [
          "load_from_json",
          151,
          155,
          153,
          14,
          153,
          46,
          151,
          24,
          155,
          38
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "save_metrics",
          884,
          919,
          906,
          10,
          906,
          24,
          905,
          12,
          909,
          15
        ],
        [
          "save_metrics",
          884,
          919,
          912,
          18,
          912,
          27,
          912,
          18,
          913,
          27
        ],
        [
          "save_metrics",
          884,
          919,
          918,
          14,
          918,
          28,
          917,
          9,
          919,
          63
        ],
        [
          "from_json_file",
          1156,
          1168,
          1159,
          14,
          1159,
          56,
          1158,
          21,
          1163,
          30
        ]
      ],
      "transformers/utils/update_metadata.py": [
        [
          "update_metadata",
          232,
          312,
          270,
          10,
          270,
          34,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          279,
          10,
          279,
          37,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          286,
          14,
          286,
          59,
          232,
          21,
          294,
          27
        ],
        [
          "update_metadata",
          232,
          312,
          288,
          14,
          288,
          62,
          232,
          21,
          294,
          27
        ]
      ],
      "transformers/utils/update_tiny_models.py": [
        [
          "get_tiny_model_names_from_repo",
          57,
          64,
          58,
          10,
          58,
          52,
          58,
          10,
          61,
          42
        ],
        [
          "get_tiny_model_summary_from_hub",
          67,
          142,
          141,
          14,
          141,
          80,
          136,
          40,
          142,
          64
        ]
      ],
      "transformers/src/transformers/data/processors/utils.py": [
        [
          "_read_tsv",
          119,
          122,
          121,
          14,
          121,
          56,
          119,
          19,
          122,
          75
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "__post_init__",
          1467,
          1917,
          1765,
          18,
          1765,
          57,
          1765,
          18,
          1766,
          32
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "_read_txt",
          191,
          199,
          195,
          18,
          195,
          45,
          194,
          13,
          198,
          38
        ],
        [
          "_read_csv",
          247,
          249,
          248,
          14,
          248,
          47,
          247,
          19,
          249,
          38
        ],
        [
          "_read_csv",
          296,
          298,
          297,
          14,
          297,
          47,
          296,
          19,
          298,
          38
        ],
        [
          "_read_json",
          342,
          345,
          343,
          14,
          343,
          47,
          342,
          20,
          345,
          24
        ]
      ],
      "transformers/examples/pytorch/question-answering/utils_qa.py": [
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          239,
          14,
          239,
          39,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          67,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          242,
          14,
          242,
          34,
          228,
          25,
          244,
          34
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          246,
          18,
          246,
          42,
          228,
          67,
          247,
          75
        ],
        [
          "postprocess_qa_predictions",
          31,
          249,
          246,
          18,
          246,
          42,
          228,
          25,
          247,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          433,
          14,
          433,
          39,
          432,
          9,
          438,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          433,
          14,
          433,
          39,
          428,
          30,
          441,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          436,
          14,
          436,
          34,
          432,
          9,
          438,
          34
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          436,
          14,
          436,
          34,
          428,
          30,
          441,
          75
        ],
        [
          "postprocess_qa_predictions_with_beam_search",
          252,
          443,
          440,
          18,
          440,
          42,
          428,
          30,
          441,
          75
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "pickle_load",
          447,
          450,
          449,
          10,
          449,
          25,
          447,
          17,
          450,
          29
        ],
        [
          "pickle_save",
          453,
          456,
          455,
          10,
          455,
          25,
          453,
          17,
          456,
          34
        ],
        [
          "save_json",
          469,
          471,
          470,
          10,
          470,
          24,
          469,
          15,
          471,
          80
        ],
        [
          "load_json",
          474,
          476,
          475,
          10,
          475,
          19,
          474,
          15,
          476,
          27
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "create_model_card",
          4790,
          4862,
          4858,
          14,
          4858,
          43,
          4845,
          28,
          4861,
          26
        ],
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4880,
          22,
          4880,
          37,
          4879,
          17,
          4883,
          50
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5029,
          18,
          5029,
          70,
          5029,
          18,
          5030,
          31
        ],
        [
          "_add_sm_patterns_to_gitignore",
          5019,
          5056,
          5045,
          18,
          5045,
          75,
          5045,
          18,
          5047,
          32
        ]
      ],
      "transformers/src/transformers/models/auto/video_processing_auto.py": [
        [
          "get_video_processor_config",
          105,
          197,
          196,
          10,
          196,
          53,
          196,
          10,
          197,
          32
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "get_video_processor_dict",
          611,
          724,
          708,
          18,
          708,
          75,
          662,
          45,
          708,
          75
        ],
        [
          "get_video_processor_dict",
          611,
          724,
          708,
          18,
          708,
          75,
          706,
          9,
          708,
          75
        ],
        [
          "to_json_file",
          806,
          815,
          814,
          14,
          814,
          56,
          806,
          22,
          815,
          47
        ],
        [
          "from_json_file",
          821,
          837,
          834,
          14,
          834,
          51,
          821,
          24,
          837,
          42
        ]
      ],
      "transformers/src/transformers/pipelines/zero_shot_audio_classification.py": [
        [
          "preprocess",
          105,
          131,
          112,
          22,
          112,
          38,
          112,
          22,
          113,
          25
        ]
      ],
      "transformers/.github/scripts/assign_reviewers.py": [
        [
          "main",
          74,
          117,
          76,
          10,
          76,
          58,
          75,
          18,
          88,
          54
        ],
        [
          "main",
          74,
          117,
          81,
          10,
          81,
          46,
          75,
          18,
          88,
          54
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_paper_link",
          54,
          91,
          61,
          10,
          61,
          47,
          59,
          5,
          70,
          26
        ],
        [
          "replace_paper_links",
          139,
          177,
          142,
          10,
          142,
          47,
          139,
          25,
          155,
          31
        ],
        [
          "replace_paper_links",
          139,
          177,
          174,
          14,
          174,
          51,
          174,
          14,
          176,
          19
        ],
        [
          "insert_dates",
          180,
          250,
          202,
          14,
          202,
          51,
          198,
          13,
          205,
          28
        ],
        [
          "insert_dates",
          180,
          250,
          210,
          18,
          210,
          55,
          206,
          13,
          212,
          19
        ],
        [
          "insert_dates",
          180,
          250,
          239,
          22,
          239,
          59,
          235,
          28,
          240,
          36
        ],
        [
          "insert_dates",
          180,
          250,
          248,
          18,
          248,
          55,
          244,
          28,
          250,
          66
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_to_model_init",
          33,
          146,
          39,
          10,
          39,
          95,
          34,
          5,
          44,
          28
        ],
        [
          "add_fast_image_processor_to_model_init",
          33,
          146,
          145,
          10,
          145,
          95,
          145,
          10,
          146,
          32
        ],
        [
          "add_fast_image_processor_to_auto",
          149,
          163,
          153,
          10,
          153,
          104,
          149,
          38,
          163,
          32
        ],
        [
          "add_fast_image_processor_to_auto",
          149,
          163,
          162,
          10,
          162,
          104,
          149,
          38,
          163,
          32
        ],
        [
          "add_fast_image_processor_to_doc",
          166,
          197,
          185,
          14,
          185,
          50,
          184,
          9,
          188,
          41
        ],
        [
          "add_fast_image_processor_to_doc",
          166,
          197,
          196,
          18,
          196,
          54,
          190,
          31,
          197,
          40
        ],
        [
          "add_fast_image_processor_to_tests",
          200,
          272,
          210,
          10,
          210,
          47,
          210,
          10,
          252,
          48
        ],
        [
          "add_fast_image_processor_to_tests",
          200,
          272,
          271,
          10,
          271,
          47,
          271,
          10,
          272,
          32
        ],
        [
          "write_default_fast_image_processor_file",
          311,
          339,
          338,
          10,
          338,
          71,
          312,
          5,
          339,
          24
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          445,
          10,
          445,
          71,
          441,
          5,
          446,
          24
        ],
        [
          "add_fast_image_processor",
          449,
          507,
          466,
          10,
          466,
          66,
          466,
          10,
          471,
          31
        ]
      ],
      "transformers/utils/add_pipeline_model_mapping_to_test.py": [
        [
          "add_pipeline_model_mapping",
          155,
          264,
          261,
          10,
          261,
          64,
          247,
          19,
          264,
          22
        ]
      ],
      "transformers/src/transformers/pipelines/__init__.py": [
        [
          "pipeline",
          514,
          1094,
          785,
          22,
          785,
          68,
          785,
          22,
          788,
          25
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "create_test_files",
          427,
          474,
          464,
          18,
          464,
          46,
          464,
          18,
          468,
          15
        ],
        [
          "add_content_to_file",
          128,
          147,
          140,
          10,
          140,
          47,
          128,
          25,
          147,
          28
        ],
        [
          "add_content_to_file",
          128,
          147,
          146,
          10,
          146,
          47,
          128,
          25,
          147,
          28
        ],
        [
          "add_model_to_auto_mappings",
          150,
          214,
          201,
          18,
          201,
          71,
          200,
          24,
          207,
          39
        ],
        [
          "insert_model_in_doc_toc",
          273,
          293,
          286,
          10,
          286,
          28,
          273,
          29,
          293,
          5
        ],
        [
          "find_all_classes_from_file",
          334,
          347,
          342,
          10,
          342,
          49,
          334,
          32,
          347,
          50
        ],
        [
          "create_new_model_like",
          477,
          571,
          512,
          10,
          512,
          74,
          504,
          26,
          537,
          47
        ],
        [
          "create_new_model_like",
          477,
          571,
          517,
          10,
          517,
          53,
          504,
          26,
          537,
          47
        ],
        [
          "create_new_model_like",
          477,
          571,
          534,
          10,
          534,
          48,
          504,
          26,
          537,
          47
        ],
        [
          "create_new_model_like",
          477,
          571,
          538,
          14,
          538,
          47,
          537,
          9,
          539,
          28
        ],
        [
          "create_new_model_like",
          477,
          571,
          543,
          10,
          543,
          99,
          542,
          16,
          548,
          34
        ]
      ],
      "transformers/src/transformers/pipelines/audio_classification.py": [
        [
          "preprocess",
          166,
          239,
          173,
          22,
          173,
          39,
          173,
          22,
          174,
          26
        ]
      ],
      "transformers/src/transformers/audio_utils.py": [
        [
          "load_audio_as",
          143,
          219,
          183,
          18,
          183,
          34,
          183,
          18,
          183,
          34
        ]
      ],
      "transformers/src/transformers/pipelines/automatic_speech_recognition.py": [
        [
          "preprocess",
          353,
          494,
          360,
          22,
          360,
          39,
          360,
          22,
          361,
          26
        ]
      ],
      "transformers/src/transformers/models/auto/auto_factory.py": [
        [
          "from_pretrained",
          251,
          391,
          312,
          22,
          312,
          68,
          312,
          22,
          316,
          49
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          143,
          14,
          143,
          64,
          133,
          9,
          144,
          44
        ],
        [
          "combine_summaries",
          149,
          195,
          190,
          10,
          190,
          61,
          190,
          10,
          195,
          19
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "save_binary",
          458,
          474,
          471,
          14,
          471,
          37,
          458,
          21,
          474,
          26
        ],
        [
          "__iter__",
          533,
          540,
          534,
          14,
          534,
          39,
          533,
          18,
          536,
          29
        ],
        [
          "save",
          542,
          553,
          549,
          14,
          549,
          40,
          542,
          14,
          550,
          28
        ],
        [
          "__init__",
          568,
          578,
          577,
          14,
          577,
          34,
          569,
          9,
          578,
          25
        ],
        [
          "save",
          587,
          595,
          594,
          14,
          594,
          40,
          587,
          14,
          595,
          30
        ]
      ],
      "transformers/utils/check_bad_commit.py": [
        [
          "create_script",
          26,
          69,
          68,
          10,
          68,
          38,
          26,
          19,
          69,
          32
        ],
        [
          "find_bad_commit",
          72,
          133,
          95,
          10,
          95,
          39,
          87,
          5,
          106,
          50
        ]
      ],
      "transformers/benchmark_v2/benchmark_framework.py": [
        [
          "save_results",
          1171,
          1199,
          1195,
          14,
          1195,
          32,
          1195,
          14,
          1199,
          23
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "save_chat",
          395,
          411,
          409,
          14,
          409,
          32,
          408,
          9,
          411,
          40
        ],
        [
          "_inner_run",
          667,
          752,
          695,
          18,
          695,
          41,
          695,
          18,
          696,
          24
        ]
      ],
      "transformers/utils/check_doc_toc.py": [
        [
          "check_model_doc",
          79,
          125,
          88,
          10,
          88,
          44,
          79,
          21,
          92,
          11
        ],
        [
          "check_model_doc",
          79,
          125,
          120,
          18,
          120,
          57,
          118,
          46,
          121,
          63
        ]
      ],
      "transformers/utils/check_config_attributes.py": [
        [
          "check_config_attributes_being_used",
          457,
          499,
          484,
          18,
          484,
          44,
          484,
          18,
          485,
          50
        ]
      ],
      "transformers/utils/check_doctest_list.py": [
        [
          "clean_doctest_list",
          44,
          76,
          56,
          10,
          56,
          50,
          44,
          24,
          57,
          21
        ],
        [
          "clean_doctest_list",
          44,
          76,
          75,
          14,
          75,
          54,
          75,
          14,
          76,
          51
        ]
      ],
      "transformers/utils/check_dummies.py": [
        [
          "read_init",
          95,
          137,
          102,
          10,
          102,
          101,
          96,
          5,
          106,
          14
        ],
        [
          "check_dummies",
          186,
          248,
          208,
          18,
          208,
          69,
          208,
          18,
          209,
          39
        ],
        [
          "check_dummies",
          186,
          248,
          221,
          22,
          221,
          89,
          217,
          17,
          222,
          49
        ]
      ],
      "transformers/utils/check_inits.py": [
        [
          "parse_init",
          92,
          232,
          105,
          10,
          105,
          61,
          92,
          16,
          109,
          14
        ],
        [
          "check_submodules",
          320,
          349,
          333,
          10,
          333,
          69,
          321,
          5,
          343,
          37
        ]
      ],
      "transformers/utils/check_modular_conversion.py": [
        [
          "process_file",
          27,
          67,
          37,
          10,
          37,
          47,
          34,
          24,
          51,
          16
        ],
        [
          "process_file",
          27,
          67,
          56,
          14,
          56,
          65,
          56,
          14,
          59,
          20
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "find_code_in_transformers",
          386,
          460,
          433,
          10,
          433,
          91,
          433,
          10,
          439,
          30
        ],
        [
          "is_copy_consistent",
          635,
          826,
          655,
          10,
          655,
          60,
          653,
          17,
          660,
          78
        ],
        [
          "is_copy_consistent",
          635,
          826,
          824,
          14,
          824,
          64,
          823,
          9,
          825,
          31
        ],
        [
          "get_model_list",
          862,
          898,
          874,
          10,
          874,
          85,
          862,
          20,
          877,
          15
        ]
      ],
      "transformers/utils/check_self_hosted_runner.py": [
        [
          "get_runner_status",
          6,
          34,
          29,
          10,
          29,
          41,
          29,
          10,
          32,
          31
        ]
      ],
      "transformers/utils/check_pipeline_typing.py": [
        [
          "main",
          30,
          78,
          70,
          14,
          70,
          42,
          64,
          9,
          71,
          31
        ],
        [
          "main",
          30,
          78,
          31,
          10,
          31,
          38,
          30,
          10,
          53,
          41
        ]
      ],
      "transformers/utils/compare_test_runs.py": [
        [
          "parse_summary_file",
          34,
          47,
          36,
          10,
          36,
          47,
          34,
          24,
          38,
          21
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "fix_docstring",
          798,
          870,
          857,
          10,
          857,
          46,
          856,
          16,
          870,
          33
        ],
        [
          "fix_docstring",
          798,
          870,
          869,
          10,
          869,
          46,
          856,
          16,
          870,
          33
        ],
        [
          "find_files_with_auto_docstring",
          943,
          968,
          949,
          14,
          949,
          51,
          948,
          9,
          951,
          45
        ],
        [
          "update_file_with_new_docstrings",
          1235,
          1326,
          1319,
          14,
          1319,
          56,
          1319,
          14,
          1320,
          42
        ],
        [
          "check_auto_docstrings",
          1335,
          1376,
          1349,
          14,
          1349,
          56,
          1348,
          9,
          1357,
          42
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "find_tested_models",
          602,
          650,
          613,
          10,
          613,
          90,
          602,
          24,
          621,
          26
        ],
        [
          "check_decorator_order",
          872,
          895,
          882,
          10,
          882,
          60,
          872,
          27,
          886,
          35
        ],
        [
          "find_all_documented_objects",
          914,
          939,
          926,
          14,
          926,
          64,
          925,
          9,
          931,
          31
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          598,
          14,
          598,
          57,
          596,
          27,
          605,
          9
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          651,
          10,
          651,
          36,
          647,
          14,
          674,
          43
        ]
      ],
      "transformers/src/transformers/distributed/configuration_utils.py": [
        [
          "to_json_file",
          52,
          66,
          62,
          14,
          62,
          56,
          52,
          22,
          66,
          37
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "_dict_from_json_file",
          948,
          951,
          949,
          14,
          949,
          51,
          948,
          30,
          951,
          31
        ],
        [
          "to_json_file",
          1089,
          1101,
          1100,
          14,
          1100,
          56,
          1089,
          22,
          1101,
          64
        ],
        [
          "to_json_file",
          1199,
          1210,
          1206,
          14,
          1206,
          56,
          1199,
          22,
          1210,
          37
        ]
      ],
      "transformers/examples/pytorch/continuous_batching.py": [
        [
          "batch_generate",
          94,
          178,
          175,
          14,
          175,
          35,
          175,
          14,
          176,
          40
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "_dict_from_json_file",
          853,
          856,
          854,
          14,
          854,
          46,
          853,
          30,
          856,
          31
        ],
        [
          "to_json_file",
          979,
          991,
          990,
          14,
          990,
          56,
          979,
          22,
          991,
          64
        ]
      ],
      "transformers/src/transformers/models/audio_spectrogram_transformer/convert_audio_spectrogram_transformer_original_to_pytorch.py": [
        [
          "get_audio_spectrogram_transformer_config",
          34,
          66,
          61,
          26,
          61,
          91,
          61,
          16,
          66,
          17
        ]
      ],
      "transformers/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py": [
        [
          "convert_beit_checkpoint",
          170,
          357,
          191,
          30,
          191,
          95,
          188,
          45,
          198,
          23
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          204,
          30,
          204,
          95,
          201,
          45,
          208,
          34
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          217,
          30,
          217,
          95,
          214,
          45,
          222,
          19
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_big_switch.py": [
        [
          "shard_on_the_fly",
          70,
          149,
          145,
          10,
          145,
          81,
          142,
          17,
          149,
          26
        ]
      ],
      "transformers/src/transformers/models/bit/convert_bit_to_pytorch.py": [
        [
          "get_config",
          38,
          57,
          41,
          26,
          41,
          91,
          38,
          16,
          45,
          50
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "add_from_file",
          107,
          144,
          113,
          22,
          113,
          51,
          112,
          13,
          113,
          51
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          184,
          10,
          184,
          52,
          179,
          16,
          189,
          40
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          224,
          10,
          224,
          62,
          192,
          19,
          251,
          24
        ],
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          241,
          10,
          241,
          66,
          192,
          19,
          251,
          24
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          150,
          14,
          150,
          66,
          147,
          18,
          154,
          32
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          152,
          14,
          152,
          110,
          147,
          18,
          154,
          32
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          210,
          14,
          210,
          66,
          208,
          9,
          211,
          44
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "merge_configurations",
          22,
          174,
          25,
          10,
          25,
          31,
          22,
          26,
          36,
          73
        ],
        [
          "merge_configurations",
          22,
          174,
          28,
          10,
          28,
          39,
          22,
          26,
          36,
          73
        ],
        [
          "create_tokenizer_config",
          280,
          296,
          295,
          10,
          295,
          34,
          280,
          29,
          296,
          48
        ],
        [
          "convert_hf_blt_to_unified",
          362,
          410,
          388,
          10,
          388,
          31,
          363,
          5,
          391,
          36
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "read_json",
          74,
          76,
          75,
          10,
          75,
          24,
          74,
          15,
          76,
          27
        ],
        [
          "write_json",
          79,
          81,
          80,
          10,
          80,
          24,
          79,
          16,
          81,
          26
        ],
        [
          "write_model",
          84,
          436,
          329,
          10,
          329,
          77,
          326,
          26,
          337,
          53
        ],
        [
          "write_model",
          84,
          436,
          341,
          10,
          341,
          91,
          341,
          10,
          355,
          42
        ],
        [
          "write_model",
          84,
          436,
          352,
          10,
          352,
          68,
          341,
          10,
          355,
          42
        ]
      ],
      "transformers/src/transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_conditional_detr_checkpoint",
          222,
          308,
          241,
          30,
          241,
          95,
          238,
          29,
          261,
          32
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_convnext_upernet_to_pytorch.py": [
        [
          "get_upernet_config",
          28,
          68,
          53,
          26,
          53,
          91,
          50,
          18,
          68,
          17
        ]
      ],
      "transformers/src/transformers/models/convnext/convert_convnext_to_pytorch.py": [
        [
          "get_convnext_config",
          36,
          78,
          66,
          26,
          66,
          91,
          64,
          15,
          68,
          33
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "get_convnextv2_config",
          37,
          79,
          71,
          26,
          71,
          91,
          65,
          18,
          79,
          33
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "write_model",
          121,
          196,
          142,
          26,
          142,
          91,
          139,
          25,
          152,
          23
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "main",
          249,
          351,
          281,
          30,
          281,
          95,
          259,
          16,
          290,
          15
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "load_model_state_dict",
          203,
          233,
          214,
          14,
          214,
          34,
          212,
          9,
          219,
          44
        ]
      ],
      "transformers/src/transformers/models/deit/convert_deit_timm_to_pytorch.py": [
        [
          "convert_deit_checkpoint",
          131,
          201,
          144,
          26,
          144,
          91,
          131,
          29,
          151,
          39
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "load_model_state_dict",
          176,
          206,
          187,
          14,
          187,
          34,
          185,
          9,
          192,
          44
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "get_d_fine_config",
          36,
          153,
          42,
          26,
          42,
          91,
          41,
          16,
          53,
          75
        ],
        [
          "get_d_fine_config",
          36,
          153,
          42,
          26,
          42,
          91,
          41,
          73,
          53,
          75
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_detr_checkpoint",
          179,
          264,
          198,
          30,
          198,
          95,
          195,
          29,
          218,
          32
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_to_pytorch.py": [
        [
          "get_detr_config",
          34,
          58,
          53,
          30,
          53,
          95,
          50,
          29,
          56,
          23
        ]
      ],
      "transformers/src/transformers/models/vit/convert_dino_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          131,
          195,
          146,
          30,
          146,
          95,
          143,
          29,
          151,
          50
        ]
      ],
      "transformers/src/transformers/models/dinov2_with_registers/convert_dinov2_with_registers_to_hf.py": [
        [
          "get_dinov2_with_registers_config",
          45,
          73,
          70,
          37,
          70,
          102,
          67,
          19,
          71,
          23
        ]
      ],
      "transformers/src/transformers/models/dinov2/convert_dinov2_to_hf.py": [
        [
          "get_dinov2_config",
          40,
          68,
          65,
          37,
          65,
          102,
          62,
          19,
          66,
          23
        ]
      ],
      "transformers/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py": [
        [
          "convert_dit_checkpoint",
          133,
          210,
          154,
          30,
          154,
          95,
          151,
          29,
          163,
          32
        ]
      ],
      "transformers/src/transformers/models/doge/convert_doge_weights_to_hf.py": [
        [
          "convert_doge_model",
          94,
          109,
          96,
          10,
          96,
          53,
          94,
          24,
          106,
          33
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "get_efficientnet_config",
          122,
          139,
          134,
          26,
          134,
          91,
          122,
          29,
          139,
          17
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "load_model_state_dict",
          158,
          188,
          169,
          14,
          169,
          34,
          167,
          9,
          174,
          44
        ],
        [
          "convert_model",
          191,
          286,
          216,
          10,
          216,
          59,
          207,
          8,
          228,
          39
        ],
        [
          "convert_model",
          191,
          286,
          216,
          10,
          216,
          59,
          211,
          5,
          228,
          39
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_tiktoken",
          105,
          210,
          187,
          10,
          187,
          76,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          190,
          10,
          190,
          80,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          193,
          10,
          193,
          87,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          196,
          10,
          196,
          89,
          105,
          22,
          210,
          35
        ],
        [
          "convert_tiktoken",
          105,
          210,
          208,
          10,
          208,
          76,
          105,
          22,
          210,
          35
        ],
        [
          "convert_model",
          255,
          408,
          281,
          10,
          281,
          50,
          255,
          19,
          308,
          31
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_FastSpeech2ConformerModel_checkpoint",
          155,
          188,
          178,
          14,
          178,
          34,
          156,
          5,
          185,
          14
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          131,
          10,
          131,
          52,
          92,
          5,
          137,
          22
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          147,
          10,
          147,
          52,
          142,
          16,
          152,
          34
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          156,
          10,
          156,
          49,
          156,
          10,
          168,
          35
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          160,
          10,
          160,
          49,
          156,
          10,
          168,
          35
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          210,
          10,
          210,
          60,
          209,
          5,
          243,
          24
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          223,
          10,
          223,
          64,
          209,
          5,
          243,
          24
        ]
      ],
      "transformers/src/transformers/models/focalnet/convert_focalnet_to_hf_format.py": [
        [
          "get_focalnet_config",
          30,
          87,
          71,
          26,
          71,
          91,
          71,
          16,
          87,
          17
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "convert_glm_model",
          156,
          173,
          158,
          10,
          158,
          53,
          156,
          23,
          173,
          41
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "convert_glm4_model",
          161,
          178,
          163,
          10,
          163,
          53,
          161,
          24,
          178,
          41
        ]
      ],
      "transformers/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_gpt2_checkpoint_to_pytorch",
          86,
          104,
          103,
          10,
          103,
          62,
          92,
          13,
          104,
          40
        ]
      ],
      "transformers/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          112,
          133,
          114,
          29,
          114,
          50,
          112,
          38,
          133,
          44
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/convert_gptsan_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_gptsan_to_pt",
          28,
          171,
          30,
          25,
          30,
          44,
          28,
          29,
          31,
          17
        ]
      ],
      "transformers/src/transformers/models/hiera/convert_hiera_to_hf.py": [
        [
          "get_labels_for_classifier",
          158,
          168,
          163,
          26,
          163,
          91,
          158,
          31,
          168,
          41
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "main",
          700,
          805,
          786,
          10,
          786,
          91,
          743,
          28,
          797,
          82
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_tokenizer",
          426,
          772,
          771,
          14,
          771,
          42,
          769,
          9,
          772,
          68
        ],
        [
          "create_safetensors_index",
          317,
          322,
          321,
          10,
          321,
          76,
          321,
          10,
          322,
          39
        ]
      ],
      "transformers/src/transformers/models/hubert/convert_hubert_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_hubert_checkpoint",
          183,
          246,
          209,
          18,
          209,
          56,
          208,
          13,
          229,
          63
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "save_sharded_model",
          174,
          247,
          244,
          10,
          244,
          30,
          243,
          18,
          247,
          22
        ],
        [
          "merge_tp_weights",
          250,
          625,
          266,
          10,
          266,
          36,
          265,
          5,
          281,
          33
        ],
        [
          "merge_tp_weights",
          250,
          625,
          622,
          10,
          622,
          31,
          621,
          19,
          625,
          63
        ]
      ],
      "transformers/src/transformers/models/idefics3/convert_idefics3_weights_to_hf.py": [
        [
          "get_config",
          118,
          153,
          123,
          10,
          123,
          28,
          118,
          16,
          129,
          35
        ]
      ],
      "transformers/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py": [
        [
          "convert_imagegpt_checkpoint_to_pytorch",
          141,
          158,
          157,
          10,
          157,
          62,
          141,
          44,
          158,
          40
        ]
      ],
      "transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py": [
        [
          "convert_weights_and_push",
          83,
          149,
          89,
          26,
          89,
          91,
          83,
          30,
          142,
          17
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "load_model_state_dict",
          209,
          239,
          220,
          14,
          220,
          34,
          218,
          9,
          225,
          44
        ],
        [
          "convert_model",
          242,
          447,
          278,
          10,
          278,
          59,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          280,
          10,
          280,
          72,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          282,
          10,
          282,
          71,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          284,
          10,
          284,
          69,
          278,
          10,
          295,
          42
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "convert_openai_checkpoint",
          213,
          260,
          221,
          13,
          221,
          75,
          219,
          17,
          221,
          92
        ],
        [
          "convert_openai_checkpoint",
          213,
          260,
          254,
          10,
          254,
          62,
          253,
          5,
          260,
          22
        ]
      ],
      "transformers/src/transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          153,
          248,
          156,
          10,
          156,
          23,
          153,
          25,
          160,
          53
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "write_model",
          213,
          554,
          223,
          10,
          223,
          64,
          214,
          5,
          244,
          32
        ],
        [
          "max_context_length",
          199,
          210,
          204,
          10,
          204,
          59,
          204,
          10,
          207,
          37
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          99,
          10,
          99,
          23,
          95,
          25,
          103,
          53
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          98,
          357,
          102,
          10,
          102,
          23,
          98,
          25,
          106,
          103
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "read_json",
          174,
          176,
          175,
          10,
          175,
          24,
          174,
          15,
          176,
          27
        ],
        [
          "write_json",
          179,
          181,
          180,
          10,
          180,
          24,
          179,
          16,
          181,
          26
        ]
      ],
      "transformers/src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          28,
          131,
          30,
          10,
          30,
          28,
          28,
          29,
          62,
          54
        ],
        [
          "convert_luke_checkpoint",
          28,
          131,
          50,
          10,
          50,
          112,
          28,
          29,
          62,
          54
        ],
        [
          "load_entity_vocab",
          134,
          141,
          136,
          10,
          136,
          55,
          134,
          23,
          137,
          39
        ]
      ],
      "transformers/src/transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py": [
        [
          "convert_mamba2_checkpoint_file_to_huggingface_model_file",
          116,
          142,
          127,
          10,
          127,
          49,
          117,
          5,
          138,
          48
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "save_sharded_safetensors",
          143,
          167,
          160,
          10,
          160,
          91,
          144,
          5,
          165,
          50
        ],
        [
          "convert_mamba_ssm_checkpoint_file_to_huggingface_model_file",
          171,
          234,
          204,
          10,
          204,
          49,
          196,
          9,
          225,
          48
        ]
      ],
      "transformers/src/transformers/models/mamba/convert_mamba_ssm_checkpoint_to_pytorch.py": [
        [
          "convert_mamba_checkpoint_file_to_huggingface_model_file",
          97,
          126,
          111,
          10,
          111,
          54,
          108,
          5,
          126,
          41
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "get_maskformer_config",
          36,
          71,
          68,
          26,
          68,
          91,
          68,
          16,
          71,
          17
        ],
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          239,
          10,
          239,
          36,
          231,
          5,
          248,
          32
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "make_registry",
          281,
          295,
          293,
          24,
          293,
          44,
          293,
          19,
          294,
          27
        ],
        [
          "load_yaml",
          681,
          685,
          684,
          10,
          684,
          37,
          681,
          15,
          685,
          51
        ],
        [
          "save_json",
          688,
          690,
          689,
          10,
          689,
          24,
          688,
          15,
          690,
          29
        ]
      ],
      "transformers/src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          125,
          10,
          125,
          79,
          124,
          39,
          191,
          42
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "get_maskformer_config",
          36,
          76,
          71,
          26,
          71,
          91,
          71,
          16,
          76,
          17
        ],
        [
          "convert_maskformer_checkpoint",
          261,
          350,
          270,
          10,
          270,
          36,
          262,
          5,
          276,
          32
        ]
      ],
      "transformers/src/transformers/models/mask2former/convert_mask2former_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "__call__",
          113,
          193,
          134,
          30,
          134,
          95,
          134,
          20,
          138,
          37
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "__init__",
          56,
          72,
          59,
          40,
          59,
          99,
          57,
          9,
          61,
          34
        ],
        [
          "__init__",
          56,
          72,
          61,
          21,
          61,
          34,
          57,
          9,
          61,
          34
        ],
        [
          "write_model_card",
          129,
          275,
          274,
          14,
          274,
          67,
          274,
          14,
          275,
          41
        ],
        [
          "parse_metadata",
          290,
          318,
          305,
          39,
          305,
          55,
          302,
          68,
          306,
          79
        ],
        [
          "parse_metadata",
          290,
          318,
          313,
          39,
          313,
          56,
          308,
          32,
          314,
          80
        ]
      ],
      "transformers/src/transformers/models/mistral3/convert_mistral3_weights_to_hf.py": [
        [
          "read_json",
          74,
          76,
          75,
          10,
          75,
          24,
          74,
          15,
          76,
          27
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "read_json",
          62,
          64,
          63,
          10,
          63,
          24,
          62,
          15,
          64,
          27
        ]
      ],
      "transformers/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py": [
        [
          "read_json",
          51,
          53,
          52,
          10,
          52,
          24,
          51,
          15,
          53,
          27
        ],
        [
          "write_json",
          56,
          58,
          57,
          10,
          57,
          24,
          56,
          16,
          58,
          26
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "load_orig_config_file",
          41,
          64,
          55,
          10,
          55,
          33,
          41,
          27,
          57,
          22
        ],
        [
          "get_mobilevitv2_config",
          67,
          122,
          117,
          26,
          117,
          91,
          102,
          5,
          122,
          17
        ],
        [
          "get_mobilevitv2_config",
          67,
          122,
          117,
          26,
          117,
          91,
          116,
          15,
          122,
          17
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          29,
          183,
          31,
          10,
          31,
          28,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          54,
          10,
          54,
          83,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          57,
          10,
          57,
          83,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          60,
          10,
          60,
          113,
          29,
          29,
          74,
          61
        ],
        [
          "load_original_entity_vocab",
          186,
          200,
          189,
          42,
          189,
          64,
          186,
          32,
          192,
          21
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "get_mobilevit_config",
          39,
          70,
          65,
          26,
          65,
          91,
          64,
          15,
          70,
          17
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_tokenizer",
          497,
          565,
          564,
          14,
          564,
          42,
          562,
          9,
          565,
          68
        ],
        [
          "write_model",
          209,
          471,
          218,
          10,
          218,
          64,
          210,
          5,
          252,
          49
        ],
        [
          "write_image_processor",
          568,
          587,
          569,
          10,
          569,
          31,
          568,
          27,
          587,
          45
        ]
      ],
      "transformers/src/transformers/models/vit_msn/convert_msn_to_pytorch.py": [
        [
          "convert_vit_msn_checkpoint",
          148,
          228,
          154,
          26,
          154,
          70,
          148,
          32,
          159,
          30
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          122,
          10,
          122,
          81,
          119,
          17,
          126,
          26
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "read_json",
          58,
          60,
          59,
          10,
          59,
          24,
          58,
          15,
          60,
          27
        ],
        [
          "write_json",
          63,
          65,
          64,
          10,
          64,
          24,
          63,
          16,
          65,
          26
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "read_json",
          55,
          57,
          56,
          10,
          56,
          24,
          55,
          15,
          57,
          27
        ],
        [
          "write_json",
          60,
          62,
          61,
          10,
          61,
          24,
          60,
          16,
          62,
          26
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "main",
          287,
          300,
          297,
          29,
          297,
          66,
          288,
          5,
          300,
          82
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "read_json",
          81,
          83,
          82,
          10,
          82,
          24,
          81,
          15,
          83,
          27
        ],
        [
          "write_json",
          86,
          88,
          87,
          10,
          87,
          24,
          86,
          16,
          88,
          26
        ]
      ],
      "transformers/src/transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": [
        [
          "convert_hf_config",
          93,
          131,
          131,
          26,
          131,
          67,
          131,
          5,
          131,
          78
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "write_json",
          74,
          76,
          75,
          10,
          75,
          24,
          74,
          16,
          76,
          26
        ],
        [
          "read_json",
          69,
          71,
          70,
          10,
          70,
          24,
          69,
          15,
          71,
          27
        ],
        [
          "get_bytes_range",
          87,
          90,
          88,
          10,
          88,
          25,
          87,
          21,
          90,
          32
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          42,
          10,
          42,
          94,
          40,
          5,
          57,
          62
        ],
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          44,
          10,
          44,
          91,
          40,
          5,
          57,
          62
        ],
        [
          "convert_openai_checkpoint_to_pytorch",
          109,
          127,
          126,
          10,
          126,
          62,
          115,
          13,
          127,
          40
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v1_config",
          142,
          164,
          158,
          26,
          158,
          91,
          155,
          25,
          164,
          17
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "convert_tiktoken_to_hf",
          291,
          327,
          315,
          14,
          315,
          52,
          295,
          43,
          320,
          36
        ],
        [
          "_download",
          147,
          182,
          158,
          23,
          158,
          49,
          158,
          23,
          159,
          78
        ],
        [
          "_download",
          147,
          182,
          164,
          49,
          164,
          75,
          164,
          10,
          167,
          17
        ],
        [
          "_download",
          147,
          182,
          176,
          19,
          176,
          45,
          171,
          21,
          177,
          74
        ],
        [
          "convert_tiktoken_to_hf",
          291,
          327,
          318,
          14,
          318,
          52,
          295,
          43,
          320,
          36
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v2_config",
          209,
          242,
          231,
          26,
          231,
          91,
          230,
          15,
          233,
          32
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          310,
          14,
          310,
          35,
          292,
          9,
          315,
          20
        ],
        [
          "convert_checkpoint",
          266,
          360,
          332,
          55,
          332,
          88,
          332,
          55,
          336,
          17
        ],
        [
          "convert_checkpoint",
          266,
          360,
          339,
          14,
          339,
          49,
          338,
          10,
          357,
          14
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "read_json",
          176,
          178,
          177,
          10,
          177,
          24,
          176,
          15,
          178,
          27
        ],
        [
          "write_json",
          181,
          183,
          182,
          10,
          182,
          24,
          181,
          16,
          183,
          26
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          269,
          10,
          269,
          32,
          263,
          34,
          273,
          35
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          320,
          30,
          320,
          95,
          308,
          30,
          324,
          49
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          369,
          30,
          369,
          95,
          345,
          30,
          372,
          23
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/convert_phi4_multimodal_weights_to_hf.py": [
        [
          "convert_and_save_processor",
          169,
          213,
          201,
          27,
          201,
          67,
          169,
          32,
          213,
          81
        ],
        [
          "read_json",
          138,
          140,
          139,
          10,
          139,
          24,
          138,
          15,
          140,
          27
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          196,
          23,
          196,
          59,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          199,
          22,
          199,
          58,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          208,
          26,
          208,
          66,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          210,
          34,
          210,
          81,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          213,
          33,
          213,
          80,
          169,
          32,
          213,
          81
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "convert_poolformer_checkpoint",
          93,
          195,
          109,
          26,
          109,
          91,
          93,
          35,
          113,
          20
        ]
      ],
      "transformers/src/transformers/models/pixtral/convert_pixtral_weights_to_hf.py": [
        [
          "convert_mistral_model",
          145,
          210,
          148,
          14,
          148,
          45,
          148,
          14,
          151,
          50
        ],
        [
          "main",
          213,
          241,
          240,
          35,
          240,
          63,
          240,
          35,
          240,
          31
        ]
      ],
      "transformers/src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py": [
        [
          "convert_trax_checkpoint_to_pytorch",
          185,
          198,
          191,
          10,
          191,
          40,
          185,
          40,
          198,
          53
        ]
      ],
      "transformers/src/transformers/models/resnet/convert_resnet_to_pytorch.py": [
        [
          "convert_weights_and_push",
          125,
          164,
          131,
          26,
          131,
          91,
          125,
          30,
          159,
          17
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          135,
          14,
          135,
          57,
          133,
          27,
          149,
          37
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "get_rt_detr_v2_config",
          37,
          73,
          43,
          26,
          43,
          91,
          37,
          27,
          48,
          38
        ]
      ],
      "transformers/src/transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          223,
          290,
          269,
          18,
          269,
          56,
          268,
          13,
          281,
          63
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "convert_segformer_checkpoint",
          120,
          368,
          153,
          26,
          153,
          91,
          153,
          16,
          157,
          19
        ],
        [
          "convert_segformer_checkpoint",
          120,
          368,
          153,
          26,
          153,
          91,
          144,
          24,
          157,
          19
        ]
      ],
      "transformers/src/transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_sew_checkpoint",
          235,
          302,
          281,
          18,
          281,
          56,
          280,
          13,
          293,
          63
        ]
      ],
      "transformers/src/transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": [
        [
          "get_rt_detr_config",
          35,
          84,
          41,
          26,
          41,
          91,
          35,
          24,
          46,
          35
        ]
      ],
      "transformers/src/transformers/models/speech_encoder_decoder/convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py": [
        [
          "create_vocab_dict",
          195,
          210,
          196,
          10,
          196,
          47,
          195,
          23,
          210,
          21
        ],
        [
          "convert_wav2vec2_checkpoint",
          214,
          284,
          268,
          10,
          268,
          72,
          215,
          5,
          284,
          63
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "convert_swiftformer_checkpoint",
          89,
          153,
          101,
          26,
          101,
          91,
          89,
          36,
          107,
          43
        ]
      ],
      "transformers/src/transformers/convert_slow_tokenizer.py": [
        [
          "__init__",
          550,
          569,
          559,
          14,
          559,
          59,
          550,
          18,
          563,
          48
        ],
        [
          "__init__",
          1416,
          1427,
          1425,
          14,
          1425,
          35,
          1416,
          18,
          1427,
          18
        ],
        [
          "__init__",
          1457,
          1467,
          1465,
          14,
          1465,
          35,
          1457,
          18,
          1467,
          18
        ],
        [
          "__init__",
          1546,
          1557,
          1555,
          14,
          1555,
          35,
          1546,
          18,
          1557,
          18
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_timm_to_pytorch.py": [
        [
          "get_swin_config",
          13,
          56,
          44,
          30,
          44,
          95,
          41,
          23,
          47,
          23
        ]
      ],
      "transformers/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py": [
        [
          "get_swinv2_config",
          30,
          89,
          68,
          30,
          68,
          95,
          65,
          23,
          71,
          23
        ],
        [
          "get_swinv2_config",
          30,
          89,
          77,
          30,
          77,
          95,
          74,
          23,
          80,
          23
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_swin_upernet_to_pytorch.py": [
        [
          "get_upernet_config",
          31,
          78,
          59,
          26,
          59,
          91,
          56,
          18,
          78,
          17
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "convert_textnet_checkpoint",
          116,
          181,
          119,
          10,
          119,
          30,
          116,
          32,
          124,
          62
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": [
        [
          "convert_gin_to_config",
          264,
          282,
          268,
          10,
          268,
          28,
          264,
          27,
          273,
          35
        ]
      ],
      "transformers/src/transformers/models/timesformer/convert_timesformer_to_pytorch.py": [
        [
          "get_timesformer_config",
          28,
          55,
          50,
          26,
          50,
          91,
          50,
          16,
          55,
          17
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          173,
          14,
          173,
          48,
          173,
          14,
          185,
          67
        ],
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          208,
          14,
          208,
          66,
          198,
          9,
          209,
          44
        ]
      ],
      "transformers/src/transformers/models/unispeech/convert_unispeech_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_unispeech_checkpoint",
          190,
          258,
          221,
          18,
          221,
          56,
          215,
          13,
          241,
          63
        ]
      ],
      "transformers/src/transformers/models/deprecated/van/convert_van_to_pytorch.py": [
        [
          "convert_weights_and_push",
          166,
          241,
          171,
          26,
          171,
          91,
          166,
          30,
          223,
          17
        ]
      ],
      "transformers/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py": [
        [
          "convert_vilt_checkpoint",
          168,
          282,
          184,
          30,
          184,
          95,
          180,
          21,
          208,
          32
        ]
      ],
      "transformers/src/transformers/models/vivit/convert_vivit_flax_to_pytorch.py": [
        [
          "get_vivit_config",
          43,
          54,
          50,
          26,
          50,
          91,
          44,
          14,
          54,
          17
        ],
        [
          "download_checkpoint",
          34,
          40,
          37,
          10,
          37,
          25,
          34,
          25,
          39,
          58
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_classifier_to_hf.py": [
        [
          "get_id2label_mapping",
          94,
          103,
          100,
          10,
          100,
          24,
          94,
          26,
          103,
          19
        ]
      ],
      "transformers/src/transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          165,
          262,
          196,
          26,
          196,
          91,
          192,
          5,
          202,
          31
        ]
      ],
      "transformers/src/transformers/models/videomae/convert_videomae_to_pytorch.py": [
        [
          "get_videomae_config",
          33,
          56,
          51,
          30,
          51,
          95,
          51,
          20,
          54,
          23
        ]
      ],
      "transformers/src/transformers/models/voxtral/convert_voxtral_weights_to_hf.py": [
        [
          "write_model",
          174,
          234,
          189,
          10,
          189,
          31,
          175,
          5,
          234,
          41
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_conformer/convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_conformer_checkpoint",
          220,
          294,
          254,
          18,
          254,
          56,
          248,
          13,
          274,
          63
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "read_txt_into_dict",
          74,
          84,
          76,
          10,
          76,
          28,
          74,
          24,
          77,
          48
        ],
        [
          "convert_wav2vec2_checkpoint",
          274,
          358,
          318,
          18,
          318,
          56,
          312,
          13,
          338,
          63
        ]
      ],
      "transformers/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          59,
          10,
          59,
          62,
          44,
          14,
          64,
          51
        ],
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          63,
          10,
          63,
          61,
          44,
          14,
          64,
          51
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "convert_checkpoint",
          185,
          261,
          187,
          10,
          187,
          31,
          185,
          24,
          205,
          38
        ]
      ],
      "transformers/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_xlnet_checkpoint_to_pytorch",
          198,
          226,
          225,
          10,
          225,
          62,
          217,
          5,
          226,
          40
        ]
      ],
      "transformers/utils/create_dependency_mapping.py": [
        [
          "extract_model_imports_from_file",
          70,
          81,
          73,
          10,
          73,
          47,
          70,
          37,
          77,
          30
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "get_yolos_config",
          34,
          66,
          61,
          26,
          61,
          91,
          58,
          25,
          66,
          17
        ]
      ],
      "transformers/.circleci/create_circleci_config.py": [
        [
          "__post_init__",
          98,
          129,
          123,
          22,
          123,
          36,
          123,
          22,
          126,
          47
        ],
        [
          "create_circleci_config",
          354,
          393,
          392,
          10,
          392,
          64,
          392,
          10,
          393,
          141
        ]
      ],
      "transformers/utils/custom_init_isort.py": [
        [
          "sort_imports",
          235,
          305,
          243,
          10,
          243,
          37,
          235,
          18,
          247,
          38
        ],
        [
          "sort_imports",
          235,
          305,
          304,
          18,
          304,
          50,
          303,
          13,
          305,
          47
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "update_relative_imports",
          112,
          124,
          123,
          10,
          123,
          28,
          123,
          10,
          124,
          42
        ],
        [
          "insert_tip_to_model_doc",
          59,
          77,
          62,
          10,
          62,
          34,
          59,
          29,
          69,
          21
        ],
        [
          "insert_tip_to_model_doc",
          59,
          77,
          76,
          10,
          76,
          34,
          76,
          10,
          77,
          43
        ],
        [
          "update_relative_imports",
          112,
          124,
          113,
          10,
          113,
          28,
          112,
          29,
          117,
          37
        ],
        [
          "remove_copied_from_statements",
          127,
          143,
          133,
          14,
          133,
          33,
          132,
          21,
          137,
          42
        ],
        [
          "remove_copied_from_statements",
          127,
          143,
          142,
          14,
          142,
          33,
          142,
          14,
          143,
          46
        ],
        [
          "update_main_init_file",
          173,
          193,
          181,
          10,
          181,
          28,
          173,
          27,
          185,
          23
        ],
        [
          "update_main_init_file",
          173,
          193,
          189,
          10,
          189,
          28,
          189,
          10,
          193,
          47
        ],
        [
          "remove_model_references_from_file",
          196,
          216,
          206,
          10,
          206,
          28,
          196,
          39,
          210,
          51
        ],
        [
          "remove_model_references_from_file",
          196,
          216,
          215,
          10,
          215,
          28,
          215,
          10,
          216,
          42
        ],
        [
          "remove_model_config_classes_from_config_check",
          219,
          266,
          227,
          10,
          227,
          28,
          219,
          51,
          235,
          51
        ],
        [
          "remove_model_config_classes_from_config_check",
          219,
          266,
          265,
          10,
          265,
          28,
          265,
          10,
          266,
          42
        ],
        [
          "add_models_to_deprecated_models_in_config_auto",
          269,
          300,
          275,
          10,
          275,
          28,
          269,
          52,
          281,
          39
        ],
        [
          "add_models_to_deprecated_models_in_config_auto",
          269,
          300,
          299,
          10,
          299,
          28,
          299,
          10,
          300,
          42
        ]
      ],
      "transformers/utils/download_glue_data.py": [
        [
          "format_mrpc",
          57,
          106,
          78,
          10,
          78,
          69,
          75,
          5,
          79,
          25
        ],
        [
          "format_mrpc",
          57,
          106,
          83,
          9,
          83,
          46,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          84,
          9,
          84,
          71,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          85,
          9,
          85,
          69,
          83,
          9,
          90,
          26
        ],
        [
          "format_mrpc",
          57,
          106,
          98,
          9,
          98,
          45,
          98,
          9,
          103,
          42
        ],
        [
          "format_mrpc",
          57,
          106,
          99,
          9,
          99,
          70,
          98,
          9,
          103,
          42
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1295,
          10,
          1295,
          67,
          1294,
          36,
          1299,
          38
        ],
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1297,
          10,
          1297,
          52,
          1294,
          36,
          1299,
          38
        ],
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1317,
          10,
          1317,
          80,
          1317,
          10,
          1318,
          65
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1401,
          14,
          1401,
          72,
          1401,
          14,
          1402,
          51
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1409,
          10,
          1409,
          72,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1412,
          10,
          1412,
          80,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1418,
          10,
          1418,
          67,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1424,
          10,
          1424,
          66,
          1408,
          26,
          1431,
          84
        ],
        [
          "create_tiny_models",
          1321,
          1431,
          1428,
          10,
          1428,
          73,
          1408,
          26,
          1431,
          84
        ]
      ],
      "transformers/utils/extract_warnings.py": [
        [
          "extract_warnings_from_single_artifact",
          15,
          64,
          47,
          22,
          47,
          36,
          47,
          22,
          48,
          34
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_relative_imports",
          125,
          143,
          135,
          10,
          135,
          44,
          125,
          26,
          143,
          38
        ],
        [
          "get_imports",
          178,
          230,
          188,
          10,
          188,
          41,
          178,
          17,
          230,
          35
        ],
        [
          "check_python_requirements",
          779,
          832,
          795,
          14,
          795,
          36,
          794,
          9,
          795,
          36
        ]
      ],
      "transformers/src/transformers/models/auto/feature_extraction_auto.py": [
        [
          "get_feature_extractor_config",
          106,
          201,
          200,
          10,
          200,
          53,
          200,
          10,
          201,
          32
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "get_feature_extractor_dict",
          417,
          529,
          512,
          18,
          512,
          72,
          467,
          47,
          512,
          72
        ],
        [
          "get_feature_extractor_dict",
          417,
          529,
          512,
          18,
          512,
          72,
          510,
          9,
          512,
          72
        ],
        [
          "from_json_file",
          584,
          600,
          597,
          14,
          597,
          46,
          584,
          24,
          600,
          44
        ],
        [
          "to_json_file",
          623,
          632,
          631,
          14,
          631,
          56,
          623,
          22,
          632,
          47
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "download_artifact",
          93,
          109,
          108,
          10,
          108,
          30,
          104,
          14,
          109,
          34
        ]
      ],
      "transformers/utils/get_pr_run_slow_jobs.py": [
        [
          "get_jobs_to_run",
          10,
          46,
          15,
          10,
          15,
          29,
          15,
          10,
          34,
          27
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_last_daily_ci_reports",
          123,
          159,
          155,
          26,
          155,
          40,
          155,
          26,
          157,
          56
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          714,
          14,
          714,
          69,
          714,
          14,
          716,
          47
        ],
        [
          "is_timm_local_checkpoint",
          693,
          718,
          708,
          14,
          708,
          40,
          708,
          14,
          710,
          47
        ]
      ],
      "transformers/src/transformers/hf_argparser.py": [
        [
          "parse_json_file",
          386,
          408,
          405,
          14,
          405,
          52,
          387,
          9,
          408,
          29
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "get_checkpoint_shard_files",
          1011,
          1078,
          1049,
          10,
          1049,
          29,
          1049,
          10,
          1058,
          51
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "get_image_processor_dict",
          264,
          382,
          365,
          18,
          365,
          70,
          320,
          45,
          365,
          70
        ],
        [
          "get_image_processor_dict",
          264,
          382,
          365,
          18,
          365,
          70,
          363,
          9,
          365,
          70
        ],
        [
          "from_json_file",
          442,
          458,
          455,
          14,
          455,
          46,
          442,
          24,
          458,
          42
        ],
        [
          "to_json_file",
          481,
          490,
          489,
          14,
          489,
          56,
          481,
          22,
          490,
          47
        ]
      ],
      "transformers/src/transformers/models/auto/image_processing_auto.py": [
        [
          "get_image_processor_config",
          243,
          338,
          337,
          10,
          337,
          53,
          337,
          10,
          338,
          32
        ]
      ],
      "transformers/src/transformers/models/oneformer/image_processing_oneformer.py": [
        [
          "load_metadata",
          382,
          397,
          394,
          10,
          394,
          25,
          394,
          10,
          397,
          21
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/lightning_base.py": [
        [
          "on_test_end",
          287,
          296,
          292,
          14,
          292,
          48,
          287,
          21,
          293,
          38
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          41,
          100,
          82,
          22,
          82,
          54,
          79,
          17,
          87,
          83
        ],
        [
          "__init__",
          41,
          100,
          72,
          22,
          72,
          53,
          71,
          25,
          76,
          17
        ],
        [
          "__init__",
          41,
          100,
          96,
          22,
          96,
          53,
          95,
          25,
          100,
          17
        ],
        [
          "__init__",
          110,
          129,
          124,
          14,
          124,
          46,
          122,
          9,
          129,
          21
        ],
        [
          "__init__",
          139,
          173,
          155,
          14,
          155,
          46,
          153,
          9,
          161,
          32
        ],
        [
          "__init__",
          139,
          173,
          159,
          14,
          159,
          45,
          153,
          9,
          161,
          32
        ],
        [
          "__init__",
          187,
          226,
          205,
          18,
          205,
          50,
          204,
          28,
          208,
          42
        ],
        [
          "__init__",
          335,
          418,
          384,
          22,
          384,
          53,
          383,
          25,
          388,
          17
        ],
        [
          "__init__",
          335,
          418,
          393,
          22,
          393,
          54,
          390,
          17,
          393,
          59
        ],
        [
          "__init__",
          335,
          418,
          414,
          22,
          414,
          53,
          413,
          25,
          418,
          17
        ]
      ],
      "transformers/src/transformers/utils/logging.py": [
        [
          "_configure_library_root_logger",
          80,
          104,
          90,
          26,
          90,
          46,
          90,
          26,
          90,
          22
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "save_model_architecture_to_file",
          754,
          761,
          755,
          10,
          755,
          59,
          754,
          37,
          756,
          45
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "create_import_structure_from_path",
          2117,
          2312,
          2203,
          14,
          2203,
          73,
          2203,
          14,
          2216,
          72
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "log_model_debug_trace",
          228,
          268,
          244,
          10,
          244,
          29,
          238,
          5,
          268,
          41
        ],
        [
          "log_model_debug_trace",
          228,
          268,
          267,
          10,
          267,
          32,
          238,
          5,
          268,
          41
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "from_json_file",
          225,
          230,
          227,
          14,
          227,
          46,
          225,
          24,
          230,
          30
        ],
        [
          "to_json_file",
          247,
          250,
          249,
          14,
          249,
          56,
          247,
          22,
          250,
          47
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "load_sharded_checkpoint",
          372,
          444,
          409,
          10,
          409,
          48,
          407,
          18,
          419,
          13
        ],
        [
          "load_state_dict",
          469,
          536,
          523,
          18,
          523,
          38,
          521,
          5,
          523,
          38
        ],
        [
          "_can_set_attn_implementation",
          2621,
          2636,
          2626,
          14,
          2626,
          34,
          2621,
          38,
          2629,
          62
        ],
        [
          "save_pretrained",
          3648,
          4088,
          4063,
          18,
          4063,
          61,
          4060,
          31,
          4070,
          13
        ],
        [
          "from_pretrained",
          4261,
          4989,
          4623,
          22,
          4623,
          69,
          4623,
          22,
          4625,
          49
        ]
      ],
      "transformers/utils/models_to_deprecate.py": [
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          273,
          14,
          273,
          42,
          273,
          14,
          274,
          47
        ],
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          188,
          14,
          188,
          42,
          188,
          14,
          191,
          46
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "build_index",
          417,
          450,
          447,
          14,
          447,
          53,
          440,
          9,
          450,
          22
        ],
        [
          "build_index",
          417,
          450,
          445,
          14,
          445,
          56,
          440,
          9,
          450,
          22
        ],
        [
          "analyze_file",
          518,
          576,
          538,
          14,
          538,
          82,
          536,
          16,
          559,
          63
        ],
        [
          "analyze_file",
          518,
          576,
          541,
          14,
          541,
          79,
          536,
          16,
          559,
          63
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "get_module_source_from_name",
          48,
          56,
          54,
          10,
          54,
          49,
          54,
          10,
          56,
          22
        ],
        [
          "convert_modular_file",
          1686,
          1715,
          1693,
          14,
          1693,
          54,
          1691,
          22,
          1699,
          68
        ],
        [
          "save_modeling_files",
          1718,
          1727,
          1726,
          14,
          1726,
          55,
          1722,
          28,
          1727,
          47
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "retrieve_artifact",
          276,
          288,
          283,
          22,
          283,
          69,
          283,
          62,
          283,
          69
        ]
      ],
      "transformers/examples/pytorch/old_test_xla_examples.py": [
        [
          "get_results",
          31,
          39,
          35,
          14,
          35,
          23,
          35,
          14,
          39,
          18
        ]
      ],
      "transformers/.circleci/parse_test_outputs.py": [
        [
          "parse_pytest_output",
          5,
          17,
          8,
          10,
          8,
          29,
          5,
          25,
          9,
          24
        ],
        [
          "parse_pytest_failure_output",
          19,
          33,
          22,
          10,
          22,
          29,
          19,
          33,
          23,
          24
        ],
        [
          "parse_pytest_errors_output",
          35,
          50,
          39,
          10,
          39,
          29,
          35,
          32,
          40,
          24
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "model_failures",
          372,
          528,
          484,
          14,
          484,
          51,
          457,
          17,
          497,
          45
        ],
        [
          "model_failures",
          372,
          528,
          494,
          14,
          494,
          51,
          457,
          17,
          497,
          45
        ],
        [
          "model_failures",
          372,
          528,
          515,
          26,
          515,
          63,
          508,
          35,
          526,
          21
        ],
        [
          "payload",
          556,
          698,
          602,
          22,
          602,
          59,
          596,
          28,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          602,
          22,
          602,
          59,
          600,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          602,
          22,
          602,
          59,
          598,
          32,
          618,
          48
        ],
        [
          "payload",
          556,
          698,
          636,
          22,
          636,
          59,
          635,
          29,
          663,
          40
        ],
        [
          "payload",
          556,
          698,
          636,
          22,
          636,
          59,
          635,
          29,
          670,
          156
        ],
        [
          "retrieve_artifact",
          944,
          959,
          954,
          22,
          954,
          60,
          954,
          22,
          954,
          60
        ]
      ],
      "transformers/examples/legacy/benchmarking/plot_csv_file.py": [
        [
          "__init__",
          84,
          103,
          88,
          14,
          88,
          49,
          84,
          18,
          90,
          29
        ]
      ],
      "transformers/utils/process_test_artifacts.py": [
        [
          "count_lines",
          30,
          36,
          33,
          14,
          33,
          32,
          30,
          17,
          33,
          32
        ],
        [
          "process_artifacts",
          47,
          69,
          49,
          10,
          49,
          30,
          47,
          23,
          54,
          37
        ],
        [
          "process_artifacts",
          47,
          69,
          68,
          10,
          68,
          31,
          68,
          10,
          69,
          48
        ]
      ],
      "transformers/src/transformers/models/bark/processing_bark.py": [
        [
          "from_pretrained",
          67,
          122,
          112,
          22,
          112,
          50,
          112,
          22,
          113,
          38
        ],
        [
          "save_pretrained",
          124,
          178,
          175,
          18,
          175,
          86,
          175,
          18,
          176,
          46
        ]
      ],
      "transformers/src/transformers/models/auto/processing_auto.py": [
        [
          "from_pretrained",
          204,
          425,
          350,
          22,
          350,
          66,
          350,
          22,
          354,
          69
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "to_json_file",
          707,
          716,
          715,
          14,
          715,
          56,
          707,
          22,
          716,
          88
        ],
        [
          "save_pretrained",
          723,
          896,
          820,
          22,
          820,
          81,
          820,
          22,
          822,
          88
        ],
        [
          "save_pretrained",
          723,
          896,
          828,
          30,
          828,
          89,
          828,
          30,
          830,
          96
        ],
        [
          "save_pretrained",
          723,
          896,
          834,
          30,
          834,
          75,
          832,
          25,
          836,
          82
        ],
        [
          "save_pretrained",
          723,
          896,
          842,
          22,
          842,
          82,
          840,
          21,
          844,
          89
        ],
        [
          "save_pretrained",
          723,
          896,
          876,
          22,
          876,
          77,
          869,
          41,
          877,
          54
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1072,
          18,
          1072,
          68,
          1072,
          18,
          1075,
          58
        ],
        [
          "dictcomp",
          1083,
          1084,
          1084,
          32,
          1084,
          73,
          1085,
          21,
          1084,
          80
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1088,
          22,
          1088,
          81,
          1088,
          22,
          1089,
          45
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1106,
          22,
          1106,
          68,
          1104,
          13,
          1106,
          68
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1133,
          26,
          1133,
          83,
          1133,
          26,
          1135,
          36
        ]
      ],
      "transformers/src/transformers/utils/quantization_config.py": [
        [
          "to_json_file",
          137,
          152,
          148,
          14,
          148,
          56,
          137,
          22,
          152,
          37
        ]
      ],
      "transformers/utils/release.py": [
        [
          "update_version_in_file",
          81,
          96,
          90,
          10,
          90,
          57,
          81,
          28,
          96,
          21
        ],
        [
          "update_version_in_file",
          81,
          96,
          95,
          10,
          95,
          57,
          81,
          28,
          96,
          21
        ],
        [
          "get_version",
          153,
          160,
          157,
          10,
          157,
          41,
          154,
          5,
          160,
          51
        ]
      ],
      "transformers/examples/legacy/seq2seq/rouge_cli.py": [
        [
          "calculate_rouge_path",
          20,
          27,
          22,
          36,
          22,
          50,
          20,
          26,
          25,
          28
        ],
        [
          "calculate_rouge_path",
          20,
          27,
          23,
          35,
          23,
          48,
          20,
          26,
          25,
          28
        ]
      ],
      "transformers/src/transformers/models/rag/retrieval_rag.py": [
        [
          "_load_passages",
          133,
          145,
          143,
          14,
          143,
          38,
          143,
          14,
          145,
          23
        ],
        [
          "_deserialize_index",
          147,
          163,
          159,
          14,
          159,
          43,
          159,
          14,
          161,
          63
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "generate_summary_report",
          164,
          190,
          186,
          10,
          186,
          32,
          165,
          5,
          190,
          23
        ]
      ],
      "transformers/examples/legacy/run_chinese_ref.py": [
        [
          "main",
          116,
          129,
          119,
          10,
          119,
          47,
          116,
          10,
          129,
          26
        ],
        [
          "main",
          116,
          129,
          127,
          10,
          127,
          52,
          116,
          10,
          129,
          26
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_classification.py": [
        [
          "main",
          286,
          754,
          735,
          18,
          735,
          47,
          735,
          18,
          738,
          57
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_distributed_eval.py": [
        [
          "run_generate",
          119,
          227,
          207,
          14,
          207,
          27,
          206,
          20,
          212,
          46
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval.py": [
        [
          "run_generate",
          85,
          178,
          176,
          27,
          176,
          52,
          176,
          9,
          176,
          53
        ],
        [
          "run_generate",
          85,
          178,
          133,
          86,
          133,
          106,
          133,
          86,
          134,
          21
        ],
        [
          "run_generate",
          85,
          178,
          162,
          39,
          162,
          58,
          161,
          16,
          167,
          21
        ],
        [
          "run_generate",
          85,
          178,
          163,
          42,
          163,
          66,
          161,
          16,
          167,
          21
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_clm_no_trainer.py": [
        [
          "main",
          268,
          722,
          311,
          18,
          311,
          72,
          308,
          19,
          312,
          44
        ],
        [
          "main",
          268,
          722,
          718,
          18,
          718,
          77,
          718,
          18,
          719,
          56
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue.py": [
        [
          "main",
          231,
          654,
          634,
          22,
          634,
          51,
          634,
          22,
          637,
          61
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "pil_loader",
          79,
          82,
          80,
          10,
          80,
          25,
          79,
          16,
          82,
          32
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_glue_no_trainer.py": [
        [
          "main",
          235,
          692,
          273,
          18,
          273,
          72,
          270,
          19,
          274,
          44
        ],
        [
          "main",
          235,
          692,
          688,
          14,
          688,
          73,
          687,
          51,
          689,
          37
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_fim_no_trainer.py": [
        [
          "main",
          328,
          911,
          907,
          18,
          907,
          77,
          907,
          18,
          908,
          56
        ],
        [
          "main",
          328,
          911,
          377,
          18,
          377,
          72,
          373,
          23,
          378,
          44
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_glue_model_parallelism.py": [
        [
          "main",
          188,
          529,
          521,
          22,
          521,
          48,
          521,
          22,
          524,
          61
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification_no_trainer.py": [
        [
          "main",
          234,
          650,
          278,
          18,
          278,
          72,
          275,
          19,
          279,
          44
        ],
        [
          "main",
          234,
          650,
          646,
          18,
          646,
          77,
          645,
          55,
          647,
          41
        ]
      ],
      "transformers/examples/legacy/run_language_modeling.py": [
        [
          "main",
          197,
          364,
          356,
          18,
          356,
          44,
          356,
          18,
          358,
          48
        ]
      ],
      "transformers/examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py": [
        [
          "handle_repository_creation",
          387,
          410,
          401,
          18,
          401,
          72,
          398,
          19,
          402,
          44
        ],
        [
          "main",
          413,
          747,
          731,
          18,
          731,
          77,
          731,
          18,
          736,
          31
        ]
      ],
      "transformers/examples/pytorch/image-pretraining/run_mim_no_trainer.py": [
        [
          "main",
          384,
          804,
          430,
          18,
          430,
          72,
          427,
          19,
          431,
          44
        ]
      ],
      "transformers/examples/legacy/multiple_choice/run_multiple_choice.py": [
        [
          "main",
          90,
          234,
          226,
          18,
          226,
          44,
          226,
          18,
          228,
          48
        ]
      ],
      "transformers/examples/pytorch/language-modeling/run_mlm_no_trainer.py": [
        [
          "main",
          275,
          760,
          318,
          18,
          318,
          72,
          315,
          19,
          319,
          44
        ],
        [
          "main",
          275,
          760,
          756,
          18,
          756,
          77,
          756,
          18,
          757,
          56
        ]
      ],
      "transformers/examples/legacy/token-classification/run_ner.py": [
        [
          "main",
          101,
          315,
          277,
          18,
          277,
          44,
          277,
          18,
          279,
          48
        ],
        [
          "main",
          101,
          315,
          303,
          18,
          303,
          52,
          303,
          18,
          304,
          49
        ],
        [
          "main",
          101,
          315,
          311,
          18,
          311,
          56,
          311,
          18,
          313,
          94
        ],
        [
          "main",
          101,
          315,
          312,
          22,
          312,
          71,
          311,
          18,
          313,
          94
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner_no_trainer.py": [
        [
          "main",
          284,
          835,
          322,
          18,
          322,
          72,
          319,
          19,
          323,
          44
        ],
        [
          "main",
          284,
          835,
          825,
          18,
          825,
          77,
          825,
          18,
          827,
          53
        ]
      ],
      "transformers/examples/pytorch/token-classification/run_ner.py": [
        [
          "main",
          228,
          652,
          636,
          18,
          636,
          51,
          636,
          18,
          637,
          50
        ]
      ],
      "transformers/examples/legacy/run_openai_gpt.py": [
        [
          "load_rocstories_dataset",
          62,
          70,
          64,
          10,
          64,
          45,
          62,
          29,
          68,
          27
        ],
        [
          "main",
          104,
          315,
          311,
          14,
          311,
          40,
          307,
          22,
          313,
          44
        ]
      ],
      "transformers/examples/pytorch/object-detection/run_object_detection_no_trainer.py": [
        [
          "main",
          411,
          796,
          449,
          18,
          449,
          72,
          446,
          19,
          450,
          44
        ],
        [
          "main",
          411,
          796,
          780,
          18,
          780,
          77,
          780,
          18,
          785,
          31
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py": [
        [
          "main",
          299,
          1057,
          342,
          18,
          342,
          72,
          339,
          19,
          343,
          44
        ],
        [
          "save_prefixed_metrics",
          64,
          84,
          83,
          10,
          83,
          55,
          83,
          10,
          84,
          39
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          268,
          26,
          268,
          86,
          268,
          16,
          307,
          30
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "main",
          253,
          637,
          291,
          18,
          291,
          72,
          288,
          19,
          292,
          44
        ],
        [
          "main",
          253,
          637,
          327,
          26,
          327,
          86,
          327,
          16,
          345,
          46
        ],
        [
          "main",
          253,
          637,
          633,
          18,
          633,
          77,
          631,
          89,
          634,
          51
        ]
      ],
      "transformers/examples/pytorch/question-answering/run_qa_no_trainer.py": [
        [
          "save_prefixed_metrics",
          69,
          89,
          88,
          10,
          88,
          55,
          88,
          10,
          89,
          39
        ],
        [
          "main",
          338,
          1035,
          381,
          18,
          381,
          72,
          378,
          19,
          382,
          44
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "main",
          419,
          839,
          580,
          22,
          580,
          42,
          571,
          17,
          581,
          47
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "main",
          396,
          837,
          584,
          22,
          584,
          42,
          584,
          22,
          585,
          47
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "read_swag_examples",
          98,
          121,
          99,
          10,
          99,
          43,
          98,
          24,
          102,
          18
        ],
        [
          "evaluate",
          413,
          470,
          464,
          10,
          464,
          36,
          459,
          17,
          466,
          40
        ]
      ],
      "transformers/examples/pytorch/multiple-choice/run_swag_no_trainer.py": [
        [
          "main",
          238,
          654,
          281,
          18,
          281,
          72,
          278,
          19,
          282,
          44
        ],
        [
          "main",
          238,
          654,
          650,
          18,
          650,
          77,
          649,
          55,
          651,
          41
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization_no_trainer.py": [
        [
          "main",
          339,
          809,
          392,
          18,
          392,
          72,
          389,
          19,
          393,
          44
        ],
        [
          "main",
          339,
          809,
          808,
          18,
          808,
          77,
          807,
          55,
          809,
          41
        ]
      ],
      "transformers/examples/pytorch/summarization/run_summarization.py": [
        [
          "main",
          327,
          775,
          755,
          22,
          755,
          54,
          748,
          31,
          756,
          56
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation.py": [
        [
          "main",
          275,
          698,
          677,
          22,
          677,
          72,
          670,
          31,
          678,
          56
        ]
      ],
      "transformers/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py": [
        [
          "main",
          406,
          804,
          443,
          18,
          443,
          72,
          440,
          19,
          444,
          44
        ]
      ],
      "transformers/examples/pytorch/translation/run_translation_no_trainer.py": [
        [
          "main",
          329,
          796,
          369,
          18,
          369,
          72,
          366,
          19,
          370,
          44
        ],
        [
          "main",
          329,
          796,
          792,
          14,
          792,
          73,
          792,
          14,
          793,
          61
        ]
      ],
      "transformers/examples/pytorch/text-classification/run_xnli.py": [
        [
          "main",
          194,
          461,
          457,
          18,
          457,
          47,
          457,
          18,
          459,
          57
        ]
      ],
      "transformers/utils/sort_auto_mappings.py": [
        [
          "sort_auto_mapping",
          50,
          99,
          62,
          10,
          62,
          43,
          50,
          23,
          67,
          12
        ],
        [
          "sort_auto_mapping",
          50,
          99,
          96,
          14,
          96,
          47,
          96,
          14,
          97,
          41
        ]
      ],
      "transformers/setup.py": [
        [
          "run",
          238,
          252,
          251,
          14,
          251,
          62,
          238,
          13,
          252,
          39
        ]
      ],
      "transformers/src/transformers/data/metrics/squad_metrics.py": [
        [
          "compute_predictions_logits",
          383,
          587,
          576,
          14,
          576,
          46,
          575,
          8,
          583,
          32
        ],
        [
          "compute_predictions_logits",
          383,
          587,
          580,
          14,
          580,
          41,
          575,
          8,
          583,
          32
        ],
        [
          "compute_predictions_logits",
          383,
          587,
          584,
          14,
          584,
          49,
          584,
          14,
          585,
          71
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          769,
          10,
          769,
          42,
          769,
          10,
          775,
          30
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          772,
          10,
          772,
          37,
          769,
          10,
          775,
          30
        ],
        [
          "compute_predictions_log_probs",
          590,
          779,
          776,
          14,
          776,
          49,
          776,
          14,
          777,
          71
        ]
      ],
      "transformers/examples/legacy/token-classification/tasks.py": [
        [
          "read_examples_from_file",
          17,
          43,
          23,
          14,
          23,
          46,
          20,
          21,
          26,
          25
        ],
        [
          "get_labels",
          58,
          66,
          60,
          18,
          60,
          27,
          60,
          18,
          62,
          32
        ],
        [
          "get_labels",
          74,
          104,
          76,
          18,
          76,
          27,
          76,
          18,
          78,
          32
        ],
        [
          "read_examples_from_file",
          108,
          126,
          115,
          14,
          115,
          46,
          111,
          21,
          116,
          41
        ],
        [
          "get_labels",
          139,
          162,
          141,
          18,
          141,
          27,
          141,
          18,
          142,
          44
        ]
      ],
      "transformers/src/transformers/data/processors/squad.py": [
        [
          "get_train_examples",
          500,
          520,
          516,
          14,
          518,
          9,
          517,
          36,
          520,
          57
        ],
        [
          "get_dev_examples",
          522,
          541,
          537,
          14,
          539,
          9,
          538,
          36,
          541,
          55
        ]
      ],
      "transformers/src/transformers/integrations/tensor_parallel.py": [
        [
          "initialize_tensor_parallelism",
          41,
          94,
          89,
          22,
          89,
          42,
          86,
          16,
          89,
          18
        ],
        [
          "initialize_tensor_parallelism",
          41,
          94,
          88,
          22,
          88,
          42,
          86,
          16,
          89,
          18
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "get_results",
          49,
          57,
          53,
          14,
          53,
          23,
          53,
          14,
          57,
          18
        ]
      ],
      "transformers/tests/utils/test_add_new_model_like.py": [
        [
          "assertFileIsEqual",
          84,
          87,
          85,
          14,
          85,
          32,
          84,
          27,
          87,
          57
        ],
        [
          "assertInFile",
          89,
          92,
          90,
          14,
          90,
          32,
          89,
          22,
          92,
          42
        ]
      ],
      "transformers/tests/repo_utils/test_check_copies.py": [
        [
          "replace_in_file",
          241,
          248,
          242,
          10,
          242,
          41,
          241,
          21,
          248,
          24
        ],
        [
          "replace_in_file",
          241,
          248,
          247,
          10,
          247,
          60,
          241,
          21,
          248,
          24
        ],
        [
          "create_tmp_repo",
          251,
          275,
          274,
          14,
          274,
          93,
          271,
          9,
          275,
          25
        ],
        [
          "test_is_copy_consistent",
          310,
          332,
          331,
          22,
          331,
          58,
          310,
          33,
          332,
          67
        ],
        [
          "test_is_copy_consistent_with_ignored_no_match",
          344,
          368,
          367,
          22,
          367,
          58,
          344,
          55,
          368,
          70
        ]
      ],
      "transformers/tests/models/auto/test_configuration_auto.py": [
        [
          "test_pattern_matching_fallback",
          63,
          71,
          68,
          18,
          68,
          63,
          63,
          40,
          71,
          57
        ]
      ],
      "transformers/tests/utils/test_configuration_utils.py": [
        [
          "test_local_versioning",
          237,
          257,
          244,
          48,
          244,
          100,
          237,
          31,
          257,
          64
        ]
      ],
      "transformers/tests/deepspeed/test_deepspeed.py": [
        [
          "load_json",
          81,
          83,
          82,
          10,
          82,
          19,
          81,
          15,
          83,
          27
        ],
        [
          "setUp",
          417,
          450,
          439,
          14,
          439,
          63,
          417,
          15,
          447,
          27
        ],
        [
          "setUp",
          417,
          450,
          441,
          14,
          441,
          63,
          417,
          15,
          447,
          27
        ]
      ],
      "transformers/tests/trainer/test_data_collator.py": [
        [
          "setUp",
          46,
          52,
          51,
          14,
          51,
          57,
          46,
          15,
          52,
          73
        ],
        [
          "setUp",
          721,
          727,
          726,
          14,
          726,
          57,
          721,
          15,
          727,
          73
        ],
        [
          "setUp",
          1043,
          1049,
          1048,
          14,
          1048,
          57,
          1043,
          15,
          1049,
          73
        ],
        [
          "setUp",
          1548,
          1554,
          1553,
          14,
          1553,
          57,
          1548,
          15,
          1554,
          73
        ]
      ],
      "transformers/tests/utils/test_dynamic_module_utils.py": [
        [
          "test_import_parsing",
          123,
          129,
          125,
          10,
          125,
          33,
          123,
          25,
          129,
          35
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_cached_file",
          44,
          62,
          51,
          14,
          51,
          58,
          51,
          14,
          62,
          107
        ],
        [
          "test_non_existence_is_cached",
          74,
          96,
          78,
          14,
          78,
          58,
          74,
          38,
          96,
          37
        ],
        [
          "test_get_file_from_repo_distant",
          114,
          156,
          155,
          29,
          155,
          47,
          114,
          41,
          156,
          52
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_new_image_processor_registration",
          208,
          237,
          221,
          21,
          221,
          48,
          220,
          22,
          221,
          48
        ],
        [
          "test_image_processor_from_local_directory_from_key",
          50,
          61,
          56,
          17,
          56,
          44,
          50,
          60,
          61,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_key",
          50,
          61,
          58,
          47,
          58,
          71,
          50,
          60,
          61,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_feature_extractor_key",
          63,
          77,
          72,
          17,
          72,
          44,
          63,
          78,
          77,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_feature_extractor_key",
          63,
          77,
          74,
          47,
          74,
          71,
          63,
          78,
          77,
          61
        ],
        [
          "test_image_processor_from_new_filename",
          79,
          90,
          85,
          17,
          85,
          44,
          79,
          48,
          90,
          61
        ],
        [
          "test_image_processor_from_new_filename",
          79,
          90,
          87,
          47,
          87,
          71,
          79,
          48,
          90,
          61
        ],
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          101,
          17,
          101,
          44,
          92,
          63,
          121,
          57
        ],
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          103,
          47,
          103,
          71,
          92,
          63,
          121,
          57
        ],
        [
          "test_image_processor_from_local_file",
          123,
          132,
          128,
          17,
          128,
          44,
          123,
          46,
          132,
          61
        ],
        [
          "test_new_image_processor_registration",
          208,
          237,
          223,
          51,
          223,
          75,
          223,
          28,
          223,
          75
        ]
      ],
      "transformers/tests/utils/test_hf_argparser.py": [
        [
          "test_11_parse_json",
          378,
          395,
          390,
          18,
          390,
          54,
          378,
          28,
          395,
          43
        ],
        [
          "test_12_parse_yaml",
          397,
          413,
          409,
          18,
          409,
          54,
          397,
          28,
          413,
          43
        ]
      ],
      "transformers/tests/models/conditional_detr/test_image_processing_conditional_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          170,
          212,
          173,
          14,
          173,
          77,
          170,
          59,
          178,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          215,
          263,
          218,
          14,
          218,
          86,
          215,
          58,
          225,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          383,
          271,
          14,
          271,
          77,
          267,
          49,
          280,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          386,
          507,
          391,
          14,
          391,
          86,
          386,
          48,
          399,
          58
        ]
      ],
      "transformers/tests/models/deformable_detr/test_image_processing_deformable_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          175,
          217,
          178,
          14,
          178,
          77,
          175,
          59,
          183,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          220,
          268,
          223,
          14,
          223,
          86,
          220,
          58,
          230,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          272,
          388,
          276,
          14,
          276,
          77,
          272,
          49,
          285,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          391,
          512,
          396,
          14,
          396,
          86,
          391,
          48,
          404,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          618,
          671,
          621,
          14,
          621,
          77,
          618,
          84,
          671,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          676,
          740,
          679,
          14,
          679,
          86,
          676,
          83,
          740,
          114
        ]
      ],
      "transformers/tests/models/detr/test_image_processing_detr.py": [
        [
          "test_should_raise_if_annotation_format_invalid",
          178,
          199,
          181,
          14,
          181,
          77,
          178,
          56,
          193,
          63
        ],
        [
          "test_valid_coco_detection_annotations",
          201,
          235,
          204,
          14,
          204,
          77,
          201,
          47,
          209,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          238,
          280,
          241,
          14,
          241,
          77,
          238,
          59,
          246,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          283,
          331,
          286,
          14,
          286,
          86,
          283,
          58,
          293,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          334,
          450,
          338,
          14,
          338,
          77,
          334,
          49,
          347,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          452,
          573,
          457,
          14,
          457,
          86,
          452,
          48,
          465,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          678,
          729,
          681,
          14,
          681,
          77,
          678,
          84,
          729,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          734,
          796,
          737,
          14,
          737,
          86,
          734,
          83,
          796,
          114
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          706,
          14,
          706,
          57,
          702,
          57,
          754,
          51
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          717,
          14,
          717,
          66,
          702,
          57,
          754,
          51
        ]
      ],
      "transformers/tests/models/grounding_dino/test_image_processing_grounding_dino.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          207,
          249,
          210,
          14,
          210,
          77,
          207,
          59,
          215,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          253,
          369,
          257,
          14,
          257,
          77,
          253,
          49,
          266,
          57
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          373,
          421,
          376,
          14,
          376,
          86,
          373,
          58,
          383,
          63
        ],
        [
          "test_batched_coco_panoptic_annotations",
          425,
          546,
          430,
          14,
          430,
          86,
          425,
          48,
          438,
          58
        ]
      ],
      "transformers/tests/models/oneformer/test_image_processing_oneformer.py": [
        [
          "test_can_load_with_local_metadata",
          359,
          378,
          370,
          22,
          370,
          45,
          367,
          13,
          378,
          64
        ]
      ],
      "transformers/tests/models/rt_detr/test_image_processing_rt_detr.py": [
        [
          "test_batched_coco_detection_annotations",
          267,
          379,
          271,
          14,
          271,
          77,
          267,
          49,
          280,
          57
        ],
        [
          "test_valid_coco_detection_annotations",
          125,
          159,
          128,
          14,
          128,
          77,
          125,
          47,
          133,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          162,
          204,
          165,
          14,
          165,
          77,
          162,
          59,
          170,
          63
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          385,
          436,
          388,
          14,
          388,
          77,
          385,
          84,
          436,
          114
        ]
      ],
      "transformers/tests/models/yolos/test_image_processing_yolos.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          226,
          268,
          229,
          14,
          229,
          77,
          226,
          59,
          234,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          271,
          319,
          274,
          14,
          274,
          86,
          271,
          58,
          281,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          323,
          439,
          327,
          14,
          327,
          77,
          323,
          49,
          336,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          442,
          564,
          447,
          14,
          447,
          86,
          442,
          48,
          455,
          58
        ]
      ],
      "transformers/tests/utils/test_import_structure.py": [
        [
          "test_transformers_specific_model_import",
          81,
          118,
          107,
          26,
          107,
          79,
          106,
          21,
          111,
          39
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_layer_pruning_behavior",
          96,
          122,
          103,
          22,
          103,
          39,
          96,
          41,
          106,
          43
        ],
        [
          "test_layer_pruning_behavior",
          96,
          122,
          118,
          22,
          118,
          39,
          113,
          18,
          122,
          99
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "test_load_img_base64_prefix",
          741,
          756,
          744,
          18,
          744,
          37,
          743,
          13,
          744,
          37
        ],
        [
          "test_load_img_base64_prefix",
          741,
          756,
          749,
          18,
          749,
          49,
          749,
          18,
          749,
          49
        ],
        [
          "test_load_img_base64",
          758,
          773,
          761,
          18,
          761,
          37,
          760,
          13,
          761,
          37
        ],
        [
          "test_load_img_base64",
          758,
          773,
          766,
          18,
          766,
          49,
          766,
          18,
          766,
          49
        ],
        [
          "test_load_img_base64_encoded_bytes",
          775,
          790,
          778,
          18,
          778,
          37,
          777,
          13,
          778,
          37
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "test_can_init_all_missing_weights",
          901,
          973,
          907,
          14,
          907,
          27,
          901,
          43,
          910,
          104
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "distributed_worker",
          110,
          193,
          153,
          18,
          153,
          40,
          153,
          18,
          157,
          38
        ],
        [
          "test_model_outputs",
          319,
          374,
          333,
          18,
          333,
          40,
          333,
          18,
          337,
          38
        ]
      ],
      "transformers/tests/models/hubert/test_modeling_hubert.py": [
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          508,
          26,
          508,
          50,
          505,
          18,
          508,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          510,
          26,
          510,
          50,
          510,
          26,
          510,
          50
        ]
      ],
      "transformers/tests/models/modernbert/test_modeling_modernbert.py": [
        [
          "test_saved_config_excludes_reference_compile",
          363,
          369,
          367,
          18,
          367,
          62,
          363,
          54,
          369,
          62
        ]
      ],
      "transformers/tests/models/mt5/test_modeling_mt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          688,
          26,
          688,
          50,
          685,
          18,
          688,
          50
        ],
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          690,
          26,
          690,
          50,
          690,
          26,
          690,
          50
        ]
      ],
      "transformers/tests/models/parakeet/test_modeling_parakeet.py": [
        [
          "test_1b_model_integration",
          330,
          352,
          336,
          14,
          336,
          36,
          330,
          35,
          352,
          76
        ],
        [
          "test_1b_model_integration_batched",
          355,
          378,
          362,
          14,
          362,
          36,
          355,
          43,
          378,
          76
        ]
      ]
    },
    "tempfile.mkdtemp": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUp",
          113,
          178,
          114,
          27,
          114,
          44,
          113,
          15,
          178,
          55
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_modeling_seamless_m4t.py": [
        [
          "setUp",
          632,
          635,
          635,
          27,
          635,
          44,
          632,
          15,
          635,
          23
        ]
      ],
      "transformers/tests/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py": [
        [
          "setUp",
          639,
          642,
          642,
          27,
          642,
          44,
          639,
          15,
          642,
          23
        ]
      ],
      "transformers/tests/models/align/test_processing_align.py": [
        [
          "setUp",
          39,
          72,
          40,
          27,
          40,
          44,
          39,
          15,
          72,
          46
        ]
      ],
      "transformers/tests/models/altclip/test_processing_altclip.py": [
        [
          "setUpClass",
          30,
          38,
          32,
          26,
          32,
          43,
          30,
          20,
          38,
          49
        ]
      ],
      "transformers/tests/models/aya_vision/test_processing_aya_vision.py": [
        [
          "setUpClass",
          39,
          64,
          40,
          26,
          40,
          43,
          39,
          20,
          64,
          23
        ]
      ],
      "transformers/tests/models/blip_2/test_processing_blip_2.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          49
        ]
      ],
      "transformers/tests/models/blip/test_processing_blip.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          49
        ]
      ],
      "transformers/tests/models/chinese_clip/test_processing_chinese_clip.py": [
        [
          "setUpClass",
          40,
          84,
          41,
          26,
          41,
          43,
          40,
          20,
          84,
          49
        ]
      ],
      "transformers/tests/models/bridgetower/test_processing_bridgetower.py": [
        [
          "setUpClass",
          38,
          46,
          39,
          26,
          39,
          43,
          38,
          20,
          46,
          49
        ]
      ],
      "transformers/tests/models/clip/test_processing_clip.py": [
        [
          "setUpClass",
          40,
          48,
          41,
          26,
          41,
          43,
          40,
          20,
          48,
          49
        ]
      ],
      "transformers/tests/models/bark/test_processing_bark.py": [
        [
          "setUp",
          28,
          34,
          30,
          27,
          30,
          44,
          28,
          15,
          34,
          41
        ]
      ],
      "transformers/tests/models/clap/test_processing_clap.py": [
        [
          "setUp",
          28,
          30,
          30,
          27,
          30,
          44,
          28,
          15,
          30,
          23
        ]
      ],
      "transformers/tests/models/clipseg/test_processing_clipseg.py": [
        [
          "setUp",
          39,
          65,
          40,
          27,
          40,
          44,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/chameleon/test_processing_chameleon.py": [
        [
          "setUpClass",
          37,
          46,
          38,
          26,
          38,
          43,
          37,
          20,
          46,
          23
        ]
      ],
      "transformers/tests/models/clvp/test_processing_clvp.py": [
        [
          "setUp",
          29,
          31,
          31,
          27,
          31,
          44,
          29,
          15,
          31,
          23
        ]
      ],
      "transformers/tests/models/aria/test_processing_aria.py": [
        [
          "setUpClass",
          35,
          66,
          36,
          26,
          36,
          43,
          35,
          20,
          66,
          25
        ]
      ],
      "transformers/tests/models/cohere2_vision/test_processing_cohere2_vision.py": [
        [
          "setUpClass",
          40,
          55,
          41,
          26,
          41,
          43,
          40,
          20,
          55,
          23
        ]
      ],
      "transformers/tests/models/colpali/test_processing_colpali.py": [
        [
          "setUpClass",
          45,
          51,
          46,
          26,
          46,
          43,
          45,
          20,
          51,
          49
        ]
      ],
      "transformers/tests/models/colqwen2/test_processing_colqwen2.py": [
        [
          "setUpClass",
          45,
          48,
          46,
          26,
          46,
          43,
          45,
          20,
          48,
          49
        ]
      ],
      "transformers/tests/models/deepseek_vl/test_processing_deepseek_vl.py": [
        [
          "setUp",
          35,
          51,
          36,
          27,
          36,
          44,
          35,
          15,
          51,
          50
        ]
      ],
      "transformers/tests/models/deepseek_vl_hybrid/test_processing_deepseek_vl_hybrid.py": [
        [
          "setUp",
          35,
          51,
          36,
          27,
          36,
          44,
          35,
          15,
          51,
          50
        ]
      ],
      "transformers/tests/models/csm/test_processing_csm.py": [
        [
          "setUpClass",
          40,
          48,
          47,
          26,
          47,
          43,
          40,
          20,
          48,
          49
        ]
      ],
      "transformers/tests/models/donut/test_processing_donut.py": [
        [
          "setUpClass",
          29,
          38,
          31,
          26,
          31,
          43,
          29,
          20,
          38,
          49
        ]
      ],
      "transformers/tests/models/emu3/test_processing_emu3.py": [
        [
          "setUpClass",
          35,
          54,
          36,
          26,
          36,
          43,
          35,
          20,
          54,
          23
        ]
      ],
      "transformers/tests/models/evolla/test_processing_evolla.py": [
        [
          "setUp",
          42,
          49,
          43,
          27,
          43,
          44,
          42,
          15,
          49,
          23
        ]
      ],
      "transformers/tests/models/flava/test_processing_flava.py": [
        [
          "setUp",
          46,
          81,
          47,
          27,
          47,
          44,
          46,
          15,
          81,
          46
        ]
      ],
      "transformers/tests/models/dia/test_processing_dia.py": [
        [
          "setUp",
          43,
          59,
          46,
          27,
          46,
          44,
          43,
          15,
          59,
          26
        ]
      ],
      "transformers/tests/models/gemma3/test_processing_gemma3.py": [
        [
          "setUpClass",
          38,
          59,
          39,
          26,
          39,
          43,
          38,
          20,
          59,
          23
        ]
      ],
      "transformers/tests/models/git/test_processing_git.py": [
        [
          "setUpClass",
          35,
          45,
          36,
          26,
          36,
          43,
          35,
          20,
          45,
          49
        ]
      ],
      "transformers/tests/models/gemma3n/test_processing_gemma3n.py": [
        [
          "setUp",
          38,
          42,
          41,
          27,
          41,
          60,
          38,
          15,
          42,
          20
        ]
      ],
      "transformers/tests/models/got_ocr2/test_processing_got_ocr2.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          23
        ]
      ],
      "transformers/tests/models/fuyu/test_processing_fuyu.py": [
        [
          "setUpClass",
          30,
          43,
          31,
          26,
          31,
          43,
          30,
          20,
          43,
          25
        ]
      ],
      "transformers/tests/models/idefics/test_processing_idefics.py": [
        [
          "setUpClass",
          47,
          57,
          48,
          26,
          48,
          43,
          47,
          20,
          57,
          22
        ]
      ],
      "transformers/tests/models/grounding_dino/test_processing_grounding_dino.py": [
        [
          "setUpClass",
          48,
          80,
          49,
          26,
          49,
          43,
          48,
          20,
          80,
          22
        ]
      ],
      "transformers/tests/models/idefics2/test_processing_idefics2.py": [
        [
          "setUpClass",
          40,
          67,
          41,
          26,
          41,
          43,
          40,
          20,
          67,
          25
        ]
      ],
      "transformers/tests/models/granite_speech/test_processing_granite_speech.py": [
        [
          "setUp",
          40,
          44,
          41,
          27,
          41,
          44,
          40,
          15,
          44,
          50
        ]
      ],
      "transformers/tests/models/florence2/test_processing_florence2.py": [
        [
          "setUpClass",
          38,
          50,
          39,
          26,
          39,
          43,
          38,
          20,
          50,
          23
        ]
      ],
      "transformers/tests/models/instructblip/test_processing_instructblip.py": [
        [
          "setUpClass",
          42,
          51,
          43,
          26,
          43,
          43,
          42,
          20,
          51,
          49
        ]
      ],
      "transformers/tests/models/internvl/test_processing_internvl.py": [
        [
          "setUpClass",
          43,
          78,
          44,
          26,
          44,
          43,
          43,
          20,
          78,
          23
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_processing_instructblipvideo.py": [
        [
          "setUpClass",
          45,
          54,
          46,
          26,
          46,
          43,
          45,
          20,
          54,
          49
        ]
      ],
      "transformers/tests/models/idefics3/test_processing_idefics3.py": [
        [
          "setUpClass",
          35,
          62,
          36,
          26,
          36,
          43,
          35,
          20,
          62,
          25
        ]
      ],
      "transformers/tests/models/janus/test_processing_janus.py": [
        [
          "setUp",
          30,
          46,
          31,
          27,
          31,
          44,
          30,
          15,
          46,
          50
        ]
      ],
      "transformers/tests/models/layoutxlm/test_processing_layoutxlm.py": [
        [
          "setUpClass",
          49,
          67,
          56,
          26,
          56,
          43,
          49,
          20,
          67,
          49
        ]
      ],
      "transformers/tests/models/llama4/test_processing_llama4.py": [
        [
          "setUpClass",
          35,
          43,
          36,
          26,
          36,
          43,
          35,
          20,
          43,
          23
        ]
      ],
      "transformers/tests/models/kosmos2/test_processing_kosmos2.py": [
        [
          "setUpClass",
          61,
          71,
          62,
          26,
          62,
          43,
          61,
          20,
          71,
          49
        ]
      ],
      "transformers/tests/models/llava/test_processing_llava.py": [
        [
          "setUpClass",
          35,
          44,
          36,
          26,
          36,
          43,
          35,
          20,
          44,
          23
        ]
      ],
      "transformers/tests/models/llava_next/test_processing_llava_next.py": [
        [
          "setUpClass",
          40,
          49,
          41,
          26,
          41,
          43,
          40,
          20,
          49,
          23
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_processing_layoutlmv2.py": [
        [
          "setUp",
          42,
          73,
          67,
          27,
          67,
          44,
          42,
          15,
          73,
          60
        ]
      ],
      "transformers/tests/models/llava_next_video/test_processing_llava_next_video.py": [
        [
          "setUpClass",
          41,
          54,
          42,
          26,
          42,
          43,
          41,
          20,
          54,
          23
        ]
      ],
      "transformers/tests/models/llava_onevision/test_processing_llava_onevision.py": [
        [
          "setUpClass",
          46,
          59,
          47,
          26,
          47,
          43,
          46,
          20,
          59,
          23
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_processing_layoutlmv3.py": [
        [
          "setUp",
          42,
          86,
          66,
          27,
          66,
          44,
          42,
          15,
          86,
          60
        ]
      ],
      "transformers/tests/models/lfm2_vl/test_processing_lfm2_vl.py": [
        [
          "setUpClass",
          42,
          70,
          43,
          26,
          43,
          43,
          42,
          20,
          70,
          36
        ]
      ],
      "transformers/tests/models/mgp_str/test_processing_mgp_str.py": [
        [
          "setUp",
          50,
          70,
          52,
          27,
          52,
          44,
          50,
          15,
          70,
          46
        ]
      ],
      "transformers/tests/models/mistral3/test_processing_mistral3.py": [
        [
          "setUpClass",
          39,
          56,
          48,
          26,
          48,
          43,
          39,
          20,
          56,
          23
        ]
      ],
      "transformers/tests/models/markuplm/test_processing_markuplm.py": [
        [
          "setUp",
          47,
          70,
          50,
          27,
          50,
          44,
          47,
          15,
          70,
          62
        ]
      ],
      "transformers/tests/models/musicgen/test_processing_musicgen.py": [
        [
          "setUp",
          53,
          55,
          55,
          27,
          55,
          44,
          53,
          15,
          55,
          23
        ]
      ],
      "transformers/tests/models/musicgen_melody/test_processing_musicgen_melody.py": [
        [
          "setUp",
          55,
          58,
          58,
          27,
          58,
          44,
          55,
          15,
          58,
          23
        ]
      ],
      "transformers/tests/models/omdet_turbo/test_processing_omdet_turbo.py": [
        [
          "setUpClass",
          48,
          68,
          49,
          26,
          49,
          43,
          48,
          20,
          68,
          21
        ]
      ],
      "transformers/tests/models/owlv2/test_processing_owlv2.py": [
        [
          "setUpClass",
          16,
          19,
          17,
          26,
          17,
          43,
          16,
          20,
          19,
          49
        ]
      ],
      "transformers/tests/models/mllama/test_processing_mllama.py": [
        [
          "setUpClass",
          40,
          51,
          50,
          26,
          50,
          43,
          40,
          20,
          51,
          49
        ]
      ],
      "transformers/tests/models/parakeet/test_processing_parakeet.py": [
        [
          "setUpClass",
          32,
          36,
          33,
          26,
          33,
          43,
          32,
          20,
          36,
          49
        ]
      ],
      "transformers/tests/models/paligemma/test_processing_paligemma.py": [
        [
          "setUpClass",
          37,
          45,
          38,
          26,
          38,
          43,
          37,
          20,
          45,
          23
        ]
      ],
      "transformers/tests/models/perception_lm/test_processing_perception_lm.py": [
        [
          "setUpClass",
          47,
          62,
          48,
          26,
          48,
          43,
          47,
          20,
          62,
          26
        ]
      ],
      "transformers/tests/models/owlvit/test_processing_owlvit.py": [
        [
          "setUp",
          39,
          65,
          40,
          27,
          40,
          44,
          39,
          15,
          65,
          46
        ]
      ],
      "transformers/tests/models/pix2struct/test_processing_pix2struct.py": [
        [
          "setUpClass",
          44,
          52,
          45,
          26,
          45,
          43,
          44,
          20,
          52,
          49
        ]
      ],
      "transformers/tests/models/pixtral/test_processing_pixtral.py": [
        [
          "setUp",
          45,
          48,
          46,
          27,
          46,
          44,
          45,
          15,
          48,
          50
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_processing_qwen2_5_omni.py": [
        [
          "setUpClass",
          213,
          218,
          214,
          26,
          214,
          43,
          213,
          20,
          218,
          49
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_processing_qwen2_5_vl.py": [
        [
          "setUpClass",
          44,
          50,
          45,
          26,
          45,
          43,
          44,
          20,
          50,
          23
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_processing_qwen2_vl.py": [
        [
          "setUpClass",
          47,
          53,
          48,
          26,
          48,
          43,
          47,
          20,
          53,
          23
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_processing_qwen2_audio.py": [
        [
          "setUpClass",
          30,
          36,
          32,
          26,
          32,
          43,
          30,
          20,
          36,
          23
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_processing_qwen3_omni_moe.py": [
        [
          "setUpClass",
          214,
          219,
          215,
          26,
          215,
          43,
          214,
          20,
          219,
          49
        ]
      ],
      "transformers/tests/models/pop2piano/test_processing_pop2piano.py": [
        [
          "setUpClass",
          66,
          73,
          67,
          26,
          67,
          43,
          66,
          20,
          73,
          49
        ]
      ],
      "transformers/tests/models/qwen3_vl/test_processing_qwen3_vl.py": [
        [
          "setUpClass",
          44,
          50,
          45,
          26,
          45,
          43,
          44,
          20,
          50,
          23
        ]
      ],
      "transformers/tests/models/sam_hq/test_processing_samhq.py": [
        [
          "setUp",
          41,
          45,
          42,
          27,
          42,
          44,
          41,
          15,
          45,
          50
        ]
      ],
      "transformers/tests/models/sam/test_processing_sam.py": [
        [
          "setUpClass",
          43,
          47,
          44,
          26,
          44,
          43,
          43,
          20,
          47,
          49
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_processing_shieldgemma2.py": [
        [
          "setUpClass",
          76,
          89,
          77,
          26,
          77,
          43,
          76,
          20,
          89,
          49
        ]
      ],
      "transformers/tests/models/trocr/test_processing_trocr.py": [
        [
          "setUpClass",
          31,
          42,
          32,
          26,
          32,
          43,
          31,
          20,
          42,
          49
        ]
      ],
      "transformers/tests/models/speecht5/test_processing_speecht5.py": [
        [
          "setUpClass",
          41,
          65,
          42,
          26,
          42,
          43,
          41,
          20,
          65,
          62
        ]
      ],
      "transformers/tests/models/speech_to_text/test_processing_speech_to_text.py": [
        [
          "setUpClass",
          37,
          58,
          38,
          26,
          38,
          43,
          37,
          20,
          44,
          66
        ]
      ],
      "transformers/tests/models/smolvlm/test_processing_smolvlm.py": [
        [
          "setUpClass",
          37,
          68,
          38,
          26,
          38,
          43,
          37,
          20,
          68,
          25
        ]
      ],
      "transformers/tests/models/seamless_m4t/test_processing_seamless_m4t.py": [
        [
          "setUp",
          31,
          33,
          33,
          27,
          33,
          44,
          31,
          15,
          33,
          23
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_processing_vision_text_dual_encoder.py": [
        [
          "setUpClass",
          39,
          61,
          40,
          26,
          40,
          43,
          39,
          20,
          61,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2/test_processing_wav2vec2.py": [
        [
          "setUpClass",
          35,
          63,
          53,
          26,
          53,
          43,
          35,
          20,
          63,
          49
        ]
      ],
      "transformers/tests/models/wav2vec2_bert/test_processing_wav2vec2_bert.py": [
        [
          "setUpClass",
          36,
          64,
          54,
          26,
          54,
          43,
          36,
          20,
          64,
          49
        ]
      ],
      "transformers/tests/models/udop/test_processing_udop.py": [
        [
          "setUpClass",
          58,
          74,
          59,
          26,
          59,
          43,
          58,
          20,
          74,
          49
        ]
      ],
      "transformers/tests/models/glm4v/test_processor_glm4v.py": [
        [
          "setUpClass",
          42,
          48,
          43,
          26,
          43,
          43,
          42,
          20,
          48,
          23
        ]
      ],
      "transformers/tests/models/ovis2/test_processor_ovis2.py": [
        [
          "setUp",
          40,
          47,
          41,
          27,
          41,
          44,
          40,
          15,
          47,
          50
        ]
      ],
      "transformers/tests/models/sam2/test_processor_sam2.py": [
        [
          "setUp",
          38,
          42,
          39,
          27,
          39,
          44,
          38,
          15,
          42,
          50
        ]
      ],
      "transformers/tests/models/whisper/test_processing_whisper.py": [
        [
          "setUp",
          40,
          42,
          42,
          27,
          42,
          44,
          40,
          15,
          42,
          23
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_processor_kosmos2_5.py": [
        [
          "setUp",
          52,
          57,
          53,
          27,
          53,
          44,
          52,
          15,
          57,
          50
        ]
      ],
      "transformers/tests/models/sam2_video/test_processor_sam2_video.py": [
        [
          "setUp",
          38,
          43,
          39,
          27,
          39,
          44,
          38,
          15,
          43,
          50
        ]
      ],
      "transformers/tests/models/wav2vec2_with_lm/test_processing_wav2vec2_with_lm.py": [
        [
          "setUp",
          50,
          77,
          67,
          27,
          67,
          44,
          50,
          15,
          77,
          25
        ]
      ],
      "transformers/tests/models/rag/test_retrieval_rag.py": [
        [
          "setUp",
          43,
          105,
          44,
          27,
          44,
          44,
          43,
          15,
          105,
          39
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_save_and_load_tokenizer",
          89,
          141,
          101,
          30,
          101,
          47,
          98,
          13,
          111,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          89,
          141,
          117,
          30,
          117,
          47,
          114,
          13,
          141,
          41
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_save_and_load_tokenizer",
          160,
          209,
          172,
          30,
          172,
          47,
          169,
          13,
          182,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          160,
          209,
          188,
          30,
          188,
          47,
          185,
          13,
          209,
          41
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_save_pretrained",
          145,
          213,
          157,
          31,
          157,
          48,
          152,
          13,
          172,
          58
        ],
        [
          "test_save_pretrained",
          145,
          213,
          178,
          31,
          178,
          48,
          175,
          17,
          191,
          58
        ],
        [
          "test_save_pretrained",
          145,
          213,
          197,
          31,
          197,
          48,
          194,
          17,
          210,
          58
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "setUpClass",
          233,
          255,
          255,
          26,
          255,
          43,
          252,
          14,
          255,
          22
        ],
        [
          "test_save_sentencepiece_tokenizer",
          545,
          570,
          555,
          24,
          555,
          41,
          550,
          16,
          570,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          545,
          570,
          556,
          24,
          556,
          41,
          550,
          16,
          570,
          78
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          747,
          30,
          747,
          47,
          744,
          13,
          760,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          766,
          30,
          766,
          47,
          763,
          13,
          793,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          735,
          828,
          802,
          30,
          802,
          47,
          800,
          18,
          828,
          41
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4040,
          31,
          4040,
          48,
          4035,
          13,
          4046,
          70
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4068,
          31,
          4068,
          48,
          4065,
          17,
          4081,
          58
        ],
        [
          "test_save_pretrained",
          4030,
          4103,
          4087,
          31,
          4087,
          48,
          4084,
          17,
          4100,
          58
        ],
        [
          "test_split_special_tokens",
          4508,
          4563,
          4551,
          27,
          4551,
          44,
          4513,
          13,
          4554,
          48
        ]
      ],
      "transformers/tests/models/esm/test_tokenization_esm.py": [
        [
          "setUpClass",
          31,
          38,
          34,
          26,
          34,
          43,
          31,
          20,
          38,
          73
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_training_new_tokenizer",
          82,
          97,
          88,
          39,
          88,
          56,
          88,
          39,
          88,
          56
        ],
        [
          "test_training_new_tokenizer_with_special_tokens_change",
          99,
          114,
          105,
          39,
          105,
          56,
          105,
          39,
          105,
          56
        ],
        [
          "test_init_from_tokenizers_model",
          125,
          171,
          145,
          22,
          145,
          39,
          125,
          41,
          148,
          52
        ],
        [
          "test_init_from_tokenizers_model",
          125,
          171,
          161,
          22,
          161,
          39,
          156,
          9,
          164,
          52
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_save_pretrained",
          148,
          211,
          155,
          31,
          155,
          48,
          150,
          13,
          170,
          58
        ],
        [
          "test_save_pretrained",
          148,
          211,
          176,
          31,
          176,
          48,
          173,
          17,
          189,
          58
        ],
        [
          "test_save_pretrained",
          148,
          211,
          195,
          31,
          195,
          48,
          192,
          17,
          208,
          58
        ],
        [
          "test_tiktoken_llama",
          850,
          915,
          895,
          22,
          895,
          39,
          850,
          29,
          915,
          45
        ]
      ],
      "transformers/tests/models/layoutxlm/test_tokenization_layoutxlm.py": [
        [
          "test_save_sentencepiece_tokenizer",
          148,
          182,
          161,
          24,
          161,
          41,
          153,
          24,
          182,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          148,
          182,
          162,
          24,
          162,
          41,
          153,
          24,
          182,
          78
        ],
        [
          "test_split_special_tokens",
          184,
          218,
          210,
          30,
          210,
          47,
          185,
          13,
          218,
          80
        ],
        [
          "test_save_and_load_tokenizer",
          1011,
          1036,
          1024,
          30,
          1024,
          47,
          1020,
          13,
          1036,
          41
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1703,
          31,
          1703,
          48,
          1698,
          13,
          1718,
          58
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1726,
          31,
          1726,
          48,
          1723,
          17,
          1739,
          58
        ],
        [
          "test_save_pretrained",
          1692,
          1761,
          1745,
          31,
          1745,
          48,
          1742,
          17,
          1758,
          58
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "test_save_and_load_tokenizer",
          967,
          992,
          980,
          30,
          980,
          47,
          976,
          13,
          992,
          41
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py": [
        [
          "test_save_and_load_tokenizer",
          1080,
          1105,
          1093,
          30,
          1093,
          47,
          1089,
          13,
          1105,
          41
        ]
      ],
      "transformers/tests/models/marian/test_tokenization_marian.py": [
        [
          "test_tokenizer_equivalence_en_de",
          91,
          102,
          98,
          20,
          98,
          37,
          91,
          42,
          102,
          49
        ]
      ],
      "transformers/tests/models/mbart/test_tokenization_mbart.py": [
        [
          "test_save_pretrained",
          135,
          204,
          146,
          31,
          146,
          48,
          141,
          13,
          161,
          58
        ],
        [
          "test_save_pretrained",
          135,
          204,
          169,
          31,
          169,
          48,
          166,
          17,
          182,
          58
        ],
        [
          "test_save_pretrained",
          135,
          204,
          188,
          31,
          188,
          48,
          185,
          17,
          201,
          58
        ],
        [
          "test_special_tokens_unaffacted_by_save_load",
          265,
          270,
          266,
          22,
          266,
          39,
          265,
          53,
          270,
          84
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "test_save_and_load_tokenizer",
          859,
          884,
          872,
          30,
          872,
          47,
          868,
          13,
          884,
          41
        ]
      ],
      "transformers/tests/models/mbart50/test_tokenization_mbart50.py": [
        [
          "test_save_pretrained",
          113,
          182,
          124,
          31,
          124,
          48,
          119,
          13,
          139,
          58
        ],
        [
          "test_save_pretrained",
          113,
          182,
          147,
          31,
          147,
          48,
          144,
          17,
          160,
          58
        ],
        [
          "test_save_pretrained",
          113,
          182,
          166,
          31,
          166,
          48,
          163,
          17,
          179,
          58
        ],
        [
          "test_special_tokens_unaffacted_by_save_load",
          240,
          245,
          241,
          22,
          241,
          39,
          240,
          53,
          245,
          84
        ]
      ],
      "transformers/tests/models/nllb/test_tokenization_nllb.py": [
        [
          "test_save_pretrained",
          143,
          206,
          150,
          31,
          150,
          48,
          145,
          13,
          165,
          58
        ],
        [
          "test_save_pretrained",
          143,
          206,
          171,
          31,
          171,
          48,
          168,
          17,
          184,
          58
        ],
        [
          "test_save_pretrained",
          143,
          206,
          190,
          31,
          190,
          48,
          187,
          17,
          203,
          58
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_save_and_load_tokenizer",
          143,
          192,
          155,
          30,
          155,
          47,
          152,
          13,
          165,
          41
        ],
        [
          "test_save_and_load_tokenizer",
          143,
          192,
          171,
          30,
          171,
          47,
          168,
          13,
          192,
          41
        ]
      ],
      "transformers/tests/models/pop2piano/test_tokenization_pop2piano.py": [
        [
          "test_save_and_load_tokenizer",
          203,
          225,
          204,
          22,
          204,
          39,
          203,
          38,
          225,
          33
        ],
        [
          "test_pickle_tokenizer",
          227,
          242,
          228,
          22,
          228,
          39,
          227,
          31,
          242,
          55
        ]
      ],
      "transformers/tests/models/rag/test_tokenization_rag.py": [
        [
          "setUp",
          38,
          100,
          39,
          27,
          39,
          44,
          38,
          15,
          100,
          39
        ]
      ],
      "transformers/tests/models/plbart/test_tokenization_plbart.py": [
        [
          "test_special_tokens_unaffacted_by_save_load",
          310,
          315,
          311,
          22,
          311,
          39,
          310,
          53,
          315,
          84
        ]
      ],
      "transformers/tests/models/vits/test_tokenization_vits.py": [
        [
          "setUpClass",
          35,
          52,
          49,
          26,
          49,
          43,
          35,
          20,
          52,
          53
        ],
        [
          "test_save_and_load_tokenizer",
          79,
          104,
          91,
          30,
          91,
          47,
          88,
          13,
          104,
          41
        ]
      ],
      "transformers/tests/models/udop/test_tokenization_udop.py": [
        [
          "test_save_sentencepiece_tokenizer",
          141,
          175,
          154,
          24,
          154,
          41,
          146,
          24,
          175,
          78
        ],
        [
          "test_save_sentencepiece_tokenizer",
          141,
          175,
          155,
          24,
          155,
          41,
          146,
          24,
          175,
          78
        ],
        [
          "test_save_and_load_tokenizer",
          939,
          964,
          952,
          30,
          952,
          47,
          948,
          13,
          964,
          41
        ],
        [
          "test_split_special_tokens",
          1835,
          1878,
          1870,
          30,
          1870,
          47,
          1836,
          13,
          1878,
          80
        ]
      ],
      "transformers/tests/models/tapas/test_tokenization_tapas.py": [
        [
          "test_save_and_load_tokenizer",
          854,
          880,
          867,
          30,
          867,
          47,
          863,
          13,
          880,
          41
        ]
      ],
      "transformers/tests/models/wav2vec2/test_tokenization_wav2vec2.py": [
        [
          "setUpClass",
          60,
          71,
          68,
          26,
          68,
          43,
          60,
          20,
          71,
          53
        ],
        [
          "test_save_pretrained",
          240,
          258,
          243,
          23,
          243,
          40,
          240,
          30,
          255,
          47
        ],
        [
          "test_save_and_load_tokenizer",
          273,
          318,
          276,
          22,
          276,
          39,
          273,
          38,
          318,
          33
        ],
        [
          "test_save_and_load_tokenizer",
          273,
          318,
          295,
          22,
          295,
          39,
          273,
          38,
          318,
          33
        ],
        [
          "setUpClass",
          379,
          390,
          387,
          26,
          387,
          43,
          379,
          20,
          390,
          53
        ]
      ],
      "transformers/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py": [
        [
          "test_save_pretrained",
          143,
          212,
          154,
          31,
          154,
          48,
          149,
          13,
          169,
          58
        ],
        [
          "test_save_pretrained",
          143,
          212,
          177,
          31,
          177,
          48,
          174,
          17,
          190,
          58
        ],
        [
          "test_save_pretrained",
          143,
          212,
          196,
          31,
          196,
          48,
          193,
          17,
          209,
          58
        ]
      ],
      "transformers/tests/trainer/test_trainer_callback.py": [
        [
          "setUp",
          108,
          109,
          109,
          27,
          109,
          44,
          108,
          15,
          109,
          23
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "get_auto_remove_tmp_dir",
          2045,
          2111,
          2105,
          23,
          2105,
          40,
          2105,
          23,
          2107,
          24
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_tatoeba_conversion.py": [
        [
          "resolver",
          27,
          29,
          28,
          19,
          28,
          36,
          27,
          18,
          29,
          49
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "setUpClass",
          66,
          71,
          68,
          22,
          68,
          39,
          66,
          20,
          71,
          24
        ]
      ],
      "transformers/tests/commands/test_chat.py": [
        [
          "test_save_and_clear_chat",
          83,
          94,
          84,
          20,
          84,
          37,
          83,
          34,
          94,
          37
        ]
      ],
      "transformers/tests/trainer/test_data_collator.py": [
        [
          "setUp",
          46,
          52,
          47,
          27,
          47,
          44,
          46,
          15,
          52,
          73
        ],
        [
          "setUp",
          721,
          727,
          722,
          27,
          722,
          44,
          721,
          15,
          727,
          73
        ],
        [
          "setUp",
          1043,
          1049,
          1044,
          27,
          1044,
          44,
          1043,
          15,
          1049,
          73
        ],
        [
          "setUp",
          1548,
          1554,
          1549,
          27,
          1549,
          44,
          1548,
          15,
          1554,
          73
        ]
      ]
    },
    "tempfile.NamedTemporaryFile": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_loading_is_fast_on_gpu",
          1904,
          1956,
          1947,
          14,
          1947,
          65,
          1904,
          37,
          1954,
          30
        ]
      ],
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_picklable",
          296,
          301,
          297,
          14,
          297,
          42,
          296,
          24,
          301,
          39
        ],
        [
          "test_conversion",
          375,
          393,
          386,
          14,
          386,
          42,
          375,
          25,
          393,
          60
        ]
      ],
      "transformers/tests/models/gemma/test_tokenization_gemma.py": [
        [
          "test_conversion",
          236,
          254,
          247,
          14,
          247,
          42,
          236,
          25,
          254,
          60
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_picklable",
          294,
          299,
          295,
          14,
          295,
          42,
          294,
          24,
          299,
          39
        ],
        [
          "test_conversion",
          413,
          431,
          424,
          14,
          424,
          42,
          413,
          25,
          431,
          60
        ]
      ],
      "transformers/tests/models/moshi/test_tokenization_moshi.py": [
        [
          "test_picklable",
          174,
          184,
          175,
          14,
          175,
          42,
          174,
          24,
          184,
          39
        ]
      ],
      "transformers/tests/utils/test_tokenization_utils.py": [
        [
          "test_legacy_load_from_one_file",
          86,
          111,
          89,
          24,
          89,
          64,
          89,
          59,
          89,
          64
        ]
      ],
      "transformers/tests/models/xglm/test_tokenization_xglm.py": [
        [
          "test_picklable_without_disk",
          144,
          149,
          145,
          14,
          145,
          42,
          144,
          37,
          149,
          39
        ]
      ],
      "transformers/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py": [
        [
          "test_picklable_without_disk",
          218,
          223,
          219,
          14,
          219,
          42,
          218,
          37,
          223,
          39
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "torchrun",
          3771,
          3788,
          3773,
          10,
          3773,
          61,
          3771,
          14,
          3777,
          22
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          338,
          10,
          338,
          38,
          338,
          10,
          357,
          14
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_to_hf.py": [
        [
          "upload_original_ckpts",
          204,
          219,
          208,
          10,
          208,
          38,
          204,
          27,
          219,
          35
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "get_processor_inputs_from_inbound_messages",
          911,
          954,
          945,
          40,
          945,
          95,
          942,
          46,
          948,
          53
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "test_load_img_base64_prefix",
          741,
          756,
          743,
          24,
          743,
          64,
          743,
          59,
          743,
          64
        ],
        [
          "test_load_img_base64",
          758,
          773,
          760,
          24,
          760,
          64,
          760,
          59,
          760,
          64
        ],
        [
          "test_load_img_base64_encoded_bytes",
          775,
          790,
          777,
          24,
          777,
          64,
          777,
          59,
          777,
          64
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "run_distributed_test",
          238,
          274,
          261,
          14,
          261,
          80,
          238,
          30,
          274,
          27
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py": [
        [
          "test_small_model_integration_test_with_video",
          688,
          733,
          707,
          14,
          707,
          55,
          688,
          54,
          712,
          18
        ]
      ]
    },
    "pathlib.Path.open": {
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template_file_priority",
          1734,
          1747,
          1743,
          26,
          1743,
          76,
          1738,
          13,
          1747,
          78
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "get_char_lens",
          164,
          165,
          165,
          33,
          165,
          54,
          164,
          23,
          165,
          67
        ],
        [
          "write_txt_file",
          631,
          635,
          632,
          9,
          632,
          28,
          631,
          20,
          633,
          25
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "remap_model_yaml_config",
          88,
          101,
          89,
          10,
          89,
          59,
          88,
          29,
          97,
          66
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_hifigan.py": [
        [
          "remap_hifigan_yaml_config",
          62,
          89,
          63,
          10,
          63,
          59,
          62,
          31,
          68,
          42
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "fetch_test_set",
          322,
          333,
          326,
          11,
          326,
          28,
          322,
          20,
          330,
          52
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_seq2seq_examples.py": [
        [
          "_dump_articles",
          33,
          35,
          35,
          5,
          35,
          24,
          33,
          20,
          35,
          44
        ]
      ],
      "transformers/examples/legacy/seq2seq/old_test_datasets.py": [
        [
          "_dump_articles",
          41,
          43,
          43,
          5,
          43,
          24,
          41,
          20,
          43,
          44
        ]
      ],
      "transformers/examples/legacy/seq2seq/pack_dataset.py": [
        [
          "pack_data_dir",
          58,
          72,
          67,
          9,
          67,
          53,
          61,
          9,
          68,
          82
        ],
        [
          "pack_data_dir",
          58,
          72,
          68,
          9,
          68,
          53,
          61,
          9,
          68,
          82
        ],
        [
          "pack_data_dir",
          58,
          72,
          63,
          41,
          63,
          61,
          61,
          9,
          68,
          82
        ],
        [
          "pack_data_dir",
          58,
          72,
          64,
          41,
          64,
          61,
          61,
          9,
          68,
          82
        ]
      ],
      "transformers/examples/legacy/seq2seq/run_eval.py": [
        [
          "generate_summaries_or_translations",
          37,
          78,
          49,
          12,
          49,
          53,
          38,
          5,
          52,
          11
        ]
      ]
    },
    "pathlib.Path.touch": {
      "transformers/src/transformers/trainer.py": [
        [
          "save_model",
          4003,
          4055,
          4021,
          13,
          4021,
          69,
          4021,
          13,
          4021,
          69
        ]
      ]
    },
    "tempfile.mkstemp": {
      "transformers/src/transformers/utils/hub.py": [
        [
          "download_url",
          582,
          606,
          603,
          24,
          603,
          41,
          582,
          18,
          606,
          19
        ]
      ]
    },
    "pathlib.Path.write_text": {
      "transformers/utils/scan_skipped_tests.py": [
        [
          "save_json",
          89,
          91,
          91,
          5,
          91,
          71,
          89,
          15,
          91,
          71
        ]
      ]
    }
  },
  "CWE-502": {
    "PIL.Image.open": {
      "transformers/tests/models/rt_detr/test_modeling_rt_detr.py": [
        [
          "prepare_img",
          660,
          662,
          661,
          13,
          661,
          78,
          661,
          13,
          662,
          16
        ]
      ],
      "transformers/tests/models/rt_detr_v2/test_modeling_rt_detr_v2.py": [
        [
          "prepare_img",
          664,
          666,
          665,
          13,
          665,
          78,
          665,
          13,
          666,
          16
        ]
      ],
      "transformers/tests/models/sam/test_modeling_sam.py": [
        [
          "prepare_image",
          721,
          724,
          723,
          17,
          723,
          66,
          722,
          15,
          724,
          20
        ],
        [
          "prepare_dog_img",
          727,
          730,
          729,
          17,
          729,
          66,
          728,
          15,
          730,
          20
        ]
      ],
      "transformers/tests/models/sam2_video/test_modeling_sam2_video.py": [
        [
          "prepare_image",
          41,
          44,
          43,
          17,
          43,
          66,
          42,
          15,
          44,
          20
        ],
        [
          "prepare_groceries_image",
          47,
          50,
          49,
          17,
          49,
          66,
          48,
          15,
          50,
          20
        ],
        [
          "prepare_dog_img",
          53,
          56,
          55,
          17,
          55,
          66,
          54,
          15,
          56,
          20
        ]
      ],
      "transformers/tests/models/sam2/test_modeling_sam2.py": [
        [
          "prepare_image",
          720,
          723,
          722,
          17,
          722,
          66,
          721,
          15,
          723,
          20
        ],
        [
          "prepare_groceries_image",
          726,
          729,
          728,
          17,
          728,
          66,
          727,
          15,
          729,
          20
        ],
        [
          "prepare_dog_img",
          732,
          735,
          734,
          17,
          734,
          66,
          733,
          15,
          735,
          20
        ]
      ],
      "transformers/tests/models/sam_hq/test_modeling_sam_hq.py": [
        [
          "prepare_image",
          768,
          771,
          770,
          17,
          770,
          66,
          769,
          15,
          771,
          20
        ],
        [
          "prepare_dog_img",
          774,
          777,
          776,
          17,
          776,
          66,
          775,
          15,
          777,
          20
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_modeling_shieldgemma2.py": [
        [
          "test_model",
          43,
          57,
          49,
          17,
          49,
          53,
          43,
          20,
          56,
          43
        ]
      ],
      "transformers/tests/models/siglip/test_modeling_siglip.py": [
        [
          "prepare_img",
          647,
          650,
          649,
          13,
          649,
          58,
          648,
          11,
          650,
          16
        ],
        [
          "test_inference_interpolate_pos_encoding",
          693,
          712,
          698,
          17,
          698,
          82,
          693,
          49,
          712,
          93
        ]
      ],
      "transformers/tests/models/segformer/test_modeling_segformer.py": [
        [
          "prepare_img",
          345,
          347,
          346,
          13,
          346,
          78,
          346,
          13,
          347,
          16
        ]
      ],
      "transformers/tests/models/smolvlm/test_modeling_smolvlm.py": [
        [
          "setUp",
          514,
          535,
          516,
          23,
          522,
          9,
          514,
          15,
          524,
          27
        ]
      ],
      "transformers/tests/models/superpoint/test_modeling_superpoint.py": [
        [
          "prepare_imgs",
          244,
          247,
          245,
          14,
          245,
          79,
          245,
          14,
          247,
          27
        ],
        [
          "prepare_imgs",
          244,
          247,
          246,
          14,
          246,
          79,
          245,
          14,
          247,
          27
        ]
      ],
      "transformers/tests/models/swiftformer/test_modeling_swiftformer.py": [
        [
          "prepare_img",
          237,
          239,
          238,
          13,
          238,
          78,
          238,
          13,
          239,
          16
        ]
      ],
      "transformers/tests/models/swin/test_modeling_swin.py": [
        [
          "test_inference_image_classification_head",
          463,
          478,
          467,
          17,
          467,
          82,
          463,
          50,
          478,
          95
        ],
        [
          "test_inference_interpolate_pos_encoding",
          481,
          498,
          488,
          17,
          488,
          82,
          481,
          49,
          498,
          73
        ]
      ],
      "transformers/tests/models/swin2sr/test_modeling_swin2sr.py": [
        [
          "test_inference_image_super_resolution_head",
          301,
          318,
          305,
          17,
          305,
          82,
          301,
          52,
          318,
          110
        ],
        [
          "test_inference_fp16",
          320,
          344,
          326,
          17,
          326,
          82,
          320,
          29,
          344,
          110
        ]
      ],
      "transformers/tests/models/swinv2/test_modeling_swinv2.py": [
        [
          "test_inference_image_classification_head",
          458,
          475,
          464,
          17,
          464,
          82,
          458,
          50,
          475,
          95
        ],
        [
          "test_inference_fp16",
          478,
          495,
          484,
          17,
          484,
          82,
          478,
          29,
          495,
          95
        ],
        [
          "test_inference_interpolate_pos_encoding",
          498,
          515,
          505,
          17,
          505,
          82,
          498,
          49,
          515,
          73
        ]
      ],
      "transformers/tests/models/textnet/test_modeling_textnet.py": [
        [
          "test_inference_no_head",
          299,
          324,
          305,
          17,
          305,
          62,
          299,
          32,
          324,
          9
        ]
      ],
      "transformers/tests/models/table_transformer/test_modeling_table_transformer.py": [
        [
          "prepare_img",
          540,
          542,
          541,
          13,
          541,
          78,
          541,
          13,
          542,
          16
        ],
        [
          "test_table_detection",
          549,
          579,
          555,
          17,
          555,
          37,
          549,
          30,
          579,
          103
        ]
      ],
      "transformers/tests/models/tvp/test_modeling_tvp.py": [
        [
          "prepare_img",
          231,
          233,
          232,
          13,
          232,
          78,
          232,
          13,
          233,
          16
        ]
      ],
      "transformers/tests/models/timm_wrapper/test_modeling_timm_wrapper.py": [
        [
          "prepare_img",
          266,
          268,
          267,
          13,
          267,
          78,
          267,
          13,
          268,
          16
        ]
      ],
      "transformers/tests/models/vipllava/test_modeling_vipllava.py": [
        [
          "test_small_model_integration_test",
          293,
          309,
          301,
          17,
          301,
          62,
          293,
          43,
          309,
          97
        ]
      ],
      "transformers/tests/models/vilt/test_modeling_vilt.py": [
        [
          "prepare_img",
          559,
          561,
          560,
          13,
          560,
          78,
          560,
          13,
          561,
          16
        ]
      ],
      "transformers/tests/models/video_llava/test_modeling_video_llava.py": [
        [
          "test_small_model_integration_test_mixed_inputs",
          440,
          467,
          452,
          17,
          452,
          62,
          440,
          56,
          467,
          9
        ]
      ],
      "transformers/tests/models/vision_text_dual_encoder/test_modeling_vision_text_dual_encoder.py": [
        [
          "test_inference",
          415,
          435,
          419,
          17,
          419,
          82,
          415,
          24,
          435,
          99
        ]
      ],
      "transformers/tests/models/vit/test_modeling_vit.py": [
        [
          "prepare_img",
          258,
          260,
          259,
          13,
          259,
          78,
          259,
          13,
          260,
          16
        ]
      ],
      "transformers/tests/models/vit_msn/test_modeling_vit_msn.py": [
        [
          "prepare_img",
          205,
          207,
          206,
          13,
          206,
          78,
          206,
          13,
          207,
          16
        ]
      ],
      "transformers/tests/models/vit_mae/test_modeling_vit_mae.py": [
        [
          "prepare_img",
          325,
          327,
          326,
          13,
          326,
          78,
          326,
          13,
          327,
          16
        ]
      ],
      "transformers/tests/models/vitmatte/test_modeling_vitmatte.py": [
        [
          "test_inference",
          271,
          296,
          278,
          17,
          278,
          36,
          271,
          24,
          296,
          94
        ],
        [
          "test_inference",
          271,
          296,
          282,
          18,
          282,
          37,
          271,
          24,
          296,
          94
        ]
      ],
      "transformers/tests/models/vitpose/test_modeling_vitpose.py": [
        [
          "prepare_img",
          227,
          230,
          229,
          13,
          229,
          58,
          228,
          11,
          230,
          16
        ]
      ],
      "transformers/tests/models/vjepa2/test_modeling_vjepa2.py": [
        [
          "prepare_img",
          218,
          220,
          219,
          13,
          219,
          78,
          219,
          13,
          220,
          16
        ]
      ],
      "transformers/tests/models/vision_encoder_decoder/test_modeling_vision_encoder_decoder.py": [
        [
          "test_inference_coco_en",
          1189,
          1246,
          1199,
          15,
          1199,
          80,
          1189,
          32,
          1246,
          87
        ],
        [
          "default_image",
          1456,
          1461,
          1460,
          17,
          1460,
          36,
          1456,
          23,
          1461,
          20
        ]
      ],
      "transformers/tests/models/yolos/test_modeling_yolos.py": [
        [
          "prepare_img",
          330,
          332,
          331,
          13,
          331,
          78,
          331,
          13,
          332,
          16
        ]
      ],
      "transformers/tests/models/zoedepth/test_modeling_zoedepth.py": [
        [
          "prepare_img",
          201,
          203,
          202,
          13,
          202,
          78,
          202,
          13,
          203,
          16
        ],
        [
          "test_post_processing_depth_estimation_post_processing_nopad_noflip",
          323,
          328,
          324,
          34,
          324,
          99,
          323,
          76,
          328,
          104
        ],
        [
          "test_inference_depth_estimation_post_processing_nopad_flip",
          330,
          335,
          331,
          34,
          331,
          99,
          330,
          68,
          335,
          103
        ],
        [
          "test_inference_depth_estimation_post_processing_pad_noflip",
          337,
          342,
          338,
          34,
          338,
          99,
          337,
          68,
          342,
          103
        ],
        [
          "test_inference_depth_estimation_post_processing_pad_flip",
          344,
          349,
          345,
          34,
          345,
          99,
          344,
          66,
          349,
          102
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_depth_estimation.py": [
        [
          "run_pipeline_test",
          94,
          123,
          101,
          17,
          101,
          82,
          94,
          27,
          122,
          36
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_classification.py": [
        [
          "get_test_pipeline",
          69,
          91,
          88,
          13,
          88,
          78,
          70,
          9,
          91,
          41
        ],
        [
          "run_pipeline_test",
          93,
          146,
          108,
          17,
          108,
          82,
          93,
          27,
          144,
          36
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_feature_extraction.py": [
        [
          "prepare_img",
          39,
          41,
          40,
          13,
          40,
          78,
          40,
          13,
          41,
          16
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_text_to_text.py": [
        [
          "get_test_pipeline",
          45,
          58,
          50,
          27,
          50,
          92,
          45,
          27,
          58,
          29
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_segmentation.py": [
        [
          "listcomp",
          321,
          322,
          322,
          13,
          322,
          83,
          322,
          89,
          322,
          83
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_object_detection.py": [
        [
          "run_pipeline_test",
          89,
          128,
          105,
          13,
          105,
          78,
          105,
          13,
          117,
          36
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_to_text.py": [
        [
          "get_test_pipeline",
          46,
          68,
          65,
          13,
          65,
          78,
          47,
          9,
          68,
          29
        ],
        [
          "test_generation_pt_blip",
          172,
          178,
          175,
          17,
          175,
          85,
          172,
          33,
          178,
          116
        ],
        [
          "test_generation_pt_git",
          182,
          188,
          185,
          17,
          185,
          85,
          182,
          32,
          188,
          91
        ],
        [
          "test_conditional_generation_pt_blip",
          192,
          203,
          195,
          17,
          195,
          85,
          192,
          45,
          203,
          19
        ],
        [
          "test_conditional_generation_pt_git",
          207,
          218,
          210,
          17,
          210,
          85,
          207,
          44,
          218,
          19
        ],
        [
          "test_conditional_generation_pt_pix2struct",
          222,
          233,
          225,
          17,
          225,
          85,
          222,
          51,
          233,
          19
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_keypoint_matching.py": [
        [
          "run_pipeline_test",
          70,
          116,
          74,
          17,
          74,
          82,
          70,
          27,
          116,
          9
        ],
        [
          "get_test_pipeline",
          47,
          68,
          65,
          13,
          65,
          78,
          48,
          9,
          68,
          38
        ],
        [
          "run_pipeline_test",
          70,
          116,
          95,
          21,
          95,
          86,
          70,
          27,
          116,
          9
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_visual_question_answering.py": [
        [
          "get_test_pipeline",
          57,
          81,
          73,
          26,
          73,
          91,
          58,
          9,
          81,
          37
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_zero_shot_image_classification.py": [
        [
          "test_small_model_pt",
          76,
          133,
          80,
          17,
          80,
          82,
          76,
          29,
          132,
          35
        ],
        [
          "test_large_model_pt",
          141,
          170,
          147,
          17,
          147,
          82,
          141,
          29,
          170,
          9
        ],
        [
          "test_siglip_model_pt",
          174,
          204,
          180,
          17,
          180,
          82,
          174,
          30,
          204,
          9
        ],
        [
          "test_blip2_model_pt",
          208,
          247,
          214,
          17,
          214,
          82,
          208,
          29,
          247,
          9
        ]
      ],
      "transformers/tests/models/kosmos2/test_processing_kosmos2.py": [
        [
          "test_full_processor",
          189,
          471,
          212,
          17,
          212,
          38,
          189,
          29,
          471,
          118
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_processor_kosmos2_5.py": [
        [
          "test_full_processor",
          301,
          391,
          315,
          17,
          315,
          38,
          301,
          29,
          391,
          9
        ]
      ],
      "transformers/src/transformers/utils/attention_visualizer.py": [
        [
          "visualize_attention_mask",
          177,
          251,
          183,
          19,
          183,
          87,
          182,
          19,
          186,
          48
        ]
      ],
      "transformers/src/transformers/models/align/convert_align_tf_to_hf.py": [
        [
          "prepare_img",
          66,
          69,
          68,
          10,
          68,
          55,
          67,
          11,
          69,
          13
        ]
      ],
      "transformers/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py": [
        [
          "prepare_img",
          163,
          166,
          165,
          10,
          165,
          55,
          164,
          11,
          166,
          13
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          270,
          17,
          270,
          41,
          268,
          27,
          270,
          13
        ]
      ],
      "transformers/src/transformers/models/bit/convert_bit_to_pytorch.py": [
        [
          "prepare_img",
          76,
          79,
          78,
          10,
          78,
          55,
          77,
          11,
          79,
          13
        ]
      ],
      "transformers/src/transformers/models/blip/convert_blip_original_pytorch_to_hf.py": [
        [
          "load_demo_image",
          39,
          51,
          41,
          17,
          41,
          66,
          39,
          21,
          51,
          16
        ]
      ],
      "transformers/src/transformers/models/blip_2/convert_blip_2_original_to_pytorch.py": [
        [
          "load_demo_image",
          49,
          53,
          51,
          13,
          51,
          58,
          50,
          11,
          53,
          16
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          408,
          13,
          412,
          5,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          424,
          13,
          426,
          5,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          427,
          15,
          429,
          5,
          357,
          13,
          436,
          58
        ]
      ],
      "transformers/src/transformers/models/clipseg/convert_clipseg_original_pytorch_to_hf.py": [
        [
          "prepare_img",
          161,
          164,
          163,
          13,
          163,
          58,
          162,
          11,
          164,
          16
        ]
      ],
      "transformers/src/transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          214,
          218,
          216,
          10,
          216,
          55,
          215,
          11,
          218,
          13
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_convnext_upernet_to_pytorch.py": [
        [
          "convert_upernet_checkpoint",
          121,
          193,
          152,
          13,
          152,
          58,
          148,
          5,
          160,
          44
        ]
      ],
      "transformers/src/transformers/models/convnext/convert_convnext_to_pytorch.py": [
        [
          "prepare_img",
          114,
          117,
          116,
          10,
          116,
          55,
          115,
          11,
          117,
          13
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "prepare_img",
          117,
          120,
          119,
          10,
          119,
          55,
          118,
          11,
          120,
          13
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "main",
          249,
          351,
          302,
          13,
          302,
          88,
          297,
          18,
          324,
          32
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "prepare_img",
          79,
          83,
          81,
          10,
          81,
          55,
          80,
          11,
          83,
          13
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "prepare_img",
          381,
          385,
          383,
          10,
          383,
          55,
          382,
          11,
          385,
          13
        ]
      ],
      "transformers/src/transformers/models/deit/convert_deit_timm_to_pytorch.py": [
        [
          "prepare_img",
          124,
          127,
          126,
          10,
          126,
          55,
          125,
          11,
          127,
          13
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          171,
          175,
          173,
          10,
          173,
          55,
          172,
          11,
          175,
          13
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_depth_anything_to_hf.py": [
        [
          "prepare_img",
          177,
          180,
          179,
          10,
          179,
          55,
          178,
          11,
          180,
          13
        ],
        [
          "convert_dpt_checkpoint",
          201,
          336,
          257,
          13,
          257,
          58,
          238,
          5,
          270,
          20
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_to_pytorch.py": [
        [
          "prepare_img",
          280,
          284,
          282,
          10,
          282,
          55,
          281,
          11,
          284,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "prepare_img",
          209,
          213,
          211,
          10,
          211,
          55,
          210,
          11,
          213,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "prepare_img",
          208,
          212,
          210,
          10,
          210,
          55,
          209,
          11,
          212,
          13
        ]
      ],
      "transformers/src/transformers/models/vit/convert_dino_to_pytorch.py": [
        [
          "prepare_img",
          124,
          127,
          126,
          10,
          126,
          55,
          125,
          11,
          127,
          13
        ]
      ],
      "transformers/src/transformers/models/dinov2_with_registers/convert_dinov2_with_registers_to_hf.py": [
        [
          "prepare_img",
          145,
          148,
          147,
          13,
          147,
          58,
          146,
          11,
          148,
          16
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dinov2_depth_to_hf.py": [
        [
          "prepare_img",
          184,
          187,
          186,
          10,
          186,
          55,
          185,
          11,
          187,
          13
        ]
      ],
      "transformers/src/transformers/models/dinov2/convert_dinov2_to_hf.py": [
        [
          "prepare_img",
          139,
          142,
          141,
          13,
          141,
          58,
          140,
          11,
          142,
          16
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "prepare_img",
          85,
          88,
          87,
          13,
          87,
          58,
          86,
          11,
          88,
          16
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "prepare_img",
          134,
          136,
          136,
          12,
          136,
          57,
          135,
          11,
          136,
          57
        ],
        [
          "convert_dpt_checkpoint",
          147,
          215,
          172,
          13,
          172,
          58,
          147,
          28,
          183,
          20
        ]
      ],
      "transformers/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py": [
        [
          "prepare_img",
          126,
          129,
          128,
          10,
          128,
          55,
          127,
          11,
          129,
          13
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "prepare_img",
          183,
          186,
          185,
          13,
          185,
          58,
          184,
          11,
          186,
          16
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_beit_to_hf.py": [
        [
          "prepare_img",
          167,
          170,
          169,
          10,
          169,
          55,
          168,
          11,
          170,
          13
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          226,
          13,
          226,
          58,
          204,
          5,
          247,
          41
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_to_pytorch.py": [
        [
          "prepare_img",
          181,
          184,
          183,
          10,
          183,
          55,
          182,
          11,
          184,
          13
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "prepare_img",
          213,
          216,
          215,
          10,
          215,
          55,
          214,
          11,
          216,
          13
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_swinv2_to_hf.py": [
        [
          "prepare_img",
          179,
          182,
          181,
          10,
          181,
          55,
          180,
          11,
          182,
          13
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          230,
          17,
          230,
          62,
          227,
          14,
          250,
          46
        ]
      ],
      "transformers/src/transformers/models/edgetam_video/convert_edgetam_video_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          235,
          278,
          256,
          21,
          256,
          70,
          255,
          19,
          269,
          95
        ]
      ],
      "transformers/src/transformers/models/edgetam/convert_edgetam_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          192,
          238,
          216,
          21,
          216,
          70,
          215,
          19,
          229,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          116,
          120,
          118,
          13,
          118,
          58,
          117,
          11,
          120,
          16
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "prepare_img",
          143,
          146,
          145,
          10,
          145,
          55,
          144,
          11,
          146,
          13
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_model",
          255,
          408,
          336,
          17,
          340,
          9,
          314,
          9,
          348,
          24
        ]
      ],
      "transformers/src/transformers/models/focalnet/convert_focalnet_to_hf_format.py": [
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          168,
          13,
          168,
          58,
          148,
          14,
          183,
          80
        ]
      ],
      "transformers/src/transformers/models/glpn/convert_glpn_to_pytorch.py": [
        [
          "prepare_img",
          117,
          121,
          119,
          13,
          119,
          58,
          118,
          11,
          121,
          16
        ]
      ],
      "transformers/src/transformers/models/git/convert_git_to_pytorch.py": [
        [
          "prepare_img",
          185,
          193,
          191,
          17,
          191,
          62,
          190,
          15,
          191,
          13
        ],
        [
          "prepare_img",
          185,
          193,
          188,
          17,
          188,
          36,
          187,
          20,
          188,
          13
        ]
      ],
      "transformers/src/transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py": [
        [
          "prepare_img",
          150,
          153,
          152,
          10,
          152,
          55,
          151,
          11,
          153,
          13
        ]
      ],
      "transformers/src/transformers/models/grounding_dino/convert_grounding_dino_to_hf.py": [
        [
          "prepare_img",
          381,
          384,
          383,
          13,
          383,
          58,
          382,
          11,
          384,
          16
        ]
      ],
      "transformers/src/transformers/models/hiera/convert_hiera_to_hf.py": [
        [
          "prepare_img",
          152,
          155,
          154,
          10,
          154,
          55,
          153,
          11,
          155,
          13
        ]
      ],
      "transformers/src/transformers/models/instructblip/convert_instructblip_original_to_pytorch.py": [
        [
          "load_demo_image",
          49,
          53,
          51,
          13,
          51,
          58,
          50,
          11,
          53,
          16
        ]
      ],
      "transformers/src/transformers/models/ijepa/convert_ijepa_to_hf.py": [
        [
          "prepare_img",
          119,
          122,
          121,
          10,
          121,
          55,
          120,
          11,
          122,
          13
        ]
      ],
      "transformers/src/transformers/models/instructblipvideo/convert_instructblipvideo_original_to_pytorch.py": [
        [
          "load_demo_image",
          49,
          53,
          51,
          13,
          51,
          58,
          50,
          11,
          53,
          16
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "load_image",
          89,
          92,
          91,
          13,
          91,
          58,
          90,
          11,
          92,
          16
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          334,
          18,
          334,
          63,
          328,
          5,
          343,
          30
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "load_image",
          92,
          95,
          94,
          13,
          94,
          58,
          93,
          11,
          95,
          16
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          325,
          18,
          325,
          63,
          319,
          5,
          334,
          30
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          84,
          88,
          87,
          10,
          87,
          29,
          85,
          11,
          88,
          13
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "prepare_img",
          223,
          226,
          225,
          10,
          225,
          55,
          224,
          11,
          226,
          13
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "prepare_img",
          254,
          257,
          256,
          10,
          256,
          55,
          255,
          11,
          257,
          13
        ]
      ],
      "transformers/src/transformers/models/mask2former/convert_mask2former_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          88,
          92,
          91,
          10,
          91,
          29,
          89,
          11,
          92,
          13
        ]
      ],
      "transformers/src/transformers/models/metaclip_2/convert_metaclip_2_to_hf.py": [
        [
          "verify_conversion",
          295,
          358,
          303,
          17,
          303,
          43,
          303,
          17,
          303,
          13
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "prepare_img",
          227,
          231,
          230,
          10,
          230,
          55,
          228,
          11,
          231,
          13
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "prepare_img",
          188,
          191,
          190,
          10,
          190,
          55,
          189,
          11,
          191,
          13
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          284,
          17,
          284,
          62,
          282,
          9,
          288,
          109
        ]
      ],
      "transformers/src/transformers/models/vit_msn/convert_msn_to_pytorch.py": [
        [
          "convert_vit_msn_checkpoint",
          148,
          228,
          197,
          13,
          197,
          58,
          190,
          5,
          210,
          30
        ]
      ],
      "transformers/src/transformers/models/mm_grounding_dino/convert_mm_grounding_dino_to_hf.py": [
        [
          "prepare_test_inputs",
          422,
          426,
          424,
          13,
          424,
          64,
          423,
          17,
          426,
          22
        ]
      ],
      "transformers/src/transformers/models/nougat/convert_nougat_to_hf.py": [
        [
          "convert_nougat_checkpoint",
          142,
          254,
          162,
          13,
          162,
          33,
          142,
          31,
          183,
          62
        ]
      ],
      "transformers/src/transformers/models/omdet_turbo/convert_omdet_turbo_to_hf.py": [
        [
          "run_test",
          237,
          255,
          240,
          13,
          240,
          58,
          237,
          14,
          254,
          69
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          168,
          171,
          170,
          10,
          170,
          55,
          169,
          11,
          171,
          13
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          246,
          249,
          248,
          10,
          248,
          55,
          247,
          11,
          249,
          13
        ]
      ],
      "transformers/src/transformers/models/owlv2/convert_owlv2_to_hf.py": [
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          277,
          13,
          277,
          32,
          258,
          5,
          281,
          32
        ]
      ],
      "transformers/src/transformers/models/ovis2/convert_ovis2_weights_to_hf.py": [
        [
          "main",
          309,
          400,
          384,
          13,
          384,
          58,
          365,
          9,
          400,
          26
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "prepare_img",
          47,
          51,
          50,
          10,
          50,
          55,
          49,
          11,
          51,
          13
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "prepare_img",
          85,
          89,
          87,
          13,
          87,
          58,
          86,
          11,
          89,
          16
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          155,
          254,
          207,
          13,
          207,
          58,
          192,
          13,
          225,
          20
        ],
        [
          "convert_dpt_checkpoint",
          155,
          254,
          212,
          20,
          212,
          78,
          192,
          13,
          225,
          20
        ]
      ],
      "transformers/src/transformers/models/pvt_v2/convert_pvt_v2_to_pytorch.py": [
        [
          "prepare_img",
          177,
          180,
          179,
          10,
          179,
          55,
          178,
          11,
          180,
          13
        ]
      ],
      "transformers/src/transformers/models/pvt/convert_pvt_to_pytorch.py": [
        [
          "prepare_img",
          143,
          146,
          145,
          10,
          145,
          55,
          144,
          11,
          146,
          13
        ]
      ],
      "transformers/src/transformers/models/sam/convert_sam_to_hf.py": [
        [
          "convert_sam_checkpoint",
          137,
          216,
          154,
          17,
          154,
          66,
          148,
          14,
          165,
          39
        ]
      ],
      "transformers/src/transformers/models/sam_hq/convert_samhq_to_hf.py": [
        [
          "convert_sam_hq_checkpoint",
          158,
          228,
          177,
          17,
          177,
          66,
          169,
          14,
          188,
          35
        ]
      ],
      "transformers/src/transformers/models/sam2/convert_sam2_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          218,
          280,
          241,
          17,
          241,
          66,
          240,
          15,
          254,
          40
        ]
      ],
      "transformers/src/transformers/models/sam2_video/convert_sam2_video_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          227,
          286,
          247,
          17,
          247,
          66,
          239,
          14,
          260,
          40
        ]
      ],
      "transformers/src/transformers/models/seggpt/convert_seggpt_to_hf.py": [
        [
          "prepare_input",
          92,
          107,
          103,
          19,
          103,
          76,
          94,
          9,
          107,
          49
        ],
        [
          "prepare_input",
          92,
          107,
          104,
          20,
          104,
          78,
          94,
          9,
          107,
          49
        ],
        [
          "prepare_input",
          92,
          107,
          105,
          19,
          105,
          76,
          94,
          9,
          107,
          49
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "prepare_img",
          213,
          217,
          215,
          10,
          215,
          55,
          214,
          11,
          217,
          13
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "prepare_img",
          112,
          116,
          114,
          13,
          114,
          58,
          113,
          11,
          116,
          16
        ]
      ],
      "transformers/src/transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": [
        [
          "prepare_img",
          539,
          543,
          541,
          10,
          541,
          55,
          540,
          11,
          543,
          13
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "prepare_img",
          360,
          363,
          362,
          13,
          362,
          58,
          361,
          11,
          363,
          16
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          418,
          15,
          418,
          62,
          405,
          5,
          427,
          20
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          420,
          15,
          420,
          62,
          405,
          5,
          427,
          20
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "prepare_img",
          41,
          44,
          43,
          10,
          43,
          55,
          42,
          11,
          44,
          13
        ]
      ],
      "transformers/src/transformers/models/superpoint/convert_superpoint_to_pytorch.py": [
        [
          "prepare_imgs",
          81,
          86,
          83,
          11,
          83,
          56,
          82,
          11,
          86,
          21
        ],
        [
          "prepare_imgs",
          81,
          86,
          85,
          11,
          85,
          56,
          82,
          11,
          86,
          21
        ]
      ],
      "transformers/src/transformers/models/swin2sr/convert_swin2sr_original_to_pytorch.py": [
        [
          "convert_swin2sr_checkpoint",
          163,
          260,
          180,
          13,
          180,
          58,
          179,
          11,
          184,
          48
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_simmim_to_pytorch.py": [
        [
          "convert_swin_checkpoint",
          123,
          155,
          136,
          13,
          136,
          58,
          123,
          29,
          145,
          43
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_timm_to_pytorch.py": [
        [
          "convert_swin_checkpoint",
          130,
          156,
          144,
          13,
          144,
          58,
          130,
          29,
          150,
          56
        ]
      ],
      "transformers/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py": [
        [
          "convert_swinv2_checkpoint",
          170,
          202,
          184,
          13,
          184,
          58,
          170,
          31,
          190,
          56
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_swin_upernet_to_pytorch.py": [
        [
          "convert_upernet_checkpoint",
          191,
          276,
          235,
          13,
          235,
          58,
          231,
          5,
          247,
          40
        ]
      ],
      "transformers/src/transformers/models/table_transformer/convert_table_transformer_to_hf.py": [
        [
          "convert_table_transformer_checkpoint",
          189,
          294,
          254,
          13,
          254,
          33,
          252,
          16,
          259,
          36
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "convert_textnet_checkpoint",
          116,
          181,
          165,
          13,
          165,
          58,
          161,
          5,
          172,
          87
        ]
      ],
      "transformers/src/transformers/models/table_transformer/convert_table_transformer_to_hf_no_timm.py": [
        [
          "convert_table_transformer_checkpoint",
          302,
          411,
          371,
          13,
          371,
          33,
          369,
          16,
          376,
          36
        ],
        [
          "convert_table_transformer_checkpoint",
          302,
          411,
          371,
          13,
          371,
          33,
          369,
          72,
          376,
          36
        ]
      ],
      "transformers/src/transformers/models/trocr/convert_trocr_unilm_to_pytorch.py": [
        [
          "prepare_img",
          109,
          119,
          118,
          10,
          118,
          55,
          118,
          10,
          119,
          13
        ]
      ],
      "transformers/src/transformers/models/oneformer/convert_to_hf_oneformer.py": [
        [
          "prepare_img",
          94,
          98,
          97,
          10,
          97,
          29,
          95,
          11,
          98,
          13
        ]
      ],
      "transformers/src/transformers/models/udop/convert_udop_to_hf.py": [
        [
          "get_image",
          47,
          53,
          51,
          13,
          51,
          32,
          48,
          16,
          53,
          16
        ]
      ],
      "transformers/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py": [
        [
          "convert_vilt_checkpoint",
          168,
          282,
          231,
          18,
          231,
          108,
          231,
          18,
          239,
          15
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          232,
          18,
          232,
          108,
          231,
          18,
          239,
          15
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          245,
          17,
          245,
          115,
          210,
          5,
          266,
          79
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          245,
          17,
          245,
          115,
          245,
          17,
          251,
          15
        ]
      ],
      "transformers/src/transformers/models/vitmatte/convert_vitmatte_to_hf.py": [
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          115,
          13,
          115,
          58,
          106,
          17,
          124,
          52
        ],
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          117,
          14,
          117,
          59,
          106,
          17,
          124,
          52
        ]
      ],
      "transformers/src/transformers/models/vit_mae/convert_vit_mae_to_pytorch.py": [
        [
          "convert_vit_mae_checkpoint",
          105,
          161,
          132,
          13,
          132,
          58,
          108,
          30,
          141,
          32
        ],
        [
          "convert_vit_mae_checkpoint",
          105,
          161,
          132,
          13,
          132,
          58,
          119,
          13,
          141,
          32
        ]
      ],
      "transformers/src/transformers/models/vit/convert_vit_timm_to_pytorch.py": [
        [
          "prepare_img",
          124,
          127,
          126,
          10,
          126,
          55,
          125,
          11,
          127,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": [
        [
          "prepare_img",
          158,
          161,
          160,
          10,
          160,
          55,
          159,
          11,
          161,
          13
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "prepare_img",
          183,
          186,
          185,
          13,
          185,
          58,
          184,
          11,
          186,
          16
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_to_hf.py": [
        [
          "prepare_img",
          198,
          201,
          200,
          13,
          200,
          58,
          199,
          11,
          201,
          16
        ]
      ],
      "transformers/src/transformers/models/zoedepth/convert_zoedepth_to_hf.py": [
        [
          "prepare_img",
          299,
          302,
          301,
          13,
          301,
          32,
          300,
          16,
          302,
          16
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "prepare_img",
          150,
          153,
          152,
          10,
          152,
          55,
          151,
          11,
          153,
          13
        ]
      ],
      "transformers/src/transformers/models/conditional_detr/image_processing_conditional_detr.py": [
        [
          "prepare_coco_panoptic_annotation",
          354,
          392,
          373,
          28,
          373,
          58,
          373,
          17,
          379,
          23
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/image_processing_deformable_detr.py": [
        [
          "prepare_coco_panoptic_annotation",
          382,
          420,
          401,
          28,
          401,
          58,
          401,
          17,
          407,
          23
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/image_processing_deta.py": [
        [
          "prepare_coco_panoptic_annotation",
          339,
          377,
          358,
          28,
          358,
          58,
          358,
          17,
          364,
          23
        ]
      ],
      "transformers/src/transformers/models/detr/image_processing_detr.py": [
        [
          "prepare_coco_panoptic_annotation",
          377,
          415,
          396,
          28,
          396,
          58,
          396,
          17,
          402,
          23
        ]
      ],
      "transformers/src/transformers/models/grounding_dino/image_processing_grounding_dino.py": [
        [
          "prepare_coco_panoptic_annotation",
          390,
          428,
          409,
          28,
          409,
          58,
          409,
          17,
          415,
          23
        ]
      ],
      "transformers/src/transformers/models/yolos/image_processing_yolos.py": [
        [
          "prepare_coco_panoptic_annotation",
          428,
          466,
          447,
          28,
          447,
          58,
          447,
          17,
          453,
          23
        ]
      ],
      "transformers/src/transformers/image_utils.py": [
        [
          "load_image",
          444,
          483,
          464,
          21,
          464,
          41,
          464,
          21,
          464,
          17
        ],
        [
          "load_image",
          444,
          483,
          462,
          21,
          462,
          109,
          462,
          21,
          462,
          17
        ],
        [
          "load_image",
          444,
          483,
          472,
          25,
          472,
          52,
          472,
          25,
          472,
          52
        ]
      ],
      "transformers/examples/pytorch/contrastive-image-text/run_clip.py": [
        [
          "filter_corrupt_images",
          429,
          438,
          434,
          17,
          434,
          38,
          434,
          28,
          434,
          38
        ]
      ],
      "transformers/examples/pytorch/image-classification/run_image_classification.py": [
        [
          "pil_loader",
          79,
          82,
          81,
          14,
          81,
          26,
          79,
          16,
          82,
          32
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "get_processor_inputs_from_inbound_messages",
          911,
          954,
          943,
          41,
          943,
          89,
          942,
          46,
          948,
          53
        ]
      ],
      "transformers/tests/models/conditional_detr/test_image_processing_conditional_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          170,
          212,
          172,
          17,
          172,
          82,
          170,
          59,
          178,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          215,
          263,
          217,
          17,
          217,
          82,
          215,
          58,
          225,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          383,
          268,
          19,
          268,
          84,
          267,
          49,
          280,
          57
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          383,
          269,
          19,
          269,
          84,
          267,
          49,
          280,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          386,
          507,
          388,
          19,
          388,
          84,
          386,
          48,
          399,
          58
        ],
        [
          "test_batched_coco_panoptic_annotations",
          386,
          507,
          389,
          19,
          389,
          84,
          386,
          48,
          399,
          58
        ]
      ],
      "transformers/tests/models/deformable_detr/test_image_processing_deformable_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          175,
          217,
          177,
          17,
          177,
          82,
          175,
          59,
          183,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          220,
          268,
          222,
          17,
          222,
          82,
          220,
          58,
          230,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          272,
          388,
          273,
          19,
          273,
          84,
          272,
          49,
          285,
          57
        ],
        [
          "test_batched_coco_detection_annotations",
          272,
          388,
          274,
          19,
          274,
          84,
          272,
          49,
          285,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          391,
          512,
          393,
          19,
          393,
          84,
          391,
          48,
          404,
          58
        ],
        [
          "test_batched_coco_panoptic_annotations",
          391,
          512,
          394,
          19,
          394,
          84,
          391,
          48,
          404,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          618,
          671,
          620,
          17,
          620,
          82,
          618,
          84,
          671,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          676,
          740,
          678,
          17,
          678,
          82,
          676,
          83,
          740,
          114
        ]
      ],
      "transformers/tests/models/detr/test_image_processing_detr.py": [
        [
          "test_should_raise_if_annotation_format_invalid",
          178,
          199,
          187,
          23,
          187,
          88,
          178,
          56,
          193,
          63
        ],
        [
          "test_valid_coco_detection_annotations",
          201,
          235,
          203,
          17,
          203,
          82,
          201,
          47,
          209,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          238,
          280,
          240,
          17,
          240,
          82,
          238,
          59,
          246,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          283,
          331,
          285,
          17,
          285,
          82,
          283,
          58,
          293,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          334,
          450,
          335,
          19,
          335,
          84,
          334,
          49,
          347,
          57
        ],
        [
          "test_batched_coco_detection_annotations",
          334,
          450,
          336,
          19,
          336,
          84,
          334,
          49,
          347,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          452,
          573,
          454,
          19,
          454,
          84,
          452,
          48,
          465,
          58
        ],
        [
          "test_batched_coco_panoptic_annotations",
          452,
          573,
          455,
          19,
          455,
          84,
          452,
          48,
          465,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          678,
          729,
          680,
          17,
          680,
          82,
          678,
          84,
          729,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          734,
          796,
          736,
          17,
          736,
          82,
          734,
          83,
          796,
          114
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_slow_fast_equivalence",
          180,
          197,
          187,
          23,
          191,
          9,
          187,
          23,
          197,
          106
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          712,
          23,
          712,
          68,
          702,
          57,
          754,
          51
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          725,
          23,
          725,
          68,
          702,
          57,
          754,
          51
        ]
      ],
      "transformers/tests/models/flava/test_image_processing_flava.py": [
        [
          "test_slow_fast_equivalence",
          402,
          425,
          409,
          23,
          411,
          9,
          409,
          23,
          425,
          9
        ]
      ],
      "transformers/tests/models/imagegpt/test_image_processing_imagegpt.py": [
        [
          "test_slow_fast_equivalence",
          272,
          289,
          279,
          23,
          281,
          9,
          279,
          23,
          289,
          9
        ]
      ],
      "transformers/tests/models/grounding_dino/test_image_processing_grounding_dino.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          207,
          249,
          209,
          17,
          209,
          82,
          207,
          59,
          215,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          253,
          369,
          254,
          19,
          254,
          84,
          253,
          49,
          266,
          57
        ],
        [
          "test_batched_coco_detection_annotations",
          253,
          369,
          255,
          19,
          255,
          84,
          253,
          49,
          266,
          57
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          373,
          421,
          375,
          17,
          375,
          82,
          373,
          58,
          383,
          63
        ],
        [
          "test_batched_coco_panoptic_annotations",
          425,
          546,
          427,
          19,
          427,
          84,
          425,
          48,
          438,
          58
        ],
        [
          "test_batched_coco_panoptic_annotations",
          425,
          546,
          428,
          19,
          428,
          84,
          425,
          48,
          438,
          58
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_image_processing_layoutlmv2.py": [
        [
          "test_slow_fast_equivalence",
          158,
          175,
          165,
          23,
          167,
          9,
          165,
          23,
          175,
          9
        ]
      ],
      "transformers/tests/models/mask2former/test_image_processing_mask2former.py": [
        [
          "test_integration_instance_segmentation",
          304,
          362,
          316,
          23,
          318,
          9,
          304,
          48,
          362,
          72
        ],
        [
          "test_integration_instance_segmentation",
          304,
          362,
          307,
          18,
          309,
          9,
          304,
          48,
          362,
          72
        ],
        [
          "test_integration_instance_segmentation",
          304,
          362,
          310,
          18,
          312,
          9,
          304,
          48,
          362,
          72
        ],
        [
          "test_integration_instance_segmentation",
          304,
          362,
          313,
          23,
          315,
          9,
          304,
          48,
          362,
          72
        ],
        [
          "test_integration_semantic_segmentation",
          364,
          404,
          367,
          18,
          369,
          9,
          364,
          48,
          404,
          73
        ],
        [
          "test_integration_semantic_segmentation",
          364,
          404,
          370,
          18,
          372,
          9,
          364,
          48,
          404,
          73
        ],
        [
          "test_integration_semantic_segmentation",
          364,
          404,
          373,
          23,
          375,
          9,
          364,
          48,
          404,
          73
        ],
        [
          "test_integration_semantic_segmentation",
          364,
          404,
          376,
          23,
          378,
          9,
          364,
          48,
          404,
          73
        ]
      ],
      "transformers/tests/models/maskformer/test_image_processing_maskformer.py": [
        [
          "test_integration_instance_segmentation",
          255,
          313,
          261,
          18,
          263,
          9,
          255,
          48,
          313,
          72
        ],
        [
          "test_integration_semantic_segmentation",
          315,
          355,
          327,
          23,
          329,
          9,
          315,
          48,
          355,
          73
        ],
        [
          "test_integration_instance_segmentation",
          255,
          313,
          258,
          18,
          260,
          9,
          255,
          48,
          313,
          72
        ],
        [
          "test_integration_instance_segmentation",
          255,
          313,
          264,
          23,
          266,
          9,
          255,
          48,
          313,
          72
        ],
        [
          "test_integration_instance_segmentation",
          255,
          313,
          267,
          23,
          269,
          9,
          255,
          48,
          313,
          72
        ],
        [
          "test_integration_semantic_segmentation",
          315,
          355,
          318,
          18,
          320,
          9,
          315,
          48,
          355,
          73
        ],
        [
          "test_integration_semantic_segmentation",
          315,
          355,
          321,
          18,
          323,
          9,
          315,
          48,
          355,
          73
        ],
        [
          "test_integration_semantic_segmentation",
          315,
          355,
          324,
          23,
          326,
          9,
          315,
          48,
          355,
          73
        ]
      ],
      "transformers/tests/models/nougat/test_image_processing_nougat.py": [
        [
          "prepare_dummy_image",
          96,
          105,
          104,
          17,
          104,
          36,
          96,
          29,
          105,
          20
        ],
        [
          "prepare_dummy_np_image",
          243,
          252,
          251,
          17,
          251,
          36,
          243,
          32,
          252,
          49
        ]
      ],
      "transformers/tests/models/owlv2/test_image_processing_owlv2.py": [
        [
          "test_image_processor_integration_test_resize",
          133,
          169,
          139,
          21,
          139,
          86,
          134,
          13,
          167,
          33
        ],
        [
          "test_image_processor_integration_test",
          122,
          130,
          126,
          21,
          126,
          86,
          123,
          13,
          130,
          48
        ]
      ],
      "transformers/tests/models/rt_detr/test_image_processing_rt_detr.py": [
        [
          "test_batched_coco_detection_annotations",
          267,
          379,
          268,
          19,
          268,
          84,
          267,
          49,
          280,
          57
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          379,
          269,
          19,
          269,
          84,
          267,
          49,
          280,
          57
        ],
        [
          "test_valid_coco_detection_annotations",
          125,
          159,
          127,
          17,
          127,
          82,
          125,
          47,
          133,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          162,
          204,
          164,
          17,
          164,
          82,
          162,
          59,
          170,
          63
        ],
        [
          "test_image_processor_outputs",
          207,
          220,
          208,
          17,
          208,
          82,
          207,
          38,
          210,
          63
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          385,
          436,
          387,
          17,
          387,
          82,
          385,
          84,
          436,
          114
        ]
      ],
      "transformers/tests/models/yolos/test_image_processing_yolos.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          226,
          268,
          228,
          17,
          228,
          82,
          226,
          59,
          234,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          271,
          319,
          273,
          17,
          273,
          82,
          271,
          58,
          281,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          323,
          439,
          324,
          19,
          324,
          84,
          323,
          49,
          336,
          57
        ],
        [
          "test_batched_coco_detection_annotations",
          323,
          439,
          325,
          19,
          325,
          84,
          323,
          49,
          336,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          442,
          564,
          444,
          19,
          444,
          84,
          442,
          48,
          455,
          58
        ],
        [
          "test_batched_coco_panoptic_annotations",
          442,
          564,
          445,
          19,
          445,
          84,
          442,
          48,
          455,
          58
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "get_image_from_hub_dataset",
          49,
          51,
          51,
          12,
          51,
          81,
          49,
          32,
          51,
          81
        ]
      ],
      "transformers/tests/models/aimv2/test_modeling_aimv2.py": [
        [
          "test_inference",
          482,
          508,
          487,
          17,
          487,
          115,
          482,
          24,
          508,
          99
        ],
        [
          "test_inference",
          515,
          543,
          521,
          17,
          521,
          115,
          515,
          24,
          543,
          81
        ],
        [
          "test_inference_for_native_resolution",
          546,
          574,
          552,
          17,
          552,
          115,
          546,
          46,
          574,
          81
        ]
      ],
      "transformers/tests/models/align/test_modeling_align.py": [
        [
          "prepare_img",
          585,
          588,
          587,
          10,
          587,
          55,
          586,
          11,
          588,
          13
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "prepare_img",
          404,
          407,
          406,
          10,
          406,
          55,
          405,
          11,
          407,
          13
        ],
        [
          "test_inference_interpolate_pos_encoding",
          577,
          615,
          589,
          17,
          589,
          82,
          577,
          49,
          615,
          9
        ]
      ],
      "transformers/tests/models/aria/test_modeling_aria.py": [
        [
          "test_batched_generation",
          425,
          491,
          440,
          18,
          440,
          64,
          425,
          33,
          491,
          54
        ],
        [
          "test_small_model_integration_test",
          241,
          274,
          249,
          21,
          249,
          80,
          241,
          43,
          274,
          57
        ],
        [
          "test_small_model_integration_test_llama_single",
          279,
          306,
          290,
          21,
          290,
          80,
          279,
          56,
          306,
          9
        ],
        [
          "test_small_model_integration_test_llama_batched",
          311,
          348,
          325,
          18,
          325,
          77,
          311,
          57,
          348,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched",
          311,
          348,
          326,
          18,
          326,
          116,
          311,
          57,
          348,
          63
        ],
        [
          "test_small_model_integration_test_batch",
          353,
          385,
          364,
          18,
          364,
          77,
          353,
          49,
          385,
          63
        ],
        [
          "test_small_model_integration_test_batch",
          353,
          385,
          365,
          18,
          365,
          116,
          353,
          49,
          385,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          390,
          419,
          405,
          18,
          405,
          77,
          390,
          68,
          419,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          390,
          419,
          406,
          18,
          406,
          116,
          390,
          68,
          419,
          63
        ],
        [
          "test_batched_generation",
          425,
          491,
          439,
          18,
          439,
          64,
          425,
          33,
          491,
          54
        ]
      ],
      "transformers/tests/models/beit/test_modeling_beit.py": [
        [
          "prepare_img",
          393,
          395,
          394,
          13,
          394,
          78,
          394,
          13,
          395,
          16
        ],
        [
          "test_inference_interpolate_pos_encoding",
          537,
          554,
          541,
          17,
          541,
          82,
          537,
          49,
          554,
          73
        ]
      ],
      "transformers/tests/models/bit/test_modeling_bit.py": [
        [
          "prepare_img",
          252,
          254,
          253,
          13,
          253,
          78,
          253,
          13,
          254,
          16
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip.py": [
        [
          "prepare_img",
          1232,
          1235,
          1234,
          10,
          1234,
          55,
          1233,
          11,
          1235,
          13
        ]
      ],
      "transformers/tests/models/bridgetower/test_modeling_bridgetower.py": [
        [
          "prepare_img",
          453,
          455,
          454,
          13,
          454,
          78,
          454,
          13,
          455,
          16
        ],
        [
          "test_inference_interpolate_pos_encoding",
          599,
          630,
          609,
          17,
          609,
          82,
          599,
          49,
          630,
          107
        ]
      ],
      "transformers/tests/models/blip_2/test_modeling_blip_2.py": [
        [
          "prepare_img",
          1497,
          1500,
          1499,
          13,
          1499,
          58,
          1498,
          11,
          1500,
          16
        ]
      ],
      "transformers/tests/models/chameleon/test_modeling_chameleon.py": [
        [
          "test_model_7b_multi_image",
          444,
          464,
          450,
          17,
          452,
          9,
          444,
          35,
          464,
          56
        ],
        [
          "test_model_7b",
          367,
          392,
          373,
          17,
          375,
          9,
          367,
          23,
          392,
          56
        ],
        [
          "test_model_7b_batched",
          397,
          439,
          403,
          17,
          405,
          9,
          397,
          31,
          439,
          56
        ],
        [
          "test_model_7b_batched",
          397,
          439,
          406,
          19,
          408,
          9,
          397,
          31,
          439,
          56
        ],
        [
          "test_model_7b_multi_image",
          444,
          464,
          453,
          19,
          455,
          9,
          444,
          35,
          464,
          56
        ]
      ],
      "transformers/tests/models/chinese_clip/test_modeling_chinese_clip.py": [
        [
          "prepare_img",
          653,
          656,
          655,
          10,
          655,
          55,
          654,
          11,
          656,
          13
        ],
        [
          "test_inference_interpolate_pos_encoding",
          693,
          728,
          705,
          17,
          705,
          82,
          693,
          49,
          728,
          9
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "prepare_img",
          609,
          612,
          611,
          13,
          611,
          58,
          610,
          11,
          612,
          16
        ],
        [
          "test_inference_interpolate_pos_encoding",
          650,
          684,
          661,
          17,
          661,
          82,
          650,
          49,
          684,
          9
        ]
      ],
      "transformers/tests/models/clip/test_modeling_clip.py": [
        [
          "prepare_img",
          741,
          744,
          743,
          10,
          743,
          55,
          742,
          11,
          744,
          13
        ],
        [
          "test_inference_interpolate_pos_encoding",
          780,
          814,
          791,
          17,
          791,
          82,
          780,
          49,
          814,
          9
        ]
      ],
      "transformers/tests/models/convnext/test_modeling_convnext.py": [
        [
          "prepare_img",
          261,
          263,
          262,
          13,
          262,
          78,
          262,
          13,
          263,
          16
        ]
      ],
      "transformers/tests/models/convnextv2/test_modeling_convnextv2.py": [
        [
          "prepare_img",
          281,
          283,
          282,
          13,
          282,
          78,
          282,
          13,
          283,
          16
        ]
      ],
      "transformers/tests/models/conditional_detr/test_modeling_conditional_detr.py": [
        [
          "prepare_img",
          514,
          516,
          515,
          13,
          515,
          78,
          515,
          13,
          516,
          16
        ]
      ],
      "transformers/tests/models/cvt/test_modeling_cvt.py": [
        [
          "prepare_img",
          244,
          246,
          245,
          13,
          245,
          78,
          245,
          13,
          246,
          16
        ]
      ],
      "transformers/tests/models/data2vec/test_modeling_data2vec_vision.py": [
        [
          "prepare_img",
          306,
          308,
          307,
          13,
          307,
          78,
          307,
          13,
          308,
          16
        ],
        [
          "test_inference_interpolate_pos_encoding",
          347,
          366,
          353,
          17,
          353,
          82,
          347,
          49,
          366,
          73
        ]
      ],
      "transformers/tests/models/d_fine/test_modeling_d_fine.py": [
        [
          "prepare_img",
          697,
          699,
          698,
          13,
          698,
          78,
          698,
          13,
          699,
          16
        ]
      ],
      "transformers/tests/models/dab_detr/test_modeling_dab_detr.py": [
        [
          "prepare_img",
          709,
          711,
          710,
          13,
          710,
          78,
          710,
          13,
          711,
          16
        ]
      ],
      "transformers/tests/models/deit/test_modeling_deit.py": [
        [
          "prepare_img",
          388,
          390,
          389,
          13,
          389,
          78,
          389,
          13,
          390,
          16
        ]
      ],
      "transformers/tests/models/depth_anything/test_modeling_depth_anything.py": [
        [
          "prepare_img",
          235,
          237,
          236,
          13,
          236,
          78,
          236,
          13,
          237,
          16
        ]
      ],
      "transformers/tests/models/deformable_detr/test_modeling_deformable_detr.py": [
        [
          "prepare_img",
          622,
          624,
          623,
          13,
          623,
          78,
          623,
          13,
          624,
          16
        ]
      ],
      "transformers/tests/models/depth_pro/test_modeling_depth_pro.py": [
        [
          "prepare_img",
          316,
          318,
          317,
          13,
          317,
          78,
          317,
          13,
          318,
          16
        ]
      ],
      "transformers/tests/models/dinat/test_modeling_dinat.py": [
        [
          "test_inference_image_classification_head",
          339,
          354,
          343,
          17,
          343,
          82,
          339,
          50,
          354,
          95
        ]
      ],
      "transformers/tests/models/dinov2/test_modeling_dinov2.py": [
        [
          "prepare_img",
          297,
          299,
          298,
          13,
          298,
          78,
          298,
          13,
          299,
          16
        ]
      ],
      "transformers/tests/models/dinov3_convnext/test_modeling_dinov3_convnext.py": [
        [
          "prepare_img",
          202,
          204,
          203,
          13,
          203,
          78,
          203,
          13,
          204,
          16
        ]
      ],
      "transformers/tests/models/dinov2_with_registers/test_modeling_dinov2_with_registers.py": [
        [
          "prepare_img",
          305,
          307,
          306,
          13,
          306,
          78,
          306,
          13,
          307,
          16
        ]
      ],
      "transformers/tests/models/dinov3_vit/test_modeling_dinov3_vit.py": [
        [
          "prepare_img",
          213,
          215,
          214,
          13,
          214,
          78,
          214,
          13,
          215,
          16
        ]
      ],
      "transformers/tests/models/detr/test_modeling_detr.py": [
        [
          "prepare_img",
          534,
          536,
          535,
          13,
          535,
          78,
          535,
          13,
          536,
          16
        ]
      ],
      "transformers/tests/models/dpt/test_modeling_dpt_hybrid.py": [
        [
          "prepare_img",
          288,
          290,
          289,
          13,
          289,
          78,
          289,
          13,
          290,
          16
        ]
      ],
      "transformers/tests/models/dpt/test_modeling_dpt_auto_backbone.py": [
        [
          "prepare_img",
          221,
          223,
          222,
          13,
          222,
          78,
          222,
          13,
          223,
          16
        ]
      ],
      "transformers/tests/models/dpt/test_modeling_dpt.py": [
        [
          "prepare_img",
          299,
          301,
          300,
          13,
          300,
          78,
          300,
          13,
          301,
          16
        ]
      ],
      "transformers/tests/models/edgetam_video/test_modeling_edgetam_video.py": [
        [
          "prepare_image",
          41,
          44,
          43,
          17,
          43,
          66,
          42,
          15,
          44,
          20
        ],
        [
          "prepare_groceries_image",
          47,
          50,
          49,
          17,
          49,
          66,
          48,
          15,
          50,
          20
        ],
        [
          "prepare_dog_img",
          53,
          56,
          55,
          17,
          55,
          66,
          54,
          15,
          56,
          20
        ]
      ],
      "transformers/tests/models/efficientnet/test_modeling_efficientnet.py": [
        [
          "prepare_img",
          233,
          235,
          234,
          13,
          234,
          78,
          234,
          13,
          235,
          16
        ]
      ],
      "transformers/tests/models/edgetam/test_modeling_edgetam.py": [
        [
          "prepare_image",
          441,
          444,
          443,
          17,
          443,
          66,
          442,
          15,
          444,
          20
        ],
        [
          "prepare_groceries_image",
          447,
          450,
          449,
          17,
          449,
          66,
          448,
          15,
          450,
          20
        ],
        [
          "prepare_dog_img",
          453,
          456,
          455,
          17,
          455,
          66,
          454,
          15,
          456,
          20
        ]
      ],
      "transformers/tests/models/emu3/test_modeling_emu3.py": [
        [
          "test_model_generation_batched",
          379,
          417,
          384,
          17,
          384,
          95,
          379,
          39,
          417,
          56
        ],
        [
          "test_model_generation",
          361,
          374,
          365,
          17,
          365,
          97,
          361,
          31,
          374,
          56
        ],
        [
          "test_model_generation_batched",
          379,
          417,
          385,
          19,
          385,
          97,
          379,
          39,
          417,
          56
        ],
        [
          "test_model_generation_multi_image",
          422,
          444,
          426,
          17,
          426,
          95,
          422,
          43,
          444,
          56
        ],
        [
          "test_model_generation_multi_image",
          422,
          444,
          427,
          19,
          427,
          97,
          422,
          43,
          444,
          56
        ]
      ],
      "transformers/tests/models/eomt/test_modeling_eomt.py": [
        [
          "test_inference",
          242,
          280,
          246,
          17,
          246,
          115,
          242,
          24,
          280,
          86
        ],
        [
          "test_inference_fp16",
          285,
          297,
          289,
          17,
          289,
          115,
          285,
          29,
          297,
          81
        ],
        [
          "test_semantic_segmentation_inference",
          300,
          335,
          305,
          17,
          305,
          115,
          300,
          46,
          335,
          86
        ],
        [
          "test_panoptic_segmentation_inference",
          338,
          383,
          342,
          17,
          342,
          115,
          338,
          46,
          380,
          74
        ],
        [
          "test_instance_segmentation_inference",
          386,
          433,
          391,
          17,
          391,
          115,
          386,
          46,
          430,
          74
        ],
        [
          "test_segmentation_pipeline",
          436,
          445,
          437,
          17,
          437,
          115,
          436,
          36,
          445,
          63
        ]
      ],
      "transformers/tests/models/florence2/test_modeling_florence2.py": [
        [
          "prepare_img",
          250,
          253,
          252,
          13,
          252,
          58,
          251,
          11,
          253,
          16
        ],
        [
          "setUp",
          259,
          271,
          260,
          23,
          265,
          9,
          259,
          15,
          266,
          19
        ],
        [
          "setUp",
          259,
          271,
          266,
          23,
          271,
          9,
          259,
          15,
          266,
          19
        ]
      ],
      "transformers/tests/models/focalnet/test_modeling_focalnet.py": [
        [
          "test_inference_image_classification_head",
          400,
          424,
          404,
          17,
          404,
          82,
          400,
          50,
          424,
          66
        ]
      ],
      "transformers/tests/models/flava/test_modeling_flava.py": [
        [
          "prepare_img",
          1203,
          1206,
          1205,
          10,
          1205,
          55,
          1204,
          11,
          1206,
          13
        ]
      ],
      "transformers/tests/models/fuyu/test_modeling_fuyu.py": [
        [
          "test_greedy_generation",
          276,
          292,
          281,
          17,
          281,
          65,
          276,
          32,
          292,
          84
        ]
      ],
      "transformers/tests/models/git/test_modeling_git.py": [
        [
          "test_forward_pass",
          460,
          478,
          466,
          17,
          466,
          82,
          460,
          27,
          478,
          99
        ],
        [
          "test_inference_image_captioning",
          480,
          499,
          485,
          17,
          485,
          82,
          480,
          41,
          499,
          99
        ],
        [
          "test_visual_question_answering",
          501,
          523,
          508,
          17,
          508,
          37,
          501,
          40,
          523,
          101
        ],
        [
          "test_batched_generation",
          525,
          541,
          531,
          17,
          531,
          82,
          525,
          33,
          541,
          106
        ],
        [
          "test_inference_interpolate_pos_encoding",
          544,
          576,
          555,
          17,
          555,
          82,
          544,
          49,
          576,
          110
        ]
      ],
      "transformers/tests/models/glpn/test_modeling_glpn.py": [
        [
          "prepare_img",
          319,
          321,
          320,
          13,
          320,
          78,
          320,
          13,
          321,
          16
        ]
      ],
      "transformers/tests/models/grounding_dino/test_modeling_grounding_dino.py": [
        [
          "prepare_img",
          625,
          627,
          626,
          13,
          626,
          78,
          626,
          13,
          627,
          16
        ]
      ],
      "transformers/tests/models/groupvit/test_modeling_groupvit.py": [
        [
          "prepare_img",
          663,
          666,
          665,
          10,
          665,
          55,
          664,
          11,
          666,
          13
        ]
      ],
      "transformers/tests/models/idefics3/test_modeling_idefics3.py": [
        [
          "setUp",
          485,
          503,
          487,
          23,
          493,
          9,
          485,
          15,
          497,
          19
        ],
        [
          "setUp",
          485,
          503,
          494,
          23,
          496,
          9,
          485,
          15,
          497,
          19
        ],
        [
          "setUp",
          485,
          503,
          497,
          23,
          503,
          9,
          485,
          15,
          497,
          19
        ]
      ],
      "transformers/tests/models/idefics2/test_modeling_idefics2.py": [
        [
          "setUp",
          544,
          562,
          546,
          23,
          552,
          9,
          544,
          15,
          556,
          19
        ],
        [
          "setUp",
          544,
          562,
          553,
          23,
          555,
          9,
          544,
          15,
          556,
          19
        ],
        [
          "setUp",
          544,
          562,
          556,
          23,
          562,
          9,
          544,
          15,
          556,
          19
        ]
      ],
      "transformers/tests/models/hiera/test_modeling_hiera.py": [
        [
          "prepare_img",
          522,
          524,
          523,
          13,
          523,
          78,
          523,
          13,
          524,
          16
        ]
      ],
      "transformers/tests/models/idefics/test_modeling_idefics.py": [
        [
          "test_inference_natural_language_visual_reasoning",
          857,
          900,
          859,
          26,
          859,
          51,
          857,
          58,
          895,
          45
        ]
      ],
      "transformers/tests/models/ijepa/test_modeling_ijepa.py": [
        [
          "prepare_img",
          258,
          260,
          259,
          13,
          259,
          78,
          259,
          13,
          260,
          16
        ]
      ],
      "transformers/tests/models/imagegpt/test_modeling_imagegpt.py": [
        [
          "prepare_img",
          320,
          322,
          321,
          13,
          321,
          78,
          321,
          13,
          322,
          16
        ]
      ],
      "transformers/tests/models/internvl/test_modeling_internvl.py": [
        [
          "test_qwen2_small_model_integration_generate",
          231,
          250,
          237,
          17,
          237,
          62,
          231,
          53,
          250,
          57
        ],
        [
          "test_qwen2_small_model_integration_forward",
          252,
          284,
          258,
          17,
          258,
          62,
          252,
          52,
          284,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate",
          339,
          387,
          349,
          18,
          349,
          111,
          339,
          61,
          387,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate",
          339,
          387,
          350,
          18,
          355,
          9,
          339,
          61,
          387,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate_multi_image",
          389,
          445,
          399,
          18,
          399,
          111,
          389,
          73,
          445,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate_multi_image",
          389,
          445,
          400,
          18,
          406,
          9,
          389,
          73,
          445,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate_multi_image",
          389,
          445,
          407,
          18,
          413,
          9,
          389,
          73,
          445,
          9
        ],
        [
          "test_llama_small_model_integration_generate",
          608,
          626,
          614,
          17,
          614,
          62,
          608,
          53,
          626,
          57
        ],
        [
          "test_llama_small_model_integration_forward",
          628,
          667,
          634,
          17,
          634,
          62,
          628,
          52,
          667,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate",
          718,
          766,
          728,
          18,
          728,
          111,
          718,
          61,
          766,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate",
          718,
          766,
          729,
          18,
          734,
          9,
          718,
          61,
          766,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate_multi_image",
          768,
          818,
          778,
          18,
          778,
          111,
          768,
          73,
          818,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate_multi_image",
          768,
          818,
          779,
          18,
          785,
          9,
          768,
          73,
          818,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate_multi_image",
          768,
          818,
          786,
          18,
          792,
          9,
          768,
          73,
          818,
          9
        ]
      ],
      "transformers/tests/models/janus/test_modeling_janus.py": [
        [
          "test_model_text_generation",
          407,
          423,
          411,
          17,
          413,
          9,
          407,
          36,
          423,
          9
        ],
        [
          "test_model_text_generation_batched",
          426,
          451,
          430,
          19,
          432,
          9,
          426,
          44,
          451,
          56
        ],
        [
          "test_model_text_generation_batched",
          426,
          451,
          433,
          19,
          435,
          9,
          426,
          44,
          451,
          56
        ],
        [
          "test_model_text_generation_with_multi_image",
          454,
          473,
          458,
          19,
          460,
          9,
          454,
          53,
          473,
          56
        ],
        [
          "test_model_text_generation_with_multi_image",
          454,
          473,
          461,
          19,
          463,
          9,
          454,
          53,
          473,
          56
        ]
      ],
      "transformers/tests/models/instructblip/test_modeling_instructblip.py": [
        [
          "test_inference_vicuna_7b",
          631,
          663,
          638,
          17,
          638,
          62,
          631,
          34,
          663,
          55
        ],
        [
          "prepare_img",
          616,
          619,
          618,
          13,
          618,
          58,
          617,
          11,
          619,
          16
        ],
        [
          "test_inference_flant5_xl",
          665,
          698,
          673,
          17,
          673,
          62,
          665,
          34,
          677,
          34
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_modeling_kosmos2_5.py": [
        [
          "test_sdpa",
          638,
          673,
          640,
          17,
          640,
          62,
          638,
          19,
          673,
          103
        ],
        [
          "test_eager",
          601,
          636,
          603,
          17,
          603,
          62,
          601,
          20,
          636,
          103
        ],
        [
          "test_FA2",
          679,
          707,
          681,
          17,
          681,
          62,
          679,
          18,
          707,
          55
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_modeling_layoutlmv3.py": [
        [
          "prepare_img",
          377,
          379,
          378,
          13,
          378,
          78,
          378,
          13,
          379,
          16
        ]
      ],
      "transformers/tests/models/kosmos2/test_modeling_kosmos2.py": [
        [
          "test_snowman_image_captioning",
          654,
          798,
          657,
          17,
          657,
          62,
          654,
          39,
          671,
          38
        ],
        [
          "prepare_img",
          619,
          622,
          621,
          10,
          621,
          55,
          620,
          11,
          622,
          13
        ],
        [
          "test_snowman_image_captioning",
          654,
          798,
          659,
          17,
          659,
          43,
          654,
          39,
          671,
          38
        ],
        [
          "test_snowman_image_captioning_batch",
          800,
          871,
          803,
          17,
          803,
          62,
          800,
          45,
          871,
          66
        ],
        [
          "test_snowman_image_captioning_batch",
          800,
          871,
          805,
          17,
          805,
          43,
          800,
          45,
          871,
          66
        ],
        [
          "test_inference_interpolate_pos_encoding",
          874,
          908,
          885,
          17,
          885,
          82,
          874,
          49,
          908,
          9
        ]
      ],
      "transformers/tests/models/lfm2_vl/test_modeling_lfm2_vl.py": [
        [
          "setUp",
          212,
          224,
          215,
          22,
          217,
          9,
          212,
          15,
          218,
          19
        ],
        [
          "setUp",
          212,
          224,
          218,
          23,
          224,
          9,
          212,
          15,
          218,
          19
        ]
      ],
      "transformers/tests/models/levit/test_modeling_levit.py": [
        [
          "prepare_img",
          381,
          383,
          382,
          13,
          382,
          78,
          382,
          13,
          383,
          16
        ]
      ],
      "transformers/tests/models/llava_next_video/test_modeling_llava_next_video.py": [
        [
          "setUp",
          334,
          345,
          342,
          22,
          342,
          43,
          334,
          15,
          345,
          25
        ]
      ],
      "transformers/tests/models/llava_onevision/test_modeling_llava_onevision.py": [
        [
          "test_small_model_integration_test_multi_image",
          392,
          422,
          401,
          17,
          401,
          62,
          392,
          55,
          422,
          60
        ],
        [
          "setUp",
          293,
          306,
          303,
          22,
          303,
          43,
          293,
          15,
          306,
          25
        ],
        [
          "test_small_model_integration_test_multi_image_nested",
          426,
          470,
          435,
          17,
          435,
          62,
          426,
          62,
          470,
          65
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          498,
          524,
          505,
          22,
          505,
          67,
          498,
          71,
          524,
          9
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          498,
          524,
          506,
          22,
          506,
          74,
          498,
          71,
          524,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          528,
          558,
          537,
          22,
          537,
          67,
          528,
          64,
          558,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          528,
          558,
          538,
          22,
          538,
          74,
          528,
          64,
          558,
          9
        ]
      ],
      "transformers/tests/models/llava_next/test_modeling_llava_next.py": [
        [
          "setUp",
          317,
          322,
          320,
          22,
          320,
          67,
          317,
          15,
          322,
          19
        ],
        [
          "test_small_model_integration_test_batch",
          373,
          394,
          378,
          22,
          378,
          67,
          373,
          49,
          394,
          9
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          424,
          460,
          432,
          22,
          432,
          67,
          424,
          71,
          449,
          70
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          424,
          460,
          433,
          22,
          433,
          74,
          424,
          71,
          449,
          70
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          464,
          489,
          472,
          22,
          472,
          67,
          464,
          64,
          489,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          464,
          489,
          473,
          22,
          473,
          74,
          464,
          64,
          489,
          9
        ]
      ],
      "transformers/tests/models/llava/test_modeling_llava.py": [
        [
          "test_small_model_integration_test",
          292,
          311,
          298,
          21,
          298,
          73,
          292,
          43,
          311,
          9
        ],
        [
          "test_small_model_integration_test_llama_single",
          315,
          341,
          324,
          21,
          324,
          73,
          315,
          56,
          341,
          9
        ],
        [
          "test_small_model_integration_test_llama_batched",
          345,
          384,
          356,
          18,
          356,
          111,
          345,
          57,
          384,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched",
          345,
          384,
          357,
          18,
          357,
          116,
          345,
          57,
          384,
          63
        ],
        [
          "test_small_model_integration_test_batch",
          388,
          426,
          396,
          18,
          396,
          111,
          388,
          49,
          426,
          9
        ],
        [
          "test_small_model_integration_test_batch",
          388,
          426,
          397,
          18,
          397,
          116,
          388,
          49,
          426,
          9
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          430,
          474,
          444,
          18,
          444,
          111,
          430,
          68,
          474,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          430,
          474,
          445,
          18,
          445,
          116,
          430,
          68,
          474,
          63
        ],
        [
          "test_batched_generation",
          480,
          525,
          490,
          18,
          490,
          64,
          480,
          33,
          525,
          50
        ],
        [
          "test_batched_generation",
          480,
          525,
          491,
          18,
          491,
          64,
          480,
          33,
          525,
          50
        ],
        [
          "test_generation_siglip_backbone",
          560,
          577,
          566,
          21,
          566,
          73,
          560,
          41,
          577,
          109
        ],
        [
          "test_pixtral",
          580,
          607,
          586,
          13,
          586,
          93,
          580,
          22,
          607,
          53
        ],
        [
          "test_pixtral",
          580,
          607,
          587,
          13,
          587,
          93,
          580,
          22,
          607,
          53
        ],
        [
          "test_pixtral_4bit",
          611,
          634,
          617,
          13,
          617,
          93,
          611,
          27,
          634,
          54
        ],
        [
          "test_pixtral_4bit",
          611,
          634,
          618,
          13,
          618,
          93,
          611,
          27,
          634,
          54
        ],
        [
          "test_pixtral_batched",
          638,
          673,
          645,
          13,
          645,
          93,
          638,
          30,
          673,
          53
        ],
        [
          "test_pixtral_batched",
          638,
          673,
          646,
          13,
          646,
          92,
          638,
          30,
          673,
          53
        ]
      ],
      "transformers/tests/models/maskformer/test_modeling_maskformer.py": [
        [
          "prepare_img",
          485,
          487,
          486,
          13,
          486,
          78,
          486,
          13,
          487,
          16
        ]
      ],
      "transformers/tests/models/mgp_str/test_modeling_mgp_str.py": [
        [
          "prepare_img",
          212,
          215,
          214,
          10,
          214,
          55,
          213,
          11,
          215,
          13
        ]
      ],
      "transformers/tests/models/metaclip_2/test_modeling_metaclip_2.py": [
        [
          "prepare_img",
          752,
          755,
          754,
          10,
          754,
          55,
          753,
          11,
          755,
          13
        ]
      ],
      "transformers/tests/models/mask2former/test_modeling_mask2former.py": [
        [
          "prepare_img",
          391,
          393,
          392,
          13,
          392,
          78,
          392,
          13,
          393,
          16
        ]
      ],
      "transformers/tests/models/mlcd/test_modeling_mlcd.py": [
        [
          "test_inference",
          148,
          206,
          155,
          17,
          155,
          62,
          148,
          24,
          206,
          9
        ]
      ],
      "transformers/tests/models/mobilenet_v2/test_modeling_mobilenet_v2.py": [
        [
          "prepare_img",
          274,
          276,
          275,
          13,
          275,
          78,
          275,
          13,
          276,
          16
        ]
      ],
      "transformers/tests/models/mllama/test_modeling_mllama.py": [
        [
          "test_11b_model_integration_generate",
          539,
          585,
          545,
          17,
          545,
          62,
          539,
          45,
          585,
          9
        ],
        [
          "test_11b_model_integration_forward",
          637,
          672,
          643,
          17,
          643,
          62,
          637,
          44,
          672,
          9
        ],
        [
          "test_11b_model_integration_batched_generate",
          678,
          738,
          686,
          18,
          686,
          111,
          678,
          53,
          738,
          9
        ],
        [
          "test_11b_model_integration_batched_generate",
          678,
          738,
          687,
          18,
          692,
          9,
          678,
          53,
          738,
          9
        ],
        [
          "test_11b_model_integration_multi_image_generate",
          744,
          803,
          748,
          18,
          748,
          111,
          744,
          57,
          803,
          9
        ],
        [
          "test_11b_model_integration_multi_image_generate",
          744,
          803,
          749,
          18,
          754,
          9,
          744,
          57,
          803,
          9
        ]
      ],
      "transformers/tests/models/mobilenet_v1/test_modeling_mobilenet_v1.py": [
        [
          "prepare_img",
          219,
          221,
          220,
          13,
          220,
          78,
          220,
          13,
          221,
          16
        ]
      ],
      "transformers/tests/models/mobilevit/test_modeling_mobilevit.py": [
        [
          "prepare_img",
          279,
          281,
          280,
          13,
          280,
          78,
          280,
          13,
          281,
          16
        ]
      ],
      "transformers/tests/models/mm_grounding_dino/test_modeling_mm_grounding_dino.py": [
        [
          "prepare_img",
          630,
          632,
          631,
          13,
          631,
          78,
          631,
          13,
          632,
          16
        ]
      ],
      "transformers/tests/models/mobilevitv2/test_modeling_mobilevitv2.py": [
        [
          "prepare_img",
          293,
          295,
          294,
          13,
          294,
          78,
          294,
          13,
          295,
          16
        ]
      ],
      "transformers/tests/models/ovis2/test_modeling_ovis2.py": [
        [
          "test_small_model_integration_test_multi_image",
          296,
          327,
          305,
          17,
          305,
          62,
          296,
          55,
          327,
          9
        ],
        [
          "setUp",
          234,
          250,
          239,
          22,
          239,
          67,
          234,
          15,
          250,
          17
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          329,
          354,
          335,
          22,
          335,
          74,
          329,
          71,
          354,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          356,
          383,
          364,
          22,
          364,
          74,
          356,
          64,
          383,
          9
        ]
      ],
      "transformers/tests/models/paligemma/test_modeling_paligemma.py": [
        [
          "test_small_model_integration_test",
          349,
          368,
          357,
          21,
          357,
          73,
          349,
          43,
          368,
          9
        ],
        [
          "test_small_model_integration_test_multiimage",
          370,
          405,
          375,
          27,
          380,
          9,
          370,
          54,
          405,
          9
        ],
        [
          "test_small_model_integration_test_multiimage",
          370,
          405,
          381,
          22,
          385,
          9,
          370,
          54,
          405,
          9
        ],
        [
          "test_small_model_integration_test_paligemma_VQA",
          407,
          424,
          415,
          21,
          415,
          73,
          407,
          57,
          424,
          9
        ],
        [
          "test_small_model_integration_test_paligemma_empty_prompt",
          426,
          444,
          435,
          21,
          435,
          73,
          426,
          66,
          444,
          9
        ],
        [
          "test_small_model_integration_test_paligemma_batched",
          446,
          470,
          456,
          18,
          461,
          9,
          446,
          61,
          470,
          110
        ],
        [
          "test_small_model_integration_test_paligemma_batched_bf16",
          472,
          499,
          483,
          18,
          488,
          9,
          472,
          66,
          499,
          110
        ],
        [
          "test_small_model_integration_test_paligemma_batched_f16",
          501,
          529,
          512,
          18,
          517,
          9,
          501,
          65,
          529,
          110
        ],
        [
          "test_integration_detection_bug",
          531,
          559,
          540,
          17,
          545,
          9,
          531,
          40,
          559,
          107
        ],
        [
          "test_paligemma_index_error_bug",
          561,
          582,
          574,
          21,
          574,
          73,
          561,
          40,
          582,
          9
        ],
        [
          "test_paligemma_finetuning_with_suffixes_bf16",
          584,
          624,
          597,
          18,
          602,
          9,
          584,
          54,
          615,
          61
        ]
      ],
      "transformers/tests/models/owlv2/test_modeling_owlv2.py": [
        [
          "prepare_img",
          746,
          749,
          748,
          10,
          748,
          55,
          747,
          11,
          749,
          13
        ]
      ],
      "transformers/tests/models/oneformer/test_modeling_oneformer.py": [
        [
          "prepare_img",
          507,
          509,
          508,
          13,
          508,
          78,
          508,
          13,
          509,
          16
        ]
      ],
      "transformers/tests/models/owlvit/test_modeling_owlvit.py": [
        [
          "prepare_img",
          739,
          742,
          741,
          10,
          741,
          55,
          740,
          11,
          742,
          13
        ]
      ],
      "transformers/tests/models/omdet_turbo/test_modeling_omdet_turbo.py": [
        [
          "listcomp",
          636,
          636,
          636,
          13,
          636,
          58,
          636,
          79,
          636,
          73
        ],
        [
          "prepare_img",
          619,
          622,
          621,
          13,
          621,
          58,
          620,
          11,
          622,
          16
        ]
      ],
      "transformers/tests/models/phi4_multimodal/test_modeling_phi4_multimodal.py": [
        [
          "setUp",
          282,
          295,
          290,
          22,
          290,
          78,
          282,
          15,
          295,
          46
        ],
        [
          "test_multi_image_vision_text_generation",
          345,
          369,
          354,
          27,
          354,
          72,
          352,
          13,
          355,
          23
        ]
      ],
      "transformers/tests/models/prompt_depth_anything/test_modeling_prompt_depth_anything.py": [
        [
          "prepare_img",
          224,
          227,
          226,
          13,
          226,
          58,
          225,
          11,
          227,
          16
        ],
        [
          "prepare_prompt_depth",
          230,
          235,
          234,
          20,
          234,
          78,
          232,
          9,
          235,
          23
        ]
      ],
      "transformers/tests/models/perceiver/test_modeling_perceiver.py": [
        [
          "prepare_img",
          837,
          839,
          838,
          13,
          838,
          78,
          838,
          13,
          839,
          16
        ]
      ],
      "transformers/tests/models/pix2struct/test_modeling_pix2struct.py": [
        [
          "listcomp",
          830,
          830,
          830,
          19,
          830,
          70,
          830,
          76,
          830,
          70
        ],
        [
          "prepare_img",
          731,
          734,
          733,
          10,
          733,
          55,
          732,
          11,
          734,
          13
        ],
        [
          "test_batched_inference_image_captioning",
          755,
          777,
          763,
          19,
          763,
          71,
          755,
          49,
          777,
          9
        ],
        [
          "test_batched_inference_image_captioning_conditioned",
          779,
          803,
          785,
          19,
          785,
          71,
          779,
          61,
          803,
          9
        ],
        [
          "test_vqa_model",
          805,
          820,
          809,
          17,
          809,
          68,
          805,
          24,
          820,
          97
        ]
      ],
      "transformers/tests/models/pvt/test_modeling_pvt.py": [
        [
          "prepare_img",
          132,
          134,
          133,
          13,
          133,
          78,
          133,
          13,
          134,
          16
        ]
      ],
      "transformers/tests/models/poolformer/test_modeling_poolformer.py": [
        [
          "prepare_img",
          218,
          220,
          219,
          13,
          219,
          78,
          219,
          13,
          220,
          16
        ]
      ],
      "transformers/tests/models/pvt_v2/test_modeling_pvt_v2.py": [
        [
          "prepare_img",
          138,
          140,
          139,
          13,
          139,
          78,
          139,
          13,
          140,
          16
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py": [
        [
          "setUp",
          583,
          609,
          609,
          26,
          609,
          82,
          583,
          15,
          609,
          22
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_modeling_qwen2_vl.py": [
        [
          "setUp",
          391,
          403,
          403,
          22,
          403,
          67,
          391,
          15,
          403,
          18
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_modeling_qwen3_omni_moe.py": [
        [
          "setUp",
          621,
          645,
          645,
          26,
          645,
          82,
          621,
          15,
          645,
          22
        ]
      ],
      "transformers/tests/models/regnet/test_modeling_regnet.py": [
        [
          "prepare_img",
          210,
          212,
          211,
          13,
          211,
          78,
          211,
          13,
          212,
          16
        ]
      ],
      "transformers/tests/models/resnet/test_modeling_resnet.py": [
        [
          "prepare_img",
          259,
          261,
          260,
          13,
          260,
          78,
          260,
          13,
          261,
          16
        ]
      ]
    },
    "torch.jit.load": {
      "transformers/tests/models/siglip/test_modeling_siglip.py": [
        [
          "_create_and_check_torchscript",
          491,
          560,
          519,
          36,
          519,
          63,
          519,
          51,
          519,
          63
        ]
      ],
      "transformers/tests/models/speech_to_text/test_modeling_speech_to_text.py": [
        [
          "_create_and_check_torchscript",
          606,
          680,
          639,
          36,
          639,
          63,
          639,
          51,
          639,
          63
        ]
      ],
      "transformers/tests/models/x_clip/test_modeling_x_clip.py": [
        [
          "_create_and_check_torchscript",
          564,
          633,
          592,
          36,
          592,
          63,
          592,
          51,
          592,
          63
        ]
      ],
      "transformers/tests/models/xcodec/test_modeling_xcodec.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          216,
          36,
          216,
          63,
          216,
          51,
          216,
          63
        ]
      ],
      "transformers/tests/models/whisper/test_modeling_whisper.py": [
        [
          "_create_and_check_torchscript",
          846,
          928,
          887,
          36,
          887,
          63,
          887,
          51,
          887,
          63
        ]
      ],
      "transformers/tests/models/align/test_modeling_align.py": [
        [
          "_create_and_check_torchscript",
          491,
          560,
          519,
          36,
          519,
          63,
          519,
          51,
          519,
          63
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "_create_and_check_torchscript",
          467,
          536,
          495,
          36,
          495,
          63,
          495,
          51,
          495,
          63
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip.py": [
        [
          "_create_and_check_torchscript",
          459,
          528,
          487,
          36,
          487,
          63,
          487,
          51,
          487,
          63
        ],
        [
          "_create_and_check_torchscript",
          949,
          1018,
          977,
          36,
          977,
          63,
          977,
          51,
          977,
          63
        ],
        [
          "_create_and_check_torchscript",
          1138,
          1207,
          1166,
          36,
          1166,
          63,
          1166,
          51,
          1166,
          63
        ]
      ],
      "transformers/tests/models/chinese_clip/test_modeling_chinese_clip.py": [
        [
          "_create_and_check_torchscript",
          574,
          643,
          602,
          36,
          602,
          63,
          602,
          51,
          602,
          63
        ]
      ],
      "transformers/tests/models/clap/test_modeling_clap.py": [
        [
          "_create_and_check_torchscript",
          528,
          597,
          556,
          36,
          556,
          63,
          556,
          51,
          556,
          63
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "_create_and_check_torchscript",
          493,
          562,
          521,
          36,
          521,
          63,
          521,
          51,
          521,
          63
        ]
      ],
      "transformers/tests/models/clip/test_modeling_clip.py": [
        [
          "_create_and_check_torchscript",
          565,
          634,
          593,
          36,
          593,
          63,
          593,
          51,
          593,
          63
        ]
      ],
      "transformers/tests/models/dac/test_modeling_dac.py": [
        [
          "_create_and_check_torchscript",
          185,
          273,
          216,
          36,
          216,
          63,
          216,
          51,
          216,
          63
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "_create_and_check_torchscript",
          1385,
          1521,
          1475,
          40,
          1475,
          67,
          1475,
          55,
          1475,
          67
        ]
      ],
      "transformers/tests/models/encodec/test_modeling_encodec.py": [
        [
          "_create_and_check_torchscript",
          212,
          300,
          243,
          36,
          243,
          63,
          243,
          51,
          243,
          63
        ]
      ],
      "transformers/tests/models/flava/test_modeling_flava.py": [
        [
          "_create_and_check_torchscript",
          920,
          999,
          956,
          36,
          956,
          63,
          956,
          51,
          956,
          63
        ]
      ],
      "transformers/tests/models/groupvit/test_modeling_groupvit.py": [
        [
          "_create_and_check_torchscript",
          569,
          638,
          597,
          36,
          597,
          63,
          597,
          51,
          597,
          63
        ]
      ],
      "transformers/tests/models/kosmos2/test_modeling_kosmos2.py": [
        [
          "_create_and_check_torchscript",
          490,
          568,
          522,
          36,
          522,
          63,
          522,
          51,
          522,
          63
        ]
      ],
      "transformers/tests/models/metaclip_2/test_modeling_metaclip_2.py": [
        [
          "_create_and_check_torchscript",
          575,
          644,
          603,
          36,
          603,
          63,
          603,
          51,
          603,
          63
        ]
      ],
      "transformers/tests/models/mimi/test_modeling_mimi.py": [
        [
          "_create_and_check_torchscript",
          225,
          313,
          256,
          36,
          256,
          63,
          256,
          51,
          256,
          63
        ]
      ],
      "transformers/tests/models/owlv2/test_modeling_owlv2.py": [
        [
          "_create_and_check_torchscript",
          462,
          527,
          489,
          36,
          489,
          63,
          489,
          51,
          489,
          63
        ],
        [
          "_create_and_check_torchscript",
          671,
          736,
          698,
          36,
          698,
          63,
          698,
          51,
          698,
          63
        ]
      ],
      "transformers/tests/models/owlvit/test_modeling_owlvit.py": [
        [
          "_create_and_check_torchscript",
          664,
          729,
          691,
          36,
          691,
          63,
          691,
          51,
          691,
          63
        ],
        [
          "_create_and_check_torchscript",
          457,
          522,
          484,
          36,
          484,
          63,
          484,
          51,
          484,
          63
        ]
      ],
      "transformers/tests/models/pix2struct/test_modeling_pix2struct.py": [
        [
          "_create_and_check_torchscript",
          623,
          692,
          651,
          36,
          651,
          63,
          651,
          51,
          651,
          63
        ]
      ]
    },
    "torch.load": {
      "transformers/tests/models/time_series_transformer/test_modeling_time_series_transformer.py": [
        [
          "prepare_batch",
          476,
          480,
          479,
          13,
          479,
          74,
          476,
          19,
          480,
          16
        ]
      ],
      "transformers/tests/models/videomae/test_modeling_videomae.py": [
        [
          "test_inference_for_pretraining",
          456,
          493,
          466,
          37,
          466,
          77,
          456,
          40,
          493,
          85
        ]
      ],
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          811,
          38,
          811,
          78,
          810,
          25,
          812,
          60
        ]
      ],
      "transformers/tests/optimization/test_optimization.py": [
        [
          "unwrap_and_save_reload_schedule",
          50,
          62,
          60,
          30,
          60,
          70,
          56,
          18,
          61,
          53
        ]
      ],
      "transformers/tests/peft_integration/test_peft_integration.py": [
        [
          "test_peft_add_adapter_with_state_dict",
          618,
          647,
          639,
          36,
          639,
          81,
          628,
          17,
          647,
          17
        ],
        [
          "test_peft_add_adapter_with_state_dict_low_cpu_mem_usage",
          649,
          690,
          665,
          36,
          665,
          81,
          659,
          17,
          672,
          36
        ],
        [
          "test_peft_from_pretrained_unexpected_keys_warning",
          719,
          745,
          734,
          36,
          734,
          81,
          728,
          17,
          745,
          42
        ],
        [
          "test_peft_from_pretrained_missing_keys_warning",
          747,
          785,
          762,
          36,
          762,
          81,
          756,
          17,
          785,
          42
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "check_best_model_has_been_loaded",
          639,
          665,
          656,
          30,
          656,
          98,
          655,
          17,
          656,
          26
        ],
        [
          "convert_to_sharded_checkpoint",
          691,
          728,
          712,
          22,
          712,
          41,
          712,
          22,
          727,
          60
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "__init__",
          158,
          264,
          226,
          34,
          226,
          85,
          226,
          45,
          226,
          85
        ],
        [
          "from_pretrained",
          686,
          720,
          710,
          23,
          710,
          73,
          708,
          18,
          711,
          45
        ],
        [
          "get_lm_corpus",
          784,
          821,
          790,
          18,
          790,
          57,
          788,
          9,
          790,
          14
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "__init__",
          83,
          128,
          110,
          37,
          110,
          87,
          109,
          21,
          110,
          33
        ]
      ],
      "transformers/examples/legacy/token-classification/utils_ner.py": [
        [
          "__init__",
          216,
          262,
          239,
          37,
          239,
          87,
          238,
          21,
          239,
          33
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_load_from_checkpoint",
          2756,
          2891,
          2844,
          34,
          2844,
          96,
          2843,
          21,
          2844,
          30
        ],
        [
          "_load_best_model",
          2893,
          3001,
          2981,
          38,
          2981,
          103,
          2980,
          25,
          2981,
          34
        ],
        [
          "_load_rng_state",
          3078,
          3119,
          3102,
          36,
          3102,
          55,
          3101,
          14,
          3106,
          35
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3345,
          25,
          3345,
          95,
          3342,
          22,
          3347,
          52
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3377,
          39,
          3383,
          21,
          3376,
          21,
          3385,
          35
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3388,
          39,
          3390,
          21,
          3387,
          21,
          3388,
          35
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3393,
          42,
          3395,
          21,
          3391,
          22,
          3402,
          69
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3427,
          29,
          3429,
          29,
          3425,
          25,
          3430,
          25
        ],
        [
          "_load_optimizer_and_scheduler",
          3334,
          3436,
          3434,
          25,
          3434,
          95,
          3431,
          22,
          3436,
          52
        ],
        [
          "_load_scaler",
          3458,
          3483,
          3471,
          36,
          3473,
          21,
          3469,
          22,
          3476,
          69
        ],
        [
          "_load_scaler",
          3458,
          3483,
          3481,
          25,
          3481,
          92,
          3478,
          22,
          3483,
          52
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "merge_transformers_sharded_states",
          268,
          282,
          280,
          25,
          280,
          90,
          277,
          9,
          281,
          40
        ],
        [
          "get_megatron_sharded_states",
          285,
          306,
          304,
          22,
          304,
          87,
          303,
          9,
          305,
          41
        ],
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          345,
          18,
          345,
          89,
          343,
          5,
          347,
          28
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          642,
          22,
          642,
          117,
          640,
          27,
          642,
          18
        ]
      ],
      "transformers/src/transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "load_xsum_checkpoint",
          72,
          77,
          74,
          10,
          74,
          75,
          72,
          26,
          77,
          24
        ]
      ],
      "transformers/src/transformers/models/blenderbot/convert_blenderbot_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_parlai_checkpoint",
          78,
          102,
          82,
          13,
          82,
          78,
          78,
          31,
          89,
          26
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_biogpt_checkpoint_to_pytorch",
          159,
          272,
          171,
          13,
          171,
          78,
          171,
          13,
          177,
          36
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          107,
          24,
          107,
          117,
          104,
          17,
          111,
          31
        ],
        [
          "convert_bloom_checkpoint_to_pytorch",
          80,
          211,
          167,
          24,
          167,
          117,
          164,
          17,
          171,
          31
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "merge_weights",
          243,
          277,
          246,
          23,
          246,
          93,
          243,
          19,
          248,
          33
        ]
      ],
      "transformers/src/transformers/models/chinese_clip/convert_chinese_clip_original_pytorch_to_hf.py": [
        [
          "convert_chinese_clip_checkpoint",
          97,
          114,
          107,
          18,
          107,
          83,
          102,
          5,
          114,
          54
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          133,
          26,
          133,
          89,
          133,
          26,
          134,
          21
        ],
        [
          "listcomp",
          138,
          141,
          139,
          13,
          141,
          13,
          142,
          17,
          141,
          13
        ],
        [
          "write_model",
          84,
          436,
          319,
          24,
          319,
          84,
          318,
          18,
          320,
          40
        ]
      ],
      "transformers/src/transformers/models/clipseg/convert_clipseg_original_pytorch_to_hf.py": [
        [
          "convert_clipseg_checkpoint",
          167,
          231,
          172,
          18,
          172,
          83,
          167,
          32,
          175,
          32
        ]
      ],
      "transformers/src/transformers/models/clvp/convert_clvp_to_hf.py": [
        [
          "convert_clvp_weights",
          194,
          217,
          204,
          31,
          204,
          96,
          204,
          31,
          204,
          27
        ],
        [
          "convert_clvp_weights",
          194,
          217,
          206,
          34,
          206,
          99,
          206,
          34,
          206,
          30
        ]
      ],
      "transformers/src/transformers/models/csm/convert_csm.py": [
        [
          "write_model",
          79,
          232,
          160,
          14,
          160,
          55,
          80,
          5,
          173,
          36
        ]
      ],
      "transformers/src/transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_cvt_checkpoint",
          278,
          330,
          310,
          24,
          310,
          101,
          307,
          13,
          315,
          39
        ]
      ],
      "transformers/src/transformers/models/flava/convert_dalle_to_flava_codebook.py": [
        [
          "convert_dalle_checkpoint",
          57,
          92,
          65,
          16,
          65,
          61,
          65,
          16,
          65,
          12
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "write_model",
          121,
          196,
          147,
          14,
          147,
          107,
          139,
          25,
          152,
          23
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "load_beit_model",
          150,
          246,
          221,
          18,
          221,
          88,
          216,
          9,
          225,
          39
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wav2vec2_checkpoint",
          194,
          270,
          210,
          22,
          210,
          67,
          207,
          22,
          214,
          46
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          128,
          18,
          128,
          83,
          104,
          37,
          130,
          32
        ],
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          128,
          18,
          128,
          83,
          105,
          23,
          130,
          32
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "load_original_state_dict",
          156,
          164,
          160,
          13,
          160,
          58,
          156,
          30,
          161,
          20
        ]
      ],
      "transformers/src/transformers/models/dac/convert_dac_checkpoint.py": [
        [
          "convert_checkpoint",
          223,
          261,
          230,
          18,
          230,
          70,
          224,
          5,
          258,
          14
        ]
      ],
      "transformers/src/transformers/models/depth_pro/convert_depth_pro_weights_to_hf.py": [
        [
          "write_model",
          132,
          202,
          171,
          14,
          171,
          53,
          133,
          5,
          178,
          23
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          201,
          336,
          232,
          18,
          232,
          76,
          201,
          28,
          235,
          32
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "convert_deta_checkpoint",
          217,
          303,
          233,
          18,
          233,
          83,
          227,
          27,
          236,
          41
        ],
        [
          "convert_deta_checkpoint",
          217,
          303,
          233,
          18,
          233,
          83,
          229,
          27,
          236,
          41
        ]
      ],
      "transformers/src/transformers/models/dialogpt/convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_dialogpt_checkpoint",
          29,
          33,
          30,
          9,
          30,
          54,
          29,
          33,
          33,
          71
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "convert_deta_checkpoint",
          216,
          296,
          232,
          18,
          232,
          83,
          226,
          20,
          236,
          32
        ],
        [
          "convert_deta_checkpoint",
          216,
          296,
          232,
          18,
          232,
          83,
          228,
          20,
          236,
          32
        ]
      ],
      "transformers/src/transformers/models/dia/convert_dia_to_hf.py": [
        [
          "convert_dia_model_to_hf",
          78,
          155,
          105,
          23,
          105,
          59,
          104,
          23,
          110,
          46
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          128,
          209,
          145,
          27,
          145,
          53,
          128,
          40,
          150,
          28
        ]
      ],
      "transformers/src/transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py": [
        [
          "load_states_from_checkpoint",
          30,
          35,
          32,
          18,
          34,
          5,
          30,
          33,
          35,
          40
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "convert_and_test_dinov3_checkpoint",
          208,
          303,
          233,
          27,
          233,
          64,
          208,
          40,
          240,
          28
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "convert_dpt_checkpoint",
          220,
          278,
          229,
          18,
          229,
          82,
          220,
          28,
          233,
          32
        ]
      ],
      "transformers/src/transformers/models/edgetam_video/convert_edgetam_video_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          235,
          278,
          238,
          18,
          238,
          64,
          235,
          32,
          247,
          48
        ]
      ],
      "transformers/src/transformers/models/edgetam/convert_edgetam_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          192,
          238,
          195,
          18,
          195,
          64,
          192,
          32,
          203,
          48
        ]
      ],
      "transformers/src/transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_efficientformer_checkpoint",
          123,
          213,
          126,
          23,
          126,
          88,
          124,
          5,
          165,
          62
        ]
      ],
      "transformers/src/transformers/models/efficientloftr/convert_efficientloftr_to_hf.py": [
        [
          "write_model",
          128,
          199,
          152,
          27,
          152,
          92,
          129,
          5,
          159,
          23
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "load_model_state_dict",
          158,
          188,
          177,
          26,
          177,
          67,
          174,
          13,
          178,
          41
        ],
        [
          "load_model_state_dict",
          158,
          188,
          185,
          16,
          185,
          63,
          184,
          9,
          185,
          63
        ]
      ],
      "transformers/src/transformers/models/encodec/convert_encodec_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint",
          279,
          338,
          328,
          27,
          328,
          72,
          318,
          13,
          329,
          42
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_FastSpeech2ConformerModel_checkpoint",
          155,
          188,
          167,
          25,
          167,
          70,
          156,
          5,
          185,
          14
        ]
      ],
      "transformers/src/transformers/models/flava/convert_flava_original_pytorch_to_hf.py": [
        [
          "convert_flava_checkpoint",
          62,
          88,
          76,
          22,
          76,
          87,
          76,
          22,
          76,
          18
        ]
      ],
      "transformers/src/transformers/models/gemma2/convert_gemma2_weights_to_hf.py": [
        [
          "write_model",
          84,
          158,
          100,
          33,
          100,
          118,
          98,
          13,
          101,
          54
        ],
        [
          "write_model",
          84,
          158,
          104,
          28,
          104,
          93,
          103,
          9,
          105,
          41
        ]
      ],
      "transformers/src/transformers/models/gemma/convert_gemma_weights_to_hf.py": [
        [
          "write_model",
          68,
          125,
          75,
          24,
          75,
          89,
          68,
          17,
          79,
          40
        ]
      ],
      "transformers/src/transformers/models/fuyu/convert_fuyu_model_weights_to_hf.py": [
        [
          "convert_fuyu_checkpoint",
          80,
          90,
          82,
          29,
          82,
          92,
          80,
          29,
          90,
          65
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "load_weights",
          40,
          61,
          56,
          23,
          56,
          77,
          55,
          13,
          57,
          39
        ]
      ],
      "transformers/src/transformers/models/glpn/convert_glpn_to_pytorch.py": [
        [
          "convert_glpn_checkpoint",
          125,
          193,
          143,
          18,
          143,
          97,
          125,
          29,
          161,
          29
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "load_weights",
          45,
          66,
          61,
          23,
          61,
          58,
          60,
          13,
          62,
          39
        ]
      ],
      "transformers/src/transformers/models/git/convert_git_to_pytorch.py": [
        [
          "convert_git_checkpoint",
          254,
          423,
          300,
          22,
          300,
          87,
          299,
          27,
          300,
          18
        ]
      ],
      "transformers/src/transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py": [
        [
          "convert_groupvit_checkpoint",
          157,
          195,
          166,
          18,
          166,
          83,
          158,
          5,
          169,
          65
        ]
      ],
      "transformers/src/transformers/models/speecht5/convert_hifigan.py": [
        [
          "convert_hifigan_checkpoint",
          59,
          86,
          73,
          23,
          73,
          68,
          71,
          13,
          84,
          14
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_hifigan.py": [
        [
          "convert_hifigan_checkpoint",
          93,
          114,
          107,
          23,
          107,
          68,
          105,
          13,
          112,
          14
        ]
      ],
      "transformers/src/transformers/models/hubert/convert_hubert_original_s3prl_checkpoint_to_pytorch.py": [
        [
          "convert_s3prl_checkpoint",
          31,
          56,
          35,
          18,
          35,
          83,
          31,
          30,
          36,
          93
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "merge_tp_weights",
          250,
          625,
          284,
          14,
          284,
          78,
          281,
          9,
          286,
          32
        ],
        [
          "listcomp",
          304,
          311,
          305,
          13,
          311,
          13,
          307,
          20,
          311,
          13
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "load_model_state_dict",
          209,
          239,
          228,
          26,
          228,
          67,
          225,
          13,
          229,
          41
        ],
        [
          "load_model_state_dict",
          209,
          239,
          236,
          16,
          236,
          63,
          235,
          9,
          236,
          63
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "convert_openai_checkpoint",
          213,
          260,
          231,
          19,
          231,
          105,
          230,
          9,
          234,
          24
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "safe_load",
          178,
          182,
          180,
          13,
          180,
          82,
          178,
          15,
          182,
          16
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          219,
          29,
          219,
          87,
          205,
          18,
          220,
          76
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          219,
          29,
          219,
          87,
          215,
          14,
          220,
          76
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          224,
          30,
          224,
          88,
          223,
          20,
          227,
          77
        ],
        [
          "convert_llava_to_hf",
          95,
          366,
          233,
          30,
          233,
          88,
          230,
          20,
          237,
          77
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          98,
          357,
          213,
          29,
          213,
          87,
          121,
          23,
          214,
          76
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "write_model",
          184,
          433,
          230,
          22,
          232,
          13,
          230,
          22,
          230,
          18
        ],
        [
          "listcomp",
          237,
          238,
          238,
          17,
          238,
          102,
          239,
          21,
          238,
          102
        ]
      ],
      "transformers/src/transformers/models/llava/convert_llava_weights_to_hf.py": [
        [
          "convert_llava_llama_to_hf",
          100,
          173,
          146,
          22,
          146,
          87,
          145,
          27,
          146,
          18
        ]
      ],
      "transformers/src/transformers/models/longformer/convert_longformer_original_pytorch_lightning_to_pytorch.py": [
        [
          "convert_longformer_qa_checkpoint_to_pytorch",
          38,
          59,
          45,
          12,
          45,
          115,
          39,
          5,
          59,
          81
        ]
      ],
      "transformers/src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          28,
          131,
          35,
          18,
          35,
          83,
          28,
          29,
          62,
          54
        ]
      ],
      "transformers/src/transformers/models/m2m_100/convert_m2m100_original_checkpoint_to_pytorch.py": [
        [
          "convert_fairseq_m2m100_checkpoint_from_disk",
          45,
          75,
          46,
          15,
          46,
          80,
          45,
          49,
          47,
          26
        ]
      ],
      "transformers/src/transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py": [
        [
          "load_state_dict_from_torch",
          40,
          41,
          41,
          12,
          41,
          106,
          40,
          32,
          41,
          106
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "convert_mamba_ssm_checkpoint_file_to_huggingface_model_file",
          171,
          234,
          216,
          18,
          220,
          5,
          196,
          9,
          225,
          48
        ]
      ],
      "transformers/src/transformers/models/mamba/convert_mamba_ssm_checkpoint_to_pytorch.py": [
        [
          "convert_mamba_checkpoint_file_to_huggingface_model_file",
          97,
          126,
          110,
          27,
          110,
          98,
          108,
          5,
          126,
          41
        ]
      ],
      "transformers/src/transformers/models/mbart/convert_mbart_original_checkpoint_to_pytorch.py": [
        [
          "convert_fairseq_mbart_checkpoint_from_disk",
          43,
          61,
          46,
          18,
          46,
          83,
          44,
          5,
          51,
          15
        ]
      ],
      "transformers/src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          135,
          13,
          137,
          13,
          124,
          39,
          191,
          42
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          143,
          13,
          145,
          13,
          124,
          39,
          191,
          42
        ],
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          241,
          13,
          243,
          13,
          235,
          5,
          263,
          14
        ]
      ],
      "transformers/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py": [
        [
          "main",
          275,
          326,
          297,
          36,
          297,
          98,
          295,
          14,
          297,
          32
        ],
        [
          "main",
          275,
          326,
          299,
          28,
          299,
          101,
          299,
          28,
          299,
          24
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py": [
        [
          "main",
          312,
          422,
          338,
          36,
          338,
          98,
          336,
          14,
          338,
          32
        ],
        [
          "main",
          312,
          422,
          340,
          28,
          340,
          102,
          340,
          28,
          340,
          24
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/convert_megatron_to_pytorch.py": [
        [
          "main",
          147,
          183,
          156,
          18,
          156,
          83,
          156,
          18,
          171,
          38
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "listcomp",
          211,
          212,
          212,
          13,
          212,
          92,
          212,
          98,
          212,
          92
        ]
      ],
      "transformers/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py": [
        [
          "listcomp",
          96,
          97,
          97,
          9,
          97,
          116,
          98,
          13,
          97,
          116
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "convert_mobilevitv2_checkpoint",
          235,
          281,
          242,
          18,
          242,
          83,
          235,
          36,
          245,
          38
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          29,
          183,
          36,
          18,
          36,
          83,
          29,
          29,
          74,
          61
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "convert_movilevit_checkpoint",
          195,
          283,
          202,
          18,
          202,
          83,
          195,
          34,
          205,
          46
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          250,
          18,
          250,
          51,
          246,
          5,
          255,
          43
        ]
      ],
      "transformers/examples/legacy/seq2seq/convert_model_to_fp16.py": [
        [
          "convert",
          23,
          32,
          25,
          18,
          25,
          83,
          23,
          13,
          26,
          40
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_model_with_hifigan.py": [
        [
          "convert_FastSpeech2ConformerWithHifiGan_checkpoint",
          42,
          75,
          54,
          25,
          54,
          70,
          43,
          5,
          73,
          14
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_model",
          209,
          471,
          345,
          19,
          345,
          84,
          345,
          19,
          345,
          14
        ],
        [
          "listcomp",
          347,
          353,
          348,
          13,
          353,
          13,
          354,
          17,
          353,
          13
        ]
      ],
      "transformers/src/transformers/models/mra/convert_mra_pytorch_to_pytorch.py": [
        [
          "convert_mra_checkpoint",
          79,
          90,
          80,
          23,
          80,
          88,
          79,
          28,
          90,
          83
        ]
      ],
      "transformers/src/transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": [
        [
          "shard_on_the_fly",
          72,
          126,
          80,
          28,
          80,
          69,
          80,
          28,
          88,
          22
        ],
        [
          "shard_on_the_fly",
          72,
          126,
          96,
          22,
          96,
          89,
          93,
          17,
          103,
          36
        ]
      ],
      "transformers/src/transformers/models/nystromformer/convert_nystromformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_nystromformer_checkpoint",
          80,
          91,
          81,
          23,
          81,
          88,
          80,
          38,
          91,
          83
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "write_model",
          68,
          216,
          110,
          14,
          110,
          105,
          106,
          5,
          114,
          34
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "write_model",
          65,
          183,
          94,
          14,
          94,
          105,
          90,
          5,
          98,
          34
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "write_model",
          206,
          284,
          248,
          18,
          248,
          96,
          248,
          18,
          250,
          40
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "write_model",
          91,
          215,
          122,
          14,
          122,
          105,
          119,
          5,
          126,
          34
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "read_data",
          161,
          196,
          184,
          45,
          184,
          101,
          184,
          26,
          188,
          60
        ]
      ],
      "transformers/src/transformers/models/opt/convert_opt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "load_checkpoint",
          30,
          76,
          32,
          10,
          32,
          75,
          30,
          21,
          33,
          20
        ],
        [
          "load_checkpoint",
          30,
          76,
          34,
          14,
          34,
          79,
          34,
          14,
          34,
          10
        ]
      ],
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_download",
          147,
          182,
          160,
          20,
          160,
          73,
          160,
          20,
          160,
          73
        ],
        [
          "_download",
          147,
          182,
          182,
          12,
          182,
          65,
          182,
          12,
          182,
          65
        ],
        [
          "convert_openai_whisper_to_tfms",
          185,
          251,
          193,
          31,
          193,
          96,
          193,
          31,
          194,
          22
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          349,
          23,
          349,
          102,
          338,
          10,
          357,
          14
        ]
      ],
      "transformers/src/transformers/models/owlv2/convert_owlv2_to_hf.py": [
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          271,
          29,
          271,
          67,
          258,
          5,
          281,
          32
        ],
        [
          "convert_owlv2_checkpoint",
          237,
          376,
          274,
          26,
          274,
          64,
          258,
          5,
          281,
          32
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "write_model",
          195,
          436,
          236,
          22,
          240,
          13,
          227,
          34,
          255,
          38
        ],
        [
          "listcomp",
          245,
          250,
          246,
          17,
          250,
          17,
          251,
          21,
          250,
          17
        ]
      ],
      "transformers/src/transformers/models/persimmon/convert_persimmon_weights_to_hf.py": [
        [
          "convert_persimmon_checkpoint",
          81,
          93,
          85,
          29,
          85,
          92,
          81,
          34,
          93,
          65
        ]
      ],
      "transformers/src/transformers/models/phi/convert_phi_weights_to_hf.py": [
        [
          "convert_phi_weights",
          105,
          164,
          124,
          34,
          124,
          95,
          124,
          34,
          124,
          30
        ]
      ],
      "transformers/src/transformers/models/plbart/convert_plbart_original_checkpoint_to_torch.py": [
        [
          "convert_fairseq_plbart_checkpoint_from_disk",
          43,
          69,
          46,
          18,
          46,
          83,
          44,
          5,
          53,
          25
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "convert_poolformer_checkpoint",
          93,
          195,
          154,
          18,
          154,
          97,
          114,
          26,
          173,
          20
        ],
        [
          "convert_poolformer_checkpoint",
          93,
          195,
          154,
          18,
          154,
          97,
          145,
          23,
          173,
          20
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          155,
          254,
          177,
          18,
          177,
          76,
          155,
          28,
          183,
          40
        ]
      ],
      "transformers/src/transformers/models/pvt_v2/convert_pvt_v2_to_pytorch.py": [
        [
          "convert_pvt_v2_checkpoint",
          184,
          260,
          210,
          18,
          210,
          85,
          191,
          23,
          213,
          32
        ],
        [
          "convert_pvt_v2_checkpoint",
          184,
          260,
          210,
          18,
          210,
          85,
          208,
          14,
          213,
          32
        ]
      ],
      "transformers/src/transformers/models/recurrent_gemma/convert_recurrent_gemma_to_hf.py": [
        [
          "write_model",
          72,
          141,
          74,
          24,
          74,
          89,
          72,
          17,
          101,
          40
        ]
      ],
      "transformers/src/transformers/models/pvt/convert_pvt_to_pytorch.py": [
        [
          "convert_pvt_checkpoint",
          150,
          203,
          168,
          18,
          168,
          82,
          157,
          23,
          171,
          32
        ],
        [
          "convert_pvt_checkpoint",
          150,
          203,
          168,
          18,
          168,
          82,
          166,
          14,
          171,
          32
        ]
      ],
      "transformers/src/transformers/models/roberta_prelayernorm/convert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_roberta_prelayernorm_checkpoint_to_pytorch",
          30,
          62,
          40,
          27,
          42,
          5,
          30,
          56,
          44,
          63
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/convert_s2t_fairseq_to_tfms.py": [
        [
          "convert_fairseq_s2t_checkpoint_to_tfms",
          54,
          112,
          55,
          15,
          55,
          80,
          54,
          44,
          98,
          23
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          150,
          26,
          150,
          92,
          149,
          13,
          151,
          113
        ],
        [
          "convert_rmkv_checkpoint_to_hf_format",
          80,
          161,
          115,
          18,
          115,
          78,
          106,
          14,
          121,
          64
        ]
      ],
      "transformers/src/transformers/models/sam/convert_sam_to_hf.py": [
        [
          "convert_sam_checkpoint",
          137,
          216,
          140,
          18,
          140,
          83,
          137,
          28,
          148,
          48
        ]
      ],
      "transformers/src/transformers/models/sam_hq/convert_samhq_to_hf.py": [
        [
          "convert_sam_hq_checkpoint",
          158,
          228,
          161,
          18,
          161,
          83,
          158,
          31,
          169,
          48
        ]
      ],
      "transformers/src/transformers/models/sam2/convert_sam2_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          218,
          280,
          221,
          18,
          221,
          64,
          218,
          29,
          229,
          48
        ]
      ],
      "transformers/src/transformers/models/sam2_video/convert_sam2_video_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          227,
          286,
          230,
          18,
          230,
          64,
          227,
          29,
          239,
          48
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "convert_segformer_checkpoint",
          120,
          368,
          194,
          22,
          194,
          101,
          182,
          23,
          222,
          52
        ],
        [
          "convert_segformer_checkpoint",
          120,
          368,
          196,
          22,
          196,
          101,
          182,
          23,
          222,
          52
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "convert_siglip_checkpoint",
          380,
          506,
          443,
          33,
          443,
          71,
          442,
          20,
          447,
          35
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          445,
          30,
          445,
          68,
          442,
          20,
          447,
          35
        ]
      ],
      "transformers/src/transformers/models/bark/convert_suno_to_hf.py": [
        [
          "_load_model",
          92,
          158,
          112,
          18,
          112,
          78,
          112,
          18,
          115,
          43
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "convert_swiftformer_checkpoint",
          89,
          153,
          128,
          26,
          128,
          89,
          128,
          26,
          128,
          22
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_simmim_to_pytorch.py": [
        [
          "convert_swin_checkpoint",
          123,
          155,
          124,
          18,
          124,
          83,
          123,
          29,
          145,
          43
        ]
      ],
      "transformers/src/transformers/models/speecht5/convert_speecht5_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_speecht5_checkpoint",
          320,
          372,
          364,
          26,
          364,
          71,
          360,
          25,
          369,
          14
        ]
      ],
      "transformers/src/transformers/models/timesformer/convert_timesformer_to_pytorch.py": [
        [
          "convert_timesformer_checkpoint",
          138,
          224,
          146,
          13,
          146,
          69,
          138,
          36,
          147,
          23
        ]
      ],
      "transformers/src/transformers/models/unispeech_sat/convert_unispeech_original_s3prl_checkpoint_to_pytorch.py": [
        [
          "convert_s3prl_checkpoint",
          70,
          97,
          74,
          18,
          74,
          83,
          70,
          30,
          84,
          49
        ]
      ],
      "transformers/src/transformers/models/deprecated/van/convert_van_to_pytorch.py": [
        [
          "convert_weight_and_push",
          121,
          163,
          132,
          23,
          132,
          68,
          122,
          5,
          142,
          61
        ]
      ],
      "transformers/src/transformers/models/udop/convert_udop_to_hf.py": [
        [
          "convert_udop_checkpoint",
          91,
          201,
          101,
          18,
          101,
          83,
          91,
          29,
          106,
          43
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          180,
          17,
          180,
          55,
          171,
          5,
          183,
          77
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          182,
          12,
          182,
          50,
          171,
          5,
          183,
          77
        ],
        [
          "convert_udop_checkpoint",
          91,
          201,
          185,
          20,
          185,
          58,
          183,
          29,
          195,
          43
        ]
      ],
      "transformers/src/transformers/models/univnet/convert_univnet.py": [
        [
          "convert_univnet_checkpoint",
          102,
          133,
          109,
          29,
          109,
          94,
          103,
          5,
          113,
          30
        ]
      ],
      "transformers/src/transformers/models/video_llava/convert_video_llava_weights_to_hf.py": [
        [
          "convert_video_llava_llama_to_hf",
          75,
          128,
          102,
          22,
          102,
          87,
          100,
          9,
          105,
          24
        ]
      ],
      "transformers/src/transformers/models/vipllava/convert_vipllava_weights_to_hf.py": [
        [
          "convert_vipllava_llama_to_hf",
          58,
          104,
          81,
          18,
          81,
          83,
          58,
          34,
          104,
          42
        ]
      ],
      "transformers/src/transformers/models/visual_bert/convert_visual_bert_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "load_state_dict",
          58,
          60,
          59,
          10,
          59,
          75,
          58,
          21,
          60,
          13
        ]
      ],
      "transformers/src/transformers/models/vitmatte/convert_vitmatte_to_hf.py": [
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          85,
          18,
          85,
          76,
          72,
          33,
          88,
          32
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "write_model",
          190,
          396,
          211,
          27,
          211,
          92,
          190,
          17,
          218,
          23
        ],
        [
          "write_model",
          190,
          396,
          268,
          29,
          268,
          87,
          253,
          5,
          270,
          73
        ]
      ],
      "transformers/src/transformers/models/videomae/convert_videomae_to_pytorch.py": [
        [
          "convert_videomae_checkpoint",
          179,
          297,
          207,
          37,
          207,
          77,
          206,
          22,
          231,
          56
        ],
        [
          "convert_videomae_checkpoint",
          179,
          297,
          190,
          13,
          190,
          69,
          183,
          17,
          191,
          23
        ],
        [
          "convert_videomae_checkpoint",
          179,
          297,
          190,
          13,
          190,
          69,
          185,
          17,
          191,
          23
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py": [
        [
          "convert_s3prl_checkpoint",
          70,
          97,
          74,
          18,
          74,
          83,
          70,
          30,
          84,
          49
        ]
      ],
      "transformers/src/transformers/models/wavlm/convert_wavlm_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_wavlm_checkpoint",
          180,
          197,
          182,
          18,
          182,
          63,
          180,
          30,
          188,
          30
        ]
      ],
      "transformers/src/transformers/models/wavlm/convert_wavlm_original_s3prl_checkpoint_to_pytorch.py": [
        [
          "convert_s3prl_checkpoint",
          70,
          97,
          74,
          18,
          74,
          83,
          70,
          30,
          84,
          49
        ]
      ],
      "transformers/src/transformers/models/xglm/convert_xglm_original_ckpt_to_trfms.py": [
        [
          "convert_fairseq_xglm_checkpoint_from_disk",
          28,
          58,
          29,
          18,
          29,
          83,
          28,
          47,
          58,
          16
        ]
      ],
      "transformers/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_xlm_checkpoint_to_pytorch",
          30,
          64,
          32,
          13,
          32,
          82,
          30,
          39,
          38,
          34
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "safe_load",
          79,
          84,
          83,
          13,
          83,
          67,
          79,
          15,
          84,
          76
        ]
      ],
      "transformers/src/transformers/models/yoso/convert_yoso_pytorch_to_pytorch.py": [
        [
          "convert_yoso_checkpoint",
          77,
          88,
          78,
          23,
          78,
          88,
          77,
          29,
          88,
          83
        ]
      ],
      "transformers/src/transformers/models/x_clip/convert_x_clip_original_pytorch_to_hf.py": [
        [
          "convert_xclip_checkpoint",
          218,
          366,
          282,
          22,
          282,
          78,
          280,
          18,
          282,
          18
        ]
      ],
      "transformers/src/transformers/models/zoedepth/convert_zoedepth_to_hf.py": [
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          350,
          29,
          350,
          87,
          328,
          9,
          351,
          62
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          350,
          29,
          350,
          87,
          331,
          18,
          351,
          62
        ],
        [
          "convert_zoedepth_checkpoint",
          306,
          400,
          361,
          25,
          361,
          83,
          351,
          5,
          366,
          29
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "convert_yolos_checkpoint",
          157,
          241,
          166,
          18,
          166,
          83,
          158,
          5,
          175,
          42
        ]
      ],
      "transformers/src/transformers/data/datasets/glue.py": [
        [
          "__init__",
          76,
          149,
          122,
          33,
          122,
          83,
          120,
          25,
          125,
          17
        ]
      ],
      "transformers/src/transformers/models/qwen2_5_omni/modeling_qwen2_5_omni.py": [
        [
          "load_speakers",
          3721,
          3725,
          3723,
          27,
          3723,
          61,
          3721,
          23,
          3723,
          69
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py": [
        [
          "load_adapter",
          1139,
          1325,
          1280,
          30,
          1284,
          17,
          1281,
          21,
          1284,
          17
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "load_state_dict",
          469,
          536,
          515,
          16,
          520,
          9,
          515,
          16,
          520,
          9
        ]
      ],
      "transformers/src/transformers/models/qwen2_5_omni/modular_qwen2_5_omni.py": [
        [
          "load_speakers",
          4021,
          4025,
          4023,
          27,
          4023,
          61,
          4021,
          23,
          4023,
          69
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/run_glue.py": [
        [
          "get_dataloader",
          76,
          97,
          84,
          20,
          84,
          70,
          80,
          16,
          88,
          60
        ]
      ],
      "transformers/examples/legacy/pytorch-lightning/run_ner.py": [
        [
          "prepare_data",
          59,
          86,
          66,
          28,
          66,
          78,
          65,
          17,
          66,
          24
        ],
        [
          "get_dataloader",
          88,
          103,
          92,
          20,
          92,
          70,
          88,
          24,
          95,
          49
        ]
      ],
      "transformers/examples/legacy/question-answering/run_squad.py": [
        [
          "train",
          73,
          263,
          107,
          35,
          107,
          118,
          107,
          9,
          108,
          119
        ],
        [
          "train",
          73,
          263,
          108,
          35,
          108,
          118,
          107,
          9,
          108,
          119
        ],
        [
          "load_and_cache_examples",
          400,
          467,
          419,
          32,
          419,
          82,
          418,
          9,
          420,
          35
        ]
      ],
      "transformers/examples/legacy/run_swag.py": [
        [
          "load_and_cache_examples",
          230,
          272,
          246,
          20,
          246,
          70,
          245,
          9,
          246,
          16
        ]
      ],
      "transformers/src/transformers/data/datasets/squad.py": [
        [
          "__init__",
          115,
          189,
          148,
          37,
          148,
          87,
          146,
          25,
          159,
          39
        ]
      ],
      "transformers/tests/models/autoformer/test_modeling_autoformer.py": [
        [
          "prepare_batch",
          413,
          417,
          416,
          13,
          416,
          74,
          413,
          19,
          417,
          16
        ]
      ],
      "transformers/tests/models/informer/test_modeling_informer.py": [
        [
          "prepare_batch",
          472,
          476,
          475,
          13,
          475,
          74,
          472,
          19,
          476,
          16
        ]
      ],
      "transformers/tests/models/llava_next/test_modeling_llava_next.py": [
        [
          "test_small_model_integration_test",
          329,
          369,
          344,
          30,
          344,
          88,
          329,
          43,
          349,
          79
        ],
        [
          "test_small_model_integration_test",
          329,
          369,
          357,
          33,
          357,
          91,
          349,
          9,
          360,
          9
        ]
      ],
      "transformers/tests/models/patchtst/test_modeling_patchtst.py": [
        [
          "prepare_batch",
          302,
          306,
          305,
          13,
          305,
          74,
          302,
          19,
          306,
          16
        ]
      ],
      "transformers/tests/models/patchtsmixer/test_modeling_patchtsmixer.py": [
        [
          "prepare_batch",
          450,
          455,
          454,
          13,
          454,
          74,
          450,
          19,
          455,
          16
        ]
      ]
    },
    "numpy.load": {
      "transformers/tests/models/timesformer/test_modeling_timesformer.py": [
        [
          "prepare_video",
          315,
          320,
          319,
          13,
          319,
          25,
          316,
          12,
          320,
          22
        ]
      ],
      "transformers/tests/models/videomae/test_modeling_videomae.py": [
        [
          "prepare_video",
          408,
          413,
          412,
          13,
          412,
          25,
          409,
          12,
          413,
          22
        ]
      ],
      "transformers/tests/models/video_llava/test_modeling_video_llava.py": [
        [
          "test_small_model_integration_test",
          415,
          436,
          423,
          22,
          423,
          40,
          415,
          43,
          436,
          9
        ],
        [
          "test_small_model_integration_test_mixed_inputs",
          440,
          467,
          450,
          22,
          450,
          40,
          440,
          56,
          467,
          9
        ],
        [
          "test_small_model_integration_test_llama",
          471,
          492,
          479,
          22,
          479,
          40,
          471,
          49,
          492,
          9
        ],
        [
          "test_small_model_integration_test_llama_batched",
          496,
          521,
          505,
          19,
          507,
          9,
          496,
          57,
          521,
          105
        ],
        [
          "test_small_model_integration_test_llama_batched",
          496,
          521,
          508,
          19,
          510,
          9,
          496,
          57,
          521,
          105
        ]
      ],
      "transformers/tests/models/vivit/test_modeling_vivit.py": [
        [
          "prepare_video",
          326,
          331,
          330,
          13,
          330,
          25,
          327,
          12,
          331,
          22
        ]
      ],
      "transformers/tests/models/x_clip/test_modeling_x_clip.py": [
        [
          "prepare_video",
          658,
          663,
          662,
          13,
          662,
          25,
          659,
          12,
          663,
          22
        ]
      ],
      "transformers/src/transformers/models/speecht5/convert_hifigan.py": [
        [
          "convert_hifigan_checkpoint",
          59,
          86,
          76,
          13,
          76,
          31,
          71,
          13,
          84,
          14
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "__init__",
          478,
          560,
          480,
          27,
          480,
          43,
          478,
          18,
          482,
          55
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "listcomp",
          47,
          47,
          47,
          20,
          47,
          78,
          47,
          84,
          47,
          78
        ]
      ],
      "transformers/src/transformers/models/paligemma/convert_paligemma_weights_to_hf.py": [
        [
          "convert_paligemma_checkpoint",
          221,
          291,
          252,
          16,
          252,
          36,
          241,
          23,
          260,
          35
        ]
      ],
      "transformers/src/transformers/models/siglip2/convert_siglip2_to_hf.py": [
        [
          "convert_siglip2_checkpoint",
          333,
          409,
          347,
          12,
          347,
          30,
          346,
          5,
          359,
          37
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "convert_siglip_checkpoint",
          380,
          506,
          395,
          12,
          395,
          27,
          395,
          12,
          401,
          32
        ]
      ],
      "transformers/src/transformers/models/timesformer/convert_timesformer_to_pytorch.py": [
        [
          "prepare_video",
          130,
          135,
          134,
          13,
          134,
          25,
          131,
          12,
          135,
          22
        ]
      ],
      "transformers/src/transformers/models/vivit/convert_vivit_flax_to_pytorch.py": [
        [
          "prepare_video",
          60,
          65,
          64,
          13,
          64,
          25,
          61,
          12,
          65,
          22
        ]
      ],
      "transformers/src/transformers/models/videomae/convert_videomae_to_pytorch.py": [
        [
          "prepare_video",
          171,
          176,
          175,
          13,
          175,
          25,
          172,
          12,
          176,
          22
        ]
      ],
      "transformers/src/transformers/models/x_clip/convert_x_clip_original_pytorch_to_hf.py": [
        [
          "prepare_video",
          202,
          215,
          214,
          13,
          214,
          25,
          209,
          12,
          215,
          22
        ]
      ],
      "transformers/src/transformers/models/bark/processing_bark.py": [
        [
          "_load_voice_preset",
          180,
          213,
          211,
          38,
          211,
          50,
          211,
          38,
          211,
          34
        ],
        [
          "__call__",
          265,
          335,
          315,
          32,
          315,
          52,
          315,
          32,
          315,
          28
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/retrieval_realm.py": [
        [
          "from_pretrained",
          101,
          120,
          116,
          25,
          116,
          70,
          116,
          25,
          120,
          44
        ]
      ],
      "transformers/tests/models/emu3/test_modeling_emu3.py": [
        [
          "test_model_generate_images",
          449,
          510,
          509,
          27,
          509,
          43,
          449,
          36,
          510,
          85
        ]
      ],
      "transformers/tests/models/instructblipvideo/test_modeling_instructblipvideo.py": [
        [
          "prepare_video",
          628,
          633,
          632,
          13,
          632,
          31,
          629,
          18,
          633,
          16
        ]
      ],
      "transformers/tests/models/llava_next_video/test_modeling_llava_next_video.py": [
        [
          "setUp",
          334,
          345,
          343,
          22,
          343,
          40,
          334,
          15,
          345,
          25
        ]
      ],
      "transformers/tests/models/llava_onevision/test_modeling_llava_onevision.py": [
        [
          "setUp",
          293,
          306,
          304,
          22,
          304,
          40,
          293,
          15,
          306,
          25
        ]
      ]
    },
    "pickle.load": {
      "transformers/tests/models/t5/test_modeling_t5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          603,
          714,
          699,
          34,
          699,
          47,
          699,
          46,
          699,
          47
        ]
      ],
      "transformers/tests/models/umt5/test_modeling_umt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          284,
          402,
          387,
          34,
          387,
          47,
          387,
          46,
          387,
          47
        ]
      ],
      "transformers/tests/models/wav2vec2/test_modeling_wav2vec2.py": [
        [
          "_create_and_check_torch_fx_tracing",
          680,
          780,
          765,
          34,
          765,
          47,
          765,
          46,
          765,
          47
        ]
      ],
      "transformers/tests/models/bert_japanese/test_tokenization_bert_japanese.py": [
        [
          "test_pickle_mecab_tokenizer",
          106,
          124,
          120,
          29,
          120,
          47,
          106,
          37,
          124,
          51
        ],
        [
          "test_pickle_sudachi_tokenizer",
          202,
          220,
          216,
          29,
          216,
          47,
          202,
          39,
          220,
          51
        ],
        [
          "test_pickle_jumanpp_tokenizer",
          297,
          315,
          311,
          29,
          311,
          47,
          297,
          39,
          315,
          51
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_pickle_tokenizer",
          830,
          849,
          845,
          37,
          845,
          55,
          833,
          13,
          849,
          63
        ]
      ],
      "transformers/tests/models/pop2piano/test_tokenization_pop2piano.py": [
        [
          "test_pickle_tokenizer",
          227,
          242,
          238,
          29,
          238,
          47,
          227,
          31,
          242,
          55
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "__init__",
          158,
          264,
          213,
          34,
          213,
          47,
          213,
          46,
          213,
          47
        ],
        [
          "get_lm_corpus",
          784,
          821,
          801,
          22,
          801,
          36,
          800,
          14,
          801,
          18
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "pickle_load",
          447,
          450,
          450,
          16,
          450,
          29,
          447,
          17,
          450,
          29
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "convert_maskformer_checkpoint",
          230,
          304,
          240,
          16,
          240,
          29,
          231,
          5,
          248,
          32
        ]
      ],
      "transformers/src/transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_checkpoint_to_huggingface",
          124,
          272,
          126,
          30,
          126,
          40,
          124,
          39,
          191,
          42
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "convert_maskformer_checkpoint",
          261,
          350,
          271,
          16,
          271,
          29,
          262,
          5,
          276,
          32
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "read_metadata",
          198,
          216,
          202,
          32,
          202,
          57,
          202,
          44,
          202,
          57
        ],
        [
          "load_model",
          239,
          269,
          260,
          20,
          260,
          45,
          239,
          16,
          269,
          5
        ]
      ],
      "transformers/src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py": [
        [
          "convert_trax_checkpoint_to_pytorch",
          185,
          198,
          192,
          25,
          192,
          38,
          185,
          40,
          198,
          53
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py": [
        [
          "convert_transfo_xl_checkpoint_to_pytorch",
          168,
          209,
          174,
          22,
          174,
          55,
          173,
          14,
          185,
          67
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "__init__",
          41,
          100,
          73,
          37,
          73,
          55,
          71,
          25,
          76,
          17
        ],
        [
          "__init__",
          335,
          418,
          385,
          37,
          385,
          55,
          383,
          25,
          388,
          17
        ]
      ],
      "transformers/src/transformers/models/rag/retrieval_rag.py": [
        [
          "_load_passages",
          133,
          145,
          144,
          24,
          144,
          49,
          143,
          14,
          145,
          23
        ],
        [
          "_deserialize_index",
          147,
          163,
          160,
          38,
          160,
          63,
          159,
          14,
          161,
          63
        ]
      ],
      "transformers/tests/models/hubert/test_modeling_hubert.py": [
        [
          "_create_and_check_torch_fx_tracing",
          411,
          522,
          511,
          34,
          511,
          47,
          511,
          46,
          511,
          47
        ]
      ],
      "transformers/tests/models/mt5/test_modeling_mt5.py": [
        [
          "_create_and_check_torch_fx_tracing",
          595,
          706,
          691,
          34,
          691,
          47,
          691,
          46,
          691,
          47
        ]
      ]
    },
    "json.load": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "remove_dtype",
          654,
          660,
          657,
          21,
          657,
          32,
          654,
          26,
          660,
          31
        ],
        [
          "test_model_from_pretrained_dtype",
          641,
          726,
          689,
          27,
          689,
          38,
          641,
          42,
          726,
          53
        ]
      ],
      "transformers/tests/models/oneformer/test_processing_oneformer.py": [
        [
          "prepare_metadata",
          43,
          58,
          45,
          22,
          45,
          33,
          43,
          22,
          50,
          39
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_processing_shieldgemma2.py": [
        [
          "test_policy_definitions_saved_in_config",
          102,
          110,
          106,
          25,
          106,
          56,
          102,
          49,
          110,
          62
        ]
      ],
      "transformers/tests/models/auto/test_processor_auto.py": [
        [
          "test_processor_from_processor_class",
          97,
          123,
          115,
          31,
          115,
          42,
          114,
          18,
          123,
          59
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          138,
          35,
          138,
          46,
          137,
          22,
          142,
          52
        ],
        [
          "test_processor_from_feat_extr_processor_class",
          125,
          154,
          146,
          31,
          146,
          42,
          145,
          18,
          154,
          59
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          169,
          35,
          169,
          46,
          168,
          22,
          173,
          52
        ],
        [
          "test_processor_from_tokenizer_processor_class",
          156,
          185,
          177,
          31,
          177,
          42,
          176,
          18,
          185,
          59
        ],
        [
          "test_push_to_hub_dynamic_processor",
          456,
          505,
          487,
          40,
          487,
          51,
          456,
          44,
          505,
          85
        ]
      ],
      "transformers/examples/pytorch/test_pytorch_examples.py": [
        [
          "get_results",
          85,
          93,
          90,
          23,
          90,
          34,
          89,
          14,
          93,
          18
        ]
      ],
      "transformers/tests/models/auto/test_tokenization_auto.py": [
        [
          "test_from_pretrained_dynamic_tokenizer",
          306,
          364,
          350,
          40,
          350,
          51,
          332,
          13,
          354,
          73
        ]
      ],
      "transformers/tests/models/canine/test_tokenization_canine.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          213,
          42,
          213,
          61,
          208,
          13,
          255,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          200,
          255,
          216,
          40,
          216,
          59,
          208,
          13,
          255,
          17
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          226,
          42,
          226,
          61,
          221,
          13,
          275,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          213,
          275,
          229,
          40,
          229,
          59,
          221,
          13,
          275,
          17
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1712,
          43,
          1712,
          110,
          1712,
          43,
          1717,
          29
        ],
        [
          "test_chat_template_dict_saving",
          1700,
          1731,
          1719,
          43,
          1719,
          110,
          1719,
          43,
          1728,
          111
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          4221,
          4272,
          4235,
          40,
          4235,
          59,
          4229,
          13,
          4272,
          17
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          209,
          42,
          209,
          61,
          204,
          13,
          257,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          196,
          257,
          212,
          40,
          212,
          59,
          204,
          13,
          257,
          17
        ]
      ],
      "transformers/tests/models/siglip/test_tokenization_siglip.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          256,
          42,
          256,
          61,
          251,
          13,
          305,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          243,
          305,
          259,
          40,
          259,
          59,
          251,
          13,
          305,
          17
        ]
      ],
      "transformers/tests/models/t5/test_tokenization_t5.py": [
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          307,
          42,
          307,
          61,
          302,
          13,
          356,
          17
        ],
        [
          "test_special_tokens_initialization_with_non_empty_additional_special_tokens",
          294,
          356,
          310,
          40,
          310,
          59,
          302,
          13,
          356,
          17
        ]
      ],
      "transformers/tests/trainer/test_trainer_distributed_loss.py": [
        [
          "test_trainer",
          29,
          61,
          46,
          25,
          46,
          36,
          45,
          14,
          61,
          45
        ],
        [
          "test_trainer",
          29,
          61,
          48,
          27,
          48,
          38,
          45,
          14,
          61,
          45
        ],
        [
          "test_trainer",
          29,
          61,
          50,
          26,
          50,
          37,
          45,
          14,
          61,
          45
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "__init__",
          155,
          207,
          181,
          28,
          181,
          50,
          178,
          22,
          207,
          9
        ]
      ],
      "transformers/src/transformers/models/biogpt/tokenization_biogpt.py": [
        [
          "__init__",
          92,
          134,
          119,
          28,
          119,
          50,
          104,
          20,
          134,
          9
        ]
      ],
      "transformers/src/transformers/models/auto/tokenization_auto.py": [
        [
          "get_tokenizer_config",
          821,
          924,
          922,
          18,
          922,
          34,
          919,
          19,
          924,
          17
        ]
      ],
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "__init__",
          81,
          99,
          92,
          28,
          92,
          50,
          82,
          9,
          99,
          118
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "__init__",
          162,
          220,
          194,
          28,
          194,
          50,
          186,
          13,
          220,
          9
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "__init__",
          283,
          330,
          307,
          28,
          307,
          50,
          306,
          14,
          330,
          9
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "__init__",
          140,
          189,
          164,
          28,
          164,
          50,
          157,
          21,
          189,
          9
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "__init__",
          140,
          188,
          164,
          28,
          164,
          50,
          163,
          14,
          188,
          9
        ]
      ],
      "transformers/src/transformers/models/ctrl/tokenization_ctrl.py": [
        [
          "__init__",
          130,
          139,
          132,
          28,
          132,
          50,
          130,
          18,
          139,
          55
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "__init__",
          140,
          195,
          168,
          28,
          168,
          50,
          164,
          22,
          195,
          9
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": [
        [
          "__init__",
          55,
          85,
          68,
          28,
          68,
          50,
          56,
          9,
          85,
          32
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "__init__",
          178,
          260,
          240,
          28,
          240,
          50,
          236,
          34,
          260,
          9
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "__init__",
          163,
          227,
          207,
          28,
          207,
          54,
          198,
          44,
          227,
          9
        ],
        [
          "__init__",
          163,
          227,
          209,
          25,
          209,
          51,
          198,
          44,
          227,
          9
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "__init__",
          133,
          178,
          154,
          28,
          154,
          50,
          149,
          21,
          178,
          9
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "__init__",
          294,
          376,
          348,
          28,
          348,
          50,
          344,
          34,
          371,
          31
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "__init__",
          100,
          141,
          118,
          36,
          118,
          58,
          111,
          21,
          128,
          41
        ],
        [
          "__init__",
          100,
          141,
          121,
          35,
          121,
          57,
          111,
          21,
          128,
          41
        ],
        [
          "__init__",
          100,
          141,
          124,
          35,
          124,
          57,
          111,
          21,
          128,
          41
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "__init__",
          257,
          326,
          288,
          28,
          288,
          50,
          285,
          22,
          326,
          9
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "__init__",
          160,
          212,
          186,
          28,
          186,
          50,
          183,
          22,
          212,
          9
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "__init__",
          156,
          214,
          188,
          28,
          188,
          50,
          180,
          13,
          214,
          9
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "load_json",
          391,
          393,
          393,
          16,
          393,
          27,
          391,
          15,
          393,
          27
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "__init__",
          184,
          264,
          216,
          28,
          216,
          50,
          213,
          22,
          264,
          37
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "__init__",
          273,
          387,
          309,
          28,
          309,
          50,
          306,
          22,
          328,
          46
        ],
        [
          "__init__",
          273,
          387,
          340,
          33,
          340,
          62,
          332,
          13,
          341,
          111
        ]
      ],
      "transformers/src/transformers/models/m2m_100/tokenization_m2m_100.py": [
        [
          "load_json",
          374,
          376,
          376,
          16,
          376,
          27,
          374,
          15,
          376,
          27
        ]
      ],
      "transformers/src/transformers/models/mgp_str/tokenization_mgp_str.py": [
        [
          "__init__",
          54,
          64,
          56,
          26,
          56,
          48,
          54,
          18,
          64,
          9
        ]
      ],
      "transformers/src/transformers/models/mluke/tokenization_mluke.py": [
        [
          "__init__",
          221,
          331,
          284,
          33,
          284,
          62,
          262,
          32,
          285,
          111
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "__init__",
          155,
          206,
          180,
          28,
          180,
          50,
          178,
          22,
          206,
          9
        ]
      ],
      "transformers/src/transformers/models/myt5/tokenization_myt5.py": [
        [
          "__init__",
          46,
          57,
          49,
          35,
          49,
          46,
          48,
          18,
          49,
          31
        ],
        [
          "__init__",
          165,
          209,
          197,
          26,
          197,
          57,
          190,
          21,
          209,
          9
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "__init__",
          259,
          281,
          273,
          28,
          273,
          50,
          272,
          14,
          281,
          55
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "__init__",
          137,
          208,
          173,
          28,
          173,
          50,
          167,
          13,
          180,
          51
        ]
      ],
      "transformers/src/transformers/models/pop2piano/tokenization_pop2piano.py": [
        [
          "__init__",
          93,
          125,
          114,
          28,
          114,
          42,
          107,
          21,
          125,
          9
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "__init__",
          156,
          214,
          188,
          28,
          188,
          50,
          180,
          13,
          214,
          9
        ]
      ],
      "transformers/src/transformers/models/speech_to_text/tokenization_speech_to_text.py": [
        [
          "load_json",
          285,
          287,
          287,
          16,
          287,
          27,
          285,
          15,
          287,
          27
        ]
      ],
      "transformers/src/transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py": [
        [
          "__init__",
          82,
          118,
          96,
          28,
          96,
          50,
          83,
          9,
          99,
          30
        ]
      ],
      "transformers/src/transformers/models/roc_bert/tokenization_roc_bert.py": [
        [
          "__init__",
          117,
          172,
          144,
          31,
          144,
          48,
          141,
          22,
          152,
          28
        ],
        [
          "__init__",
          117,
          172,
          147,
          39,
          147,
          56,
          141,
          22,
          152,
          28
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "__init__",
          251,
          315,
          279,
          28,
          279,
          50,
          276,
          22,
          315,
          28
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "__init__",
          72,
          104,
          85,
          28,
          85,
          50,
          73,
          9,
          104,
          9
        ]
      ],
      "transformers/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": [
        [
          "__init__",
          107,
          145,
          131,
          28,
          131,
          50,
          130,
          14,
          145,
          9
        ]
      ],
      "transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py": [
        [
          "__init__",
          140,
          187,
          160,
          26,
          160,
          48,
          141,
          9,
          164,
          34
        ],
        [
          "__init__",
          698,
          738,
          724,
          28,
          724,
          50,
          699,
          9,
          738,
          9
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "__init__",
          87,
          141,
          133,
          52,
          133,
          74,
          132,
          18,
          133,
          48
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "__init__",
          254,
          326,
          292,
          28,
          292,
          50,
          286,
          13,
          304,
          38
        ],
        [
          "__init__",
          254,
          326,
          306,
          52,
          306,
          74,
          305,
          18,
          306,
          48
        ]
      ],
      "transformers/src/transformers/tokenization_utils_base.py": [
        [
          "from_pretrained",
          1859,
          2128,
          2043,
          48,
          2043,
          64,
          2042,
          30,
          2044,
          73
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2173,
          31,
          2173,
          64,
          2172,
          18,
          2177,
          37
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2297,
          42,
          2297,
          77,
          2296,
          22,
          2298,
          64
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2329,
          41,
          2329,
          70,
          2328,
          22,
          2330,
          65
        ],
        [
          "_from_pretrained",
          2131,
          2387,
          2343,
          45,
          2343,
          76,
          2342,
          22,
          2345,
          53
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "__init__",
          194,
          266,
          247,
          28,
          247,
          50,
          243,
          34,
          266,
          9
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "save_metrics",
          884,
          919,
          913,
          31,
          913,
          42,
          912,
          18,
          913,
          27
        ],
        [
          "from_json_file",
          1156,
          1168,
          1160,
          27,
          1160,
          38,
          1158,
          21,
          1163,
          30
        ]
      ],
      "transformers/utils/update_tiny_models.py": [
        [
          "get_tiny_model_names_from_repo",
          57,
          64,
          59,
          27,
          59,
          39,
          58,
          10,
          61,
          42
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "_read_txt",
          191,
          199,
          196,
          28,
          196,
          41,
          194,
          13,
          198,
          38
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "__post_init__",
          1467,
          1917,
          1766,
          36,
          1766,
          47,
          1765,
          18,
          1766,
          32
        ]
      ],
      "transformers/examples/legacy/seq2seq/utils.py": [
        [
          "load_json",
          474,
          476,
          476,
          16,
          476,
          27,
          474,
          15,
          476,
          27
        ]
      ],
      "transformers/src/transformers/models/auto/video_processing_auto.py": [
        [
          "get_video_processor_config",
          105,
          197,
          197,
          16,
          197,
          32,
          196,
          10,
          197,
          32
        ]
      ],
      "transformers/.github/scripts/assign_reviewers.py": [
        [
          "main",
          74,
          117,
          82,
          17,
          82,
          28,
          75,
          18,
          88,
          54
        ]
      ],
      "transformers/src/transformers/pipelines/__init__.py": [
        [
          "pipeline",
          514,
          1094,
          786,
          38,
          786,
          49,
          785,
          22,
          788,
          25
        ]
      ],
      "transformers/src/transformers/models/auto/auto_factory.py": [
        [
          "from_pretrained",
          251,
          391,
          313,
          38,
          313,
          49,
          312,
          22,
          316,
          49
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "__init__",
          568,
          578,
          578,
          29,
          578,
          40,
          569,
          9,
          578,
          25
        ]
      ],
      "transformers/src/transformers/models/audio_spectrogram_transformer/convert_audio_spectrogram_transformer_original_to_pytorch.py": [
        [
          "get_audio_spectrogram_transformer_config",
          34,
          66,
          61,
          16,
          61,
          92,
          61,
          16,
          66,
          17
        ]
      ],
      "transformers/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py": [
        [
          "convert_beit_checkpoint",
          170,
          357,
          191,
          20,
          191,
          96,
          188,
          45,
          198,
          23
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          204,
          20,
          204,
          96,
          201,
          45,
          208,
          34
        ],
        [
          "convert_beit_checkpoint",
          170,
          357,
          217,
          20,
          217,
          96,
          214,
          45,
          222,
          19
        ]
      ],
      "transformers/src/transformers/models/bit/convert_bit_to_pytorch.py": [
        [
          "get_config",
          38,
          57,
          41,
          16,
          41,
          92,
          38,
          16,
          45,
          50
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "merge_configurations",
          22,
          174,
          26,
          23,
          26,
          34,
          22,
          26,
          36,
          73
        ],
        [
          "merge_configurations",
          22,
          174,
          29,
          24,
          29,
          35,
          22,
          26,
          36,
          73
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "read_json",
          74,
          76,
          76,
          16,
          76,
          27,
          74,
          15,
          76,
          27
        ],
        [
          "write_model",
          84,
          436,
          330,
          28,
          330,
          52,
          326,
          26,
          337,
          53
        ]
      ],
      "transformers/src/transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_conditional_detr_checkpoint",
          222,
          308,
          241,
          20,
          241,
          96,
          238,
          29,
          261,
          32
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_convnext_upernet_to_pytorch.py": [
        [
          "get_upernet_config",
          28,
          68,
          53,
          16,
          53,
          92,
          50,
          18,
          68,
          17
        ]
      ],
      "transformers/src/transformers/models/convnext/convert_convnext_to_pytorch.py": [
        [
          "get_convnext_config",
          36,
          78,
          66,
          16,
          66,
          92,
          64,
          15,
          68,
          33
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "get_convnextv2_config",
          37,
          79,
          71,
          16,
          71,
          92,
          65,
          18,
          79,
          33
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "write_model",
          121,
          196,
          142,
          16,
          142,
          92,
          139,
          25,
          152,
          23
        ]
      ],
      "transformers/src/transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "main",
          249,
          351,
          281,
          20,
          281,
          96,
          259,
          16,
          290,
          15
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "get_d_fine_config",
          36,
          153,
          42,
          16,
          42,
          92,
          41,
          16,
          53,
          75
        ],
        [
          "get_d_fine_config",
          36,
          153,
          42,
          16,
          42,
          92,
          41,
          73,
          53,
          75
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "load_model_state_dict",
          203,
          233,
          215,
          21,
          215,
          32,
          212,
          9,
          219,
          44
        ]
      ],
      "transformers/src/transformers/models/deit/convert_deit_timm_to_pytorch.py": [
        [
          "convert_deit_checkpoint",
          131,
          201,
          144,
          16,
          144,
          92,
          131,
          29,
          151,
          39
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "load_model_state_dict",
          176,
          206,
          188,
          21,
          188,
          32,
          185,
          9,
          192,
          44
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_detr_checkpoint",
          179,
          264,
          198,
          20,
          198,
          96,
          195,
          29,
          218,
          32
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_to_pytorch.py": [
        [
          "get_detr_config",
          34,
          58,
          53,
          20,
          53,
          96,
          50,
          29,
          56,
          23
        ]
      ],
      "transformers/src/transformers/models/vit/convert_dino_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          131,
          195,
          146,
          20,
          146,
          96,
          143,
          29,
          151,
          50
        ]
      ],
      "transformers/src/transformers/models/dinov2_with_registers/convert_dinov2_with_registers_to_hf.py": [
        [
          "get_dinov2_with_registers_config",
          45,
          73,
          70,
          27,
          70,
          103,
          67,
          19,
          71,
          23
        ]
      ],
      "transformers/src/transformers/models/dinov2/convert_dinov2_to_hf.py": [
        [
          "get_dinov2_config",
          40,
          68,
          65,
          27,
          65,
          103,
          62,
          19,
          66,
          23
        ]
      ],
      "transformers/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py": [
        [
          "convert_dit_checkpoint",
          133,
          210,
          154,
          20,
          154,
          96,
          151,
          29,
          163,
          32
        ]
      ],
      "transformers/src/transformers/models/doge/convert_doge_weights_to_hf.py": [
        [
          "convert_doge_model",
          94,
          109,
          97,
          18,
          97,
          29,
          94,
          24,
          106,
          33
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "get_efficientnet_config",
          122,
          139,
          134,
          16,
          134,
          92,
          122,
          29,
          139,
          17
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "load_model_state_dict",
          158,
          188,
          170,
          21,
          170,
          32,
          167,
          9,
          174,
          44
        ],
        [
          "convert_model",
          191,
          286,
          217,
          23,
          217,
          34,
          207,
          8,
          228,
          39
        ],
        [
          "convert_model",
          191,
          286,
          217,
          23,
          217,
          34,
          211,
          5,
          228,
          39
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_model",
          255,
          408,
          282,
          28,
          282,
          42,
          255,
          19,
          308,
          31
        ]
      ],
      "transformers/src/transformers/models/focalnet/convert_focalnet_to_hf_format.py": [
        [
          "get_focalnet_config",
          30,
          87,
          71,
          16,
          71,
          92,
          71,
          16,
          87,
          17
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "convert_glm_model",
          156,
          173,
          159,
          27,
          159,
          38,
          156,
          23,
          173,
          41
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "convert_glm4_model",
          161,
          178,
          164,
          27,
          164,
          38,
          161,
          24,
          178,
          41
        ]
      ],
      "transformers/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": [
        [
          "convert_tf_checkpoint_to_pytorch",
          112,
          133,
          114,
          19,
          114,
          51,
          112,
          38,
          133,
          44
        ]
      ],
      "transformers/src/transformers/models/hiera/convert_hiera_to_hf.py": [
        [
          "get_labels_for_classifier",
          158,
          168,
          163,
          16,
          163,
          92,
          158,
          31,
          168,
          41
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "merge_tp_weights",
          250,
          625,
          267,
          24,
          267,
          35,
          265,
          5,
          281,
          33
        ]
      ],
      "transformers/src/transformers/models/idefics3/convert_idefics3_weights_to_hf.py": [
        [
          "get_config",
          118,
          153,
          124,
          23,
          124,
          34,
          118,
          16,
          129,
          35
        ]
      ],
      "transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py": [
        [
          "convert_weights_and_push",
          83,
          149,
          89,
          16,
          89,
          92,
          83,
          30,
          142,
          17
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "load_model_state_dict",
          209,
          239,
          221,
          21,
          221,
          32,
          218,
          9,
          225,
          44
        ],
        [
          "convert_model",
          242,
          447,
          279,
          23,
          279,
          34,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          281,
          31,
          281,
          42,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          283,
          30,
          283,
          41,
          278,
          10,
          295,
          42
        ],
        [
          "convert_model",
          242,
          447,
          285,
          28,
          285,
          39,
          278,
          10,
          295,
          42
        ]
      ],
      "transformers/src/transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          153,
          248,
          157,
          16,
          157,
          27,
          153,
          25,
          160,
          53
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "max_context_length",
          199,
          210,
          205,
          18,
          205,
          29,
          204,
          10,
          207,
          37
        ],
        [
          "write_model",
          213,
          554,
          224,
          18,
          224,
          29,
          214,
          5,
          244,
          32
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          100,
          16,
          100,
          27,
          95,
          25,
          103,
          53
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          98,
          357,
          103,
          16,
          103,
          27,
          98,
          25,
          106,
          103
        ]
      ],
      "transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py": [
        [
          "read_json",
          174,
          176,
          176,
          16,
          176,
          27,
          174,
          15,
          176,
          27
        ]
      ],
      "transformers/src/transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          28,
          131,
          31,
          20,
          31,
          43,
          28,
          29,
          62,
          54
        ]
      ],
      "transformers/src/transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py": [
        [
          "convert_mamba2_checkpoint_file_to_huggingface_model_file",
          116,
          142,
          128,
          18,
          128,
          37,
          117,
          5,
          138,
          48
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "convert_mamba_ssm_checkpoint_file_to_huggingface_model_file",
          171,
          234,
          205,
          18,
          205,
          37,
          196,
          9,
          225,
          48
        ]
      ],
      "transformers/src/transformers/models/mamba/convert_mamba_ssm_checkpoint_to_pytorch.py": [
        [
          "convert_mamba_checkpoint_file_to_huggingface_model_file",
          97,
          126,
          112,
          36,
          112,
          55,
          108,
          5,
          126,
          41
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "get_maskformer_config",
          36,
          71,
          68,
          16,
          68,
          92,
          68,
          16,
          71,
          17
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "get_maskformer_config",
          36,
          76,
          71,
          16,
          71,
          92,
          71,
          16,
          76,
          17
        ]
      ],
      "transformers/src/transformers/models/mask2former/convert_mask2former_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "__call__",
          113,
          193,
          134,
          20,
          134,
          96,
          134,
          20,
          138,
          37
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "__init__",
          56,
          72,
          59,
          30,
          59,
          100,
          57,
          9,
          61,
          34
        ]
      ],
      "transformers/src/transformers/models/mistral3/convert_mistral3_weights_to_hf.py": [
        [
          "read_json",
          74,
          76,
          76,
          16,
          76,
          27,
          74,
          15,
          76,
          27
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "read_json",
          62,
          64,
          64,
          16,
          64,
          27,
          62,
          15,
          64,
          27
        ]
      ],
      "transformers/src/transformers/models/mixtral/convert_mixtral_weights_to_hf.py": [
        [
          "read_json",
          51,
          53,
          53,
          16,
          53,
          27,
          51,
          15,
          53,
          27
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "get_mobilevitv2_config",
          67,
          122,
          117,
          16,
          117,
          92,
          102,
          5,
          122,
          17
        ],
        [
          "get_mobilevitv2_config",
          67,
          122,
          117,
          16,
          117,
          92,
          116,
          15,
          122,
          17
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_luke_checkpoint",
          29,
          183,
          32,
          20,
          32,
          43,
          29,
          29,
          74,
          61
        ],
        [
          "convert_luke_checkpoint",
          29,
          183,
          55,
          28,
          55,
          39,
          29,
          29,
          74,
          61
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "get_mobilevit_config",
          39,
          70,
          65,
          16,
          65,
          92,
          64,
          15,
          70,
          17
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "write_model",
          209,
          471,
          219,
          18,
          219,
          29,
          210,
          5,
          252,
          49
        ],
        [
          "write_image_processor",
          568,
          587,
          570,
          18,
          570,
          29,
          568,
          27,
          587,
          45
        ]
      ],
      "transformers/src/transformers/models/vit_msn/convert_msn_to_pytorch.py": [
        [
          "convert_vit_msn_checkpoint",
          148,
          228,
          154,
          16,
          154,
          71,
          148,
          32,
          159,
          30
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "read_json",
          58,
          60,
          60,
          16,
          60,
          27,
          58,
          15,
          60,
          27
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "read_json",
          55,
          57,
          57,
          16,
          57,
          27,
          55,
          15,
          57,
          27
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "read_json",
          81,
          83,
          83,
          16,
          83,
          27,
          81,
          15,
          83,
          27
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "read_json",
          69,
          71,
          71,
          16,
          71,
          27,
          69,
          15,
          71,
          27
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          43,
          17,
          43,
          39,
          40,
          5,
          57,
          62
        ],
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          45,
          18,
          45,
          41,
          40,
          5,
          57,
          62
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v1_config",
          142,
          164,
          158,
          16,
          158,
          92,
          155,
          25,
          164,
          17
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v2_config",
          209,
          242,
          231,
          16,
          231,
          92,
          230,
          15,
          233,
          32
        ]
      ],
      "transformers/src/transformers/models/perception_lm/convert_perception_lm_weights_to_hf.py": [
        [
          "read_json",
          176,
          178,
          178,
          16,
          178,
          27,
          176,
          15,
          178,
          27
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          320,
          20,
          320,
          96,
          308,
          30,
          324,
          49
        ],
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          369,
          20,
          369,
          96,
          345,
          30,
          372,
          23
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/convert_phi4_multimodal_weights_to_hf.py": [
        [
          "read_json",
          138,
          140,
          140,
          16,
          140,
          27,
          138,
          15,
          140,
          27
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          196,
          13,
          196,
          60,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          201,
          17,
          201,
          68,
          169,
          32,
          213,
          81
        ],
        [
          "convert_and_save_processor",
          169,
          213,
          210,
          24,
          210,
          82,
          169,
          32,
          213,
          81
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "convert_poolformer_checkpoint",
          93,
          195,
          109,
          16,
          109,
          92,
          93,
          35,
          113,
          20
        ]
      ],
      "transformers/src/transformers/models/pixtral/convert_pixtral_weights_to_hf.py": [
        [
          "convert_mistral_model",
          145,
          210,
          149,
          26,
          149,
          37,
          148,
          14,
          151,
          50
        ]
      ],
      "transformers/src/transformers/models/resnet/convert_resnet_to_pytorch.py": [
        [
          "convert_weights_and_push",
          125,
          164,
          131,
          16,
          131,
          92,
          125,
          30,
          159,
          17
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "get_rt_detr_v2_config",
          37,
          73,
          43,
          16,
          43,
          92,
          37,
          27,
          48,
          38
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "convert_segformer_checkpoint",
          120,
          368,
          153,
          16,
          153,
          92,
          153,
          16,
          157,
          19
        ],
        [
          "convert_segformer_checkpoint",
          120,
          368,
          153,
          16,
          153,
          92,
          144,
          24,
          157,
          19
        ]
      ],
      "transformers/src/transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": [
        [
          "get_rt_detr_config",
          35,
          84,
          41,
          16,
          41,
          92,
          35,
          24,
          46,
          35
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "convert_swiftformer_checkpoint",
          89,
          153,
          101,
          16,
          101,
          92,
          89,
          36,
          107,
          43
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_timm_to_pytorch.py": [
        [
          "get_swin_config",
          13,
          56,
          44,
          20,
          44,
          96,
          41,
          23,
          47,
          23
        ]
      ],
      "transformers/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py": [
        [
          "get_swinv2_config",
          30,
          89,
          68,
          20,
          68,
          96,
          65,
          23,
          71,
          23
        ],
        [
          "get_swinv2_config",
          30,
          89,
          77,
          20,
          77,
          96,
          74,
          23,
          80,
          23
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_swin_upernet_to_pytorch.py": [
        [
          "get_upernet_config",
          31,
          78,
          59,
          16,
          59,
          92,
          56,
          18,
          78,
          17
        ]
      ],
      "transformers/src/transformers/models/timesformer/convert_timesformer_to_pytorch.py": [
        [
          "get_timesformer_config",
          28,
          55,
          50,
          16,
          50,
          92,
          50,
          16,
          55,
          17
        ]
      ],
      "transformers/src/transformers/models/deprecated/van/convert_van_to_pytorch.py": [
        [
          "convert_weights_and_push",
          166,
          241,
          171,
          16,
          171,
          92,
          166,
          30,
          223,
          17
        ]
      ],
      "transformers/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py": [
        [
          "convert_vilt_checkpoint",
          168,
          282,
          184,
          20,
          184,
          96,
          180,
          21,
          208,
          32
        ]
      ],
      "transformers/src/transformers/models/vivit/convert_vivit_flax_to_pytorch.py": [
        [
          "get_vivit_config",
          43,
          54,
          50,
          16,
          50,
          92,
          44,
          14,
          54,
          17
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_classifier_to_hf.py": [
        [
          "get_id2label_mapping",
          94,
          103,
          101,
          20,
          101,
          31,
          94,
          26,
          103,
          19
        ]
      ],
      "transformers/src/transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": [
        [
          "convert_vit_checkpoint",
          165,
          262,
          196,
          16,
          196,
          92,
          192,
          5,
          202,
          31
        ]
      ],
      "transformers/src/transformers/models/videomae/convert_videomae_to_pytorch.py": [
        [
          "get_videomae_config",
          33,
          56,
          51,
          20,
          51,
          96,
          51,
          20,
          54,
          23
        ]
      ],
      "transformers/src/transformers/models/voxtral/convert_voxtral_weights_to_hf.py": [
        [
          "write_model",
          174,
          234,
          190,
          27,
          190,
          38,
          175,
          5,
          234,
          41
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "get_yolos_config",
          34,
          66,
          61,
          16,
          61,
          92,
          58,
          25,
          66,
          17
        ]
      ],
      "transformers/utils/create_dummy_models.py": [
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1296,
          20,
          1296,
          32,
          1294,
          36,
          1299,
          38
        ],
        [
          "update_tiny_model_summary_file",
          1294,
          1318,
          1298,
          16,
          1298,
          28,
          1294,
          36,
          1299,
          38
        ]
      ],
      "transformers/src/transformers/models/auto/feature_extraction_auto.py": [
        [
          "get_feature_extractor_config",
          106,
          201,
          201,
          16,
          201,
          32,
          200,
          10,
          201,
          32
        ]
      ],
      "transformers/utils/get_pr_run_slow_jobs.py": [
        [
          "get_jobs_to_run",
          10,
          46,
          16,
          20,
          16,
          32,
          15,
          10,
          34,
          27
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          709,
          27,
          709,
          38,
          708,
          14,
          710,
          47
        ],
        [
          "is_timm_local_checkpoint",
          693,
          718,
          715,
          27,
          715,
          38,
          714,
          14,
          716,
          47
        ]
      ],
      "transformers/src/transformers/models/auto/image_processing_auto.py": [
        [
          "get_image_processor_config",
          243,
          338,
          338,
          16,
          338,
          32,
          337,
          10,
          338,
          32
        ]
      ],
      "transformers/src/transformers/models/oneformer/image_processing_oneformer.py": [
        [
          "load_metadata",
          382,
          397,
          395,
          22,
          395,
          33,
          394,
          10,
          397,
          21
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "load_sharded_checkpoint",
          372,
          444,
          410,
          17,
          410,
          28,
          407,
          18,
          419,
          13
        ],
        [
          "from_pretrained",
          4261,
          4989,
          4625,
          53,
          4625,
          64,
          4623,
          22,
          4625,
          49
        ]
      ],
      "transformers/utils/models_to_deprecate.py": [
        [
          "get_list_of_models_to_deprecate",
          172,
          293,
          189,
          27,
          189,
          38,
          188,
          14,
          191,
          46
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "analyze_file",
          518,
          576,
          539,
          65,
          539,
          79,
          536,
          16,
          559,
          63
        ],
        [
          "analyze_file",
          518,
          576,
          542,
          26,
          542,
          40,
          536,
          16,
          559,
          63
        ]
      ],
      "transformers/examples/pytorch/old_test_xla_examples.py": [
        [
          "get_results",
          31,
          39,
          36,
          23,
          36,
          34,
          35,
          14,
          39,
          18
        ]
      ],
      "transformers/utils/process_test_artifacts.py": [
        [
          "process_artifacts",
          47,
          69,
          50,
          16,
          50,
          27,
          47,
          23,
          54,
          37
        ]
      ],
      "transformers/src/transformers/models/bark/processing_bark.py": [
        [
          "from_pretrained",
          67,
          122,
          113,
          42,
          113,
          75,
          112,
          22,
          113,
          38
        ]
      ],
      "transformers/src/transformers/models/auto/processing_auto.py": [
        [
          "from_pretrained",
          204,
          425,
          351,
          35,
          351,
          51,
          350,
          22,
          354,
          69
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation.py": [
        [
          "main",
          187,
          445,
          268,
          16,
          268,
          87,
          268,
          16,
          307,
          30
        ]
      ],
      "transformers/examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py": [
        [
          "main",
          253,
          637,
          327,
          16,
          327,
          87,
          327,
          16,
          345,
          46
        ]
      ],
      "transformers/src/transformers/data/processors/squad.py": [
        [
          "get_train_examples",
          500,
          520,
          519,
          26,
          519,
          42,
          517,
          36,
          520,
          57
        ],
        [
          "get_dev_examples",
          522,
          541,
          540,
          26,
          540,
          42,
          538,
          36,
          541,
          55
        ]
      ],
      "transformers/examples/pytorch/test_accelerate_examples.py": [
        [
          "get_results",
          49,
          57,
          54,
          23,
          54,
          34,
          53,
          14,
          57,
          18
        ]
      ],
      "transformers/tests/deepspeed/test_deepspeed.py": [
        [
          "load_json",
          81,
          83,
          83,
          16,
          83,
          27,
          81,
          15,
          83,
          27
        ],
        [
          "setUp",
          417,
          450,
          440,
          28,
          440,
          39,
          417,
          15,
          447,
          27
        ],
        [
          "setUp",
          417,
          450,
          442,
          28,
          442,
          39,
          417,
          15,
          447,
          27
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_layer_pruning_behavior",
          96,
          122,
          104,
          28,
          104,
          39,
          96,
          41,
          106,
          43
        ],
        [
          "test_layer_pruning_behavior",
          96,
          122,
          119,
          28,
          119,
          39,
          113,
          18,
          122,
          99
        ]
      ],
      "transformers/tests/models/gpt_oss/test_modeling_gpt_oss.py": [
        [
          "distributed_worker",
          110,
          193,
          154,
          36,
          154,
          47,
          153,
          18,
          157,
          38
        ],
        [
          "test_model_outputs",
          319,
          374,
          334,
          36,
          334,
          47,
          333,
          18,
          337,
          38
        ]
      ],
      "transformers/tests/models/modernbert/test_modeling_modernbert.py": [
        [
          "test_saved_config_excludes_reference_compile",
          363,
          369,
          368,
          31,
          368,
          42,
          363,
          54,
          369,
          62
        ]
      ],
      "transformers/tests/models/parakeet/test_modeling_parakeet.py": [
        [
          "test_1b_model_integration",
          330,
          352,
          337,
          24,
          337,
          35,
          330,
          35,
          352,
          76
        ],
        [
          "test_1b_model_integration_batched",
          355,
          378,
          363,
          24,
          363,
          35,
          355,
          43,
          378,
          76
        ]
      ]
    },
    "json.loads": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_checkpoint_sharding_local_bin",
          784,
          825,
          816,
          29,
          816,
          48,
          815,
          22,
          824,
          77
        ],
        [
          "test_explicit_transformers_weights_save_and_reload",
          1980,
          2004,
          1999,
          26,
          1999,
          45,
          1980,
          60,
          2004,
          74
        ],
        [
          "test_explicit_transformers_weights_index_save_and_reload",
          2006,
          2030,
          2025,
          26,
          2025,
          45,
          2006,
          66,
          2030,
          85
        ]
      ],
      "transformers/tests/models/csm/test_processing_csm.py": [
        [
          "test_chat_template_is_saved",
          57,
          66,
          59,
          33,
          59,
          77,
          57,
          37,
          66,
          100
        ]
      ],
      "transformers/tests/test_processing_common.py": [
        [
          "test_processor_to_json_string",
          186,
          200,
          188,
          15,
          188,
          52,
          186,
          39,
          189,
          63
        ]
      ],
      "transformers/tests/models/llava/test_processing_llava.py": [
        [
          "test_chat_template_is_saved",
          76,
          85,
          78,
          33,
          78,
          77,
          76,
          37,
          85,
          100
        ]
      ],
      "transformers/tests/models/llava_next/test_processing_llava_next.py": [
        [
          "test_chat_template_is_saved",
          83,
          92,
          85,
          33,
          85,
          77,
          83,
          37,
          92,
          100
        ]
      ],
      "transformers/tests/models/llava_next_video/test_processing_llava_next_video.py": [
        [
          "test_chat_template_is_saved",
          92,
          101,
          94,
          33,
          94,
          77,
          92,
          37,
          101,
          100
        ]
      ],
      "transformers/tests/models/llava_onevision/test_processing_llava_onevision.py": [
        [
          "test_chat_template_is_saved",
          96,
          105,
          98,
          33,
          98,
          77,
          96,
          37,
          105,
          100
        ]
      ],
      "transformers/tests/models/mllama/test_processing_mllama.py": [
        [
          "test_chat_template_is_saved",
          70,
          79,
          72,
          33,
          72,
          77,
          70,
          37,
          79,
          100
        ]
      ],
      "transformers/tests/models/perception_lm/test_processing_perception_lm.py": [
        [
          "test_chat_template_is_saved",
          82,
          91,
          84,
          33,
          84,
          77,
          82,
          37,
          91,
          100
        ]
      ],
      "transformers/tests/models/ovis2/test_processor_ovis2.py": [
        [
          "test_processor_to_json_string",
          60,
          67,
          62,
          15,
          62,
          52,
          60,
          39,
          63,
          63
        ],
        [
          "test_chat_template_is_saved",
          69,
          78,
          71,
          33,
          71,
          77,
          69,
          37,
          78,
          100
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_fast.py": [
        [
          "test_local_versioning",
          211,
          236,
          213,
          26,
          213,
          66,
          211,
          31,
          236,
          77
        ],
        [
          "test_local_versioning",
          211,
          236,
          225,
          30,
          225,
          74,
          211,
          31,
          236,
          77
        ],
        [
          "test_local_versioning",
          211,
          236,
          235,
          30,
          235,
          74,
          211,
          31,
          236,
          77
        ],
        [
          "test_repo_versioning",
          238,
          255,
          245,
          26,
          245,
          66,
          238,
          30,
          255,
          73
        ],
        [
          "test_repo_versioning",
          238,
          255,
          254,
          26,
          254,
          70,
          238,
          30,
          255,
          73
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_chat_template",
          1114,
          1174,
          1165,
          35,
          1165,
          104,
          1123,
          13,
          1174,
          103
        ]
      ],
      "transformers/tests/models/longformer/test_tokenization_longformer.py": [
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          209,
          221,
          215,
          35,
          215,
          104,
          210,
          13,
          221,
          80
        ],
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          209,
          221,
          216,
          36,
          216,
          106,
          210,
          13,
          221,
          80
        ]
      ],
      "transformers/tests/models/roberta/test_tokenization_roberta.py": [
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          207,
          219,
          213,
          35,
          213,
          104,
          208,
          13,
          219,
          80
        ],
        [
          "test_change_add_prefix_space_and_trim_offsets_args",
          207,
          219,
          214,
          36,
          214,
          106,
          208,
          13,
          219,
          80
        ]
      ],
      "transformers/tests/models/auto/test_video_processing_auto.py": [
        [
          "test_video_processor_from_local_directory_from_config",
          82,
          114,
          111,
          29,
          111,
          63,
          82,
          63,
          114,
          67
        ]
      ],
      "transformers/tests/test_video_processing_common.py": [
        [
          "test_video_processor_to_json_string",
          114,
          119,
          117,
          19,
          117,
          62,
          115,
          13,
          118,
          63
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          277,
          23,
          277,
          45,
          268,
          9,
          287,
          30
        ],
        [
          "get_impacted_files_from_tiny_model_summary",
          237,
          313,
          278,
          23,
          278,
          45,
          268,
          9,
          287,
          30
        ]
      ],
      "transformers/src/transformers/models/bart/tokenization_bart_fast.py": [
        [
          "__init__",
          120,
          185,
          164,
          21,
          164,
          75,
          164,
          21,
          167,
          29
        ]
      ],
      "transformers/src/transformers/models/bert/tokenization_bert_fast.py": [
        [
          "__init__",
          75,
          115,
          103,
          28,
          103,
          87,
          76,
          9,
          105,
          77
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot_fast.py": [
        [
          "__init__",
          124,
          187,
          166,
          21,
          166,
          75,
          166,
          21,
          169,
          29
        ]
      ],
      "transformers/src/transformers/models/convbert/tokenization_convbert_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/models/distilbert/tokenization_distilbert_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/models/electra/tokenization_electra_fast.py": [
        [
          "__init__",
          72,
          112,
          100,
          28,
          100,
          87,
          73,
          9,
          102,
          77
        ]
      ],
      "transformers/src/transformers/models/funnel/tokenization_funnel_fast.py": [
        [
          "__init__",
          93,
          141,
          129,
          28,
          129,
          87,
          94,
          9,
          131,
          77
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "load_vocab_and_emoji",
          35,
          52,
          38,
          17,
          38,
          36,
          35,
          26,
          46,
          34
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "load_vocab_and_emoji",
          43,
          60,
          46,
          17,
          46,
          36,
          43,
          26,
          54,
          34
        ]
      ],
      "transformers/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py": [
        [
          "__init__",
          98,
          153,
          136,
          25,
          136,
          84,
          99,
          9,
          138,
          74
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py": [
        [
          "__init__",
          121,
          196,
          168,
          21,
          168,
          75,
          168,
          21,
          171,
          29
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led_fast.py": [
        [
          "__init__",
          120,
          185,
          164,
          21,
          164,
          75,
          164,
          21,
          167,
          29
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer_fast.py": [
        [
          "__init__",
          119,
          182,
          161,
          21,
          161,
          75,
          161,
          21,
          164,
          29
        ]
      ],
      "transformers/src/transformers/models/lxmert/tokenization_lxmert_fast.py": [
        [
          "__init__",
          72,
          112,
          100,
          28,
          100,
          87,
          73,
          9,
          102,
          77
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm_fast.py": [
        [
          "__init__",
          144,
          241,
          213,
          21,
          213,
          75,
          213,
          21,
          216,
          29
        ]
      ],
      "transformers/src/transformers/models/mobilebert/tokenization_mobilebert_fast.py": [
        [
          "__init__",
          77,
          117,
          105,
          28,
          105,
          87,
          78,
          9,
          107,
          77
        ]
      ],
      "transformers/src/transformers/models/mpnet/tokenization_mpnet_fast.py": [
        [
          "__init__",
          93,
          145,
          135,
          25,
          135,
          84,
          117,
          22,
          137,
          74
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp_fast.py": [
        [
          "__init__",
          120,
          188,
          167,
          21,
          167,
          75,
          167,
          21,
          170,
          29
        ]
      ],
      "transformers/src/transformers/models/deprecated/realm/tokenization_realm_fast.py": [
        [
          "__init__",
          79,
          119,
          107,
          28,
          107,
          87,
          80,
          9,
          109,
          77
        ]
      ],
      "transformers/src/transformers/models/deprecated/retribert/tokenization_retribert_fast.py": [
        [
          "__init__",
          79,
          119,
          107,
          28,
          107,
          87,
          80,
          9,
          109,
          77
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta_fast.py": [
        [
          "__init__",
          118,
          181,
          160,
          21,
          160,
          75,
          160,
          21,
          163,
          29
        ]
      ],
      "transformers/src/transformers/models/roformer/tokenization_roformer_fast.py": [
        [
          "__init__",
          57,
          99,
          85,
          28,
          85,
          87,
          58,
          9,
          87,
          77
        ]
      ],
      "transformers/src/transformers/models/splinter/tokenization_splinter_fast.py": [
        [
          "__init__",
          77,
          117,
          107,
          25,
          107,
          84,
          78,
          9,
          109,
          74
        ]
      ],
      "transformers/src/transformers/models/squeezebert/tokenization_squeezebert_fast.py": [
        [
          "__init__",
          76,
          116,
          104,
          28,
          104,
          87,
          77,
          9,
          106,
          77
        ]
      ],
      "transformers/src/transformers/tokenization_utils_fast.py": [
        [
          "__init__",
          98,
          220,
          211,
          29,
          211,
          91,
          211,
          29,
          211,
          91
        ],
        [
          "train_new_from_iterator",
          744,
          922,
          778,
          26,
          778,
          61,
          745,
          9,
          786,
          51
        ],
        [
          "train_new_from_iterator",
          744,
          922,
          860,
          38,
          860,
          67,
          860,
          38,
          862,
          49
        ]
      ],
      "transformers/src/transformers/trainer_callback.py": [
        [
          "load_from_json",
          151,
          155,
          155,
          22,
          155,
          37,
          151,
          24,
          155,
          38
        ]
      ],
      "transformers/examples/legacy/multiple_choice/utils_multiple_choice.py": [
        [
          "_create_examples",
          347,
          409,
          367,
          24,
          367,
          51,
          366,
          13,
          368,
          56
        ]
      ],
      "transformers/src/transformers/training_args.py": [
        [
          "__post_init__",
          1467,
          1917,
          1482,
          31,
          1482,
          54,
          1482,
          31,
          1485,
          49
        ]
      ],
      "transformers/src/transformers/video_processing_utils.py": [
        [
          "get_video_processor_dict",
          611,
          724,
          710,
          36,
          710,
          51,
          710,
          47,
          710,
          51
        ],
        [
          "from_json_file",
          821,
          837,
          836,
          32,
          836,
          47,
          821,
          24,
          837,
          42
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_push_from_checkpoint",
          4864,
          4930,
          4881,
          29,
          4881,
          48,
          4879,
          17,
          4883,
          50
        ]
      ],
      "transformers/src/transformers/utils/chat_template_utils.py": [
        [
          "get_json_schema",
          237,
          371,
          364,
          50,
          364,
          82,
          364,
          50,
          365,
          16
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "parse_generate_flags",
          424,
          475,
          468,
          40,
          468,
          72,
          468,
          51,
          468,
          72
        ]
      ],
      "transformers/utils/check_self_hosted_runner.py": [
        [
          "get_runner_status",
          6,
          34,
          20,
          14,
          20,
          26,
          6,
          23,
          23,
          25
        ]
      ],
      "transformers/src/transformers/generation/configuration_utils.py": [
        [
          "_dict_from_json_file",
          948,
          951,
          951,
          16,
          951,
          31,
          948,
          30,
          951,
          31
        ]
      ],
      "transformers/src/transformers/configuration_utils.py": [
        [
          "_dict_from_json_file",
          853,
          856,
          856,
          16,
          856,
          31,
          853,
          30,
          856,
          31
        ]
      ],
      "transformers/src/transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_cvt_checkpoint",
          278,
          330,
          286,
          16,
          286,
          107,
          278,
          28,
          294,
          48
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          112,
          16,
          112,
          100,
          104,
          37,
          130,
          32
        ],
        [
          "convert_deformable_detr_checkpoint",
          87,
          201,
          112,
          16,
          112,
          100,
          105,
          23,
          130,
          32
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "get_deta_config",
          36,
          71,
          66,
          16,
          66,
          100,
          65,
          25,
          71,
          17
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "get_deta_config",
          36,
          56,
          51,
          16,
          51,
          100,
          37,
          14,
          56,
          17
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_to_pytorch.py": [
        [
          "get_dpt_config",
          34,
          58,
          52,
          20,
          52,
          104,
          47,
          52,
          56,
          22
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "get_dpt_config",
          34,
          70,
          64,
          20,
          64,
          104,
          57,
          52,
          68,
          22
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/convert_gptsan_tf_checkpoint_to_pytorch.py": [
        [
          "convert_tf_gptsan_to_pt",
          28,
          171,
          30,
          14,
          30,
          52,
          28,
          29,
          31,
          17
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "main",
          700,
          805,
          783,
          32,
          783,
          77,
          743,
          28,
          797,
          82
        ],
        [
          "main",
          700,
          805,
          784,
          30,
          784,
          73,
          743,
          28,
          797,
          82
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_model",
          146,
          284,
          157,
          23,
          157,
          85,
          154,
          20,
          179,
          49
        ]
      ],
      "transformers/src/transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "listcomp",
          189,
          189,
          189,
          13,
          189,
          28,
          189,
          34,
          189,
          28
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "write_model",
          272,
          398,
          285,
          20,
          285,
          54,
          273,
          5,
          299,
          59
        ]
      ],
      "transformers/src/transformers/models/vits/convert_original_checkpoint.py": [
        [
          "convert_checkpoint",
          266,
          360,
          312,
          19,
          312,
          34,
          292,
          9,
          315,
          20
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_seer_10b_to_pytorch.py": [
        [
          "convert_weights_and_push",
          162,
          272,
          167,
          16,
          167,
          100,
          162,
          30,
          204,
          58
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_to_pytorch.py": [
        [
          "convert_weights_and_push",
          221,
          422,
          227,
          16,
          227,
          100,
          221,
          30,
          403,
          17
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "prepare_config",
          43,
          113,
          44,
          19,
          44,
          64,
          43,
          20,
          47,
          31
        ],
        [
          "convert_textnet_checkpoint",
          116,
          181,
          120,
          19,
          120,
          38,
          116,
          32,
          124,
          62
        ]
      ],
      "transformers/src/transformers/feature_extraction_utils.py": [
        [
          "get_feature_extractor_dict",
          417,
          529,
          514,
          38,
          514,
          53,
          514,
          49,
          514,
          53
        ],
        [
          "from_json_file",
          584,
          600,
          599,
          34,
          599,
          49,
          584,
          24,
          600,
          44
        ]
      ],
      "transformers/src/transformers/hf_argparser.py": [
        [
          "parse_json_file",
          386,
          408,
          406,
          20,
          406,
          52,
          387,
          9,
          408,
          29
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "define_sagemaker_information",
          198,
          221,
          207,
          24,
          207,
          73,
          207,
          24,
          209,
          96
        ],
        [
          "get_checkpoint_shard_files",
          1011,
          1078,
          1050,
          17,
          1050,
          36,
          1049,
          10,
          1058,
          51
        ]
      ],
      "transformers/src/transformers/image_processing_base.py": [
        [
          "get_image_processor_dict",
          264,
          382,
          367,
          36,
          367,
          51,
          367,
          47,
          367,
          51
        ],
        [
          "from_json_file",
          442,
          458,
          457,
          32,
          457,
          47,
          442,
          24,
          458,
          42
        ]
      ],
      "transformers/src/transformers/data/datasets/language_modeling.py": [
        [
          "listcomp",
          160,
          160,
          160,
          20,
          160,
          35,
          160,
          20,
          160,
          35
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "is_sagemaker_dp_enabled",
          1282,
          1293,
          1287,
          28,
          1287,
          55,
          1287,
          39,
          1287,
          55
        ],
        [
          "is_sagemaker_mp_enabled",
          1296,
          1317,
          1301,
          23,
          1301,
          45,
          1301,
          34,
          1301,
          45
        ],
        [
          "is_sagemaker_mp_enabled",
          1296,
          1317,
          1311,
          23,
          1311,
          45,
          1311,
          34,
          1311,
          45
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "setup",
          1371,
          1476,
          1474,
          31,
          1474,
          53,
          1474,
          31,
          1475,
          51
        ]
      ],
      "transformers/src/transformers/model_debugging_utils.py": [
        [
          "log_model_debug_trace",
          228,
          268,
          264,
          17,
          264,
          56,
          238,
          5,
          268,
          41
        ]
      ],
      "transformers/src/transformers/modelcard.py": [
        [
          "from_json_file",
          225,
          230,
          229,
          20,
          229,
          35,
          225,
          24,
          230,
          30
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "error_out",
          184,
          207,
          201,
          37,
          201,
          55,
          187,
          17,
          207,
          9
        ],
        [
          "post",
          209,
          219,
          211,
          37,
          211,
          60,
          209,
          14,
          213,
          92
        ]
      ],
      "transformers/utils/patch_helper.py": [
        [
          "get_prs_by_label",
          73,
          95,
          90,
          11,
          90,
          35,
          73,
          22,
          91,
          17
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "error_out",
          701,
          760,
          715,
          35,
          715,
          52,
          715,
          35,
          715,
          31
        ],
        [
          "post",
          762,
          773,
          765,
          37,
          765,
          55,
          762,
          14,
          767,
          92
        ],
        [
          "get_new_model_failure_blocks",
          817,
          892,
          837,
          34,
          839,
          13,
          837,
          34,
          841,
          47
        ]
      ],
      "transformers/src/transformers/processing_utils.py": [
        [
          "get_processor_dict",
          899,
          1149,
          1073,
          38,
          1073,
          62,
          1072,
          18,
          1075,
          58
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1108,
          34,
          1108,
          49,
          1108,
          45,
          1108,
          49
        ],
        [
          "get_processor_dict",
          899,
          1149,
          1135,
          40,
          1135,
          71,
          1133,
          26,
          1135,
          36
        ]
      ],
      "transformers/tests/sagemaker/scripts/pytorch/run_ddp.py": [
        [
          "main",
          21,
          48,
          25,
          13,
          25,
          46,
          22,
          12,
          31,
          20
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "create_generation_config_from_req",
          233,
          289,
          257,
          48,
          257,
          83,
          257,
          29,
          257,
          25
        ]
      ],
      "transformers/tests/test_configuration_common.py": [
        [
          "create_and_test_config_to_json_string",
          79,
          83,
          81,
          15,
          81,
          49,
          79,
          47,
          82,
          50
        ]
      ],
      "transformers/tests/models/auto/test_feature_extraction_auto.py": [
        [
          "test_feature_extractor_from_local_directory_from_config",
          57,
          77,
          74,
          29,
          74,
          63,
          57,
          65,
          77,
          63
        ]
      ],
      "transformers/tests/test_feature_extraction_common.py": [
        [
          "test_feat_extract_to_json_string",
          26,
          30,
          28,
          15,
          28,
          55,
          26,
          42,
          29,
          56
        ]
      ],
      "transformers/tests/utils/test_hub_utils.py": [
        [
          "test_get_file_from_repo_distant",
          114,
          156,
          155,
          18,
          155,
          55,
          114,
          41,
          156,
          52
        ]
      ],
      "transformers/tests/models/auto/test_image_processing_auto.py": [
        [
          "test_image_processor_from_local_directory_from_config",
          92,
          121,
          118,
          29,
          118,
          63,
          92,
          63,
          121,
          57
        ]
      ],
      "transformers/tests/models/conditional_detr/test_image_processing_conditional_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          170,
          212,
          174,
          22,
          174,
          41,
          170,
          59,
          178,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          215,
          263,
          219,
          22,
          219,
          41,
          215,
          58,
          225,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          383,
          272,
          22,
          272,
          41,
          267,
          49,
          280,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          386,
          507,
          392,
          22,
          392,
          41,
          386,
          48,
          399,
          58
        ]
      ],
      "transformers/tests/models/deformable_detr/test_image_processing_deformable_detr.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          175,
          217,
          179,
          22,
          179,
          41,
          175,
          59,
          183,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          220,
          268,
          224,
          22,
          224,
          41,
          220,
          58,
          230,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          272,
          388,
          277,
          22,
          277,
          41,
          272,
          49,
          285,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          391,
          512,
          397,
          22,
          397,
          41,
          391,
          48,
          404,
          58
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          618,
          671,
          622,
          22,
          622,
          41,
          618,
          84,
          671,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          676,
          740,
          680,
          22,
          680,
          41,
          676,
          83,
          740,
          114
        ]
      ],
      "transformers/tests/models/detr/test_image_processing_detr.py": [
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          283,
          331,
          287,
          22,
          287,
          41,
          283,
          58,
          293,
          63
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_panoptic_annotations",
          734,
          796,
          738,
          22,
          738,
          41,
          734,
          83,
          796,
          114
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          678,
          729,
          682,
          22,
          682,
          41,
          678,
          84,
          729,
          114
        ],
        [
          "test_should_raise_if_annotation_format_invalid",
          178,
          199,
          182,
          32,
          182,
          51,
          178,
          56,
          193,
          63
        ],
        [
          "test_valid_coco_detection_annotations",
          201,
          235,
          205,
          22,
          205,
          41,
          201,
          47,
          209,
          63
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          238,
          280,
          242,
          22,
          242,
          41,
          238,
          59,
          246,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          334,
          450,
          339,
          22,
          339,
          41,
          334,
          49,
          347,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          452,
          573,
          458,
          22,
          458,
          41,
          452,
          48,
          465,
          58
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_image_processor_to_json_string",
          259,
          264,
          262,
          19,
          262,
          62,
          260,
          13,
          263,
          63
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          707,
          32,
          707,
          51,
          702,
          57,
          754,
          51
        ],
        [
          "test_processor_can_use_legacy_annotation_format",
          702,
          772,
          718,
          31,
          718,
          50,
          702,
          57,
          754,
          51
        ]
      ],
      "transformers/tests/models/imagegpt/test_image_processing_imagegpt.py": [
        [
          "test_image_processor_to_json_string",
          136,
          144,
          139,
          19,
          139,
          62,
          137,
          13,
          140,
          63
        ]
      ],
      "transformers/tests/models/grounding_dino/test_image_processing_grounding_dino.py": [
        [
          "test_batched_coco_detection_annotations",
          253,
          369,
          258,
          22,
          258,
          41,
          253,
          49,
          266,
          57
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          207,
          249,
          211,
          22,
          211,
          41,
          207,
          59,
          215,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          373,
          421,
          377,
          22,
          377,
          41,
          373,
          58,
          383,
          63
        ],
        [
          "test_batched_coco_panoptic_annotations",
          425,
          546,
          431,
          22,
          431,
          41,
          425,
          48,
          438,
          58
        ]
      ],
      "transformers/tests/models/rt_detr/test_image_processing_rt_detr.py": [
        [
          "test_valid_coco_detection_annotations",
          125,
          159,
          129,
          22,
          129,
          41,
          125,
          47,
          133,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          267,
          379,
          272,
          22,
          272,
          41,
          267,
          49,
          280,
          57
        ],
        [
          "test_call_pytorch_with_coco_detection_annotations",
          162,
          204,
          166,
          22,
          166,
          41,
          162,
          59,
          170,
          63
        ],
        [
          "test_fast_processor_equivalence_cpu_accelerator_coco_detection_annotations",
          385,
          436,
          389,
          22,
          389,
          41,
          385,
          84,
          436,
          114
        ]
      ],
      "transformers/tests/models/yolos/test_image_processing_yolos.py": [
        [
          "test_call_pytorch_with_coco_detection_annotations",
          226,
          268,
          230,
          22,
          230,
          41,
          226,
          59,
          234,
          63
        ],
        [
          "test_call_pytorch_with_coco_panoptic_annotations",
          271,
          319,
          275,
          22,
          275,
          41,
          271,
          58,
          281,
          63
        ],
        [
          "test_batched_coco_detection_annotations",
          323,
          439,
          328,
          22,
          328,
          41,
          323,
          49,
          336,
          57
        ],
        [
          "test_batched_coco_panoptic_annotations",
          442,
          564,
          448,
          22,
          448,
          41,
          442,
          48,
          455,
          58
        ]
      ],
      "transformers/tests/utils/test_model_card.py": [
        [
          "test_model_card_to_json_string",
          60,
          64,
          62,
          15,
          62,
          52,
          60,
          40,
          63,
          50
        ]
      ],
      "transformers/tests/utils/test_model_debugging_utils.py": [
        [
          "test_debugger_outputs",
          52,
          63,
          61,
          24,
          61,
          54,
          60,
          17,
          63,
          49
        ]
      ]
    },
    "pickle.loads": {
      "transformers/tests/models/code_llama/test_tokenization_code_llama.py": [
        [
          "test_picklable",
          296,
          301,
          301,
          9,
          301,
          39,
          296,
          24,
          301,
          39
        ]
      ],
      "transformers/tests/models/llama/test_tokenization_llama.py": [
        [
          "test_picklable",
          294,
          299,
          299,
          9,
          299,
          39,
          294,
          24,
          299,
          39
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "test_pickle_subword_regularization_tokenizer",
          523,
          543,
          533,
          25,
          533,
          51,
          527,
          9,
          543,
          9
        ],
        [
          "test_pickle_added_tokens",
          852,
          856,
          854,
          16,
          854,
          47,
          852,
          34,
          856,
          66
        ]
      ],
      "transformers/tests/models/moshi/test_tokenization_moshi.py": [
        [
          "test_picklable",
          174,
          184,
          184,
          9,
          184,
          39,
          174,
          24,
          184,
          39
        ]
      ],
      "transformers/tests/tokenization/test_tokenization_utils.py": [
        [
          "assert_dump_and_restore",
          68,
          88,
          72,
          23,
          72,
          54,
          68,
          33,
          78,
          30
        ]
      ],
      "transformers/tests/models/xglm/test_tokenization_xglm.py": [
        [
          "test_picklable_without_disk",
          144,
          149,
          149,
          9,
          149,
          39,
          144,
          37,
          149,
          39
        ]
      ],
      "transformers/tests/models/xlm_roberta/test_tokenization_xlm_roberta.py": [
        [
          "test_picklable_without_disk",
          218,
          223,
          223,
          9,
          223,
          39,
          218,
          37,
          223,
          39
        ]
      ],
      "transformers/src/transformers/models/bloom/tokenization_bloom_fast.py": [
        [
          "__init__",
          88,
          124,
          121,
          48,
          121,
          74,
          121,
          48,
          124,
          29
        ],
        [
          "__init__",
          88,
          124,
          122,
          42,
          122,
          68,
          121,
          48,
          124,
          29
        ]
      ],
      "transformers/src/transformers/models/cohere/tokenization_cohere_fast.py": [
        [
          "__init__",
          113,
          161,
          158,
          48,
          158,
          74,
          158,
          48,
          161,
          29
        ],
        [
          "__init__",
          113,
          161,
          159,
          42,
          159,
          68,
          158,
          48,
          161,
          29
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "convert_perceiver_checkpoint",
          263,
          436,
          270,
          22,
          270,
          43,
          263,
          34,
          273,
          35
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "run_hp_search_sigopt",
          448,
          543,
          534,
          20,
          534,
          54,
          533,
          13,
          535,
          50
        ]
      ]
    },
    "yaml.safe_load": {
      "transformers/src/transformers/commands/chat.py": [
        [
          "_inner_run",
          667,
          752,
          696,
          28,
          696,
          44,
          695,
          18,
          696,
          24
        ]
      ],
      "transformers/utils/check_doc_toc.py": [
        [
          "check_model_doc",
          79,
          125,
          89,
          19,
          89,
          42,
          79,
          21,
          92,
          11
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          353,
          21,
          353,
          50,
          341,
          10,
          355,
          42
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "remap_model_yaml_config",
          88,
          101,
          90,
          16,
          90,
          32,
          88,
          29,
          97,
          66
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_hifigan.py": [
        [
          "remap_hifigan_yaml_config",
          62,
          89,
          64,
          16,
          64,
          32,
          62,
          31,
          68,
          42
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "parse_metadata",
          290,
          318,
          305,
          24,
          305,
          56,
          302,
          68,
          306,
          79
        ],
        [
          "parse_metadata",
          290,
          318,
          313,
          24,
          313,
          57,
          308,
          32,
          314,
          80
        ]
      ],
      "transformers/src/transformers/models/olmo2/convert_olmo2_weights_to_hf.py": [
        [
          "write_model",
          68,
          216,
          82,
          20,
          82,
          58,
          69,
          5,
          84,
          58
        ],
        [
          "_write_tokenizer",
          219,
          248,
          231,
          28,
          231,
          66,
          230,
          23,
          234,
          57
        ]
      ],
      "transformers/src/transformers/models/olmo/convert_olmo_weights_to_hf.py": [
        [
          "write_model",
          65,
          183,
          71,
          19,
          71,
          57,
          65,
          17,
          83,
          54
        ]
      ],
      "transformers/src/transformers/models/olmoe/convert_olmoe_weights_to_hf.py": [
        [
          "write_model",
          91,
          215,
          97,
          20,
          97,
          58,
          91,
          17,
          99,
          23
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "convert_checkpoint",
          185,
          261,
          188,
          24,
          188,
          40,
          185,
          24,
          205,
          38
        ]
      ],
      "transformers/src/transformers/hf_argparser.py": [
        [
          "parse_yaml_file",
          410,
          430,
          429,
          35,
          429,
          77,
          411,
          9,
          430,
          29
        ]
      ]
    },
    "tensorflow.saved_model.load": {
      "transformers/src/transformers/models/big_bird/convert_bigbird_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_big_bird",
          50,
          206,
          110,
          17,
          110,
          44,
          110,
          17,
          110,
          54
        ]
      ]
    },
    "yaml.load": {
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "load_config_from_state_dict",
          104,
          109,
          108,
          16,
          108,
          62,
          104,
          33,
          109,
          39
        ],
        [
          "load_yaml",
          681,
          685,
          685,
          16,
          685,
          51,
          681,
          15,
          685,
          51
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "load_orig_config_file",
          41,
          64,
          57,
          19,
          57,
          62,
          57,
          40,
          57,
          62
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "main",
          287,
          300,
          297,
          19,
          297,
          91,
          288,
          5,
          300,
          82
        ]
      ]
    }
  },
  "CWE-643": {},
  "CWE-760": {
    "uuid.uuid4": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "setUp",
          2163,
          2164,
          2164,
          63,
          2164,
          74,
          2163,
          15,
          2164,
          22
        ]
      ],
      "transformers/benchmark/benchmarks_entrypoint.py": [
        [
          "initialise_benchmark",
          103,
          144,
          108,
          28,
          108,
          39,
          103,
          30,
          110,
          28
        ]
      ],
      "transformers/src/transformers/models/olmo3/convert_olmo3_weights_to_hf.py": [
        [
          "generate_uuid",
          83,
          84,
          84,
          16,
          84,
          27,
          84,
          12,
          84,
          28
        ]
      ],
      "transformers/benchmark_v2/run_benchmarks.py": [
        [
          "main",
          278,
          491,
          281,
          30,
          281,
          41,
          279,
          5,
          380,
          40
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "get_or_set_request_id",
          751,
          756,
          752,
          67,
          752,
          78,
          752,
          63,
          752,
          79
        ]
      ]
    },
    "hashlib.sha256": {
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_class_in_module",
          268,
          313,
          300,
          28,
          300,
          100,
          295,
          47,
          303,
          32
        ]
      ]
    }
  },
  "CWE-918": {
    "requests.get": {
      "transformers/tests/models/rag/test_modeling_rag.py": [
        [
          "setUpClass",
          1066,
          1077,
          1075,
          20,
          1075,
          49,
          1066,
          20,
          1077,
          38
        ],
        [
          "setUpClass",
          685,
          696,
          694,
          20,
          694,
          49,
          685,
          20,
          696,
          38
        ]
      ],
      "transformers/tests/models/sam/test_modeling_sam.py": [
        [
          "prepare_image",
          721,
          724,
          723,
          28,
          723,
          61,
          722,
          15,
          724,
          20
        ],
        [
          "prepare_dog_img",
          727,
          730,
          729,
          28,
          729,
          61,
          728,
          15,
          730,
          20
        ]
      ],
      "transformers/tests/models/sam2_video/test_modeling_sam2_video.py": [
        [
          "prepare_image",
          41,
          44,
          43,
          28,
          43,
          61,
          42,
          15,
          44,
          20
        ],
        [
          "prepare_groceries_image",
          47,
          50,
          49,
          28,
          49,
          61,
          48,
          15,
          50,
          20
        ],
        [
          "prepare_dog_img",
          53,
          56,
          55,
          28,
          55,
          61,
          54,
          15,
          56,
          20
        ]
      ],
      "transformers/tests/models/sam2/test_modeling_sam2.py": [
        [
          "prepare_image",
          720,
          723,
          722,
          28,
          722,
          61,
          721,
          15,
          723,
          20
        ],
        [
          "prepare_groceries_image",
          726,
          729,
          728,
          28,
          728,
          61,
          727,
          15,
          729,
          20
        ],
        [
          "prepare_dog_img",
          732,
          735,
          734,
          28,
          734,
          61,
          733,
          15,
          735,
          20
        ]
      ],
      "transformers/tests/models/shieldgemma2/test_modeling_shieldgemma2.py": [
        [
          "test_model",
          43,
          57,
          48,
          20,
          48,
          36,
          43,
          20,
          56,
          43
        ]
      ],
      "transformers/tests/models/sam_hq/test_modeling_sam_hq.py": [
        [
          "prepare_image",
          768,
          771,
          770,
          28,
          770,
          61,
          769,
          15,
          771,
          20
        ],
        [
          "prepare_dog_img",
          774,
          777,
          776,
          28,
          776,
          61,
          775,
          15,
          777,
          20
        ]
      ],
      "transformers/tests/models/siglip/test_modeling_siglip.py": [
        [
          "prepare_img",
          647,
          650,
          649,
          24,
          649,
          53,
          648,
          11,
          650,
          16
        ]
      ],
      "transformers/tests/models/smolvlm/test_modeling_smolvlm.py": [
        [
          "setUp",
          514,
          535,
          518,
          17,
          520,
          17,
          514,
          15,
          524,
          27
        ]
      ],
      "transformers/tests/models/textnet/test_modeling_textnet.py": [
        [
          "test_inference_no_head",
          299,
          324,
          305,
          28,
          305,
          57,
          299,
          32,
          324,
          9
        ]
      ],
      "transformers/tests/models/vipllava/test_modeling_vipllava.py": [
        [
          "test_small_model_integration_test",
          293,
          309,
          301,
          28,
          301,
          57,
          293,
          43,
          309,
          97
        ]
      ],
      "transformers/tests/models/video_llava/test_modeling_video_llava.py": [
        [
          "test_small_model_integration_test_mixed_inputs",
          440,
          467,
          452,
          28,
          452,
          57,
          440,
          56,
          467,
          9
        ]
      ],
      "transformers/tests/models/vitpose/test_modeling_vitpose.py": [
        [
          "prepare_img",
          227,
          230,
          229,
          24,
          229,
          53,
          228,
          11,
          230,
          16
        ]
      ],
      "transformers/utils/check_bad_commit.py": [
        [
          "get_commit_info",
          136,
          159,
          143,
          26,
          143,
          42,
          136,
          21,
          145,
          34
        ],
        [
          "get_commit_info",
          136,
          159,
          149,
          25,
          149,
          41,
          146,
          21,
          151,
          49
        ],
        [
          "get_commit_info",
          136,
          159,
          156,
          23,
          156,
          39,
          155,
          15,
          157,
          14
        ]
      ],
      "transformers/src/transformers/models/align/convert_align_tf_to_hf.py": [
        [
          "prepare_img",
          66,
          69,
          68,
          21,
          68,
          50,
          67,
          11,
          69,
          13
        ]
      ],
      "transformers/src/transformers/models/beit/convert_beit_unilm_to_pytorch.py": [
        [
          "prepare_img",
          163,
          166,
          165,
          21,
          165,
          50,
          164,
          11,
          166,
          13
        ]
      ],
      "transformers/src/transformers/models/bit/convert_bit_to_pytorch.py": [
        [
          "prepare_img",
          76,
          79,
          78,
          21,
          78,
          50,
          77,
          11,
          79,
          13
        ]
      ],
      "transformers/src/transformers/models/blip/convert_blip_original_pytorch_to_hf.py": [
        [
          "load_demo_image",
          39,
          51,
          41,
          28,
          41,
          61,
          39,
          21,
          51,
          16
        ]
      ],
      "transformers/src/transformers/models/blip_2/convert_blip_2_original_to_pytorch.py": [
        [
          "load_demo_image",
          49,
          53,
          51,
          24,
          51,
          53,
          50,
          11,
          53,
          16
        ]
      ],
      "transformers/src/transformers/models/clipseg/convert_clipseg_original_pytorch_to_hf.py": [
        [
          "prepare_img",
          161,
          164,
          163,
          24,
          163,
          53,
          162,
          11,
          164,
          16
        ]
      ],
      "transformers/src/transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          214,
          218,
          216,
          21,
          216,
          50,
          215,
          11,
          218,
          13
        ]
      ],
      "transformers/src/transformers/models/chameleon/convert_chameleon_weights_to_hf.py": [
        [
          "write_model",
          84,
          436,
          409,
          9,
          411,
          9,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          425,
          9,
          425,
          108,
          357,
          13,
          436,
          58
        ],
        [
          "write_model",
          84,
          436,
          428,
          9,
          428,
          103,
          357,
          13,
          436,
          58
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_convnext_upernet_to_pytorch.py": [
        [
          "convert_upernet_checkpoint",
          121,
          193,
          152,
          24,
          152,
          53,
          148,
          5,
          160,
          44
        ]
      ],
      "transformers/src/transformers/models/convnext/convert_convnext_to_pytorch.py": [
        [
          "prepare_img",
          114,
          117,
          116,
          21,
          116,
          50,
          115,
          11,
          117,
          13
        ]
      ],
      "transformers/src/transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": [
        [
          "prepare_img",
          117,
          120,
          119,
          21,
          119,
          50,
          118,
          11,
          120,
          13
        ]
      ],
      "transformers/src/transformers/models/deit/convert_deit_timm_to_pytorch.py": [
        [
          "prepare_img",
          124,
          127,
          126,
          21,
          126,
          50,
          125,
          11,
          127,
          13
        ]
      ],
      "transformers/src/transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": [
        [
          "prepare_img",
          79,
          83,
          81,
          21,
          81,
          50,
          80,
          11,
          83,
          13
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "prepare_img",
          381,
          385,
          383,
          21,
          383,
          50,
          382,
          11,
          385,
          13
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          171,
          175,
          173,
          21,
          173,
          50,
          172,
          11,
          175,
          13
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_depth_anything_to_hf.py": [
        [
          "prepare_img",
          177,
          180,
          179,
          21,
          179,
          50,
          178,
          11,
          180,
          13
        ],
        [
          "convert_dpt_checkpoint",
          201,
          336,
          257,
          24,
          257,
          53,
          238,
          5,
          270,
          20
        ]
      ],
      "transformers/src/transformers/models/detr/convert_detr_to_pytorch.py": [
        [
          "prepare_img",
          280,
          284,
          282,
          21,
          282,
          50,
          281,
          11,
          284,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": [
        [
          "prepare_img",
          209,
          213,
          211,
          21,
          211,
          50,
          210,
          11,
          213,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": [
        [
          "prepare_img",
          208,
          212,
          210,
          21,
          210,
          50,
          209,
          11,
          212,
          13
        ]
      ],
      "transformers/src/transformers/models/vit/convert_dino_to_pytorch.py": [
        [
          "prepare_img",
          124,
          127,
          126,
          21,
          126,
          50,
          125,
          11,
          127,
          13
        ]
      ],
      "transformers/src/transformers/models/dinov2_with_registers/convert_dinov2_with_registers_to_hf.py": [
        [
          "prepare_img",
          145,
          148,
          147,
          24,
          147,
          53,
          146,
          11,
          148,
          16
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dinov2_depth_to_hf.py": [
        [
          "prepare_img",
          184,
          187,
          186,
          21,
          186,
          50,
          185,
          11,
          187,
          13
        ]
      ],
      "transformers/src/transformers/models/dinov2/convert_dinov2_to_hf.py": [
        [
          "prepare_img",
          139,
          142,
          141,
          24,
          141,
          53,
          140,
          11,
          142,
          16
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "prepare_img",
          85,
          88,
          87,
          24,
          87,
          53,
          86,
          11,
          88,
          16
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "prepare_img",
          134,
          136,
          136,
          23,
          136,
          52,
          135,
          11,
          136,
          57
        ],
        [
          "convert_dpt_checkpoint",
          147,
          215,
          172,
          24,
          172,
          53,
          147,
          28,
          183,
          20
        ]
      ],
      "transformers/src/transformers/models/dit/convert_dit_unilm_to_pytorch.py": [
        [
          "prepare_img",
          126,
          129,
          128,
          21,
          128,
          50,
          127,
          11,
          129,
          13
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "prepare_img",
          183,
          186,
          185,
          24,
          185,
          53,
          184,
          11,
          186,
          16
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_beit_to_hf.py": [
        [
          "prepare_img",
          167,
          170,
          169,
          21,
          169,
          50,
          168,
          11,
          170,
          13
        ],
        [
          "convert_dpt_checkpoint",
          174,
          279,
          226,
          24,
          226,
          53,
          204,
          5,
          247,
          41
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_to_pytorch.py": [
        [
          "prepare_img",
          181,
          184,
          183,
          21,
          183,
          50,
          182,
          11,
          184,
          13
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_swinv2_to_hf.py": [
        [
          "prepare_img",
          179,
          182,
          181,
          21,
          181,
          50,
          180,
          11,
          182,
          13
        ],
        [
          "convert_dpt_checkpoint",
          186,
          290,
          230,
          28,
          230,
          57,
          227,
          14,
          250,
          46
        ]
      ],
      "transformers/src/transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": [
        [
          "prepare_img",
          213,
          216,
          215,
          21,
          215,
          50,
          214,
          11,
          216,
          13
        ]
      ],
      "transformers/src/transformers/models/edgetam_video/convert_edgetam_video_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          235,
          278,
          256,
          32,
          256,
          65,
          255,
          19,
          269,
          95
        ]
      ],
      "transformers/src/transformers/models/edgetam/convert_edgetam_to_hf.py": [
        [
          "convert_edgetam_checkpoint",
          192,
          238,
          216,
          32,
          216,
          65,
          215,
          19,
          229,
          95
        ]
      ],
      "transformers/src/transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          116,
          120,
          118,
          24,
          118,
          53,
          117,
          11,
          120,
          16
        ]
      ],
      "transformers/src/transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": [
        [
          "prepare_img",
          143,
          146,
          145,
          21,
          145,
          50,
          144,
          11,
          146,
          13
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_model",
          255,
          408,
          337,
          13,
          339,
          13,
          314,
          9,
          348,
          24
        ]
      ],
      "transformers/src/transformers/models/focalnet/convert_focalnet_to_hf_format.py": [
        [
          "convert_focalnet_checkpoint",
          123,
          215,
          168,
          24,
          168,
          53,
          148,
          14,
          183,
          80
        ]
      ],
      "transformers/src/transformers/models/glpn/convert_glpn_to_pytorch.py": [
        [
          "prepare_img",
          117,
          121,
          119,
          24,
          119,
          53,
          118,
          11,
          121,
          16
        ]
      ],
      "transformers/src/transformers/models/git/convert_git_to_pytorch.py": [
        [
          "prepare_img",
          185,
          193,
          191,
          28,
          191,
          57,
          190,
          15,
          191,
          13
        ]
      ],
      "transformers/src/transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py": [
        [
          "prepare_img",
          150,
          153,
          152,
          21,
          152,
          50,
          151,
          11,
          153,
          13
        ]
      ],
      "transformers/src/transformers/models/grounding_dino/convert_grounding_dino_to_hf.py": [
        [
          "prepare_img",
          381,
          384,
          383,
          24,
          383,
          53,
          382,
          11,
          384,
          16
        ]
      ],
      "transformers/src/transformers/models/hiera/convert_hiera_to_hf.py": [
        [
          "prepare_img",
          152,
          155,
          154,
          21,
          154,
          50,
          153,
          11,
          155,
          13
        ]
      ],
      "transformers/src/transformers/models/instructblip/convert_instructblip_original_to_pytorch.py": [
        [
          "load_demo_image",
          49,
          53,
          51,
          24,
          51,
          53,
          50,
          11,
          53,
          16
        ]
      ],
      "transformers/src/transformers/models/instructblipvideo/convert_instructblipvideo_original_to_pytorch.py": [
        [
          "load_demo_image",
          49,
          53,
          51,
          24,
          51,
          53,
          50,
          11,
          53,
          16
        ]
      ],
      "transformers/src/transformers/models/ijepa/convert_ijepa_to_hf.py": [
        [
          "prepare_img",
          119,
          122,
          121,
          21,
          121,
          50,
          120,
          11,
          122,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "convert_openai_checkpoint",
          213,
          260,
          219,
          17,
          219,
          69,
          219,
          17,
          221,
          92
        ]
      ],
      "transformers/src/transformers/models/llava_next/convert_llava_next_weights_to_hf.py": [
        [
          "convert_llava_to_hf",
          95,
          366,
          334,
          29,
          334,
          58,
          328,
          5,
          343,
          30
        ],
        [
          "load_image",
          89,
          92,
          91,
          24,
          91,
          53,
          90,
          11,
          92,
          16
        ]
      ],
      "transformers/src/transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": [
        [
          "load_image",
          92,
          95,
          94,
          24,
          94,
          53,
          93,
          11,
          95,
          16
        ],
        [
          "convert_llava_to_hf",
          98,
          357,
          325,
          29,
          325,
          58,
          319,
          5,
          334,
          30
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          84,
          88,
          86,
          16,
          86,
          45,
          85,
          11,
          88,
          13
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": [
        [
          "prepare_img",
          223,
          226,
          225,
          21,
          225,
          50,
          224,
          11,
          226,
          13
        ]
      ],
      "transformers/src/transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": [
        [
          "prepare_img",
          254,
          257,
          256,
          21,
          256,
          50,
          255,
          11,
          257,
          13
        ]
      ],
      "transformers/src/transformers/models/mask2former/convert_mask2former_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          88,
          92,
          90,
          16,
          90,
          45,
          89,
          11,
          92,
          13
        ]
      ],
      "transformers/src/transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": [
        [
          "prepare_img",
          227,
          231,
          230,
          21,
          230,
          50,
          228,
          11,
          231,
          13
        ]
      ],
      "transformers/src/transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": [
        [
          "prepare_img",
          188,
          191,
          190,
          21,
          190,
          50,
          189,
          11,
          191,
          13
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_mlcd_checkpoint",
          236,
          301,
          284,
          28,
          284,
          57,
          282,
          9,
          288,
          109
        ]
      ],
      "transformers/src/transformers/models/vit_msn/convert_msn_to_pytorch.py": [
        [
          "convert_vit_msn_checkpoint",
          148,
          228,
          197,
          24,
          197,
          53,
          190,
          5,
          210,
          30
        ]
      ],
      "transformers/src/transformers/models/mm_grounding_dino/convert_mm_grounding_dino_to_hf.py": [
        [
          "prepare_test_inputs",
          422,
          426,
          424,
          24,
          424,
          59,
          423,
          17,
          426,
          22
        ]
      ],
      "transformers/src/transformers/models/omdet_turbo/convert_omdet_turbo_to_hf.py": [
        [
          "run_test",
          237,
          255,
          240,
          24,
          240,
          53,
          237,
          14,
          254,
          69
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          168,
          171,
          170,
          21,
          170,
          50,
          169,
          11,
          171,
          13
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "prepare_img",
          246,
          249,
          248,
          21,
          248,
          50,
          247,
          11,
          249,
          13
        ]
      ],
      "transformers/src/transformers/models/ovis2/convert_ovis2_weights_to_hf.py": [
        [
          "main",
          309,
          400,
          384,
          24,
          384,
          53,
          365,
          9,
          400,
          26
        ]
      ],
      "transformers/src/transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": [
        [
          "prepare_img",
          47,
          51,
          50,
          21,
          50,
          50,
          49,
          11,
          51,
          13
        ]
      ],
      "transformers/src/transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": [
        [
          "prepare_img",
          85,
          89,
          87,
          24,
          87,
          53,
          86,
          11,
          89,
          16
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_dpt_checkpoint",
          155,
          254,
          207,
          24,
          207,
          53,
          192,
          13,
          225,
          20
        ],
        [
          "convert_dpt_checkpoint",
          155,
          254,
          212,
          31,
          212,
          73,
          192,
          13,
          225,
          20
        ]
      ],
      "transformers/src/transformers/models/pvt_v2/convert_pvt_v2_to_pytorch.py": [
        [
          "prepare_img",
          177,
          180,
          179,
          21,
          179,
          50,
          178,
          11,
          180,
          13
        ]
      ],
      "transformers/src/transformers/models/pvt/convert_pvt_to_pytorch.py": [
        [
          "prepare_img",
          143,
          146,
          145,
          21,
          145,
          50,
          144,
          11,
          146,
          13
        ]
      ],
      "transformers/src/transformers/models/sam/convert_sam_to_hf.py": [
        [
          "convert_sam_checkpoint",
          137,
          216,
          154,
          28,
          154,
          61,
          148,
          14,
          165,
          39
        ]
      ],
      "transformers/src/transformers/models/sam_hq/convert_samhq_to_hf.py": [
        [
          "convert_sam_hq_checkpoint",
          158,
          228,
          177,
          28,
          177,
          61,
          169,
          14,
          188,
          35
        ]
      ],
      "transformers/src/transformers/models/sam2/convert_sam2_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          218,
          280,
          241,
          28,
          241,
          61,
          240,
          15,
          254,
          40
        ]
      ],
      "transformers/src/transformers/models/sam2_video/convert_sam2_video_to_hf.py": [
        [
          "convert_sam2_checkpoint",
          227,
          286,
          247,
          28,
          247,
          61,
          239,
          14,
          260,
          40
        ]
      ],
      "transformers/src/transformers/models/seggpt/convert_seggpt_to_hf.py": [
        [
          "prepare_input",
          92,
          107,
          103,
          30,
          103,
          71,
          94,
          9,
          107,
          49
        ],
        [
          "prepare_input",
          92,
          107,
          104,
          31,
          104,
          73,
          94,
          9,
          107,
          49
        ],
        [
          "prepare_input",
          92,
          107,
          105,
          30,
          105,
          71,
          94,
          9,
          107,
          49
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "prepare_img",
          213,
          217,
          215,
          21,
          215,
          50,
          214,
          11,
          217,
          13
        ]
      ],
      "transformers/src/transformers/models/segformer/convert_segformer_original_to_pytorch.py": [
        [
          "prepare_img",
          112,
          116,
          114,
          24,
          114,
          53,
          113,
          11,
          116,
          16
        ]
      ],
      "transformers/src/transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": [
        [
          "prepare_img",
          539,
          543,
          541,
          21,
          541,
          50,
          540,
          11,
          543,
          13
        ]
      ],
      "transformers/src/transformers/models/siglip/convert_siglip_to_hf.py": [
        [
          "prepare_img",
          360,
          363,
          362,
          24,
          362,
          53,
          361,
          11,
          363,
          16
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          418,
          26,
          418,
          57,
          405,
          5,
          427,
          20
        ],
        [
          "convert_siglip_checkpoint",
          380,
          506,
          420,
          26,
          420,
          57,
          405,
          5,
          427,
          20
        ]
      ],
      "transformers/src/transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": [
        [
          "prepare_img",
          41,
          44,
          43,
          21,
          43,
          50,
          42,
          11,
          44,
          13
        ]
      ],
      "transformers/src/transformers/models/superpoint/convert_superpoint_to_pytorch.py": [
        [
          "prepare_imgs",
          81,
          86,
          83,
          22,
          83,
          51,
          82,
          11,
          86,
          21
        ],
        [
          "prepare_imgs",
          81,
          86,
          85,
          22,
          85,
          51,
          82,
          11,
          86,
          21
        ]
      ],
      "transformers/src/transformers/models/swin2sr/convert_swin2sr_original_to_pytorch.py": [
        [
          "convert_swin2sr_checkpoint",
          163,
          260,
          180,
          24,
          180,
          53,
          179,
          11,
          184,
          48
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_simmim_to_pytorch.py": [
        [
          "convert_swin_checkpoint",
          123,
          155,
          136,
          24,
          136,
          53,
          123,
          29,
          145,
          43
        ]
      ],
      "transformers/src/transformers/models/swin/convert_swin_timm_to_pytorch.py": [
        [
          "convert_swin_checkpoint",
          130,
          156,
          144,
          24,
          144,
          53,
          130,
          29,
          150,
          56
        ]
      ],
      "transformers/src/transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py": [
        [
          "convert_swinv2_checkpoint",
          170,
          202,
          184,
          24,
          184,
          53,
          170,
          31,
          190,
          56
        ]
      ],
      "transformers/src/transformers/models/upernet/convert_swin_upernet_to_pytorch.py": [
        [
          "convert_upernet_checkpoint",
          191,
          276,
          235,
          24,
          235,
          53,
          231,
          5,
          247,
          40
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "prepare_config",
          43,
          113,
          44,
          30,
          44,
          58,
          43,
          20,
          47,
          31
        ],
        [
          "convert_textnet_checkpoint",
          116,
          181,
          165,
          24,
          165,
          53,
          161,
          5,
          172,
          87
        ]
      ],
      "transformers/src/transformers/models/trocr/convert_trocr_unilm_to_pytorch.py": [
        [
          "prepare_img",
          109,
          119,
          118,
          21,
          118,
          50,
          118,
          10,
          119,
          13
        ]
      ],
      "transformers/src/transformers/models/vilt/convert_vilt_original_to_pytorch.py": [
        [
          "convert_vilt_checkpoint",
          168,
          282,
          231,
          29,
          231,
          103,
          231,
          18,
          239,
          15
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          232,
          29,
          232,
          103,
          231,
          18,
          239,
          15
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          245,
          28,
          245,
          110,
          210,
          5,
          266,
          79
        ],
        [
          "convert_vilt_checkpoint",
          168,
          282,
          245,
          28,
          245,
          110,
          245,
          17,
          251,
          15
        ]
      ],
      "transformers/src/transformers/models/oneformer/convert_to_hf_oneformer.py": [
        [
          "prepare_img",
          94,
          98,
          96,
          16,
          96,
          45,
          95,
          11,
          98,
          13
        ]
      ],
      "transformers/src/transformers/models/vitmatte/convert_vitmatte_to_hf.py": [
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          115,
          24,
          115,
          53,
          106,
          17,
          124,
          52
        ],
        [
          "convert_vitmatte_checkpoint",
          72,
          144,
          117,
          25,
          117,
          54,
          106,
          17,
          124,
          52
        ]
      ],
      "transformers/src/transformers/models/vit_mae/convert_vit_mae_to_pytorch.py": [
        [
          "convert_vit_mae_checkpoint",
          105,
          161,
          132,
          24,
          132,
          53,
          108,
          30,
          141,
          32
        ],
        [
          "convert_vit_mae_checkpoint",
          105,
          161,
          132,
          24,
          132,
          53,
          119,
          13,
          141,
          32
        ]
      ],
      "transformers/src/transformers/models/vivit/convert_vivit_flax_to_pytorch.py": [
        [
          "download_checkpoint",
          34,
          40,
          38,
          14,
          38,
          43,
          34,
          25,
          39,
          58
        ]
      ],
      "transformers/src/transformers/models/vit/convert_vit_timm_to_pytorch.py": [
        [
          "prepare_img",
          124,
          127,
          126,
          21,
          126,
          50,
          125,
          11,
          127,
          13
        ]
      ],
      "transformers/src/transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": [
        [
          "prepare_img",
          158,
          161,
          160,
          21,
          160,
          50,
          159,
          11,
          161,
          13
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "prepare_img",
          183,
          186,
          185,
          24,
          185,
          53,
          184,
          11,
          186,
          16
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_to_hf.py": [
        [
          "prepare_img",
          198,
          201,
          200,
          24,
          200,
          53,
          199,
          11,
          201,
          16
        ]
      ],
      "transformers/src/transformers/models/yolos/convert_yolos_to_pytorch.py": [
        [
          "prepare_img",
          150,
          153,
          152,
          21,
          152,
          50,
          151,
          11,
          153,
          13
        ]
      ],
      "transformers/utils/deprecate_models.py": [
        [
          "get_last_stable_minor_release",
          29,
          42,
          32,
          20,
          32,
          36,
          31,
          11,
          42,
          30
        ]
      ],
      "transformers/utils/get_github_job_time.py": [
        [
          "get_job_time",
          29,
          52,
          37,
          14,
          37,
          47,
          36,
          11,
          41,
          23
        ],
        [
          "get_job_time",
          29,
          52,
          45,
          22,
          45,
          74,
          45,
          67,
          45,
          74
        ]
      ],
      "transformers/utils/get_ci_error_statistics.py": [
        [
          "get_jobs",
          13,
          36,
          21,
          14,
          21,
          47,
          20,
          11,
          25,
          19
        ],
        [
          "get_jobs",
          13,
          36,
          29,
          22,
          29,
          74,
          29,
          67,
          29,
          74
        ],
        [
          "get_job_links",
          39,
          62,
          47,
          14,
          47,
          47,
          46,
          11,
          51,
          24
        ],
        [
          "get_job_links",
          39,
          62,
          55,
          22,
          55,
          74,
          55,
          67,
          55,
          74
        ],
        [
          "get_artifacts_links",
          65,
          90,
          75,
          14,
          75,
          47,
          73,
          9,
          79,
          24
        ],
        [
          "get_artifacts_links",
          65,
          90,
          83,
          22,
          83,
          74,
          83,
          67,
          83,
          74
        ],
        [
          "download_artifact",
          93,
          109,
          104,
          14,
          104,
          79,
          104,
          14,
          109,
          34
        ],
        [
          "download_artifact",
          93,
          109,
          106,
          16,
          106,
          63,
          104,
          14,
          109,
          34
        ]
      ],
      "transformers/utils/get_previous_daily_ci.py": [
        [
          "get_daily_ci_runs",
          8,
          39,
          24,
          24,
          26,
          9,
          23,
          27,
          27,
          19
        ],
        [
          "get_daily_ci_runs",
          8,
          39,
          33,
          14,
          33,
          67,
          29,
          11,
          35,
          30
        ],
        [
          "get_daily_ci_runs",
          8,
          39,
          36,
          18,
          36,
          75,
          36,
          18,
          37,
          21
        ],
        [
          "get_last_daily_ci_run",
          42,
          65,
          50,
          24,
          52,
          9,
          50,
          24,
          53,
          27
        ]
      ],
      "transformers/tests/models/flava/test_image_processing_flava.py": [
        [
          "test_slow_fast_equivalence",
          402,
          425,
          410,
          13,
          410,
          95,
          409,
          23,
          425,
          9
        ]
      ],
      "transformers/tests/models/imagegpt/test_image_processing_imagegpt.py": [
        [
          "test_slow_fast_equivalence",
          272,
          289,
          280,
          13,
          280,
          95,
          279,
          23,
          289,
          9
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_image_processing_layoutlmv2.py": [
        [
          "test_slow_fast_equivalence",
          158,
          175,
          166,
          13,
          166,
          95,
          165,
          23,
          175,
          9
        ]
      ],
      "transformers/tests/models/aimv2/test_modeling_aimv2.py": [
        [
          "test_inference",
          482,
          508,
          487,
          28,
          487,
          110,
          482,
          24,
          508,
          99
        ],
        [
          "test_inference",
          515,
          543,
          521,
          28,
          521,
          110,
          515,
          24,
          543,
          81
        ],
        [
          "test_inference_for_native_resolution",
          546,
          574,
          552,
          28,
          552,
          110,
          546,
          46,
          574,
          81
        ]
      ],
      "transformers/tests/models/align/test_modeling_align.py": [
        [
          "prepare_img",
          585,
          588,
          587,
          21,
          587,
          50,
          586,
          11,
          588,
          13
        ]
      ],
      "transformers/tests/models/altclip/test_modeling_altclip.py": [
        [
          "prepare_img",
          404,
          407,
          406,
          21,
          406,
          50,
          405,
          11,
          407,
          13
        ]
      ],
      "transformers/tests/models/aria/test_modeling_aria.py": [
        [
          "test_batched_generation",
          425,
          491,
          439,
          29,
          439,
          59,
          425,
          33,
          491,
          54
        ],
        [
          "test_small_model_integration_test",
          241,
          274,
          249,
          32,
          249,
          75,
          241,
          43,
          274,
          57
        ],
        [
          "test_small_model_integration_test_llama_single",
          279,
          306,
          290,
          32,
          290,
          75,
          279,
          56,
          306,
          9
        ],
        [
          "test_small_model_integration_test_llama_batched",
          311,
          348,
          325,
          29,
          325,
          72,
          311,
          57,
          348,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched",
          311,
          348,
          326,
          29,
          326,
          111,
          311,
          57,
          348,
          63
        ],
        [
          "test_small_model_integration_test_batch",
          353,
          385,
          364,
          29,
          364,
          72,
          353,
          49,
          385,
          63
        ],
        [
          "test_small_model_integration_test_batch",
          353,
          385,
          365,
          29,
          365,
          111,
          353,
          49,
          385,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          390,
          419,
          405,
          29,
          405,
          72,
          390,
          68,
          419,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          390,
          419,
          406,
          29,
          406,
          111,
          390,
          68,
          419,
          63
        ],
        [
          "test_batched_generation",
          425,
          491,
          440,
          29,
          440,
          59,
          425,
          33,
          491,
          54
        ]
      ],
      "transformers/tests/models/blip/test_modeling_blip.py": [
        [
          "prepare_img",
          1232,
          1235,
          1234,
          21,
          1234,
          50,
          1233,
          11,
          1235,
          13
        ]
      ],
      "transformers/tests/models/blip_2/test_modeling_blip_2.py": [
        [
          "prepare_img",
          1497,
          1500,
          1499,
          24,
          1499,
          53,
          1498,
          11,
          1500,
          16
        ]
      ],
      "transformers/tests/models/chameleon/test_modeling_chameleon.py": [
        [
          "test_model_7b_batched",
          397,
          439,
          404,
          13,
          404,
          112,
          397,
          31,
          439,
          56
        ],
        [
          "test_model_7b",
          367,
          392,
          374,
          13,
          374,
          112,
          367,
          23,
          392,
          56
        ],
        [
          "test_model_7b_batched",
          397,
          439,
          407,
          13,
          407,
          107,
          397,
          31,
          439,
          56
        ],
        [
          "test_model_7b_multi_image",
          444,
          464,
          451,
          13,
          451,
          112,
          444,
          35,
          464,
          56
        ],
        [
          "test_model_7b_multi_image",
          444,
          464,
          454,
          13,
          454,
          107,
          444,
          35,
          464,
          56
        ]
      ],
      "transformers/tests/models/chinese_clip/test_modeling_chinese_clip.py": [
        [
          "prepare_img",
          653,
          656,
          655,
          21,
          655,
          50,
          654,
          11,
          656,
          13
        ]
      ],
      "transformers/tests/models/clipseg/test_modeling_clipseg.py": [
        [
          "prepare_img",
          609,
          612,
          611,
          24,
          611,
          53,
          610,
          11,
          612,
          16
        ]
      ],
      "transformers/tests/models/clip/test_modeling_clip.py": [
        [
          "prepare_img",
          741,
          744,
          743,
          21,
          743,
          50,
          742,
          11,
          744,
          13
        ]
      ],
      "transformers/tests/models/edgetam_video/test_modeling_edgetam_video.py": [
        [
          "prepare_image",
          41,
          44,
          43,
          28,
          43,
          61,
          42,
          15,
          44,
          20
        ],
        [
          "prepare_groceries_image",
          47,
          50,
          49,
          28,
          49,
          61,
          48,
          15,
          50,
          20
        ],
        [
          "prepare_dog_img",
          53,
          56,
          55,
          28,
          55,
          61,
          54,
          15,
          56,
          20
        ]
      ],
      "transformers/tests/models/edgetam/test_modeling_edgetam.py": [
        [
          "prepare_image",
          441,
          444,
          443,
          28,
          443,
          61,
          442,
          15,
          444,
          20
        ],
        [
          "prepare_groceries_image",
          447,
          450,
          449,
          28,
          449,
          61,
          448,
          15,
          450,
          20
        ],
        [
          "prepare_dog_img",
          453,
          456,
          455,
          28,
          455,
          61,
          454,
          15,
          456,
          20
        ]
      ],
      "transformers/tests/models/emu3/test_modeling_emu3.py": [
        [
          "test_model_generation",
          361,
          374,
          365,
          28,
          365,
          92,
          361,
          31,
          374,
          56
        ],
        [
          "test_model_generation_batched",
          379,
          417,
          384,
          28,
          384,
          90,
          379,
          39,
          417,
          56
        ],
        [
          "test_model_generation_batched",
          379,
          417,
          385,
          30,
          385,
          92,
          379,
          39,
          417,
          56
        ],
        [
          "test_model_generation_multi_image",
          422,
          444,
          426,
          28,
          426,
          90,
          422,
          43,
          444,
          56
        ],
        [
          "test_model_generation_multi_image",
          422,
          444,
          427,
          30,
          427,
          92,
          422,
          43,
          444,
          56
        ]
      ],
      "transformers/tests/models/eomt/test_modeling_eomt.py": [
        [
          "test_inference",
          242,
          280,
          246,
          28,
          246,
          110,
          242,
          24,
          280,
          86
        ],
        [
          "test_inference_fp16",
          285,
          297,
          289,
          28,
          289,
          110,
          285,
          29,
          297,
          81
        ],
        [
          "test_semantic_segmentation_inference",
          300,
          335,
          305,
          28,
          305,
          110,
          300,
          46,
          335,
          86
        ],
        [
          "test_panoptic_segmentation_inference",
          338,
          383,
          342,
          28,
          342,
          110,
          338,
          46,
          380,
          74
        ],
        [
          "test_instance_segmentation_inference",
          386,
          433,
          391,
          28,
          391,
          110,
          386,
          46,
          430,
          74
        ],
        [
          "test_segmentation_pipeline",
          436,
          445,
          437,
          28,
          437,
          110,
          436,
          36,
          445,
          63
        ]
      ],
      "transformers/tests/models/florence2/test_modeling_florence2.py": [
        [
          "setUp",
          259,
          271,
          261,
          13,
          264,
          13,
          259,
          15,
          266,
          19
        ],
        [
          "setUp",
          259,
          271,
          267,
          13,
          270,
          13,
          259,
          15,
          266,
          19
        ],
        [
          "prepare_img",
          250,
          253,
          252,
          24,
          252,
          53,
          251,
          11,
          253,
          16
        ]
      ],
      "transformers/tests/models/flava/test_modeling_flava.py": [
        [
          "prepare_img",
          1203,
          1206,
          1205,
          21,
          1205,
          50,
          1204,
          11,
          1206,
          13
        ]
      ],
      "transformers/tests/models/fuyu/test_modeling_fuyu.py": [
        [
          "test_greedy_generation",
          276,
          292,
          281,
          39,
          281,
          55,
          276,
          32,
          292,
          84
        ]
      ],
      "transformers/tests/models/groupvit/test_modeling_groupvit.py": [
        [
          "prepare_img",
          663,
          666,
          665,
          21,
          665,
          50,
          664,
          11,
          666,
          13
        ]
      ],
      "transformers/tests/models/idefics3/test_modeling_idefics3.py": [
        [
          "setUp",
          485,
          503,
          489,
          17,
          491,
          17,
          485,
          15,
          497,
          19
        ],
        [
          "setUp",
          485,
          503,
          495,
          21,
          495,
          104,
          485,
          15,
          497,
          19
        ],
        [
          "setUp",
          485,
          503,
          499,
          17,
          501,
          17,
          485,
          15,
          497,
          19
        ]
      ],
      "transformers/tests/models/idefics2/test_modeling_idefics2.py": [
        [
          "setUp",
          544,
          562,
          548,
          17,
          550,
          17,
          544,
          15,
          556,
          19
        ],
        [
          "setUp",
          544,
          562,
          554,
          21,
          554,
          104,
          544,
          15,
          556,
          19
        ],
        [
          "setUp",
          544,
          562,
          558,
          17,
          560,
          17,
          544,
          15,
          556,
          19
        ]
      ],
      "transformers/tests/models/internvl/test_modeling_internvl.py": [
        [
          "test_qwen2_small_model_integration_batched_generate",
          339,
          387,
          351,
          13,
          354,
          13,
          339,
          61,
          387,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate",
          718,
          766,
          730,
          13,
          733,
          13,
          718,
          61,
          766,
          9
        ],
        [
          "test_qwen2_small_model_integration_generate",
          231,
          250,
          237,
          28,
          237,
          57,
          231,
          53,
          250,
          57
        ],
        [
          "test_qwen2_small_model_integration_forward",
          252,
          284,
          258,
          28,
          258,
          57,
          252,
          52,
          284,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate",
          339,
          387,
          349,
          29,
          349,
          106,
          339,
          61,
          387,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate_multi_image",
          389,
          445,
          399,
          29,
          399,
          106,
          389,
          73,
          445,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate_multi_image",
          389,
          445,
          402,
          17,
          404,
          17,
          389,
          73,
          445,
          9
        ],
        [
          "test_qwen2_small_model_integration_batched_generate_multi_image",
          389,
          445,
          409,
          17,
          411,
          17,
          389,
          73,
          445,
          9
        ],
        [
          "test_llama_small_model_integration_generate",
          608,
          626,
          614,
          28,
          614,
          57,
          608,
          53,
          626,
          57
        ],
        [
          "test_llama_small_model_integration_forward",
          628,
          667,
          634,
          28,
          634,
          57,
          628,
          52,
          667,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate",
          718,
          766,
          728,
          29,
          728,
          106,
          718,
          61,
          766,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate_multi_image",
          768,
          818,
          778,
          29,
          778,
          106,
          768,
          73,
          818,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate_multi_image",
          768,
          818,
          781,
          17,
          783,
          17,
          768,
          73,
          818,
          9
        ],
        [
          "test_llama_small_model_integration_batched_generate_multi_image",
          768,
          818,
          788,
          17,
          790,
          17,
          768,
          73,
          818,
          9
        ]
      ],
      "transformers/tests/models/janus/test_modeling_janus.py": [
        [
          "test_model_text_generation",
          407,
          423,
          412,
          13,
          412,
          112,
          407,
          36,
          423,
          9
        ],
        [
          "test_model_text_generation_batched",
          426,
          451,
          431,
          13,
          431,
          112,
          426,
          44,
          451,
          56
        ],
        [
          "test_model_text_generation_batched",
          426,
          451,
          434,
          13,
          434,
          107,
          426,
          44,
          451,
          56
        ],
        [
          "test_model_text_generation_with_multi_image",
          454,
          473,
          459,
          13,
          459,
          112,
          454,
          53,
          473,
          56
        ],
        [
          "test_model_text_generation_with_multi_image",
          454,
          473,
          462,
          13,
          462,
          107,
          454,
          53,
          473,
          56
        ]
      ],
      "transformers/tests/models/instructblip/test_modeling_instructblip.py": [
        [
          "prepare_img",
          616,
          619,
          618,
          24,
          618,
          53,
          617,
          11,
          619,
          16
        ],
        [
          "test_inference_vicuna_7b",
          631,
          663,
          638,
          28,
          638,
          57,
          631,
          34,
          663,
          55
        ],
        [
          "test_inference_flant5_xl",
          665,
          698,
          673,
          28,
          673,
          57,
          665,
          34,
          677,
          34
        ]
      ],
      "transformers/tests/models/kosmos2_5/test_modeling_kosmos2_5.py": [
        [
          "test_eager",
          601,
          636,
          603,
          28,
          603,
          57,
          601,
          20,
          636,
          103
        ],
        [
          "test_sdpa",
          638,
          673,
          640,
          28,
          640,
          57,
          638,
          19,
          673,
          103
        ],
        [
          "test_FA2",
          679,
          707,
          681,
          28,
          681,
          57,
          679,
          18,
          707,
          55
        ]
      ],
      "transformers/tests/models/kosmos2/test_modeling_kosmos2.py": [
        [
          "prepare_img",
          619,
          622,
          621,
          21,
          621,
          50,
          620,
          11,
          622,
          13
        ],
        [
          "test_snowman_image_captioning",
          654,
          798,
          657,
          28,
          657,
          57,
          654,
          39,
          671,
          38
        ],
        [
          "test_snowman_image_captioning_batch",
          800,
          871,
          803,
          28,
          803,
          57,
          800,
          45,
          871,
          66
        ]
      ],
      "transformers/tests/models/lfm2_vl/test_modeling_lfm2_vl.py": [
        [
          "setUp",
          212,
          224,
          216,
          13,
          216,
          95,
          212,
          15,
          218,
          19
        ],
        [
          "setUp",
          212,
          224,
          220,
          17,
          222,
          17,
          212,
          15,
          218,
          19
        ]
      ],
      "transformers/tests/models/llava_onevision/test_modeling_llava_onevision.py": [
        [
          "test_small_model_integration_test_multi_image_nested",
          426,
          470,
          435,
          28,
          435,
          57,
          426,
          62,
          470,
          65
        ],
        [
          "test_small_model_integration_test_multi_image",
          392,
          422,
          401,
          28,
          401,
          57,
          392,
          55,
          422,
          60
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          498,
          524,
          505,
          33,
          505,
          62,
          498,
          71,
          524,
          9
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          498,
          524,
          506,
          33,
          506,
          69,
          498,
          71,
          524,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          528,
          558,
          537,
          33,
          537,
          62,
          528,
          64,
          558,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          528,
          558,
          538,
          33,
          538,
          69,
          528,
          64,
          558,
          9
        ]
      ],
      "transformers/tests/models/llava_next/test_modeling_llava_next.py": [
        [
          "setUp",
          317,
          322,
          320,
          33,
          320,
          62,
          317,
          15,
          322,
          19
        ],
        [
          "test_small_model_integration_test_batch",
          373,
          394,
          378,
          33,
          378,
          62,
          373,
          49,
          394,
          9
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          424,
          460,
          432,
          33,
          432,
          62,
          424,
          71,
          449,
          70
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          424,
          460,
          433,
          33,
          433,
          69,
          424,
          71,
          449,
          70
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          464,
          489,
          472,
          33,
          472,
          62,
          464,
          64,
          489,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          464,
          489,
          473,
          33,
          473,
          69,
          464,
          64,
          489,
          9
        ]
      ],
      "transformers/tests/models/llava/test_modeling_llava.py": [
        [
          "test_small_model_integration_test",
          292,
          311,
          298,
          32,
          298,
          68,
          292,
          43,
          311,
          9
        ],
        [
          "test_small_model_integration_test_llama_single",
          315,
          341,
          324,
          32,
          324,
          68,
          315,
          56,
          341,
          9
        ],
        [
          "test_small_model_integration_test_llama_batched",
          345,
          384,
          356,
          29,
          356,
          106,
          345,
          57,
          384,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched",
          345,
          384,
          357,
          29,
          357,
          111,
          345,
          57,
          384,
          63
        ],
        [
          "test_small_model_integration_test_batch",
          388,
          426,
          396,
          29,
          396,
          106,
          388,
          49,
          426,
          9
        ],
        [
          "test_small_model_integration_test_batch",
          388,
          426,
          397,
          29,
          397,
          111,
          388,
          49,
          426,
          9
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          430,
          474,
          444,
          29,
          444,
          106,
          430,
          68,
          474,
          63
        ],
        [
          "test_small_model_integration_test_llama_batched_regression",
          430,
          474,
          445,
          29,
          445,
          111,
          430,
          68,
          474,
          63
        ],
        [
          "test_batched_generation",
          480,
          525,
          490,
          29,
          490,
          59,
          480,
          33,
          525,
          50
        ],
        [
          "test_batched_generation",
          480,
          525,
          491,
          29,
          491,
          59,
          480,
          33,
          525,
          50
        ],
        [
          "test_generation_siglip_backbone",
          560,
          577,
          566,
          32,
          566,
          68,
          560,
          41,
          577,
          109
        ],
        [
          "test_pixtral",
          580,
          607,
          586,
          24,
          586,
          88,
          580,
          22,
          607,
          53
        ],
        [
          "test_pixtral",
          580,
          607,
          587,
          24,
          587,
          88,
          580,
          22,
          607,
          53
        ],
        [
          "test_pixtral_4bit",
          611,
          634,
          617,
          24,
          617,
          88,
          611,
          27,
          634,
          54
        ],
        [
          "test_pixtral_4bit",
          611,
          634,
          618,
          24,
          618,
          88,
          611,
          27,
          634,
          54
        ],
        [
          "test_pixtral_batched",
          638,
          673,
          645,
          24,
          645,
          88,
          638,
          30,
          673,
          53
        ],
        [
          "test_pixtral_batched",
          638,
          673,
          646,
          24,
          646,
          87,
          638,
          30,
          673,
          53
        ]
      ],
      "transformers/tests/models/mgp_str/test_modeling_mgp_str.py": [
        [
          "prepare_img",
          212,
          215,
          214,
          21,
          214,
          50,
          213,
          11,
          215,
          13
        ]
      ],
      "transformers/tests/models/metaclip_2/test_modeling_metaclip_2.py": [
        [
          "prepare_img",
          752,
          755,
          754,
          21,
          754,
          50,
          753,
          11,
          755,
          13
        ]
      ],
      "transformers/tests/models/mlcd/test_modeling_mlcd.py": [
        [
          "test_inference",
          148,
          206,
          155,
          28,
          155,
          57,
          148,
          24,
          206,
          9
        ]
      ],
      "transformers/tests/models/mllama/test_modeling_mllama.py": [
        [
          "test_11b_model_integration_batched_generate",
          678,
          738,
          688,
          13,
          691,
          13,
          678,
          53,
          738,
          9
        ],
        [
          "test_11b_model_integration_generate",
          539,
          585,
          545,
          28,
          545,
          57,
          539,
          45,
          585,
          9
        ],
        [
          "test_11b_model_integration_forward",
          637,
          672,
          643,
          28,
          643,
          57,
          637,
          44,
          672,
          9
        ],
        [
          "test_11b_model_integration_batched_generate",
          678,
          738,
          686,
          29,
          686,
          106,
          678,
          53,
          738,
          9
        ],
        [
          "test_11b_model_integration_multi_image_generate",
          744,
          803,
          748,
          29,
          748,
          106,
          744,
          57,
          803,
          9
        ],
        [
          "test_11b_model_integration_multi_image_generate",
          744,
          803,
          750,
          13,
          753,
          13,
          744,
          57,
          803,
          9
        ]
      ],
      "transformers/tests/models/ovis2/test_modeling_ovis2.py": [
        [
          "test_small_model_integration_test_multi_image",
          296,
          327,
          305,
          28,
          305,
          57,
          296,
          55,
          327,
          9
        ],
        [
          "setUp",
          234,
          250,
          239,
          33,
          239,
          62,
          234,
          15,
          250,
          17
        ],
        [
          "test_small_model_integration_test_batch_different_resolutions",
          329,
          354,
          335,
          33,
          335,
          69,
          329,
          71,
          354,
          9
        ],
        [
          "test_small_model_integration_test_batch_matches_single",
          356,
          383,
          364,
          33,
          364,
          69,
          356,
          64,
          383,
          9
        ]
      ],
      "transformers/tests/models/paligemma/test_modeling_paligemma.py": [
        [
          "test_small_model_integration_test_paligemma_batched",
          446,
          470,
          457,
          13,
          460,
          13,
          446,
          61,
          470,
          110
        ],
        [
          "test_small_model_integration_test_multiimage",
          370,
          405,
          376,
          13,
          379,
          13,
          370,
          54,
          405,
          9
        ],
        [
          "test_small_model_integration_test_paligemma_batched_f16",
          501,
          529,
          513,
          13,
          516,
          13,
          501,
          65,
          529,
          110
        ],
        [
          "test_small_model_integration_test",
          349,
          368,
          357,
          32,
          357,
          68,
          349,
          43,
          368,
          9
        ],
        [
          "test_small_model_integration_test_multiimage",
          370,
          405,
          382,
          13,
          384,
          13,
          370,
          54,
          405,
          9
        ],
        [
          "test_small_model_integration_test_paligemma_VQA",
          407,
          424,
          415,
          32,
          415,
          68,
          407,
          57,
          424,
          9
        ],
        [
          "test_small_model_integration_test_paligemma_empty_prompt",
          426,
          444,
          435,
          32,
          435,
          68,
          426,
          66,
          444,
          9
        ],
        [
          "test_small_model_integration_test_paligemma_batched_bf16",
          472,
          499,
          484,
          13,
          487,
          13,
          472,
          66,
          499,
          110
        ],
        [
          "test_integration_detection_bug",
          531,
          559,
          541,
          13,
          544,
          13,
          531,
          40,
          559,
          107
        ],
        [
          "test_paligemma_index_error_bug",
          561,
          582,
          574,
          32,
          574,
          68,
          561,
          40,
          582,
          9
        ],
        [
          "test_paligemma_finetuning_with_suffixes_bf16",
          584,
          624,
          598,
          13,
          601,
          13,
          584,
          54,
          615,
          61
        ]
      ],
      "transformers/tests/models/owlv2/test_modeling_owlv2.py": [
        [
          "prepare_img",
          746,
          749,
          748,
          21,
          748,
          50,
          747,
          11,
          749,
          13
        ]
      ],
      "transformers/tests/models/omdet_turbo/test_modeling_omdet_turbo.py": [
        [
          "prepare_img",
          619,
          622,
          621,
          24,
          621,
          53,
          620,
          11,
          622,
          16
        ],
        [
          "listcomp",
          636,
          636,
          636,
          32,
          636,
          48,
          636,
          79,
          636,
          73
        ]
      ],
      "transformers/tests/models/owlvit/test_modeling_owlvit.py": [
        [
          "prepare_img",
          739,
          742,
          741,
          21,
          741,
          50,
          740,
          11,
          742,
          13
        ]
      ],
      "transformers/tests/models/phi4_multimodal/test_modeling_phi4_multimodal.py": [
        [
          "setUp",
          282,
          295,
          290,
          33,
          290,
          73,
          282,
          15,
          295,
          46
        ],
        [
          "setUp",
          282,
          295,
          291,
          23,
          291,
          63,
          282,
          15,
          295,
          46
        ],
        [
          "test_multi_image_vision_text_generation",
          345,
          369,
          354,
          38,
          354,
          67,
          352,
          13,
          355,
          23
        ]
      ],
      "transformers/tests/models/prompt_depth_anything/test_modeling_prompt_depth_anything.py": [
        [
          "prepare_img",
          224,
          227,
          226,
          24,
          226,
          53,
          225,
          11,
          227,
          16
        ],
        [
          "prepare_prompt_depth",
          230,
          235,
          234,
          31,
          234,
          73,
          232,
          9,
          235,
          23
        ]
      ],
      "transformers/tests/models/pix2struct/test_modeling_pix2struct.py": [
        [
          "prepare_img",
          731,
          734,
          733,
          21,
          733,
          50,
          732,
          11,
          734,
          13
        ],
        [
          "test_batched_inference_image_captioning",
          755,
          777,
          763,
          30,
          763,
          66,
          755,
          49,
          777,
          9
        ],
        [
          "test_batched_inference_image_captioning_conditioned",
          779,
          803,
          785,
          30,
          785,
          66,
          779,
          61,
          803,
          9
        ],
        [
          "test_vqa_model",
          805,
          820,
          809,
          28,
          809,
          63,
          805,
          24,
          820,
          97
        ],
        [
          "listcomp",
          830,
          830,
          830,
          30,
          830,
          65,
          830,
          76,
          830,
          70
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py": [
        [
          "setUp",
          583,
          609,
          609,
          37,
          609,
          77,
          583,
          15,
          609,
          22
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py": [
        [
          "test_small_model_integration_test_with_video",
          688,
          733,
          708,
          21,
          708,
          43,
          688,
          54,
          712,
          18
        ]
      ],
      "transformers/tests/models/qwen2_vl/test_modeling_qwen2_vl.py": [
        [
          "setUp",
          391,
          403,
          403,
          33,
          403,
          62,
          391,
          15,
          403,
          18
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_modeling_qwen3_omni_moe.py": [
        [
          "setUp",
          621,
          645,
          645,
          37,
          645,
          77,
          621,
          15,
          645,
          22
        ]
      ]
    },
    "httpx.put": {
      "transformers/tests/utils/test_modeling_utils.py": [
        [
          "test_safetensors_on_the_fly_sharded_conversion_gated",
          2267,
          2288,
          2275,
          9,
          2277,
          9,
          2267,
          62,
          2281,
          87
        ]
      ]
    },
    "httpx.get": {
      "transformers/tests/pipelines/test_pipelines_image_segmentation.py": [
        [
          "listcomp",
          321,
          322,
          322,
          35,
          322,
          73,
          322,
          89,
          322,
          83
        ]
      ],
      "transformers/tests/pipelines/test_pipelines_image_to_text.py": [
        [
          "test_generation_pt_blip",
          172,
          178,
          175,
          39,
          175,
          75,
          172,
          33,
          178,
          116
        ],
        [
          "test_generation_pt_git",
          182,
          188,
          185,
          39,
          185,
          75,
          182,
          32,
          188,
          91
        ],
        [
          "test_conditional_generation_pt_blip",
          192,
          203,
          195,
          39,
          195,
          75,
          192,
          45,
          203,
          19
        ],
        [
          "test_conditional_generation_pt_git",
          207,
          218,
          210,
          39,
          210,
          75,
          207,
          44,
          218,
          19
        ],
        [
          "test_conditional_generation_pt_pix2struct",
          222,
          233,
          225,
          39,
          225,
          75,
          222,
          51,
          233,
          19
        ]
      ],
      "transformers/tests/commands/test_serving.py": [
        [
          "_call_healthcheck",
          507,
          517,
          512,
          24,
          512,
          54,
          512,
          24,
          512,
          54
        ]
      ],
      "transformers/src/transformers/pipelines/video_classification.py": [
        [
          "preprocess",
          140,
          158,
          145,
          29,
          145,
          67,
          145,
          21,
          145,
          17
        ]
      ],
      "transformers/src/transformers/video_utils.py": [
        [
          "load_video",
          618,
          714,
          688,
          28,
          688,
          66,
          688,
          20,
          688,
          16
        ]
      ],
      "transformers/src/transformers/pipelines/zero_shot_audio_classification.py": [
        [
          "preprocess",
          105,
          131,
          110,
          25,
          110,
          63,
          110,
          25,
          110,
          21
        ]
      ],
      "transformers/src/transformers/utils/attention_visualizer.py": [
        [
          "visualize_attention_mask",
          177,
          251,
          183,
          41,
          183,
          77,
          182,
          19,
          186,
          48
        ]
      ],
      "transformers/src/transformers/pipelines/audio_classification.py": [
        [
          "preprocess",
          166,
          239,
          171,
          26,
          171,
          65,
          171,
          26,
          171,
          22
        ]
      ],
      "transformers/src/transformers/audio_utils.py": [
        [
          "load_audio_librosa",
          115,
          140,
          136,
          21,
          136,
          76,
          135,
          17,
          135,
          13
        ],
        [
          "load_audio_as",
          143,
          219,
          179,
          24,
          179,
          79,
          179,
          34,
          179,
          79
        ]
      ],
      "transformers/src/transformers/pipelines/automatic_speech_recognition.py": [
        [
          "preprocess",
          353,
          494,
          358,
          26,
          358,
          65,
          358,
          26,
          358,
          22
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "define_sagemaker_information",
          198,
          221,
          200,
          25,
          200,
          75,
          200,
          25,
          200,
          75
        ]
      ],
      "transformers/src/transformers/image_utils.py": [
        [
          "load_image",
          444,
          483,
          462,
          44,
          462,
          99,
          462,
          21,
          462,
          17
        ]
      ],
      "transformers/tests/test_image_processing_common.py": [
        [
          "test_slow_fast_equivalence",
          180,
          197,
          189,
          17,
          189,
          106,
          187,
          23,
          197,
          106
        ]
      ],
      "transformers/tests/utils/test_image_utils.py": [
        [
          "get_image_from_hub_dataset",
          49,
          51,
          51,
          35,
          51,
          71,
          49,
          32,
          51,
          81
        ]
      ]
    },
    "httpx.Client": {
      "transformers/tests/commands/test_serving.py": [
        [
          "_open_stream_and_cancel",
          520,
          539,
          521,
          10,
          521,
          23,
          520,
          29,
          533,
          42
        ]
      ]
    },
    "cv2.VideoCapture": {
      "transformers/src/transformers/video_utils.py": [
        [
          "read_video_opencv",
          330,
          389,
          358,
          13,
          358,
          40,
          331,
          5,
          361,
          56
        ]
      ],
      "transformers/tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py": [
        [
          "test_small_model_integration_test_with_video",
          688,
          733,
          710,
          19,
          710,
          42,
          688,
          54,
          712,
          18
        ]
      ]
    },
    "urllib.parse.urlparse": {
      "transformers/src/transformers/video_utils.py": [
        [
          "load_video",
          618,
          714,
          675,
          8,
          675,
          22,
          675,
          8,
          675,
          67
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "is_remote_url",
          193,
          195,
          194,
          14,
          194,
          38,
          193,
          19,
          195,
          45
        ]
      ],
      "transformers/src/transformers/models/idefics/processing_idefics.py": [
        [
          "is_url",
          129,
          135,
          134,
          14,
          134,
          29,
          134,
          14,
          135,
          46
        ]
      ]
    },
    "wget.download": {
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "fetch_test_set",
          322,
          333,
          325,
          13,
          325,
          56,
          322,
          20,
          330,
          52
        ],
        [
          "download_and_unzip",
          652,
          660,
          658,
          16,
          658,
          33,
          654,
          16,
          660,
          23
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "download_lang_info",
          277,
          288,
          284,
          13,
          284,
          44,
          284,
          13,
          284,
          44
        ]
      ]
    },
    "urllib.request.urlopen": {
      "transformers/src/transformers/models/whisper/convert_openai_to_hf.py": [
        [
          "_download",
          147,
          182,
          164,
          10,
          164,
          36,
          164,
          10,
          167,
          17
        ]
      ],
      "transformers/tests/models/qwen2_5_omni/test_modeling_qwen2_5_omni.py": [
        [
          "setUp",
          583,
          609,
          604,
          21,
          604,
          43,
          583,
          15,
          609,
          22
        ],
        [
          "setUp",
          583,
          609,
          607,
          21,
          607,
          54,
          583,
          15,
          609,
          22
        ],
        [
          "test_small_model_integration_test_w_audio",
          762,
          810,
          783,
          41,
          783,
          58,
          762,
          51,
          810,
          61
        ]
      ],
      "transformers/tests/models/qwen2_audio/test_modeling_qwen2_audio.py": [
        [
          "test_small_model_integration_test_single",
          207,
          249,
          224,
          45,
          224,
          56,
          207,
          50,
          249,
          9
        ],
        [
          "test_small_model_integration_test_batch",
          252,
          328,
          310,
          45,
          310,
          69,
          308,
          29,
          313,
          29
        ],
        [
          "test_small_model_integration_test_multiurn",
          331,
          389,
          371,
          41,
          371,
          65,
          369,
          25,
          374,
          25
        ]
      ],
      "transformers/tests/models/qwen3_omni_moe/test_modeling_qwen3_omni_moe.py": [
        [
          "setUp",
          621,
          645,
          640,
          21,
          640,
          43,
          621,
          15,
          645,
          22
        ],
        [
          "setUp",
          621,
          645,
          643,
          21,
          643,
          54,
          621,
          15,
          645,
          22
        ],
        [
          "test_small_model_integration_test_w_audio",
          798,
          846,
          819,
          41,
          819,
          58,
          798,
          51,
          846,
          61
        ]
      ]
    },
    "urllib.request.urlretrieve": {
      "transformers/utils/download_glue_data.py": [
        [
          "format_mrpc",
          57,
          106,
          70,
          9,
          70,
          61,
          66,
          9,
          70,
          61
        ],
        [
          "download_and_extract",
          47,
          54,
          50,
          5,
          50,
          58,
          47,
          26,
          54,
          25
        ],
        [
          "format_mrpc",
          57,
          106,
          69,
          9,
          69,
          63,
          66,
          9,
          70,
          61
        ],
        [
          "format_mrpc",
          57,
          106,
          75,
          5,
          75,
          88,
          75,
          5,
          79,
          25
        ],
        [
          "download_diagnostic",
          109,
          116,
          114,
          5,
          114,
          66,
          113,
          17,
          116,
          10
        ]
      ]
    },
    "aiohttp.ClientTimeout": {
      "transformers/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py": [
        [
          "main",
          406,
          804,
          464,
          59,
          464,
          94,
          456,
          9,
          466,
          45
        ]
      ]
    },
    "httpx.post": {
      "transformers/src/transformers/safetensors_conversion.py": [
        [
          "spawn_conversion",
          23,
          55,
          47,
          14,
          47,
          66,
          23,
          22,
          52,
          18
        ]
      ]
    },
    "httpx.stream": {
      "transformers/src/transformers/safetensors_conversion.py": [
        [
          "spawn_conversion",
          23,
          55,
          50,
          10,
          50,
          53,
          23,
          22,
          52,
          18
        ]
      ]
    }
  },
  "CWE-943": {},
  "CWE-1333": {
    "re.sub": {
      "transformers/tests/models/vision_encoder_decoder/test_modeling_vision_encoder_decoder.py": [
        [
          "test_inference_docvqa",
          1254,
          1315,
          1302,
          20,
          1302,
          58,
          1254,
          31,
          1315,
          9
        ],
        [
          "test_inference_cordv2",
          1318,
          1377,
          1365,
          20,
          1365,
          58,
          1318,
          31,
          1377,
          9
        ],
        [
          "test_inference_rvlcdip",
          1380,
          1438,
          1427,
          20,
          1427,
          58,
          1380,
          32,
          1438,
          9
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "clean_code",
          97,
          126,
          122,
          16,
          122,
          39,
          120,
          9,
          124,
          25
        ],
        [
          "keep_doc_examples_only",
          129,
          153,
          149,
          16,
          149,
          39,
          147,
          9,
          151,
          25
        ]
      ],
      "transformers/src/transformers/models/big_bird/tokenization_big_bird.py": [
        [
          "_decode",
          185,
          231,
          218,
          20,
          218,
          75,
          218,
          20,
          218,
          16
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "apply_print_resets",
          1587,
          1588,
          1588,
          12,
          1588,
          53,
          1587,
          24,
          1588,
          53
        ],
        [
          "summary_failures_short",
          2295,
          2306,
          2305,
          24,
          2305,
          106,
          2301,
          13,
          2306,
          33
        ],
        [
          "pytest_xdist_worker_id",
          2447,
          2454,
          2453,
          14,
          2453,
          56,
          2448,
          5,
          2454,
          22
        ],
        [
          "preprocess_string",
          2807,
          2833,
          2820,
          29,
          2820,
          107,
          2820,
          29,
          2820,
          25
        ]
      ],
      "transformers/src/transformers/models/flaubert/tokenization_flaubert.py": [
        [
          "replace_unicode_punct",
          66,
          106,
          71,
          12,
          71,
          38,
          66,
          27,
          106,
          15
        ],
        [
          "replace_unicode_punct",
          66,
          106,
          96,
          12,
          96,
          38,
          66,
          27,
          106,
          15
        ]
      ],
      "transformers/src/transformers/models/fsmt/tokenization_fsmt.py": [
        [
          "replace_unicode_punct",
          49,
          89,
          54,
          12,
          54,
          38,
          49,
          27,
          89,
          15
        ],
        [
          "replace_unicode_punct",
          49,
          89,
          79,
          12,
          79,
          38,
          49,
          27,
          89,
          15
        ]
      ],
      "transformers/src/transformers/models/herbert/tokenization_herbert.py": [
        [
          "replace_unicode_punct",
          48,
          88,
          53,
          12,
          53,
          38,
          48,
          27,
          88,
          15
        ],
        [
          "replace_unicode_punct",
          48,
          88,
          78,
          12,
          78,
          38,
          48,
          27,
          88,
          15
        ]
      ],
      "transformers/src/transformers/models/openai/tokenization_openai.py": [
        [
          "text_standardize",
          220,
          232,
          229,
          12,
          229,
          109,
          220,
          22,
          232,
          23
        ],
        [
          "text_standardize",
          220,
          232,
          230,
          12,
          230,
          44,
          220,
          22,
          232,
          23
        ],
        [
          "text_standardize",
          220,
          232,
          231,
          12,
          231,
          41,
          220,
          22,
          232,
          23
        ]
      ],
      "transformers/src/transformers/models/nougat/tokenization_nougat_fast.py": [
        [
          "markdown_compatible",
          56,
          95,
          71,
          12,
          71,
          106,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          73,
          12,
          73,
          106,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          75,
          12,
          80,
          5,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          85,
          12,
          85,
          74,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          87,
          12,
          91,
          5,
          56,
          25,
          95,
          15
        ],
        [
          "markdown_compatible",
          56,
          95,
          93,
          12,
          93,
          79,
          56,
          25,
          95,
          15
        ],
        [
          "_clean",
          236,
          237,
          237,
          16,
          237,
          47,
          236,
          16,
          237,
          55
        ],
        [
          "remove_hallucinated_references",
          423,
          451,
          446,
          16,
          450,
          9,
          446,
          16,
          451,
          19
        ],
        [
          "correct_tables",
          453,
          486,
          480,
          22,
          480,
          100,
          476,
          22,
          486,
          25
        ],
        [
          "post_process_single",
          488,
          581,
          500,
          22,
          502,
          9,
          488,
          29,
          511,
          36
        ],
        [
          "post_process_single",
          488,
          581,
          508,
          22,
          508,
          108,
          488,
          29,
          511,
          36
        ],
        [
          "post_process_single",
          488,
          581,
          519,
          22,
          519,
          103,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          521,
          22,
          521,
          95,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          523,
          22,
          523,
          65,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          525,
          22,
          529,
          9,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          530,
          22,
          530,
          95,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          532,
          22,
          536,
          9,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          538,
          22,
          538,
          84,
          515,
          22,
          542,
          42
        ],
        [
          "post_process_single",
          488,
          581,
          565,
          22,
          569,
          9,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          571,
          22,
          571,
          76,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          573,
          22,
          573,
          84,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          575,
          22,
          575,
          75,
          561,
          22,
          578,
          23
        ],
        [
          "post_process_single",
          488,
          581,
          577,
          22,
          577,
          58,
          561,
          22,
          578,
          23
        ]
      ],
      "transformers/src/transformers/models/siglip/tokenization_siglip.py": [
        [
          "canonicalize_text",
          275,
          294,
          291,
          16,
          291,
          40,
          291,
          16,
          294,
          19
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "tokenize_numbers",
          68,
          91,
          88,
          20,
          88,
          50,
          86,
          9,
          89,
          34
        ],
        [
          "detokenize_numbers",
          94,
          112,
          111,
          16,
          111,
          37,
          110,
          9,
          111,
          12
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "_parse_date",
          2409,
          2423,
          2411,
          12,
          2411,
          41,
          2409,
          17,
          2412,
          59
        ],
        [
          "format_text",
          2469,
          2480,
          2475,
          12,
          2475,
          41,
          2475,
          12,
          2478,
          11
        ]
      ],
      "transformers/src/transformers/tokenization_utils.py": [
        [
          "tokenize",
          621,
          699,
          653,
          20,
          653,
          90,
          646,
          68,
          653,
          16
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "prepare_for_tokenization",
          142,
          205,
          200,
          29,
          200,
          62,
          192,
          29,
          200,
          25
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "_filter_timestamp_ids",
          308,
          309,
          309,
          16,
          309,
          56,
          308,
          31,
          309,
          56
        ]
      ],
      "transformers/src/transformers/models/xlm/tokenization_xlm.py": [
        [
          "replace_unicode_punct",
          66,
          106,
          71,
          12,
          71,
          38,
          66,
          27,
          106,
          15
        ],
        [
          "replace_unicode_punct",
          66,
          106,
          96,
          12,
          96,
          38,
          66,
          27,
          106,
          15
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "get_fast_image_processing_content_header",
          275,
          308,
          302,
          22,
          302,
          99,
          300,
          22,
          305,
          12
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "create_doc_file",
          217,
          270,
          231,
          30,
          231,
          58,
          217,
          21,
          262,
          32
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          93,
          26,
          93,
          75,
          86,
          21,
          95,
          47
        ]
      ],
      "transformers/src/transformers/utils/chat_template_utils.py": [
        [
          "dictcomp",
          230,
          230,
          230,
          32,
          230,
          74,
          230,
          80,
          230,
          74
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "stream_output",
          130,
          174,
          142,
          27,
          142,
          70,
          142,
          27,
          158,
          45
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "replace_code",
          463,
          485,
          480,
          20,
          480,
          43,
          479,
          34,
          481,
          45
        ],
        [
          "replace_code",
          463,
          485,
          482,
          24,
          482,
          63,
          482,
          24,
          483,
          20
        ],
        [
          "replace_code",
          463,
          485,
          483,
          24,
          483,
          63,
          482,
          24,
          483,
          20
        ]
      ],
      "transformers/src/transformers/models/aimv2/convert_aimv2_original_pytorch_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          111,
          124,
          120,
          28,
          120,
          56,
          120,
          28,
          121,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          111,
          124,
          122,
          24,
          122,
          61,
          122,
          24,
          122,
          20
        ]
      ],
      "transformers/src/transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "genexpr",
          150,
          150,
          150,
          16,
          150,
          36,
          150,
          16,
          150,
          39
        ],
        [
          "genexpr",
          150,
          150,
          150,
          68,
          150,
          90,
          150,
          68,
          150,
          93
        ]
      ],
      "transformers/src/transformers/models/blip/convert_blip_original_pytorch_to_hf.py": [
        [
          "rename_key",
          54,
          78,
          56,
          15,
          56,
          68,
          56,
          15,
          56,
          11
        ],
        [
          "rename_key",
          54,
          78,
          58,
          15,
          58,
          46,
          58,
          15,
          58,
          11
        ],
        [
          "rename_key",
          54,
          78,
          60,
          15,
          60,
          47,
          60,
          15,
          60,
          11
        ],
        [
          "rename_key",
          54,
          78,
          62,
          15,
          62,
          50,
          62,
          15,
          62,
          11
        ],
        [
          "rename_key",
          54,
          78,
          64,
          15,
          64,
          50,
          64,
          15,
          64,
          11
        ],
        [
          "rename_key",
          54,
          78,
          66,
          15,
          66,
          60,
          66,
          15,
          66,
          11
        ],
        [
          "rename_key",
          54,
          78,
          68,
          15,
          68,
          84,
          68,
          15,
          68,
          11
        ],
        [
          "rename_key",
          54,
          78,
          71,
          15,
          71,
          80,
          71,
          15,
          71,
          11
        ],
        [
          "rename_key",
          54,
          78,
          73,
          15,
          73,
          77,
          73,
          15,
          73,
          11
        ],
        [
          "rename_key",
          54,
          78,
          76,
          15,
          76,
          68,
          76,
          15,
          76,
          11
        ]
      ],
      "transformers/src/transformers/models/csm/convert_csm.py": [
        [
          "convert_key",
          73,
          76,
          75,
          15,
          75,
          47,
          74,
          9,
          75,
          11
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_old_keys_to_new_keys",
          91,
          106,
          102,
          28,
          102,
          56,
          102,
          28,
          103,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          91,
          106,
          104,
          24,
          104,
          61,
          104,
          24,
          104,
          20
        ]
      ],
      "transformers/src/transformers/models/d_fine/convert_d_fine_original_pytorch_checkpoint_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          323,
          331,
          327,
          23,
          327,
          62,
          326,
          13,
          328,
          29
        ]
      ],
      "transformers/src/transformers/models/dia/convert_dia_to_hf.py": [
        [
          "convert_dia_model_to_hf",
          78,
          155,
          127,
          14,
          127,
          37,
          127,
          14,
          127,
          78
        ],
        [
          "convert_dia_model_to_hf",
          78,
          155,
          117,
          23,
          117,
          51,
          117,
          23,
          117,
          19
        ],
        [
          "convert_dia_model_to_hf",
          78,
          155,
          130,
          23,
          130,
          73,
          130,
          23,
          130,
          19
        ]
      ],
      "transformers/src/transformers/models/dinov3_convnext/convert_dinov3_convnext_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          120,
          28,
          120,
          56,
          120,
          28,
          121,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          122,
          24,
          122,
          61,
          122,
          24,
          122,
          20
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "convert_key_pattern",
          98,
          105,
          104,
          20,
          104,
          52,
          104,
          20,
          104,
          52
        ]
      ],
      "transformers/src/transformers/models/dinov3_vit/convert_dinov3_vit_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          78,
          93,
          89,
          28,
          89,
          56,
          89,
          28,
          90,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          78,
          93,
          91,
          24,
          91,
          61,
          91,
          24,
          91,
          20
        ]
      ],
      "transformers/src/transformers/models/edgetam_video/convert_edgetam_video_to_hf.py": [
        [
          "replace_keys",
          110,
          232,
          144,
          23,
          144,
          55,
          144,
          23,
          144,
          19
        ]
      ],
      "transformers/src/transformers/models/efficientloftr/convert_efficientloftr_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          120,
          28,
          120,
          56,
          120,
          28,
          121,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          109,
          124,
          122,
          24,
          122,
          61,
          122,
          24,
          122,
          20
        ]
      ],
      "transformers/src/transformers/models/eomt/convert_eomt_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          72,
          81,
          77,
          32,
          77,
          64,
          77,
          32,
          77,
          28
        ],
        [
          "convert_old_keys_to_new_keys",
          72,
          81,
          79,
          32,
          79,
          66,
          79,
          32,
          79,
          28
        ]
      ],
      "transformers/src/transformers/models/emu3/convert_emu3_weights_to_hf.py": [
        [
          "convert_state_dict_to_hf",
          239,
          252,
          249,
          19,
          249,
          55,
          248,
          13,
          249,
          15
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "convert_espnet_state_dict_to_hf",
          104,
          151,
          134,
          27,
          134,
          63,
          132,
          21,
          134,
          23
        ]
      ],
      "transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "genexpr",
          81,
          81,
          81,
          16,
          81,
          36,
          81,
          16,
          81,
          39
        ],
        [
          "genexpr",
          81,
          81,
          81,
          68,
          81,
          90,
          81,
          68,
          81,
          93
        ],
        [
          "convert_fsmt_checkpoint_to_pytorch",
          90,
          260,
          158,
          14,
          158,
          58,
          156,
          10,
          168,
          35
        ]
      ],
      "transformers/src/transformers/models/ijepa/convert_ijepa_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          67,
          91,
          85,
          28,
          85,
          56,
          85,
          28,
          86,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          67,
          91,
          87,
          24,
          87,
          61,
          87,
          24,
          87,
          20
        ]
      ],
      "transformers/src/transformers/models/internvl/convert_internvl_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          160,
          24,
          160,
          61,
          159,
          13,
          160,
          20
        ],
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          166,
          28,
          166,
          65,
          165,
          17,
          166,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          169,
          28,
          169,
          65,
          168,
          17,
          169,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          150,
          183,
          180,
          24,
          180,
          61,
          179,
          13,
          180,
          20
        ]
      ],
      "transformers/src/transformers/models/janus/convert_janus_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          120,
          129,
          125,
          32,
          125,
          64,
          125,
          32,
          125,
          28
        ],
        [
          "convert_old_keys_to_new_keys",
          120,
          129,
          127,
          32,
          127,
          66,
          127,
          32,
          127,
          28
        ]
      ],
      "transformers/src/transformers/models/kyutai_speech_to_text/convert_kyutai_speech_to_text_to_hf.py": [
        [
          "convert_key",
          87,
          90,
          89,
          15,
          89,
          47,
          88,
          9,
          89,
          11
        ]
      ],
      "transformers/src/transformers/models/lightglue/convert_lightglue_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          92,
          107,
          103,
          28,
          103,
          56,
          103,
          28,
          104,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          92,
          107,
          105,
          24,
          105,
          61,
          105,
          24,
          105,
          20
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          94,
          109,
          105,
          28,
          105,
          56,
          105,
          28,
          106,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          94,
          109,
          107,
          24,
          107,
          61,
          107,
          24,
          107,
          20
        ],
        [
          "write_model",
          213,
          554,
          437,
          28,
          437,
          84,
          436,
          24,
          439,
          38
        ],
        [
          "write_model",
          213,
          554,
          438,
          26,
          438,
          80,
          436,
          24,
          439,
          38
        ]
      ],
      "transformers/src/transformers/models/bamba/convert_mamba_ssm_checkpoint.py": [
        [
          "convert_state_dict_from_mamba_ssm",
          34,
          83,
          50,
          13,
          50,
          63,
          37,
          9,
          56,
          25
        ],
        [
          "convert_state_dict_from_mamba_ssm",
          34,
          83,
          51,
          13,
          51,
          65,
          37,
          9,
          56,
          25
        ]
      ],
      "transformers/src/transformers/models/mlcd/convert_mlcd_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          212,
          227,
          223,
          28,
          223,
          56,
          223,
          28,
          224,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          212,
          227,
          225,
          24,
          225,
          61,
          225,
          24,
          225,
          20
        ]
      ],
      "transformers/src/transformers/models/mm_grounding_dino/convert_mm_grounding_dino_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          391,
          406,
          402,
          28,
          402,
          56,
          402,
          28,
          403,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          391,
          406,
          404,
          24,
          404,
          61,
          404,
          24,
          404,
          20
        ]
      ],
      "transformers/src/transformers/models/parakeet/convert_nemo_to_hf.py": [
        [
          "convert_key",
          51,
          54,
          53,
          15,
          53,
          47,
          52,
          9,
          53,
          11
        ]
      ],
      "transformers/src/transformers/models/ovis2/convert_ovis2_weights_to_hf.py": [
        [
          "convert_orig2hf",
          235,
          274,
          253,
          19,
          253,
          51,
          252,
          13,
          253,
          15
        ]
      ],
      "transformers/src/transformers/models/pix2struct/convert_pix2struct_original_pytorch_to_hf.py": [
        [
          "rename_and_convert_flax_params",
          40,
          102,
          85,
          27,
          85,
          71,
          85,
          27,
          86,
          23
        ],
        [
          "rename_and_convert_flax_params",
          40,
          102,
          90,
          27,
          90,
          71,
          90,
          27,
          90,
          23
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          134,
          151,
          148,
          35,
          148,
          71,
          148,
          35,
          148,
          31
        ]
      ],
      "transformers/src/transformers/models/regnet/convert_regnet_seer_10b_to_pytorch.py": [
        [
          "convert_weights_and_push",
          162,
          272,
          220,
          23,
          220,
          44,
          218,
          13,
          225,
          37
        ]
      ],
      "transformers/src/transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": [
        [
          "convert_state_dict",
          49,
          77,
          60,
          16,
          60,
          74,
          60,
          16,
          64,
          39
        ],
        [
          "convert_state_dict",
          49,
          77,
          62,
          16,
          62,
          77,
          60,
          16,
          64,
          39
        ]
      ],
      "transformers/src/transformers/models/rt_detr_v2/convert_rt_detr_v2_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          163,
          171,
          167,
          23,
          167,
          62,
          166,
          13,
          168,
          29
        ]
      ],
      "transformers/src/transformers/models/siglip2/convert_siglip2_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          265,
          280,
          276,
          28,
          276,
          56,
          276,
          28,
          277,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          265,
          280,
          278,
          24,
          278,
          61,
          278,
          24,
          278,
          20
        ]
      ],
      "transformers/src/transformers/models/superglue/convert_superglue_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          100,
          115,
          111,
          28,
          111,
          56,
          111,
          28,
          112,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          100,
          115,
          113,
          24,
          113,
          61,
          113,
          24,
          113,
          20
        ]
      ],
      "transformers/src/transformers/models/textnet/convert_textnet_to_hf.py": [
        [
          "convert_textnet_checkpoint",
          116,
          181,
          159,
          23,
          159,
          60,
          152,
          23,
          160,
          39
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": [
        [
          "rename_keys",
          197,
          247,
          205,
          23,
          205,
          73,
          205,
          23,
          205,
          19
        ],
        [
          "rename_keys",
          197,
          247,
          212,
          27,
          212,
          63,
          212,
          27,
          213,
          23
        ],
        [
          "rename_keys",
          197,
          247,
          213,
          27,
          213,
          85,
          212,
          27,
          213,
          23
        ],
        [
          "rename_keys",
          197,
          247,
          216,
          27,
          216,
          63,
          216,
          27,
          217,
          23
        ],
        [
          "rename_keys",
          197,
          247,
          217,
          27,
          217,
          85,
          216,
          27,
          217,
          23
        ]
      ],
      "transformers/src/transformers/models/moonshine/convert_usefulsensors_to_hf.py": [
        [
          "_convert_layer_names",
          56,
          92,
          88,
          12,
          88,
          45,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          57,
          12,
          62,
          5,
          56,
          26,
          63,
          16
        ],
        [
          "_convert_layer_names",
          56,
          92,
          64,
          16,
          64,
          71,
          64,
          16,
          65,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          65,
          16,
          65,
          73,
          64,
          16,
          65,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          67,
          16,
          67,
          91,
          67,
          16,
          68,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          68,
          16,
          68,
          93,
          67,
          16,
          68,
          12
        ],
        [
          "_convert_layer_names",
          56,
          92,
          69,
          12,
          69,
          74,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          70,
          12,
          70,
          76,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          71,
          12,
          71,
          76,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          72,
          12,
          72,
          91,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          73,
          12,
          73,
          72,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          74,
          12,
          74,
          74,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          75,
          12,
          75,
          74,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          76,
          12,
          76,
          75,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          77,
          12,
          77,
          80,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          78,
          12,
          78,
          82,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          79,
          12,
          79,
          82,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          80,
          12,
          80,
          83,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          81,
          12,
          81,
          79,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          82,
          12,
          82,
          81,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          83,
          12,
          83,
          81,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          84,
          12,
          84,
          82,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          85,
          12,
          85,
          69,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          86,
          12,
          86,
          80,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          87,
          12,
          87,
          71,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          89,
          12,
          89,
          43,
          69,
          12,
          92,
          15
        ],
        [
          "_convert_layer_names",
          56,
          92,
          90,
          12,
          90,
          72,
          69,
          12,
          92,
          15
        ]
      ],
      "transformers/src/transformers/models/vjepa2/convert_vjepa2_classifier_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          125,
          139,
          135,
          24,
          135,
          52,
          135,
          24,
          136,
          20
        ],
        [
          "convert_old_keys_to_new_keys",
          125,
          139,
          137,
          20,
          137,
          57,
          137,
          20,
          137,
          16
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          164,
          179,
          175,
          28,
          175,
          56,
          175,
          28,
          176,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          164,
          179,
          177,
          24,
          177,
          61,
          177,
          24,
          177,
          20
        ],
        [
          "write_model",
          190,
          396,
          233,
          23,
          233,
          107,
          232,
          30,
          243,
          51
        ],
        [
          "write_model",
          190,
          396,
          248,
          31,
          248,
          95,
          246,
          33,
          248,
          27
        ]
      ],
      "transformers/src/transformers/pipelines/document_question_answering.py": [
        [
          "postprocess_encoder_decoder_single",
          487,
          501,
          493,
          20,
          493,
          58,
          487,
          44,
          499,
          29
        ]
      ],
      "transformers/src/transformers/utils/doc.py": [
        [
          "_convert_output_args_doc",
          104,
          127,
          125,
          21,
          125,
          66,
          123,
          9,
          125,
          17
        ],
        [
          "_convert_output_args_doc",
          104,
          127,
          124,
          21,
          124,
          75,
          123,
          9,
          125,
          17
        ],
        [
          "filter_outputs_from_example",
          992,
          1003,
          1001,
          21,
          1001,
          75,
          1000,
          19,
          1001,
          17
        ]
      ],
      "transformers/src/transformers/integrations/fbgemm_fp8.py": [
        [
          "_replace_with_fbgemm_fp8_linear",
          157,
          231,
          210,
          29,
          210,
          90,
          209,
          22,
          214,
          51
        ]
      ],
      "transformers/src/transformers/models/whisper/english_normalizer.py": [
        [
          "__call__",
          573,
          597,
          595,
          13,
          595,
          34,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          573,
          597,
          584,
          13,
          584,
          44,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          82,
          93,
          84,
          13,
          84,
          47,
          82,
          18,
          88,
          29
        ],
        [
          "__call__",
          82,
          93,
          85,
          13,
          85,
          42,
          82,
          18,
          88,
          29
        ],
        [
          "__call__",
          82,
          93,
          91,
          13,
          91,
          34,
          91,
          13,
          93,
          16
        ],
        [
          "preprocess",
          436,
          463,
          457,
          13,
          457,
          50,
          454,
          13,
          463,
          16
        ],
        [
          "preprocess",
          436,
          463,
          458,
          13,
          458,
          50,
          454,
          13,
          463,
          16
        ],
        [
          "preprocess",
          436,
          463,
          461,
          13,
          461,
          62,
          454,
          13,
          463,
          16
        ],
        [
          "postprocess",
          465,
          488,
          482,
          13,
          482,
          81,
          465,
          21,
          488,
          16
        ],
        [
          "postprocess",
          465,
          488,
          483,
          13,
          483,
          62,
          465,
          21,
          488,
          16
        ],
        [
          "postprocess",
          465,
          488,
          486,
          13,
          486,
          45,
          465,
          21,
          488,
          16
        ],
        [
          "__call__",
          573,
          597,
          576,
          13,
          576,
          47,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          577,
          13,
          577,
          42,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          578,
          13,
          578,
          47,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          579,
          13,
          579,
          35,
          573,
          18,
          581,
          58
        ],
        [
          "__call__",
          573,
          597,
          582,
          17,
          582,
          47,
          581,
          13,
          582,
          13
        ],
        [
          "__call__",
          573,
          597,
          585,
          13,
          585,
          46,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          573,
          597,
          592,
          13,
          592,
          49,
          584,
          13,
          597,
          16
        ],
        [
          "__call__",
          573,
          597,
          593,
          13,
          593,
          43,
          584,
          13,
          597,
          16
        ]
      ],
      "transformers/src/transformers/utils/hp_naming.py": [
        [
          "parse_repr",
          138,
          162,
          151,
          23,
          151,
          49,
          151,
          23,
          152,
          19
        ],
        [
          "parse_repr",
          138,
          162,
          152,
          29,
          152,
          56,
          151,
          23,
          152,
          19
        ]
      ],
      "transformers/src/transformers/integrations/integration_utils.py": [
        [
          "dictcomp",
          1499,
          1499,
          1499,
          34,
          1499,
          73,
          1499,
          82,
          1499,
          76
        ]
      ],
      "transformers/src/transformers/modeling_gguf_pytorch_utils.py": [
        [
          "get_gguf_hf_weights_map",
          281,
          360,
          338,
          23,
          338,
          74,
          338,
          23,
          338,
          19
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "update_key_name",
          878,
          909,
          886,
          29,
          886,
          58,
          885,
          13,
          886,
          65
        ],
        [
          "update_key_name",
          878,
          909,
          887,
          26,
          887,
          55,
          887,
          17,
          887,
          70
        ],
        [
          "update_key_name",
          878,
          909,
          888,
          22,
          888,
          51,
          888,
          13,
          888,
          67
        ],
        [
          "update_key_name",
          878,
          909,
          892,
          16,
          892,
          45,
          891,
          9,
          895,
          49
        ],
        [
          "save_pretrained",
          3648,
          4088,
          3870,
          35,
          3870,
          68,
          3868,
          21,
          3873,
          36
        ],
        [
          "caching_allocator_warmup",
          5760,
          5840,
          5815,
          28,
          5815,
          64,
          5815,
          28,
          5816,
          105
        ]
      ],
      "transformers/src/transformers/models/florence2/modular_florence2.py": [
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          874,
          33,
          874,
          79,
          873,
          13,
          875,
          36
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_strip_source_for_tokens",
          161,
          173,
          172,
          12,
          172,
          35,
          161,
          30,
          173,
          102
        ],
        [
          "_sanitize_for_embedding",
          203,
          231,
          226,
          26,
          226,
          51,
          224,
          13,
          226,
          52
        ],
        [
          "_normalize",
          148,
          158,
          158,
          12,
          158,
          52,
          158,
          12,
          158,
          52
        ],
        [
          "_strip_source_for_tokens",
          161,
          173,
          171,
          12,
          171,
          56,
          161,
          30,
          173,
          102
        ],
        [
          "_sanitize_for_embedding",
          203,
          231,
          220,
          22,
          220,
          51,
          218,
          9,
          220,
          52
        ],
        [
          "_sanitize_for_embedding",
          203,
          231,
          230,
          21,
          230,
          87,
          229,
          9,
          230,
          17
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "update_body",
          256,
          298,
          290,
          33,
          290,
          73,
          287,
          13,
          291,
          48
        ],
        [
          "update_body",
          256,
          298,
          283,
          33,
          283,
          73,
          282,
          33,
          285,
          49
        ],
        [
          "leave_ImportFrom",
          144,
          158,
          154,
          26,
          156,
          13,
          152,
          24,
          157,
          24
        ],
        [
          "update_body",
          256,
          298,
          282,
          33,
          282,
          90,
          282,
          33,
          285,
          49
        ],
        [
          "update_body",
          256,
          298,
          289,
          33,
          289,
          56,
          287,
          13,
          291,
          48
        ],
        [
          "_fix_post_init_location",
          300,
          313,
          306,
          33,
          306,
          56,
          304,
          13,
          308,
          53
        ],
        [
          "_fix_post_init_location",
          300,
          313,
          307,
          33,
          307,
          73,
          304,
          13,
          308,
          53
        ],
        [
          "_fix_init_location",
          315,
          330,
          323,
          33,
          323,
          56,
          322,
          20,
          325,
          54
        ],
        [
          "_fix_init_location",
          315,
          330,
          324,
          33,
          324,
          73,
          322,
          20,
          325,
          54
        ]
      ],
      "transformers/src/transformers/utils/notebook.py": [
        [
          "on_evaluate",
          342,
          375,
          357,
          41,
          357,
          65,
          357,
          41,
          357,
          37
        ]
      ],
      "transformers/src/transformers/models/speecht5/number_normalizer.py": [
        [
          "__call__",
          178,
          192,
          186,
          16,
          186,
          88,
          178,
          18,
          192,
          29
        ],
        [
          "__call__",
          178,
          192,
          189,
          26,
          189,
          90,
          178,
          18,
          192,
          29
        ],
        [
          "__call__",
          178,
          192,
          190,
          26,
          190,
          58,
          178,
          18,
          192,
          29
        ]
      ],
      "transformers/src/transformers/models/clvp/number_normalizer.py": [
        [
          "normalize_numbers",
          204,
          215,
          209,
          16,
          209,
          72,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          210,
          16,
          210,
          61,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          211,
          16,
          211,
          71,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          212,
          16,
          212,
          77,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          213,
          16,
          213,
          74,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          214,
          16,
          214,
          59,
          204,
          27,
          215,
          19
        ],
        [
          "expand_abbreviations",
          217,
          223,
          222,
          20,
          222,
          51,
          221,
          13,
          222,
          16
        ],
        [
          "collapse_whitespace",
          225,
          229,
          229,
          16,
          229,
          52,
          225,
          29,
          229,
          52
        ]
      ],
      "transformers/src/transformers/models/florence2/processing_florence2.py": [
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          681,
          33,
          681,
          79,
          680,
          13,
          682,
          36
        ]
      ],
      "transformers/src/transformers/models/kosmos2/processing_kosmos2.py": [
        [
          "adjust_entity_positions",
          634,
          641,
          639,
          24,
          639,
          54,
          634,
          29,
          641,
          26
        ],
        [
          "adjust_entity_positions",
          634,
          641,
          638,
          26,
          638,
          58,
          634,
          29,
          641,
          26
        ],
        [
          "clean_text_and_extract_entities_with_bboxes",
          665,
          691,
          680,
          22,
          680,
          46,
          665,
          49,
          684,
          43
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/processing_phi4_multimodal.py": [
        [
          "listcomp",
          155,
          156,
          156,
          13,
          156,
          93,
          156,
          99,
          156,
          93
        ],
        [
          "listcomp",
          152,
          153,
          153,
          13,
          153,
          93,
          153,
          99,
          153,
          93
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py": [
        [
          "remove_special_characters",
          518,
          523,
          520,
          36,
          520,
          93,
          520,
          36,
          520,
          32
        ]
      ],
      "transformers/examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py": [
        [
          "remove_special_characters",
          495,
          500,
          497,
          36,
          497,
          93,
          497,
          36,
          497,
          32
        ]
      ],
      "transformers/examples/legacy/seq2seq/sentence_splitter.py": [
        [
          "add_newline_to_end_of_each_sentence",
          31,
          35,
          33,
          5,
          33,
          24,
          31,
          41,
          34,
          25
        ]
      ],
      "transformers/src/transformers/data/metrics/squad_metrics.py": [
        [
          "remove_articles",
          39,
          41,
          41,
          16,
          41,
          39,
          39,
          25,
          41,
          39
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "get_processor_inputs_from_inbound_messages",
          911,
          954,
          942,
          46,
          942,
          110,
          942,
          46,
          948,
          53
        ]
      ],
      "transformers/src/transformers/integrations/tensor_parallel.py": [
        [
          "_get_parameter_tp_plan",
          123,
          138,
          133,
          26,
          133,
          60,
          123,
          28,
          134,
          36
        ],
        [
          "setcomp",
          1069,
          1069,
          1069,
          21,
          1069,
          44,
          1069,
          50,
          1069,
          44
        ],
        [
          "verify_tp_plan",
          1061,
          1089,
          1075,
          30,
          1075,
          60,
          1074,
          22,
          1077,
          40
        ]
      ]
    },
    "re.escape": {
      "transformers/tests/peft_integration/test_peft_integration.py": [
        [
          "test_delete_adapter",
          366,
          428,
          407,
          23,
          407,
          83,
          374,
          17,
          428,
          61
        ]
      ],
      "transformers/tests/models/codegen/test_tokenization_codegen.py": [
        [
          "test_truncation",
          257,
          266,
          264,
          37,
          264,
          62,
          257,
          25,
          266,
          63
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "_process_date_pattern",
          2315,
          2326,
          2319,
          32,
          2319,
          45,
          2315,
          27,
          2322,
          45
        ],
        [
          "_process_date_pattern",
          2315,
          2326,
          2320,
          32,
          2320,
          45,
          2315,
          27,
          2322,
          45
        ]
      ],
      "transformers/src/transformers/tokenization_utils.py": [
        [
          "listcomp",
          646,
          646,
          646,
          37,
          646,
          52,
          646,
          58,
          646,
          52
        ],
        [
          "listcomp",
          647,
          648,
          648,
          17,
          648,
          40,
          648,
          17,
          648,
          40
        ]
      ],
      "transformers/.github/scripts/assign_reviewers.py": [
        [
          "pattern_to_regex",
          26,
          37,
          29,
          19,
          29,
          40,
          28,
          24,
          37,
          18
        ],
        [
          "pattern_to_regex",
          26,
          37,
          32,
          19,
          32,
          36,
          31,
          24,
          37,
          18
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "find_custom_args_with_details",
          1201,
          1232,
          1210,
          29,
          1210,
          59,
          1201,
          35,
          1227,
          12
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "listcomp",
          678,
          678,
          678,
          38,
          678,
          49,
          678,
          55,
          678,
          49
        ],
        [
          "listcomp",
          5790,
          5790,
          5790,
          30,
          5790,
          44,
          5790,
          50,
          5790,
          44
        ]
      ],
      "transformers/src/transformers/models/florence2/modular_florence2.py": [
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          864,
          43,
          864,
          70,
          864,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          864,
          74,
          864,
          103,
          864,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          864,
          107,
          864,
          134,
          864,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          866,
          46,
          866,
          73,
          866,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          866,
          77,
          866,
          106,
          866,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          866,
          110,
          866,
          137,
          866,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          869,
          37,
          869,
          66,
          864,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          869,
          37,
          869,
          66,
          866,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          869,
          74,
          869,
          101,
          864,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          869,
          74,
          869,
          101,
          866,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          870,
          46,
          870,
          73,
          864,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          870,
          46,
          870,
          73,
          866,
          23,
          873,
          34
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_sanitize_for_embedding",
          203,
          231,
          230,
          28,
          230,
          45,
          229,
          9,
          230,
          17
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "genexpr",
          61,
          61,
          61,
          30,
          61,
          43,
          61,
          49,
          61,
          43
        ]
      ],
      "transformers/src/transformers/models/qwen3_omni_moe/modular_qwen3_omni_moe.py": [
        [
          "listcomp",
          2612,
          2612,
          2612,
          31,
          2612,
          44,
          2612,
          50,
          2612,
          44
        ]
      ],
      "transformers/src/transformers/models/donut/processing_donut.py": [
        [
          "token2json",
          135,
          191,
          154,
          27,
          154,
          40,
          152,
          27,
          157,
          32
        ],
        [
          "token2json",
          135,
          191,
          162,
          37,
          162,
          56,
          160,
          29,
          166,
          38
        ],
        [
          "token2json",
          135,
          191,
          161,
          39,
          161,
          60,
          160,
          29,
          166,
          38
        ]
      ],
      "transformers/src/transformers/models/florence2/processing_florence2.py": [
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          671,
          43,
          671,
          70,
          671,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          671,
          74,
          671,
          103,
          671,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          671,
          107,
          671,
          134,
          671,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          673,
          46,
          673,
          73,
          673,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          673,
          77,
          673,
          106,
          673,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          673,
          110,
          673,
          137,
          673,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          676,
          37,
          676,
          66,
          671,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          676,
          37,
          676,
          66,
          673,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          676,
          74,
          676,
          101,
          671,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          676,
          74,
          676,
          101,
          673,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          677,
          46,
          677,
          73,
          671,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          677,
          46,
          677,
          73,
          673,
          23,
          680,
          34
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/processing_phi4_multimodal.py": [
        [
          "listcomp",
          152,
          153,
          153,
          20,
          153,
          41,
          153,
          99,
          153,
          93
        ],
        [
          "listcomp",
          155,
          156,
          156,
          20,
          156,
          41,
          156,
          99,
          156,
          93
        ]
      ],
      "transformers/src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py": [
        [
          "listcomp",
          232,
          232,
          232,
          31,
          232,
          44,
          232,
          50,
          232,
          44
        ]
      ],
      "transformers/src/transformers/models/qwen3_omni_moe/processing_qwen3_omni_moe.py": [
        [
          "listcomp",
          242,
          242,
          242,
          31,
          242,
          44,
          242,
          50,
          242,
          44
        ]
      ]
    },
    "re.split": {
      "transformers/tests/models/whisper/test_modeling_whisper.py": [
        [
          "test_whisper_longform_single_batch",
          2459,
          2493,
          2483,
          32,
          2483,
          85,
          2459,
          44,
          2493,
          38
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "preprocess_string",
          2807,
          2833,
          2816,
          18,
          2816,
          69,
          2807,
          23,
          2818,
          45
        ]
      ],
      "transformers/utils/compare_test_runs.py": [
        [
          "normalize_test_line",
          18,
          31,
          29,
          16,
          29,
          41,
          29,
          16,
          29,
          52
        ]
      ],
      "transformers/src/transformers/models/big_bird/convert_bigbird_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_big_bird",
          50,
          206,
          137,
          31,
          137,
          57,
          137,
          31,
          137,
          27
        ]
      ],
      "transformers/src/transformers/models/canine/convert_canine_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_canine",
          30,
          124,
          94,
          31,
          94,
          57,
          94,
          31,
          94,
          27
        ]
      ],
      "transformers/src/transformers/models/byt5/convert_byt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          75,
          31,
          75,
          57,
          75,
          31,
          75,
          27
        ]
      ],
      "transformers/src/transformers/models/electra/convert_electra_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_electra",
          30,
          109,
          78,
          35,
          78,
          61,
          78,
          44,
          78,
          61
        ]
      ],
      "transformers/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_gpt2",
          30,
          83,
          60,
          31,
          60,
          56,
          60,
          31,
          60,
          27
        ]
      ],
      "transformers/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": [
        [
          "load_tf_weights_in_gpt_neo",
          32,
          109,
          75,
          31,
          75,
          56,
          75,
          31,
          75,
          27
        ]
      ],
      "transformers/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py": [
        [
          "load_tf_weights_in_imagegpt",
          30,
          138,
          79,
          31,
          79,
          56,
          79,
          31,
          79,
          27
        ]
      ],
      "transformers/src/transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_lxmert",
          30,
          106,
          75,
          31,
          75,
          57,
          75,
          31,
          75,
          27
        ]
      ],
      "transformers/src/transformers/models/mobilebert/convert_mobilebert_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_mobilebert",
          28,
          103,
          70,
          31,
          70,
          57,
          70,
          31,
          70,
          27
        ]
      ],
      "transformers/src/transformers/models/myt5/convert_myt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          75,
          31,
          75,
          57,
          75,
          31,
          75,
          27
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          85,
          31,
          85,
          56,
          85,
          31,
          85,
          27
        ]
      ],
      "transformers/src/transformers/models/rembert/convert_rembert_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_rembert",
          30,
          110,
          78,
          31,
          78,
          57,
          78,
          31,
          78,
          27
        ]
      ],
      "transformers/src/transformers/models/roformer/convert_roformer_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_roformer",
          30,
          100,
          68,
          31,
          68,
          57,
          68,
          31,
          68,
          27
        ]
      ],
      "transformers/src/transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          75,
          31,
          75,
          57,
          75,
          31,
          75,
          27
        ]
      ],
      "transformers/src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_tapas",
          37,
          168,
          108,
          31,
          108,
          57,
          108,
          31,
          108,
          27
        ]
      ],
      "transformers/src/transformers/models/whisper/english_normalizer.py": [
        [
          "preprocess",
          436,
          463,
          440,
          20,
          440,
          53,
          436,
          20,
          441,
          45
        ]
      ],
      "transformers/src/transformers/models/esm/openfold_utils/protein.py": [
        [
          "from_proteinnet_string",
          72,
          119,
          74,
          47,
          74,
          78,
          72,
          28,
          81,
          19
        ]
      ]
    },
    "re.findall": {
      "transformers/tests/models/whisper/test_modeling_whisper.py": [
        [
          "test_whisper_longform_single_batch",
          2459,
          2493,
          2487,
          29,
          2487,
          84,
          2459,
          44,
          2493,
          38
        ]
      ],
      "transformers/tests/extended/test_trainer_ext.py": [
        [
          "test_trainer_log_level_replica",
          109,
          136,
          135,
          25,
          135,
          59,
          109,
          40,
          136,
          54
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "create_test_list_from_filter",
          1109,
          1121,
          1117,
          34,
          1117,
          68,
          1117,
          29,
          1117,
          25
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "_tokenize",
          296,
          305,
          302,
          17,
          302,
          43,
          301,
          24,
          303,
          26
        ]
      ],
      "transformers/src/transformers/models/phobert/tokenization_phobert.py": [
        [
          "_tokenize",
          275,
          283,
          279,
          17,
          279,
          43,
          275,
          19,
          281,
          26
        ]
      ],
      "transformers/src/transformers/utils/versions.py": [
        [
          "require_version",
          49,
          111,
          72,
          17,
          72,
          74,
          72,
          17,
          73,
          20
        ],
        [
          "require_version",
          49,
          111,
          82,
          21,
          82,
          58,
          81,
          13,
          83,
          24
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_paper_link",
          54,
          91,
          72,
          27,
          72,
          66,
          72,
          27,
          76,
          35
        ],
        [
          "get_paper_link",
          54,
          91,
          65,
          17,
          65,
          79,
          59,
          5,
          70,
          26
        ],
        [
          "get_paper_link",
          54,
          91,
          66,
          18,
          66,
          72,
          59,
          5,
          70,
          26
        ],
        [
          "get_paper_link",
          54,
          91,
          67,
          18,
          67,
          72,
          59,
          5,
          70,
          26
        ],
        [
          "replace_paper_links",
          139,
          177,
          152,
          19,
          152,
          75,
          139,
          25,
          155,
          31
        ],
        [
          "replace_paper_links",
          139,
          177,
          153,
          20,
          153,
          76,
          139,
          25,
          155,
          31
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_file",
          342,
          446,
          379,
          20,
          379,
          71,
          374,
          12,
          385,
          75
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          384,
          26,
          384,
          63,
          374,
          12,
          385,
          75
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          387,
          31,
          387,
          73,
          385,
          33,
          388,
          90
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          390,
          32,
          390,
          75,
          388,
          38,
          391,
          93
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          393,
          31,
          393,
          73,
          391,
          39,
          394,
          90
        ],
        [
          "add_fast_image_processor",
          449,
          507,
          470,
          28,
          470,
          86,
          466,
          10,
          471,
          31
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "add_model_to_auto_mappings",
          150,
          214,
          204,
          30,
          206,
          13,
          200,
          24,
          207,
          39
        ]
      ],
      "transformers/utils/check_bad_commit.py": [
        [
          "find_bad_commit",
          72,
          133,
          113,
          25,
          113,
          58,
          107,
          17,
          114,
          33
        ],
        [
          "find_bad_commit",
          72,
          133,
          124,
          15,
          124,
          48,
          123,
          15,
          127,
          23
        ]
      ],
      "transformers/utils/check_inits.py": [
        [
          "parse_init",
          92,
          232,
          124,
          23,
          124,
          58,
          123,
          23,
          125,
          30
        ],
        [
          "check_submodules",
          320,
          349,
          335,
          38,
          335,
          98,
          321,
          5,
          343,
          37
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "get_args_in_signature",
          994,
          1001,
          998,
          25,
          998,
          85,
          994,
          27,
          999,
          34
        ],
        [
          "get_args_in_dataclass",
          1004,
          1010,
          1007,
          25,
          1007,
          100,
          1004,
          27,
          1008,
          34
        ],
        [
          "update_file_with_new_docstrings",
          1235,
          1326,
          1252,
          17,
          1252,
          82,
          1250,
          28,
          1253,
          16
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "find_tested_models",
          602,
          650,
          618,
          18,
          618,
          82,
          602,
          24,
          621,
          26
        ],
        [
          "find_tested_models",
          602,
          650,
          620,
          19,
          620,
          78,
          602,
          24,
          621,
          26
        ],
        [
          "find_tested_models",
          602,
          650,
          631,
          28,
          631,
          73,
          631,
          28,
          642,
          9
        ],
        [
          "find_tested_models",
          602,
          650,
          643,
          28,
          643,
          75,
          637,
          13,
          644,
          27
        ],
        [
          "find_all_documented_objects",
          914,
          939,
          928,
          24,
          928,
          73,
          925,
          9,
          931,
          31
        ],
        [
          "find_all_documented_objects",
          914,
          939,
          932,
          34,
          932,
          92,
          931,
          13,
          934,
          43
        ],
        [
          "find_all_documented_objects",
          914,
          939,
          937,
          47,
          937,
          97,
          937,
          47,
          937,
          43
        ]
      ],
      "transformers/src/transformers/models/dac/convert_dac_checkpoint.py": [
        [
          "recursively_load_weights",
          143,
          187,
          160,
          32,
          160,
          59,
          160,
          32,
          161,
          46
        ],
        [
          "recursively_load_weights",
          143,
          187,
          166,
          32,
          166,
          59,
          166,
          32,
          167,
          30
        ]
      ],
      "transformers/src/transformers/dynamic_module_utils.py": [
        [
          "get_relative_imports",
          125,
          143,
          139,
          24,
          139,
          91,
          125,
          26,
          143,
          38
        ],
        [
          "get_relative_imports",
          125,
          143,
          141,
          25,
          141,
          95,
          125,
          26,
          143,
          38
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "update_key_name",
          878,
          909,
          884,
          22,
          884,
          48,
          883,
          9,
          885,
          41
        ],
        [
          "__init__",
          1971,
          2008,
          1991,
          25,
          1991,
          72,
          1990,
          27,
          1992,
          33
        ]
      ],
      "transformers/src/transformers/models/florence2/modular_florence2.py": [
        [
          "parse_ocr_from_text_and_spans",
          687,
          730,
          710,
          19,
          710,
          43,
          710,
          19,
          714,
          41
        ],
        [
          "parse_phrase_grounding_from_text_and_spans",
          732,
          771,
          749,
          19,
          749,
          50,
          733,
          9,
          754,
          34
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          776,
          827,
          802,
          19,
          802,
          43,
          799,
          23,
          808,
          34
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          776,
          827,
          802,
          19,
          802,
          43,
          801,
          23,
          808,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          867,
          19,
          867,
          43,
          864,
          23,
          873,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          867,
          19,
          867,
          43,
          866,
          23,
          873,
          34
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_tokenize",
          176,
          186,
          186,
          16,
          186,
          62,
          176,
          15,
          186,
          63
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "get_lowercase_name",
          92,
          98,
          98,
          45,
          98,
          83,
          98,
          16,
          98,
          85
        ],
        [
          "_replace_name",
          129,
          133,
          130,
          12,
          130,
          59,
          129,
          23,
          130,
          59
        ]
      ],
      "transformers/utils/notification_service.py": [
        [
          "payload",
          556,
          698,
          621,
          33,
          621,
          57,
          620,
          35,
          621,
          29
        ]
      ],
      "transformers/src/transformers/models/florence2/processing_florence2.py": [
        [
          "parse_ocr_from_text_and_spans",
          494,
          537,
          517,
          19,
          517,
          43,
          517,
          19,
          521,
          41
        ],
        [
          "parse_phrase_grounding_from_text_and_spans",
          539,
          578,
          556,
          19,
          556,
          50,
          540,
          9,
          561,
          34
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          583,
          634,
          609,
          19,
          609,
          43,
          606,
          23,
          615,
          34
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          583,
          634,
          609,
          19,
          609,
          43,
          608,
          23,
          615,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          674,
          19,
          674,
          43,
          671,
          23,
          680,
          34
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          674,
          19,
          674,
          43,
          673,
          23,
          680,
          34
        ]
      ],
      "transformers/utils/scan_skipped_tests.py": [
        [
          "get_common_tests",
          33,
          42,
          40,
          26,
          40,
          93,
          39,
          19,
          40,
          93
        ]
      ],
      "transformers/setup.py": [
        [
          "genexpr",
          197,
          197,
          197,
          27,
          197,
          75,
          197,
          84,
          197,
          78
        ]
      ]
    },
    "re.match": {
      "transformers/tests/test_pipeline_mixin.py": [
        [
          "listcomp",
          918,
          918,
          918,
          18,
          918,
          46,
          918,
          61,
          918,
          55
        ]
      ],
      "transformers/tests/models/byt5/test_tokenization_byt5.py": [
        [
          "lambda",
          62,
          62,
          62,
          38,
          62,
          68,
          62,
          35,
          62,
          68
        ]
      ],
      "transformers/tests/test_tokenization_common.py": [
        [
          "lambda",
          270,
          270,
          270,
          38,
          270,
          68,
          270,
          35,
          270,
          68
        ]
      ],
      "transformers/tests/models/layoutlmv3/test_tokenization_layoutlmv3.py": [
        [
          "lambda",
          1658,
          1658,
          1658,
          38,
          1658,
          68,
          1658,
          35,
          1658,
          68
        ]
      ],
      "transformers/tests/models/layoutlmv2/test_tokenization_layoutlmv2.py": [
        [
          "lambda",
          1768,
          1768,
          1768,
          38,
          1768,
          68,
          1768,
          35,
          1768,
          68
        ]
      ],
      "transformers/tests/models/perceiver/test_tokenization_perceiver.py": [
        [
          "lambda",
          63,
          63,
          63,
          38,
          63,
          68,
          63,
          35,
          63,
          68
        ]
      ],
      "transformers/tests/models/markuplm/test_tokenization_markuplm.py": [
        [
          "lambda",
          1553,
          1553,
          1553,
          38,
          1553,
          68,
          1553,
          35,
          1553,
          68
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "listcomp",
          630,
          630,
          630,
          63,
          630,
          94,
          630,
          63,
          630,
          94
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "listcomp",
          4087,
          4087,
          4087,
          23,
          4087,
          72,
          4087,
          91,
          4087,
          85
        ]
      ],
      "transformers/src/transformers/models/nougat/tokenization_nougat_fast.py": [
        [
          "normalize_list_like_lines",
          98,
          146,
          134,
          16,
          134,
          110,
          134,
          16,
          134,
          110
        ],
        [
          "post_process_single",
          488,
          581,
          544,
          12,
          544,
          48,
          544,
          12,
          544,
          48
        ]
      ],
      "transformers/src/transformers/utils/versions.py": [
        [
          "require_version",
          49,
          111,
          69,
          8,
          69,
          45,
          66,
          12,
          69,
          45
        ]
      ],
      "transformers/src/transformers/trainer.py": [
        [
          "_sorted_checkpoints",
          4183,
          4218,
          4194,
          31,
          4194,
          79,
          4194,
          31,
          4195,
          42
        ]
      ],
      "transformers/utils/compare_test_runs.py": [
        [
          "normalize_test_line",
          18,
          31,
          22,
          13,
          22,
          90,
          18,
          25,
          23,
          12
        ]
      ],
      "transformers/src/transformers/models/bert/convert_bert_original_tf2_checkpoint_to_pytorch.py": [
        [
          "load_tf2_weights_in_bert",
          43,
          210,
          196,
          12,
          196,
          87,
          195,
          17,
          196,
          87
        ],
        [
          "load_tf2_weights_in_bert",
          43,
          210,
          196,
          92,
          198,
          9,
          196,
          92,
          198,
          9
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "layer_name_mapping",
          50,
          67,
          65,
          24,
          65,
          57,
          65,
          20,
          67,
          37
        ]
      ],
      "transformers/src/transformers/models/clap/convert_clap_original_pytorch_to_hf.py": [
        [
          "rename_state_dict",
          61,
          101,
          73,
          12,
          73,
          51,
          73,
          12,
          73,
          51
        ],
        [
          "rename_state_dict",
          61,
          101,
          75,
          32,
          75,
          71,
          75,
          32,
          77,
          15
        ],
        [
          "rename_state_dict",
          61,
          101,
          78,
          14,
          78,
          51,
          78,
          14,
          78,
          51
        ],
        [
          "rename_state_dict",
          61,
          101,
          79,
          35,
          79,
          72,
          79,
          31,
          82,
          69
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "listcomp",
          111,
          111,
          111,
          55,
          111,
          78,
          111,
          23,
          111,
          78
        ],
        [
          "convert_keys",
          108,
          131,
          114,
          17,
          114,
          46,
          112,
          9,
          121,
          69
        ]
      ],
      "transformers/src/transformers/models/edgetam_video/convert_edgetam_video_to_hf.py": [
        [
          "replace_keys",
          110,
          232,
          143,
          16,
          143,
          37,
          142,
          13,
          143,
          37
        ],
        [
          "replace_keys",
          110,
          232,
          147,
          12,
          147,
          60,
          147,
          12,
          147,
          60
        ],
        [
          "replace_keys",
          110,
          232,
          148,
          28,
          148,
          76,
          148,
          24,
          149,
          28
        ],
        [
          "replace_keys",
          110,
          232,
          154,
          12,
          154,
          50,
          154,
          12,
          154,
          50
        ],
        [
          "replace_keys",
          110,
          232,
          159,
          12,
          159,
          58,
          159,
          12,
          159,
          58
        ],
        [
          "replace_keys",
          110,
          232,
          160,
          28,
          160,
          74,
          160,
          24,
          161,
          28
        ],
        [
          "replace_keys",
          110,
          232,
          167,
          12,
          167,
          64,
          167,
          12,
          167,
          64
        ],
        [
          "replace_keys",
          110,
          232,
          168,
          28,
          168,
          80,
          168,
          24,
          169,
          28
        ],
        [
          "replace_keys",
          110,
          232,
          176,
          12,
          176,
          59,
          176,
          12,
          176,
          59
        ],
        [
          "replace_keys",
          110,
          232,
          177,
          28,
          177,
          75,
          177,
          24,
          178,
          28
        ],
        [
          "replace_keys",
          110,
          232,
          186,
          12,
          186,
          60,
          186,
          12,
          186,
          60
        ],
        [
          "replace_keys",
          110,
          232,
          190,
          12,
          190,
          66,
          190,
          12,
          190,
          66
        ],
        [
          "replace_keys",
          110,
          232,
          193,
          12,
          193,
          60,
          193,
          12,
          193,
          60
        ],
        [
          "replace_keys",
          110,
          232,
          194,
          28,
          194,
          76,
          194,
          24,
          195,
          28
        ],
        [
          "replace_keys",
          110,
          232,
          204,
          12,
          204,
          72,
          204,
          12,
          204,
          72
        ],
        [
          "replace_keys",
          110,
          232,
          205,
          28,
          205,
          88,
          205,
          24,
          206,
          29
        ]
      ],
      "transformers/src/transformers/models/edgetam/convert_edgetam_to_hf.py": [
        [
          "replace_keys",
          111,
          189,
          127,
          28,
          127,
          76,
          127,
          24,
          128,
          28
        ],
        [
          "replace_keys",
          111,
          189,
          126,
          12,
          126,
          60,
          126,
          12,
          126,
          60
        ],
        [
          "replace_keys",
          111,
          189,
          134,
          12,
          134,
          58,
          134,
          12,
          134,
          58
        ],
        [
          "replace_keys",
          111,
          189,
          135,
          28,
          135,
          74,
          135,
          24,
          136,
          28
        ],
        [
          "replace_keys",
          111,
          189,
          142,
          12,
          142,
          64,
          142,
          12,
          142,
          64
        ],
        [
          "replace_keys",
          111,
          189,
          143,
          28,
          143,
          80,
          143,
          24,
          144,
          28
        ],
        [
          "replace_keys",
          111,
          189,
          151,
          12,
          151,
          59,
          151,
          12,
          151,
          59
        ],
        [
          "replace_keys",
          111,
          189,
          152,
          28,
          152,
          75,
          152,
          24,
          153,
          28
        ],
        [
          "replace_keys",
          111,
          189,
          161,
          12,
          161,
          60,
          161,
          12,
          161,
          60
        ],
        [
          "replace_keys",
          111,
          189,
          165,
          12,
          165,
          66,
          165,
          12,
          165,
          66
        ],
        [
          "replace_keys",
          111,
          189,
          168,
          12,
          168,
          60,
          168,
          12,
          168,
          60
        ],
        [
          "replace_keys",
          111,
          189,
          169,
          28,
          169,
          76,
          169,
          24,
          170,
          28
        ]
      ],
      "transformers/src/transformers/models/glm4v/convert_glm4v_mgt_weights_to_hf.py": [
        [
          "merge_tp_weights",
          250,
          625,
          254,
          21,
          254,
          59,
          254,
          21,
          255,
          20
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "listcomp",
          209,
          209,
          209,
          61,
          209,
          99,
          209,
          28,
          209,
          99
        ]
      ],
      "transformers/src/transformers/models/mm_grounding_dino/convert_mm_grounding_dino_to_hf.py": [
        [
          "preprocess_old_state",
          313,
          387,
          336,
          25,
          336,
          72,
          336,
          25,
          337,
          92
        ],
        [
          "preprocess_old_state",
          313,
          387,
          341,
          25,
          341,
          79,
          341,
          25,
          342,
          112
        ],
        [
          "preprocess_old_state",
          313,
          387,
          346,
          25,
          346,
          81,
          346,
          25,
          347,
          114
        ],
        [
          "preprocess_old_state",
          313,
          387,
          364,
          21,
          364,
          75,
          363,
          34,
          368,
          45
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v1_config",
          142,
          164,
          148,
          15,
          148,
          69,
          148,
          15,
          149,
          14
        ]
      ],
      "transformers/src/transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": [
        [
          "get_mobilenet_v2_config",
          209,
          242,
          215,
          15,
          215,
          71,
          215,
          15,
          216,
          14
        ]
      ],
      "transformers/src/transformers/models/prompt_depth_anything/convert_prompt_depth_anything_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          134,
          151,
          143,
          25,
          143,
          50,
          142,
          17,
          144,
          24
        ]
      ],
      "transformers/src/transformers/models/sam/convert_sam_to_hf.py": [
        [
          "replace_keys",
          107,
          134,
          119,
          12,
          119,
          59,
          119,
          12,
          119,
          59
        ],
        [
          "replace_keys",
          107,
          134,
          120,
          28,
          120,
          75,
          120,
          24,
          121,
          28
        ]
      ],
      "transformers/src/transformers/models/sam2/convert_sam2_to_hf.py": [
        [
          "replace_keys",
          137,
          215,
          154,
          12,
          154,
          60,
          154,
          12,
          154,
          60
        ],
        [
          "replace_keys",
          137,
          215,
          155,
          28,
          155,
          76,
          155,
          24,
          156,
          28
        ],
        [
          "replace_keys",
          137,
          215,
          162,
          12,
          162,
          58,
          162,
          12,
          162,
          58
        ],
        [
          "replace_keys",
          137,
          215,
          163,
          28,
          163,
          74,
          163,
          24,
          164,
          28
        ],
        [
          "replace_keys",
          137,
          215,
          170,
          12,
          170,
          64,
          170,
          12,
          170,
          64
        ],
        [
          "replace_keys",
          137,
          215,
          171,
          28,
          171,
          80,
          171,
          24,
          172,
          28
        ],
        [
          "replace_keys",
          137,
          215,
          179,
          12,
          179,
          59,
          179,
          12,
          179,
          59
        ],
        [
          "replace_keys",
          137,
          215,
          180,
          28,
          180,
          75,
          180,
          24,
          181,
          28
        ],
        [
          "replace_keys",
          137,
          215,
          189,
          12,
          189,
          60,
          189,
          12,
          189,
          60
        ],
        [
          "replace_keys",
          137,
          215,
          193,
          12,
          193,
          66,
          193,
          12,
          193,
          66
        ],
        [
          "replace_keys",
          137,
          215,
          196,
          12,
          196,
          60,
          196,
          12,
          196,
          60
        ],
        [
          "replace_keys",
          137,
          215,
          197,
          28,
          197,
          76,
          197,
          24,
          198,
          28
        ]
      ],
      "transformers/src/transformers/models/sam2_video/convert_sam2_video_to_hf.py": [
        [
          "replace_keys",
          138,
          224,
          155,
          12,
          155,
          60,
          155,
          12,
          155,
          60
        ],
        [
          "replace_keys",
          138,
          224,
          156,
          28,
          156,
          76,
          156,
          24,
          157,
          28
        ],
        [
          "replace_keys",
          138,
          224,
          163,
          12,
          163,
          58,
          163,
          12,
          163,
          58
        ],
        [
          "replace_keys",
          138,
          224,
          164,
          28,
          164,
          74,
          164,
          24,
          165,
          28
        ],
        [
          "replace_keys",
          138,
          224,
          171,
          12,
          171,
          64,
          171,
          12,
          171,
          64
        ],
        [
          "replace_keys",
          138,
          224,
          172,
          28,
          172,
          80,
          172,
          24,
          173,
          28
        ],
        [
          "replace_keys",
          138,
          224,
          180,
          12,
          180,
          59,
          180,
          12,
          180,
          59
        ],
        [
          "replace_keys",
          138,
          224,
          181,
          28,
          181,
          75,
          181,
          24,
          182,
          28
        ],
        [
          "replace_keys",
          138,
          224,
          190,
          12,
          190,
          60,
          190,
          12,
          190,
          60
        ],
        [
          "replace_keys",
          138,
          224,
          194,
          12,
          194,
          66,
          194,
          12,
          194,
          66
        ],
        [
          "replace_keys",
          138,
          224,
          197,
          12,
          197,
          60,
          197,
          12,
          197,
          60
        ],
        [
          "replace_keys",
          138,
          224,
          198,
          28,
          198,
          76,
          198,
          24,
          199,
          28
        ],
        [
          "replace_keys",
          138,
          224,
          206,
          12,
          206,
          72,
          206,
          12,
          206,
          72
        ],
        [
          "replace_keys",
          138,
          224,
          207,
          28,
          207,
          88,
          207,
          24,
          208,
          29
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": [
        [
          "rename_keys",
          197,
          247,
          210,
          22,
          210,
          63,
          210,
          22,
          211,
          37
        ],
        [
          "rename_keys",
          197,
          247,
          204,
          12,
          204,
          49,
          201,
          9,
          204,
          49
        ],
        [
          "rename_keys",
          197,
          247,
          209,
          12,
          209,
          49,
          207,
          35,
          209,
          49
        ]
      ],
      "transformers/src/transformers/models/timesfm/convert_timesfm_orignal_to_hf.py": [
        [
          "get_nested_attr",
          23,
          33,
          27,
          17,
          27,
          48,
          26,
          9,
          28,
          16
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          95,
          180,
          102,
          33,
          102,
          60,
          101,
          17,
          103,
          40
        ],
        [
          "convert_old_keys_to_new_keys",
          95,
          180,
          129,
          33,
          129,
          60,
          128,
          17,
          130,
          40
        ]
      ],
      "transformers/src/transformers/utils/doc.py": [
        [
          "docstring_decorator",
          1022,
          1095,
          1085,
          16,
          1085,
          51,
          1085,
          16,
          1085,
          51
        ]
      ],
      "transformers/src/transformers/models/whisper/english_normalizer.py": [
        [
          "process_words",
          213,
          434,
          243,
          52,
          243,
          83,
          243,
          52,
          243,
          83
        ],
        [
          "process_words",
          213,
          434,
          246,
          16,
          246,
          65,
          245,
          38,
          246,
          65
        ]
      ],
      "transformers/src/transformers/utils/import_utils.py": [
        [
          "split_package_version",
          1996,
          2002,
          1998,
          13,
          1998,
          50,
          1996,
          27,
          1999,
          12
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "tp_plan",
          2073,
          2120,
          2095,
          32,
          2095,
          66,
          2094,
          29,
          2095,
          66
        ]
      ],
      "transformers/utils/modular_model_detector.py": [
        [
          "_leading_symbol_prefix",
          189,
          200,
          199,
          13,
          199,
          48,
          189,
          28,
          199,
          48
        ],
        [
          "genexpr",
          173,
          173,
          173,
          64,
          173,
          101,
          173,
          31,
          173,
          101
        ],
        [
          "_leading_symbol_prefix",
          189,
          200,
          199,
          53,
          199,
          86,
          199,
          53,
          199,
          86
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "replace_class_node",
          862,
          1052,
          993,
          16,
          993,
          115,
          990,
          28,
          993,
          115
        ]
      ],
      "transformers/src/transformers/integrations/mxfp4.py": [
        [
          "genexpr",
          318,
          318,
          318,
          9,
          318,
          51,
          318,
          101,
          318,
          51
        ],
        [
          "genexpr",
          318,
          318,
          318,
          56,
          318,
          95,
          318,
          56,
          318,
          95
        ]
      ],
      "transformers/.circleci/parse_test_outputs.py": [
        [
          "parse_pytest_errors_output",
          35,
          50,
          41,
          21,
          41,
          70,
          40,
          13,
          42,
          20
        ],
        [
          "parse_pytest_output",
          5,
          17,
          10,
          21,
          10,
          75,
          9,
          13,
          11,
          20
        ],
        [
          "parse_pytest_failure_output",
          19,
          33,
          24,
          21,
          24,
          71,
          23,
          13,
          25,
          20
        ]
      ]
    },
    "re.search": {
      "transformers/tests/models/t5/test_tokenization_t5.py": [
        [
          "listcomp",
          374,
          374,
          374,
          26,
          374,
          60,
          374,
          78,
          374,
          72
        ],
        [
          "listcomp",
          385,
          385,
          385,
          26,
          385,
          60,
          385,
          78,
          385,
          72
        ]
      ],
      "transformers/utils/tests_fetcher.py": [
        [
          "parse_commit_message",
          1068,
          1091,
          1082,
          22,
          1082,
          63,
          1082,
          22,
          1083,
          33
        ]
      ],
      "transformers/src/transformers/testing_utils.py": [
        [
          "preprocess_string",
          2807,
          2833,
          2823,
          17,
          2823,
          62,
          2823,
          17,
          2823,
          62
        ]
      ],
      "transformers/tests/trainer/test_trainer.py": [
        [
          "test_push_to_hub",
          5315,
          5335,
          5327,
          25,
          5327,
          77,
          5315,
          26,
          5335,
          68
        ],
        [
          "test_push_to_hub_in_organization",
          5337,
          5359,
          5352,
          25,
          5352,
          77,
          5337,
          42,
          5359,
          68
        ],
        [
          "test_push_to_hub_tags",
          5459,
          5484,
          5477,
          25,
          5477,
          77,
          5459,
          31,
          5484,
          72
        ]
      ],
      "transformers/src/transformers/models/nougat/tokenization_nougat_fast.py": [
        [
          "normalize_list_like_lines",
          98,
          146,
          119,
          17,
          119,
          45,
          118,
          9,
          120,
          20
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5.py": [
        [
          "lambda",
          278,
          278,
          278,
          39,
          278,
          69,
          278,
          31,
          278,
          82
        ]
      ],
      "transformers/src/transformers/models/t5/tokenization_t5_fast.py": [
        [
          "lambda",
          226,
          226,
          226,
          39,
          226,
          69,
          226,
          31,
          226,
          82
        ]
      ],
      "transformers/src/transformers/models/udop/tokenization_udop.py": [
        [
          "lambda",
          340,
          340,
          340,
          39,
          340,
          69,
          340,
          31,
          340,
          82
        ]
      ],
      "transformers/.github/scripts/assign_reviewers.py": [
        [
          "get_file_owners",
          39,
          57,
          55,
          12,
          55,
          43,
          48,
          17,
          55,
          55
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "insert_dates",
          180,
          250,
          223,
          17,
          223,
          43,
          223,
          17,
          226,
          16
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_to_tests",
          200,
          272,
          256,
          35,
          256,
          96,
          256,
          35,
          257,
          38
        ],
        [
          "get_fast_image_processing_content_header",
          275,
          308,
          280,
          22,
          280,
          87,
          275,
          46,
          281,
          25
        ],
        [
          "get_fast_image_processing_content_header",
          275,
          308,
          304,
          13,
          304,
          71,
          300,
          22,
          305,
          12
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          354,
          13,
          354,
          58,
          353,
          13,
          355,
          16
        ],
        [
          "add_fast_image_processor_file",
          342,
          446,
          365,
          13,
          365,
          76,
          362,
          26,
          366,
          16
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "add_model_to_auto_mappings",
          150,
          214,
          179,
          12,
          179,
          81,
          178,
          9,
          179,
          81
        ],
        [
          "insert_model_in_doc_toc",
          273,
          293,
          289,
          21,
          289,
          103,
          273,
          29,
          293,
          5
        ],
        [
          "create_test_files",
          427,
          474,
          450,
          12,
          450,
          103,
          449,
          9,
          450,
          103
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          82,
          18,
          82,
          58,
          81,
          9,
          84,
          73
        ]
      ],
      "transformers/src/transformers/utils/chat_template_utils.py": [
        [
          "get_json_schema",
          237,
          371,
          362,
          24,
          362,
          88,
          361,
          16,
          363,
          23
        ],
        [
          "render_jinja_template",
          466,
          565,
          476,
          45,
          476,
          101,
          476,
          45,
          476,
          101
        ]
      ],
      "transformers/utils/check_config_attributes.py": [
        [
          "check_attribute_being_used",
          357,
          454,
          387,
          17,
          390,
          17,
          387,
          17,
          391,
          27
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "_is_definition_header_ending_line",
          170,
          172,
          172,
          12,
          172,
          53,
          170,
          39,
          172,
          65
        ],
        [
          "split_code_into_blocks",
          278,
          383,
          307,
          29,
          309,
          9,
          307,
          29,
          309,
          9
        ],
        [
          "split_code_into_blocks",
          278,
          383,
          339,
          23,
          339,
          90,
          339,
          23,
          340,
          22
        ],
        [
          "find_code_in_transformers",
          386,
          460,
          441,
          41,
          441,
          110,
          441,
          41,
          441,
          118
        ],
        [
          "get_indent",
          537,
          553,
          552,
          16,
          552,
          49,
          552,
          16,
          552,
          61
        ],
        [
          "is_copy_consistent",
          635,
          826,
          707,
          66,
          707,
          104,
          707,
          66,
          707,
          112
        ],
        [
          "dictcomp",
          943,
          944,
          944,
          17,
          944,
          50,
          945,
          21,
          944,
          68
        ],
        [
          "listcomp",
          950,
          950,
          950,
          19,
          950,
          52,
          950,
          70,
          950,
          64
        ]
      ],
      "transformers/utils/check_pipeline_typing.py": [
        [
          "main",
          30,
          78,
          35,
          30,
          35,
          104,
          30,
          10,
          53,
          41
        ],
        [
          "main",
          30,
          78,
          39,
          26,
          39,
          111,
          30,
          10,
          53,
          41
        ]
      ],
      "transformers/utils/check_docstrings.py": [
        [
          "find_indent",
          488,
          495,
          492,
          14,
          492,
          47,
          488,
          17,
          493,
          21
        ],
        [
          "replace_default_in_arg_description",
          568,
          630,
          596,
          14,
          596,
          60,
          596,
          14,
          596,
          72
        ],
        [
          "replace_default_in_arg_description",
          568,
          630,
          603,
          50,
          603,
          101,
          603,
          50,
          603,
          113
        ],
        [
          "replace_default_in_arg_description",
          568,
          630,
          605,
          31,
          605,
          82,
          605,
          31,
          606,
          63
        ],
        [
          "match_docstring_with_signature",
          676,
          795,
          707,
          12,
          707,
          69,
          705,
          33,
          707,
          69
        ],
        [
          "match_docstring_with_signature",
          676,
          795,
          711,
          14,
          711,
          74,
          711,
          14,
          711,
          74
        ],
        [
          "find_custom_args_with_details",
          1201,
          1232,
          1225,
          13,
          1225,
          57,
          1201,
          35,
          1227,
          12
        ]
      ],
      "transformers/src/transformers/models/auto/configuration_auto.py": [
        [
          "docstring_decorator",
          1181,
          1202,
          1188,
          34,
          1188,
          79,
          1188,
          34,
          1188,
          87
        ],
        [
          "docstring_decorator",
          1181,
          1202,
          1191,
          22,
          1191,
          67,
          1191,
          22,
          1192,
          30
        ]
      ],
      "transformers/src/transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": [
        [
          "get_dtype_size",
          70,
          77,
          73,
          18,
          73,
          54,
          73,
          18,
          74,
          25
        ]
      ],
      "transformers/src/transformers/models/csm/convert_csm.py": [
        [
          "write_model",
          79,
          232,
          178,
          12,
          178,
          50,
          173,
          9,
          178,
          50
        ]
      ],
      "transformers/src/transformers/models/dab_detr/convert_dab_detr_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "write_model",
          121,
          196,
          157,
          14,
          157,
          62,
          157,
          14,
          157,
          62
        ],
        [
          "write_model",
          121,
          196,
          160,
          21,
          160,
          43,
          159,
          23,
          161,
          20
        ]
      ],
      "transformers/src/transformers/models/edgetam/convert_edgetam_to_hf.py": [
        [
          "listcomp",
          208,
          208,
          208,
          58,
          208,
          78,
          208,
          34,
          208,
          86
        ]
      ],
      "transformers/src/transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py": [
        [
          "rename_key",
          38,
          104,
          53,
          34,
          53,
          63,
          53,
          34,
          53,
          63
        ],
        [
          "rename_key",
          38,
          104,
          55,
          17,
          55,
          50,
          54,
          25,
          55,
          51
        ],
        [
          "rename_key",
          38,
          104,
          56,
          21,
          56,
          53,
          56,
          21,
          56,
          17
        ],
        [
          "rename_key",
          38,
          104,
          58,
          21,
          58,
          51,
          58,
          21,
          58,
          17
        ],
        [
          "rename_key",
          38,
          104,
          81,
          36,
          81,
          63,
          81,
          36,
          81,
          63
        ]
      ],
      "transformers/src/transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_funnel",
          31,
          118,
          89,
          35,
          89,
          67,
          89,
          31,
          90,
          57
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "generate_base_path",
          521,
          533,
          524,
          17,
          524,
          43,
          521,
          28,
          527,
          74
        ]
      ],
      "transformers/src/transformers/models/llama4/convert_llama4_weights_to_hf.py": [
        [
          "genexpr",
          144,
          144,
          144,
          16,
          144,
          38,
          144,
          44,
          144,
          38
        ],
        [
          "genexpr",
          165,
          165,
          165,
          12,
          165,
          34,
          165,
          40,
          165,
          34
        ],
        [
          "write_model",
          213,
          554,
          435,
          18,
          435,
          54,
          435,
          18,
          435,
          54
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": [
        [
          "model_type_info_from_model_name",
          115,
          127,
          126,
          30,
          126,
          60,
          126,
          30,
          126,
          26
        ],
        [
          "lambda",
          311,
          311,
          311,
          58,
          311,
          94,
          311,
          28,
          311,
          115
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "genexpr",
          109,
          109,
          109,
          12,
          109,
          34,
          109,
          40,
          109,
          34
        ]
      ],
      "transformers/src/transformers/models/sam2/convert_sam2_to_hf.py": [
        [
          "listcomp",
          234,
          234,
          234,
          58,
          234,
          78,
          234,
          34,
          234,
          86
        ]
      ],
      "transformers/src/transformers/models/vitpose/convert_vitpose_to_hf.py": [
        [
          "write_model",
          190,
          396,
          222,
          12,
          222,
          48,
          218,
          9,
          222,
          48
        ],
        [
          "write_model",
          190,
          396,
          222,
          53,
          222,
          92,
          222,
          53,
          222,
          92
        ],
        [
          "write_model",
          190,
          396,
          226,
          14,
          226,
          38,
          226,
          14,
          226,
          38
        ],
        [
          "write_model",
          190,
          396,
          230,
          14,
          230,
          39,
          230,
          14,
          230,
          39
        ],
        [
          "write_model",
          190,
          396,
          244,
          20,
          244,
          46,
          243,
          17,
          244,
          46
        ],
        [
          "write_model",
          190,
          396,
          246,
          37,
          246,
          59,
          246,
          33,
          248,
          27
        ]
      ],
      "transformers/utils/create_dependency_mapping.py": [
        [
          "is_model_import",
          58,
          67,
          62,
          20,
          62,
          43,
          58,
          21,
          63,
          31
        ]
      ],
      "transformers/src/transformers/pipelines/document_question_answering.py": [
        [
          "postprocess_encoder_decoder_single",
          487,
          501,
          498,
          18,
          498,
          66,
          487,
          44,
          499,
          29
        ]
      ],
      "transformers/src/transformers/utils/doc.py": [
        [
          "_get_indent",
          98,
          101,
          100,
          14,
          100,
          38,
          98,
          17,
          101,
          31
        ],
        [
          "_prepare_output_docstrings",
          130,
          179,
          140,
          34,
          140,
          83,
          140,
          34,
          140,
          91
        ],
        [
          "docstring_decorator",
          1101,
          1117,
          1105,
          34,
          1105,
          74,
          1105,
          34,
          1105,
          82
        ]
      ],
      "transformers/src/transformers/integrations/hub_kernels.py": [
        [
          "is_kernel",
          163,
          168,
          167,
          13,
          167,
          86,
          167,
          13,
          167,
          98
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "extract_commit_hash",
          245,
          256,
          252,
          14,
          252,
          60,
          251,
          21,
          253,
          21
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "_load_state_dict_into_meta_model",
          656,
          789,
          742,
          32,
          742,
          70,
          739,
          16,
          743,
          35
        ],
        [
          "_can_set_attn_implementation",
          2621,
          2636,
          2629,
          12,
          2629,
          62,
          2621,
          38,
          2629,
          62
        ],
        [
          "genexpr",
          3931,
          3931,
          3931,
          47,
          3931,
          66,
          3931,
          72,
          3931,
          66
        ]
      ],
      "transformers/src/transformers/models/florence2/modular_florence2.py": [
        [
          "parse_phrase_grounding_from_text_and_spans",
          732,
          771,
          758,
          21,
          758,
          56,
          758,
          21,
          759,
          24
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          776,
          827,
          812,
          21,
          812,
          56,
          812,
          21,
          813,
          24
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          877,
          21,
          877,
          64,
          877,
          21,
          878,
          24
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "lambda",
          166,
          166,
          166,
          51,
          166,
          90,
          166,
          44,
          166,
          102
        ],
        [
          "visit_ImportFrom",
          536,
          548,
          542,
          12,
          542,
          72,
          536,
          26,
          542,
          72
        ],
        [
          "genexpr",
          789,
          789,
          789,
          31,
          789,
          60,
          789,
          66,
          789,
          60
        ],
        [
          "genexpr",
          792,
          792,
          792,
          17,
          792,
          46,
          792,
          52,
          792,
          46
        ],
        [
          "find_file_type",
          1073,
          1086,
          1081,
          13,
          1081,
          97,
          1073,
          20,
          1082,
          12
        ],
        [
          "visit_ImportFrom",
          1202,
          1241,
          1212,
          27,
          1215,
          17,
          1211,
          17,
          1216,
          26
        ],
        [
          "visit_SimpleStatementLine",
          1243,
          1282,
          1262,
          21,
          1262,
          118,
          1259,
          33,
          1262,
          118
        ],
        [
          "leave_Module",
          1284,
          1326,
          1325,
          25,
          1325,
          96,
          1324,
          13,
          1326,
          99
        ],
        [
          "convert_modular_file",
          1686,
          1715,
          1688,
          15,
          1688,
          63,
          1686,
          26,
          1690,
          26
        ],
        [
          "convert_modular_file",
          1686,
          1715,
          1702,
          33,
          1704,
          17,
          1702,
          33,
          1711,
          28
        ]
      ],
      "transformers/utils/notification_service_doc_tests.py": [
        [
          "extract_first_line_failure",
          46,
          58,
          51,
          12,
          51,
          44,
          50,
          9,
          51,
          44
        ]
      ],
      "transformers/src/transformers/models/donut/processing_donut.py": [
        [
          "token2json",
          135,
          191,
          146,
          31,
          146,
          70,
          146,
          31,
          147,
          38
        ],
        [
          "token2json",
          135,
          191,
          156,
          25,
          156,
          80,
          152,
          27,
          157,
          32
        ],
        [
          "token2json",
          135,
          191,
          163,
          27,
          165,
          17,
          160,
          29,
          166,
          38
        ]
      ],
      "transformers/src/transformers/models/florence2/processing_florence2.py": [
        [
          "parse_phrase_grounding_from_text_and_spans",
          539,
          578,
          565,
          21,
          565,
          56,
          565,
          21,
          566,
          24
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          583,
          634,
          619,
          21,
          619,
          56,
          619,
          21,
          620,
          24
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          684,
          21,
          684,
          64,
          684,
          21,
          685,
          24
        ]
      ],
      "transformers/src/transformers/models/kosmos2/processing_kosmos2.py": [
        [
          "extract_entities_with_patch_indices",
          576,
          631,
          614,
          17,
          614,
          55,
          612,
          13,
          617,
          16
        ],
        [
          "extract_entities_with_patch_indices",
          576,
          631,
          615,
          17,
          615,
          59,
          612,
          13,
          617,
          16
        ]
      ],
      "transformers/src/transformers/quantizers/quantizer_torchao.py": [
        [
          "fuzzy_match_size",
          52,
          64,
          59,
          17,
          59,
          53,
          52,
          22,
          61,
          16
        ]
      ],
      "transformers/utils/scan_skipped_tests.py": [
        [
          "_extract_reason_from_decorators",
          53,
          61,
          55,
          20,
          55,
          79,
          53,
          37,
          56,
          19
        ],
        [
          "_extract_reason_from_decorators",
          53,
          61,
          58,
          20,
          58,
          82,
          58,
          20,
          59,
          19
        ]
      ],
      "transformers/utils/sort_auto_mappings.py": [
        [
          "sort_auto_mapping",
          50,
          99,
          71,
          26,
          71,
          64,
          71,
          22,
          71,
          18
        ]
      ],
      "transformers/src/transformers/commands/serving.py": [
        [
          "stream_chat_completion",
          1033,
          1153,
          1097,
          45,
          1097,
          96,
          1097,
          45,
          1097,
          96
        ]
      ],
      "transformers/tests/models/colpali/test_modeling_colpali.py": [
        [
          "genexpr",
          236,
          236,
          236,
          35,
          236,
          51,
          236,
          82,
          236,
          51
        ],
        [
          "listcomp",
          243,
          243,
          243,
          68,
          243,
          84,
          243,
          45,
          243,
          92
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "test_can_init_all_missing_weights",
          901,
          973,
          910,
          28,
          910,
          104,
          901,
          43,
          910,
          104
        ],
        [
          "test_can_init_all_missing_weights",
          901,
          973,
          958,
          20,
          958,
          74,
          952,
          17,
          958,
          74
        ],
        [
          "genexpr",
          2515,
          2515,
          2515,
          35,
          2515,
          51,
          2515,
          82,
          2515,
          51
        ],
        [
          "listcomp",
          2521,
          2521,
          2521,
          68,
          2521,
          84,
          2521,
          45,
          2521,
          92
        ],
        [
          "setcomp",
          2579,
          2579,
          2579,
          76,
          2579,
          96,
          2579,
          56,
          2579,
          108
        ]
      ],
      "transformers/tests/models/grounding_dino/test_modeling_grounding_dino.py": [
        [
          "genexpr",
          604,
          604,
          604,
          28,
          604,
          44,
          604,
          75,
          604,
          44
        ],
        [
          "listcomp",
          610,
          610,
          610,
          68,
          610,
          84,
          610,
          45,
          610,
          92
        ]
      ],
      "transformers/tests/models/mm_grounding_dino/test_modeling_mm_grounding_dino.py": [
        [
          "genexpr",
          609,
          609,
          609,
          28,
          609,
          44,
          609,
          75,
          609,
          44
        ],
        [
          "listcomp",
          615,
          615,
          615,
          68,
          615,
          84,
          615,
          45,
          615,
          92
        ]
      ]
    },
    "str.endswith": {
      "transformers/utils/tests_fetcher.py": [
        [
          "listcomp",
          981,
          981,
          981,
          72,
          981,
          93,
          981,
          38,
          981,
          93
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor",
          449,
          507,
          460,
          20,
          460,
          54,
          459,
          13,
          460,
          54
        ]
      ],
      "transformers/src/transformers/commands/add_new_model_like.py": [
        [
          "get_user_field",
          574,
          620,
          598,
          12,
          598,
          33,
          575,
          5,
          598,
          33
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "is_building_block",
          527,
          538,
          531,
          8,
          531,
          32,
          527,
          23,
          531,
          32
        ],
        [
          "is_building_block",
          527,
          538,
          533,
          8,
          533,
          32,
          533,
          8,
          533,
          32
        ],
        [
          "is_building_block",
          527,
          538,
          535,
          8,
          535,
          32,
          535,
          8,
          535,
          32
        ],
        [
          "is_building_block",
          527,
          538,
          537,
          8,
          537,
          31,
          537,
          8,
          537,
          31
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1042,
          9,
          1042,
          40,
          1042,
          9,
          1042,
          40
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1043,
          12,
          1043,
          35,
          1043,
          12,
          1043,
          35
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1044,
          12,
          1044,
          35,
          1044,
          12,
          1044,
          35
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1045,
          12,
          1045,
          33,
          1045,
          12,
          1045,
          33
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1046,
          12,
          1046,
          38,
          1046,
          12,
          1046,
          38
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1047,
          12,
          1047,
          37,
          1047,
          12,
          1047,
          37
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1048,
          12,
          1048,
          38,
          1048,
          12,
          1048,
          38
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1060,
          35,
          1060,
          61,
          1060,
          35,
          1060,
          61
        ]
      ],
      "transformers/src/transformers/models/blt/convert_blt_weights_to_hf.py": [
        [
          "convert_hf_blt_to_unified",
          362,
          410,
          391,
          8,
          391,
          36,
          363,
          5,
          391,
          36
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "convert_audio_encoder_weights",
          233,
          347,
          249,
          20,
          249,
          46,
          247,
          24,
          249,
          46
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          252,
          22,
          252,
          48,
          252,
          22,
          252,
          48
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          255,
          22,
          255,
          53,
          255,
          22,
          255,
          53
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          258,
          22,
          258,
          52,
          258,
          22,
          258,
          52
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          264,
          20,
          264,
          46,
          262,
          24,
          264,
          46
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          267,
          22,
          267,
          48,
          267,
          22,
          267,
          48
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          270,
          22,
          270,
          53,
          270,
          22,
          270,
          53
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          273,
          22,
          273,
          52,
          273,
          22,
          273,
          52
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          276,
          18,
          276,
          42,
          276,
          18,
          276,
          42
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          282,
          20,
          282,
          45,
          280,
          24,
          282,
          45
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          285,
          22,
          285,
          54,
          285,
          22,
          285,
          54
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          288,
          22,
          288,
          48,
          288,
          22,
          288,
          48
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          291,
          22,
          291,
          50,
          291,
          22,
          291,
          50
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          294,
          22,
          294,
          40,
          294,
          22,
          294,
          40
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          304,
          20,
          304,
          62,
          304,
          20,
          304,
          62
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          314,
          22,
          314,
          46,
          314,
          22,
          314,
          46
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          317,
          22,
          317,
          42,
          317,
          22,
          317,
          42
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          320,
          22,
          320,
          47,
          320,
          22,
          320,
          47
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          323,
          22,
          323,
          46,
          323,
          22,
          323,
          46
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          327,
          12,
          327,
          38,
          327,
          12,
          327,
          38
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          397,
          20,
          397,
          51,
          397,
          20,
          397,
          51
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          400,
          22,
          400,
          55,
          400,
          22,
          400,
          55
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          403,
          18,
          403,
          54,
          403,
          18,
          403,
          54
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          408,
          18,
          408,
          48,
          408,
          18,
          408,
          48
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          423,
          18,
          423,
          47,
          423,
          18,
          423,
          47
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          430,
          18,
          430,
          49,
          430,
          18,
          430,
          49
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          433,
          18,
          433,
          47,
          433,
          18,
          433,
          47
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          436,
          18,
          436,
          58,
          436,
          18,
          436,
          58
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          439,
          18,
          439,
          59,
          439,
          18,
          439,
          59
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          442,
          18,
          442,
          51,
          442,
          18,
          442,
          51
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          446,
          18,
          446,
          44,
          446,
          18,
          446,
          44
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          449,
          18,
          449,
          54,
          449,
          18,
          449,
          54
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          452,
          18,
          452,
          54,
          452,
          18,
          452,
          54
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          455,
          18,
          455,
          53,
          455,
          18,
          455,
          53
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          458,
          18,
          458,
          47,
          458,
          18,
          458,
          47
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          461,
          18,
          461,
          50,
          461,
          18,
          461,
          50
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          464,
          18,
          464,
          59,
          464,
          18,
          464,
          59
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          467,
          18,
          467,
          52,
          467,
          18,
          467,
          52
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          470,
          18,
          470,
          46,
          470,
          18,
          470,
          46
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          492,
          12,
          492,
          54,
          492,
          12,
          492,
          54
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          499,
          14,
          499,
          55,
          499,
          14,
          499,
          55
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "remove_suffix",
          34,
          37,
          35,
          8,
          35,
          28,
          34,
          19,
          35,
          28
        ]
      ],
      "transformers/src/transformers/models/musicgen/convert_musicgen_transformers.py": [
        [
          "decoder_config_from_checkpoint",
          91,
          127,
          92,
          8,
          92,
          35,
          91,
          36,
          92,
          35
        ],
        [
          "decoder_config_from_checkpoint",
          91,
          127,
          97,
          10,
          97,
          38,
          97,
          10,
          97,
          38
        ],
        [
          "decoder_config_from_checkpoint",
          91,
          127,
          101,
          10,
          101,
          37,
          101,
          10,
          101,
          37
        ]
      ],
      "transformers/src/transformers/models/xcodec/convert_xcodec_weights_to_hf.py": [
        [
          "_rewrite_weight_norm",
          87,
          92,
          88,
          8,
          88,
          31,
          87,
          26,
          88,
          31
        ],
        [
          "_rewrite_weight_norm",
          87,
          92,
          90,
          8,
          90,
          31,
          90,
          8,
          90,
          31
        ]
      ],
      "transformers/utils/get_pr_run_slow_jobs.py": [
        [
          "check_name",
          81,
          83,
          83,
          47,
          83,
          70,
          83,
          47,
          83,
          70
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "is_timm_local_checkpoint",
          693,
          718,
          707,
          20,
          707,
          58,
          707,
          20,
          707,
          58
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "_load_state_dict_into_meta_model",
          656,
          789,
          681,
          22,
          681,
          56,
          677,
          8,
          683,
          100
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          4996,
          12,
          4996,
          41,
          4992,
          37,
          4996,
          41
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          4998,
          12,
          4998,
          42,
          4998,
          12,
          4998,
          42
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5005,
          16,
          5005,
          39,
          5005,
          16,
          5005,
          39
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5007,
          16,
          5007,
          39,
          5007,
          16,
          5007,
          39
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5010,
          16,
          5010,
          64,
          5010,
          16,
          5010,
          64
        ],
        [
          "_fix_state_dict_key_on_load",
          4992,
          5015,
          5012,
          16,
          5012,
          64,
          5012,
          16,
          5012,
          64
        ]
      ],
      "transformers/utils/pr_slow_ci_models.py": [
        [
          "check_model_names",
          144,
          146,
          146,
          47,
          146,
          70,
          146,
          47,
          146,
          70
        ]
      ],
      "transformers/src/transformers/quantizers/quantizer_fp_quant.py": [
        [
          "should_exclude",
          151,
          155,
          152,
          16,
          152,
          38,
          151,
          28,
          152,
          38
        ],
        [
          "create_quantized_param",
          90,
          126,
          105,
          12,
          105,
          42,
          91,
          9,
          105,
          42
        ],
        [
          "create_quantized_param",
          90,
          126,
          115,
          12,
          115,
          43,
          115,
          12,
          115,
          43
        ],
        [
          "should_exclude",
          151,
          155,
          152,
          43,
          152,
          63,
          152,
          43,
          152,
          63
        ]
      ],
      "transformers/src/transformers/quantizers/quantizer_higgs.py": [
        [
          "should_update",
          165,
          169,
          166,
          16,
          166,
          38,
          165,
          27,
          166,
          38
        ],
        [
          "should_update",
          165,
          169,
          166,
          43,
          166,
          63,
          166,
          43,
          166,
          63
        ]
      ],
      "transformers/src/transformers/quantizers/quantizer_mxfp4.py": [
        [
          "update_param_name",
          368,
          379,
          375,
          16,
          375,
          50,
          375,
          16,
          375,
          50
        ],
        [
          "update_param_name",
          368,
          379,
          377,
          16,
          377,
          47,
          377,
          16,
          377,
          47
        ]
      ],
      "transformers/src/transformers/commands/run.py": [
        [
          "try_infer_format_from_ext",
          25,
          36,
          30,
          12,
          30,
          29,
          29,
          9,
          30,
          29
        ]
      ]
    },
    "regex.compile": {
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "__init__",
          155,
          207,
          194,
          20,
          194,
          112,
          178,
          22,
          207,
          9
        ]
      ],
      "transformers/src/transformers/models/bertweet/tokenization_bertweet.py": [
        [
          "reduce_lengthening",
          733,
          738,
          737,
          15,
          737,
          41,
          733,
          24,
          738,
          39
        ],
        [
          "remove_handles",
          741,
          749,
          745,
          15,
          747,
          5,
          741,
          20,
          749,
          33
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "__init__",
          162,
          220,
          207,
          20,
          207,
          112,
          186,
          13,
          220,
          9
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "__init__",
          283,
          330,
          318,
          20,
          321,
          9,
          306,
          14,
          330,
          9
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "__init__",
          140,
          189,
          177,
          20,
          177,
          112,
          157,
          21,
          189,
          9
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "__init__",
          140,
          188,
          177,
          20,
          177,
          112,
          163,
          14,
          188,
          9
        ],
        [
          "listcomp",
          363,
          363,
          363,
          22,
          363,
          54,
          363,
          60,
          363,
          54
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "__init__",
          140,
          195,
          181,
          20,
          181,
          112,
          164,
          22,
          195,
          9
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "__init__",
          133,
          178,
          167,
          20,
          167,
          112,
          149,
          21,
          178,
          9
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "__init__",
          100,
          141,
          131,
          29,
          131,
          46,
          131,
          29,
          141,
          9
        ],
        [
          "prepare_for_tokenization",
          185,
          228,
          214,
          33,
          214,
          85,
          214,
          33,
          221,
          34
        ],
        [
          "prepare_for_tokenization",
          185,
          228,
          223,
          33,
          223,
          86,
          223,
          33,
          223,
          29
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "__init__",
          257,
          326,
          301,
          20,
          301,
          112,
          285,
          22,
          326,
          9
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "__init__",
          160,
          212,
          199,
          20,
          199,
          112,
          183,
          22,
          212,
          9
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "__init__",
          156,
          214,
          201,
          20,
          201,
          112,
          180,
          13,
          214,
          9
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "__init__",
          184,
          264,
          231,
          20,
          231,
          112,
          213,
          22,
          264,
          37
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "__init__",
          273,
          387,
          322,
          20,
          322,
          112,
          306,
          22,
          328,
          46
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "__init__",
          155,
          206,
          193,
          20,
          193,
          112,
          178,
          22,
          206,
          9
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "__init__",
          137,
          208,
          192,
          20,
          192,
          48,
          185,
          26,
          194,
          48
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "__init__",
          156,
          214,
          201,
          20,
          201,
          112,
          180,
          13,
          214,
          9
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "__init__",
          251,
          315,
          293,
          20,
          293,
          112,
          276,
          22,
          315,
          28
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "__init__",
          254,
          326,
          311,
          20,
          311,
          112,
          311,
          20,
          326,
          31
        ],
        [
          "__init__",
          254,
          326,
          312,
          30,
          312,
          60,
          311,
          20,
          326,
          31
        ]
      ],
      "transformers/src/transformers/utils/auto_docstring.py": [
        [
          "parse_shape",
          993,
          998,
          994,
          21,
          994,
          65,
          993,
          17,
          996,
          12
        ],
        [
          "parse_default",
          1001,
          1006,
          1002,
          23,
          1002,
          59,
          1001,
          19,
          1004,
          12
        ],
        [
          "parse_docstring",
          1009,
          1083,
          1029,
          20,
          1029,
          67,
          1025,
          31,
          1034,
          17
        ],
        [
          "parse_docstring",
          1009,
          1083,
          1029,
          20,
          1029,
          67,
          1028,
          31,
          1034,
          17
        ],
        [
          "parse_docstring",
          1009,
          1083,
          1050,
          25,
          1054,
          9,
          1050,
          25,
          1055,
          57
        ]
      ],
      "transformers/src/transformers/models/recurrent_gemma/convert_recurrent_gemma_to_hf.py": [
        [
          "write_model",
          72,
          141,
          103,
          19,
          103,
          74,
          101,
          9,
          105,
          34
        ]
      ],
      "transformers/src/transformers/models/clvp/number_normalizer.py": [
        [
          "listcomp",
          31,
          32,
          32,
          14,
          32,
          57,
          33,
          17,
          32,
          63
        ],
        [
          "collapse_whitespace",
          225,
          229,
          229,
          23,
          229,
          40,
          225,
          29,
          229,
          52
        ]
      ]
    },
    "regex.findall": {
      "transformers/src/transformers/models/bart/tokenization_bart.py": [
        [
          "_tokenize",
          258,
          266,
          261,
          22,
          261,
          47,
          258,
          19,
          261,
          47
        ]
      ],
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "_tokenize",
          168,
          176,
          172,
          17,
          172,
          43,
          168,
          19,
          174,
          26
        ]
      ],
      "transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py": [
        [
          "_tokenize",
          277,
          285,
          280,
          22,
          280,
          47,
          277,
          19,
          280,
          47
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "_tokenize",
          459,
          472,
          467,
          22,
          467,
          47,
          467,
          22,
          467,
          47
        ]
      ],
      "transformers/src/transformers/models/clvp/tokenization_clvp.py": [
        [
          "_tokenize",
          292,
          307,
          296,
          22,
          296,
          47,
          292,
          19,
          296,
          47
        ]
      ],
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "_tokenize",
          252,
          260,
          255,
          22,
          255,
          47,
          252,
          19,
          255,
          47
        ]
      ],
      "transformers/src/transformers/models/ctrl/tokenization_ctrl.py": [
        [
          "_tokenize",
          192,
          200,
          196,
          17,
          196,
          43,
          192,
          19,
          198,
          26
        ]
      ],
      "transformers/src/transformers/models/deberta/tokenization_deberta.py": [
        [
          "_tokenize",
          302,
          310,
          305,
          22,
          305,
          47,
          302,
          19,
          305,
          47
        ]
      ],
      "transformers/src/transformers/models/gpt2/tokenization_gpt2.py": [
        [
          "_tokenize",
          274,
          282,
          277,
          22,
          277,
          47,
          274,
          19,
          277,
          47
        ]
      ],
      "transformers/src/transformers/models/layoutlmv3/tokenization_layoutlmv3.py": [
        [
          "_tokenize",
          383,
          391,
          386,
          22,
          386,
          47,
          383,
          19,
          386,
          47
        ]
      ],
      "transformers/src/transformers/models/led/tokenization_led.py": [
        [
          "_tokenize",
          267,
          275,
          270,
          22,
          270,
          47,
          267,
          19,
          270,
          47
        ]
      ],
      "transformers/src/transformers/models/longformer/tokenization_longformer.py": [
        [
          "_tokenize",
          267,
          275,
          270,
          22,
          270,
          47,
          267,
          19,
          270,
          47
        ]
      ],
      "transformers/src/transformers/models/markuplm/tokenization_markuplm.py": [
        [
          "_tokenize",
          342,
          350,
          345,
          22,
          345,
          47,
          342,
          19,
          345,
          47
        ]
      ],
      "transformers/src/transformers/models/luke/tokenization_luke.py": [
        [
          "_tokenize",
          444,
          452,
          447,
          22,
          447,
          47,
          444,
          19,
          447,
          47
        ]
      ],
      "transformers/src/transformers/models/mvp/tokenization_mvp.py": [
        [
          "_tokenize",
          259,
          267,
          262,
          22,
          262,
          47,
          259,
          19,
          262,
          47
        ]
      ],
      "transformers/src/transformers/models/qwen2/tokenization_qwen2.py": [
        [
          "_tokenize",
          262,
          270,
          265,
          22,
          265,
          47,
          262,
          19,
          265,
          47
        ]
      ],
      "transformers/src/transformers/models/roberta/tokenization_roberta.py": [
        [
          "_tokenize",
          267,
          275,
          270,
          22,
          270,
          47,
          267,
          19,
          270,
          47
        ]
      ],
      "transformers/src/transformers/models/deprecated/tapex/tokenization_tapex.py": [
        [
          "_tokenize",
          441,
          449,
          444,
          22,
          444,
          47,
          441,
          19,
          444,
          47
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "_tokenize",
          480,
          488,
          483,
          22,
          483,
          47,
          480,
          19,
          483,
          47
        ]
      ],
      "transformers/src/transformers/utils/auto_docstring.py": [
        [
          "format_args_docstring",
          1153,
          1172,
          1159,
          24,
          1159,
          56,
          1153,
          27,
          1160,
          23
        ],
        [
          "auto_class_docstring",
          1767,
          1881,
          1803,
          12,
          1803,
          86,
          1803,
          12,
          1804,
          17
        ]
      ],
      "transformers/src/transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": [
        [
          "convert_gin_to_config",
          264,
          282,
          271,
          19,
          271,
          58,
          264,
          27,
          273,
          35
        ],
        [
          "convert_gin_to_config",
          264,
          282,
          277,
          18,
          277,
          72,
          277,
          18,
          282,
          17
        ]
      ],
      "transformers/src/transformers/models/whisper/english_normalizer.py": [
        [
          "__call__",
          82,
          93,
          89,
          26,
          89,
          57,
          89,
          17,
          89,
          13
        ]
      ]
    },
    "str.startswith": {
      "transformers/src/transformers/pipelines/token_classification.py": [
        [
          "get_tag",
          596,
          608,
          597,
          12,
          597,
          39,
          596,
          17,
          597,
          39
        ],
        [
          "get_tag",
          596,
          608,
          600,
          14,
          600,
          41,
          600,
          14,
          600,
          41
        ]
      ],
      "transformers/src/transformers/models/marian/tokenization_marian.py": [
        [
          "remove_language_code",
          185,
          191,
          188,
          12,
          188,
          32,
          185,
          30,
          188,
          32
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "_is_inner_wordpiece",
          85,
          86,
          86,
          12,
          86,
          33,
          85,
          25,
          86,
          33
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "get_release_date",
          124,
          136,
          125,
          8,
          125,
          56,
          124,
          22,
          125,
          56
        ],
        [
          "get_release_date",
          124,
          136,
          134,
          10,
          134,
          50,
          134,
          10,
          134,
          50
        ],
        [
          "get_release_date",
          124,
          136,
          134,
          55,
          134,
          95,
          134,
          55,
          134,
          95
        ]
      ],
      "transformers/src/transformers/audio_utils.py": [
        [
          "load_audio_as",
          143,
          219,
          178,
          12,
          178,
          52,
          178,
          30,
          178,
          52
        ]
      ],
      "transformers/benchmark/benchmark.py": [
        [
          "summarize",
          60,
          146,
          95,
          12,
          95,
          47,
          86,
          21,
          95,
          47
        ]
      ],
      "transformers/src/transformers/pipelines/base.py": [
        [
          "check_task",
          1356,
          1373,
          1363,
          12,
          1363,
          41,
          1363,
          12,
          1363,
          41
        ]
      ],
      "transformers/src/transformers/commands/chat.py": [
        [
          "handle_non_exit_user_commands",
          580,
          660,
          603,
          14,
          603,
          43,
          603,
          14,
          603,
          43
        ],
        [
          "handle_non_exit_user_commands",
          580,
          660,
          613,
          14,
          613,
          42,
          613,
          14,
          613,
          42
        ],
        [
          "handle_non_exit_user_commands",
          580,
          660,
          635,
          14,
          635,
          46,
          635,
          14,
          635,
          46
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "_should_continue",
          175,
          178,
          178,
          12,
          178,
          34,
          175,
          22,
          178,
          34
        ],
        [
          "is_copy_consistent",
          635,
          826,
          653,
          42,
          653,
          69,
          636,
          5,
          653,
          69
        ],
        [
          "is_copy_consistent",
          635,
          826,
          660,
          51,
          660,
          78,
          653,
          17,
          660,
          78
        ]
      ],
      "transformers/utils/collated_reports.py": [
        [
          "parse_short_summary_line",
          35,
          46,
          36,
          8,
          36,
          32,
          35,
          30,
          36,
          32
        ],
        [
          "parse_short_summary_line",
          35,
          46,
          38,
          8,
          38,
          32,
          38,
          8,
          38,
          32
        ],
        [
          "parse_short_summary_line",
          35,
          46,
          40,
          8,
          40,
          33,
          40,
          8,
          40,
          33
        ],
        [
          "parse_short_summary_line",
          35,
          46,
          44,
          8,
          44,
          31,
          44,
          8,
          44,
          31
        ]
      ],
      "transformers/utils/check_repo.py": [
        [
          "ignore_undocumented",
          1034,
          1073,
          1057,
          8,
          1057,
          38,
          1057,
          8,
          1057,
          38
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1060,
          8,
          1060,
          29,
          1060,
          8,
          1060,
          29
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1066,
          8,
          1066,
          30,
          1066,
          8,
          1066,
          30
        ],
        [
          "ignore_undocumented",
          1034,
          1073,
          1069,
          8,
          1069,
          29,
          1069,
          8,
          1069,
          29
        ]
      ],
      "transformers/src/transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py": [
        [
          "from_type",
          46,
          54,
          47,
          12,
          47,
          36,
          46,
          19,
          47,
          36
        ],
        [
          "from_type",
          46,
          54,
          49,
          12,
          49,
          36,
          49,
          12,
          49,
          36
        ],
        [
          "from_type",
          46,
          54,
          51,
          12,
          51,
          36,
          51,
          12,
          51,
          36
        ]
      ],
      "transformers/src/transformers/models/esm/convert_esm.py": [
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          101,
          8,
          101,
          34,
          96,
          5,
          101,
          34
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          107,
          8,
          107,
          34,
          105,
          5,
          107,
          34
        ],
        [
          "convert_esm_checkpoint_to_pytorch",
          95,
          381,
          183,
          8,
          183,
          34,
          181,
          5,
          183,
          34
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "convert_audio_encoder_weights",
          233,
          347,
          242,
          8,
          242,
          48,
          234,
          5,
          242,
          48
        ],
        [
          "convert_audio_encoder_weights",
          233,
          347,
          326,
          10,
          326,
          45,
          326,
          10,
          326,
          45
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          356,
          8,
          356,
          57,
          351,
          5,
          356,
          57
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          362,
          8,
          362,
          47,
          359,
          34,
          362,
          47
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          366,
          10,
          366,
          50,
          366,
          10,
          366,
          50
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          370,
          10,
          370,
          52,
          370,
          10,
          370,
          52
        ],
        [
          "convert_transformer_weights",
          350,
          512,
          490,
          10,
          490,
          47,
          490,
          10,
          490,
          47
        ]
      ],
      "transformers/src/transformers/models/marian/convert_marian_to_pytorch.py": [
        [
          "remove_prefix",
          40,
          43,
          41,
          8,
          41,
          30,
          40,
          19,
          41,
          30
        ]
      ],
      "transformers/utils/get_pr_run_slow_jobs.py": [
        [
          "check_name",
          81,
          83,
          83,
          17,
          83,
          42,
          81,
          16,
          83,
          42
        ]
      ],
      "transformers/src/transformers/utils/generic.py": [
        [
          "infer_framework_from_repr",
          67,
          78,
          73,
          8,
          73,
          50,
          67,
          31,
          73,
          50
        ],
        [
          "infer_framework_from_repr",
          67,
          78,
          75,
          10,
          75,
          52,
          75,
          10,
          75,
          52
        ],
        [
          "infer_framework_from_repr",
          67,
          78,
          77,
          10,
          77,
          50,
          77,
          10,
          77,
          50
        ]
      ],
      "transformers/src/transformers/utils/hub.py": [
        [
          "_create_repo",
          709,
          742,
          736,
          20,
          736,
          51,
          732,
          13,
          736,
          51
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "_get_key_renaming_mapping",
          5017,
          5090,
          5069,
          24,
          5069,
          50,
          5069,
          24,
          5069,
          50
        ]
      ],
      "transformers/utils/pr_slow_ci_models.py": [
        [
          "check_model_names",
          144,
          146,
          146,
          17,
          146,
          42,
          144,
          23,
          146,
          42
        ]
      ],
      "transformers/src/transformers/models/mllama/processing_mllama.py": [
        [
          "build_string_from_input",
          132,
          166,
          162,
          11,
          162,
          40,
          162,
          5,
          162,
          40
        ]
      ],
      "transformers/tests/models/detr/test_image_processing_detr.py": [
        [
          "test_should_raise_if_annotation_format_invalid",
          178,
          199,
          199,
          33,
          199,
          111,
          193,
          13,
          199,
          112
        ],
        [
          "test_valid_coco_detection_annotations",
          201,
          235,
          229,
          29,
          229,
          93,
          209,
          13,
          235,
          109
        ]
      ],
      "transformers/tests/models/rt_detr/test_image_processing_rt_detr.py": [
        [
          "test_valid_coco_detection_annotations",
          125,
          159,
          153,
          29,
          153,
          93,
          133,
          13,
          159,
          109
        ]
      ],
      "transformers/tests/test_modeling_common.py": [
        [
          "flash_attn_inference_equivalence",
          3131,
          3281,
          3146,
          68,
          3146,
          116,
          3146,
          68,
          3146,
          116
        ]
      ],
      "transformers/tests/models/modernbert/test_modeling_modernbert.py": [
        [
          "flash_attn_inference_equivalence",
          383,
          510,
          398,
          68,
          398,
          116,
          398,
          68,
          398,
          116
        ]
      ]
    },
    "regex.sub": {
      "transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py": [
        [
          "bpe",
          108,
          166,
          111,
          17,
          111,
          51,
          111,
          17,
          114,
          24
        ],
        [
          "bpe",
          108,
          166,
          112,
          17,
          112,
          45,
          111,
          17,
          114,
          24
        ],
        [
          "bpe",
          108,
          166,
          113,
          17,
          113,
          45,
          111,
          17,
          114,
          24
        ]
      ],
      "transformers/src/transformers/models/clip/tokenization_clip.py": [
        [
          "whitespace_clean",
          76,
          79,
          77,
          12,
          77,
          36,
          76,
          22,
          79,
          15
        ]
      ],
      "transformers/src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": [
        [
          "prepare_for_tokenization",
          95,
          110,
          97,
          16,
          97,
          40,
          95,
          34,
          110,
          27
        ],
        [
          "prepare_for_tokenization",
          95,
          110,
          98,
          16,
          98,
          40,
          95,
          34,
          110,
          27
        ],
        [
          "prepare_for_tokenization",
          95,
          110,
          99,
          16,
          99,
          40,
          95,
          34,
          110,
          27
        ],
        [
          "prepare_for_tokenization",
          95,
          110,
          100,
          16,
          100,
          42,
          95,
          34,
          110,
          27
        ],
        [
          "prepare_for_tokenization",
          95,
          110,
          103,
          16,
          103,
          56,
          95,
          34,
          110,
          27
        ],
        [
          "prepare_for_tokenization",
          95,
          110,
          106,
          16,
          106,
          43,
          95,
          34,
          110,
          27
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper.py": [
        [
          "_filter_timestamp_ids",
          672,
          673,
          673,
          16,
          673,
          56,
          672,
          31,
          673,
          56
        ]
      ],
      "transformers/src/transformers/utils/auto_docstring.py": [
        [
          "parse_docstring",
          1009,
          1083,
          1065,
          33,
          1065,
          75,
          1055,
          13,
          1067,
          30
        ],
        [
          "_process_parameter_type",
          1273,
          1304,
          1297,
          26,
          1297,
          79,
          1297,
          26,
          1297,
          22
        ],
        [
          "_process_parameter_type",
          1273,
          1304,
          1299,
          26,
          1299,
          72,
          1299,
          26,
          1300,
          20
        ],
        [
          "_process_kwargs_parameters",
          1448,
          1537,
          1499,
          34,
          1499,
          87,
          1499,
          34,
          1499,
          30
        ],
        [
          "_process_kwargs_parameters",
          1448,
          1537,
          1501,
          34,
          1501,
          80,
          1501,
          34,
          1502,
          28
        ],
        [
          "auto_class_docstring",
          1767,
          1881,
          1842,
          34,
          1842,
          87,
          1842,
          34,
          1842,
          30
        ],
        [
          "auto_class_docstring",
          1767,
          1881,
          1844,
          34,
          1844,
          80,
          1844,
          34,
          1845,
          28
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          142,
          154,
          149,
          24,
          149,
          52,
          149,
          24,
          150,
          20
        ],
        [
          "convert_old_keys_to_new_keys",
          142,
          154,
          151,
          20,
          151,
          57,
          151,
          20,
          151,
          16
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          115,
          127,
          124,
          20,
          124,
          57,
          124,
          20,
          124,
          16
        ],
        [
          "convert_old_keys_to_new_keys",
          115,
          127,
          122,
          24,
          122,
          52,
          122,
          24,
          123,
          20
        ]
      ],
      "transformers/src/transformers/models/depth_pro/convert_depth_pro_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          97,
          108,
          104,
          28,
          104,
          56,
          104,
          28,
          105,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          97,
          108,
          106,
          24,
          106,
          61,
          106,
          24,
          106,
          20
        ]
      ],
      "transformers/src/transformers/models/got_ocr2/convert_got_ocr2_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          64,
          76,
          74,
          24,
          74,
          61,
          73,
          13,
          74,
          20
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          60,
          75,
          71,
          28,
          71,
          56,
          71,
          28,
          72,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          60,
          75,
          73,
          24,
          73,
          61,
          73,
          24,
          73,
          20
        ],
        [
          "write_model",
          146,
          284,
          202,
          21,
          202,
          58,
          195,
          21,
          207,
          29
        ],
        [
          "write_model",
          146,
          284,
          203,
          21,
          203,
          58,
          195,
          21,
          207,
          29
        ],
        [
          "write_model",
          146,
          284,
          204,
          21,
          204,
          58,
          195,
          21,
          207,
          29
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "convert_old_keys_to_new_keys",
          93,
          108,
          104,
          28,
          104,
          56,
          104,
          28,
          105,
          24
        ],
        [
          "convert_old_keys_to_new_keys",
          93,
          108,
          106,
          24,
          106,
          61,
          106,
          24,
          106,
          20
        ],
        [
          "write_model",
          209,
          471,
          369,
          23,
          369,
          115,
          368,
          21,
          369,
          19
        ]
      ],
      "transformers/src/transformers/models/pixtral/convert_pixtral_weights_to_hf.py": [
        [
          "convert_dictionary",
          107,
          133,
          113,
          20,
          113,
          61,
          112,
          9,
          113,
          16
        ]
      ],
      "transformers/src/transformers/models/clvp/number_normalizer.py": [
        [
          "normalize_numbers",
          204,
          215,
          209,
          16,
          209,
          72,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          210,
          16,
          210,
          61,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          211,
          16,
          211,
          71,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          212,
          16,
          212,
          77,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          213,
          16,
          213,
          74,
          204,
          27,
          215,
          19
        ],
        [
          "normalize_numbers",
          204,
          215,
          214,
          16,
          214,
          59,
          204,
          27,
          215,
          19
        ],
        [
          "expand_abbreviations",
          217,
          223,
          222,
          20,
          222,
          51,
          221,
          13,
          222,
          16
        ],
        [
          "collapse_whitespace",
          225,
          229,
          229,
          16,
          229,
          52,
          225,
          29,
          229,
          52
        ]
      ]
    },
    "regex.finditer": {
      "transformers/src/transformers/models/codegen/tokenization_codegen.py": [
        [
          "truncate",
          358,
          384,
          365,
          23,
          365,
          69,
          358,
          18,
          367,
          26
        ],
        [
          "truncate",
          358,
          384,
          370,
          21,
          370,
          65,
          370,
          16,
          372,
          24
        ]
      ]
    },
    "re.compile": {
      "transformers/src/transformers/models/codegen/tokenization_codegen_fast.py": [
        [
          "listcomp",
          209,
          209,
          209,
          22,
          209,
          54,
          209,
          60,
          209,
          54
        ]
      ],
      "transformers/src/transformers/models/gpt_sw3/tokenization_gpt_sw3.py": [
        [
          "__init__",
          90,
          151,
          137,
          43,
          139,
          9,
          123,
          30,
          151,
          9
        ]
      ],
      "transformers/src/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": [
        [
          "__init__",
          220,
          253,
          225,
          34,
          225,
          105,
          220,
          18,
          237,
          38
        ],
        [
          "__init__",
          220,
          253,
          226,
          34,
          226,
          94,
          220,
          18,
          237,
          38
        ],
        [
          "__init__",
          220,
          253,
          227,
          34,
          227,
          111,
          220,
          18,
          237,
          38
        ],
        [
          "__init__",
          220,
          253,
          228,
          34,
          230,
          9,
          220,
          18,
          237,
          38
        ],
        [
          "__init__",
          220,
          253,
          231,
          34,
          233,
          9,
          220,
          18,
          237,
          38
        ],
        [
          "__init__",
          220,
          253,
          238,
          38,
          244,
          13,
          238,
          38,
          238,
          34
        ],
        [
          "__init__",
          220,
          253,
          246,
          38,
          250,
          13,
          246,
          38,
          246,
          34
        ]
      ],
      "transformers/src/transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": [
        [
          "__init__",
          397,
          430,
          403,
          34,
          403,
          94,
          397,
          18,
          414,
          38
        ],
        [
          "__init__",
          397,
          430,
          408,
          34,
          410,
          9,
          397,
          18,
          414,
          38
        ],
        [
          "__init__",
          397,
          430,
          402,
          34,
          402,
          105,
          397,
          18,
          414,
          38
        ],
        [
          "__init__",
          397,
          430,
          404,
          34,
          404,
          111,
          397,
          18,
          414,
          38
        ],
        [
          "__init__",
          397,
          430,
          405,
          34,
          407,
          9,
          397,
          18,
          414,
          38
        ],
        [
          "__init__",
          397,
          430,
          415,
          38,
          421,
          13,
          415,
          38,
          415,
          34
        ],
        [
          "__init__",
          397,
          430,
          423,
          38,
          427,
          13,
          423,
          38,
          423,
          34
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/tokenization_jukebox.py": [
        [
          "_normalize",
          241,
          260,
          257,
          19,
          257,
          35,
          241,
          20,
          260,
          19
        ]
      ],
      "transformers/src/transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": [
        [
          "__init__",
          158,
          264,
          191,
          54,
          191,
          102,
          183,
          24,
          203,
          48
        ],
        [
          "_compile_space_around_punctuation_pattern",
          270,
          273,
          273,
          16,
          273,
          100,
          270,
          51,
          273,
          100
        ]
      ],
      "transformers/src/transformers/models/tapas/tokenization_tapas.py": [
        [
          "_process_date_pattern",
          2315,
          2326,
          2326,
          27,
          2326,
          55,
          2325,
          5,
          2326,
          55
        ]
      ],
      "transformers/src/transformers/models/vits/tokenization_vits.py": [
        [
          "has_non_roman_characters",
          37,
          44,
          39,
          25,
          39,
          51,
          37,
          30,
          44,
          24
        ]
      ],
      "transformers/src/transformers/models/whisper/tokenization_whisper_fast.py": [
        [
          "__init__",
          87,
          141,
          137,
          30,
          137,
          60,
          137,
          30,
          141,
          31
        ]
      ],
      "transformers/src/transformers/trainer_pt_utils.py": [
        [
          "listcomp",
          957,
          957,
          957,
          10,
          957,
          28,
          957,
          34,
          957,
          28
        ]
      ],
      "transformers/src/transformers/commands/add_fast_image_processor.py": [
        [
          "add_fast_image_processor_to_model_init",
          33,
          146,
          48,
          23,
          51,
          9,
          48,
          23,
          54,
          20
        ],
        [
          "add_fast_image_processor_to_model_init",
          33,
          146,
          83,
          17,
          83,
          59,
          75,
          19,
          115,
          63
        ],
        [
          "add_fast_image_processor_to_tests",
          200,
          272,
          223,
          13,
          223,
          55,
          210,
          10,
          252,
          48
        ]
      ],
      "transformers/utils/add_pipeline_model_mapping_to_test.py": [
        [
          "add_pipeline_model_mapping",
          155,
          264,
          206,
          9,
          206,
          50,
          201,
          15,
          207,
          52
        ]
      ],
      "transformers/utils/check_copies.py": [
        [
          "check_codes_match",
          584,
          632,
          600,
          23,
          600,
          62,
          584,
          23,
          602,
          55
        ],
        [
          "check_codes_match",
          584,
          632,
          601,
          22,
          601,
          52,
          584,
          23,
          602,
          55
        ],
        [
          "convert_to_localized_md",
          901,
          988,
          931,
          24,
          933,
          5,
          901,
          29,
          939,
          37
        ],
        [
          "convert_to_localized_md",
          901,
          988,
          935,
          30,
          935,
          76,
          901,
          29,
          939,
          37
        ],
        [
          "convert_to_localized_md",
          901,
          988,
          937,
          30,
          937,
          69,
          901,
          29,
          939,
          37
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": [
        [
          "convert_checkpoint_from_megatron_to_transformers",
          325,
          605,
          406,
          16,
          406,
          68,
          368,
          9,
          443,
          33
        ],
        [
          "convert_checkpoint_from_transformers_to_megatron",
          608,
          909,
          781,
          16,
          781,
          75,
          779,
          18,
          786,
          66
        ]
      ],
      "transformers/src/transformers/models/dac/convert_dac_checkpoint.py": [
        [
          "recursively_load_weights",
          143,
          187,
          152,
          21,
          152,
          35,
          151,
          13,
          153,
          33
        ]
      ],
      "transformers/src/transformers/models/gemma3n/convert_gemma3n_weights.py": [
        [
          "generate_base_path",
          521,
          533,
          523,
          22,
          523,
          39,
          521,
          28,
          527,
          74
        ]
      ],
      "transformers/src/transformers/models/deprecated/jukebox/convert_jukebox.py": [
        [
          "fix_jukebox_keys",
          96,
          209,
          100,
          32,
          100,
          110,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          101,
          31,
          103,
          5,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          104,
          33,
          104,
          106,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          106,
          33,
          106,
          111,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          107,
          31,
          109,
          5,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          110,
          32,
          110,
          105,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          112,
          30,
          112,
          104,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          113,
          28,
          115,
          5,
          96,
          22,
          118,
          49
        ],
        [
          "fix_jukebox_keys",
          96,
          209,
          116,
          29,
          116,
          98,
          96,
          22,
          118,
          49
        ]
      ],
      "transformers/src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py": [
        [
          "convert_megatron_checkpoint",
          94,
          269,
          153,
          16,
          153,
          68,
          150,
          19,
          167,
          39
        ]
      ],
      "transformers/src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py": [
        [
          "convert_megatron_checkpoint",
          94,
          306,
          151,
          16,
          151,
          72,
          148,
          19,
          165,
          39
        ]
      ],
      "transformers/utils/get_pr_run_slow_jobs.py": [
        [
          "get_jobs_to_run",
          10,
          46,
          21,
          12,
          21,
          70,
          15,
          10,
          34,
          27
        ],
        [
          "get_jobs_to_run",
          10,
          46,
          22,
          12,
          22,
          72,
          15,
          10,
          34,
          27
        ],
        [
          "get_jobs_to_run",
          10,
          46,
          25,
          12,
          25,
          55,
          15,
          10,
          34,
          27
        ],
        [
          "get_jobs_to_run",
          10,
          46,
          26,
          12,
          26,
          61,
          15,
          10,
          34,
          27
        ],
        [
          "get_jobs_to_run",
          10,
          46,
          29,
          12,
          29,
          61,
          15,
          10,
          34,
          27
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "save_pretrained",
          3648,
          4088,
          3996,
          19,
          3996,
          53,
          3988,
          13,
          3999,
          54
        ],
        [
          "from_pretrained",
          4261,
          4989,
          4832,
          34,
          4832,
          118,
          4832,
          34,
          4832,
          30
        ],
        [
          "_adjust_missing_and_unexpected_keys",
          5631,
          5665,
          5647,
          36,
          5647,
          104,
          5647,
          36,
          5647,
          32
        ],
        [
          "_adjust_missing_and_unexpected_keys",
          5631,
          5665,
          5649,
          39,
          5649,
          110,
          5649,
          39,
          5649,
          35
        ],
        [
          "caching_allocator_warmup",
          5760,
          5840,
          5790,
          9,
          5790,
          67,
          5790,
          9,
          5790,
          67
        ]
      ],
      "transformers/src/transformers/models/zamba2/modeling_zamba2.py": [
        [
          "get_layers",
          1414,
          1460,
          1425,
          41,
          1432,
          21,
          1424,
          38,
          1436,
          61
        ],
        [
          "get_layers",
          1414,
          1460,
          1438,
          47,
          1442,
          29,
          1438,
          47,
          1443,
          75
        ],
        [
          "get_layers",
          1414,
          1460,
          1449,
          56,
          1454,
          33,
          1449,
          56,
          1455,
          84
        ]
      ],
      "transformers/utils/modular_model_converter.py": [
        [
          "preserve_case_replace",
          59,
          78,
          62,
          22,
          62,
          98,
          59,
          27,
          78,
          44
        ]
      ],
      "transformers/src/transformers/models/clvp/number_normalizer.py": [
        [
          "listcomp",
          31,
          32,
          32,
          14,
          32,
          57,
          33,
          17,
          32,
          63
        ],
        [
          "collapse_whitespace",
          225,
          229,
          229,
          23,
          229,
          40,
          225,
          29,
          229,
          52
        ]
      ],
      "transformers/src/transformers/models/zamba2/modular_zamba2.py": [
        [
          "get_layers",
          970,
          1016,
          981,
          41,
          988,
          21,
          980,
          38,
          992,
          61
        ],
        [
          "get_layers",
          970,
          1016,
          994,
          47,
          998,
          29,
          994,
          47,
          999,
          75
        ],
        [
          "get_layers",
          970,
          1016,
          1005,
          56,
          1010,
          33,
          1005,
          56,
          1011,
          84
        ]
      ],
      "transformers/utils/pr_slow_ci_models.py": [
        [
          "get_new_model",
          98,
          109,
          100,
          11,
          100,
          69,
          98,
          19,
          103,
          22
        ]
      ],
      "transformers/src/transformers/models/fuyu/processing_fuyu.py": [
        [
          "_segment_prompt_into_text_token_conversions",
          144,
          166,
          150,
          21,
          152,
          5,
          144,
          49,
          155,
          42
        ]
      ],
      "transformers/src/transformers/models/idefics3/processing_idefics3.py": [
        [
          "__init__",
          128,
          157,
          145,
          54,
          145,
          110,
          129,
          9,
          157,
          91
        ]
      ],
      "transformers/utils/scan_skipped_tests.py": [
        [
          "extract_test_info",
          64,
          76,
          70,
          15,
          70,
          93,
          64,
          23,
          71,
          68
        ]
      ],
      "transformers/src/transformers/data/metrics/squad_metrics.py": [
        [
          "remove_articles",
          39,
          41,
          40,
          17,
          40,
          57,
          39,
          25,
          41,
          39
        ]
      ]
    },
    "re.finditer": {
      "transformers/src/transformers/models/codegen/tokenization_codegen_fast.py": [
        [
          "truncate",
          204,
          230,
          211,
          23,
          211,
          69,
          204,
          18,
          213,
          26
        ],
        [
          "truncate",
          204,
          230,
          216,
          21,
          216,
          65,
          216,
          16,
          218,
          24
        ]
      ],
      "transformers/utils/update_metadata.py": [
        [
          "camel_case_split",
          124,
          143,
          142,
          15,
          142,
          94,
          124,
          22,
          143,
          40
        ]
      ],
      "transformers/utils/add_dates.py": [
        [
          "insert_dates",
          180,
          250,
          212,
          28,
          212,
          55,
          206,
          13,
          212,
          19
        ],
        [
          "insert_dates",
          180,
          250,
          204,
          24,
          204,
          51,
          198,
          13,
          205,
          28
        ]
      ],
      "transformers/src/transformers/models/florence2/modular_florence2.py": [
        [
          "parse_phrase_grounding_from_text_and_spans",
          732,
          771,
          764,
          34,
          764,
          70,
          764,
          29,
          765,
          32
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          776,
          827,
          816,
          34,
          816,
          70,
          815,
          22,
          817,
          32
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          883,
          55,
          883,
          101,
          883,
          55,
          883,
          30
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          888,
          37,
          888,
          71,
          887,
          17,
          889,
          41
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          829,
          913,
          895,
          59,
          895,
          95,
          893,
          21,
          896,
          40
        ]
      ],
      "transformers/src/transformers/models/qwen3_omni_moe/modular_qwen3_omni_moe.py": [
        [
          "replace_multimodal_special_tokens",
          2594,
          2670,
          2614,
          77,
          2614,
          104,
          2610,
          13,
          2617,
          45
        ]
      ],
      "transformers/src/transformers/models/gemma3/processing_gemma3.py": [
        [
          "__call__",
          71,
          142,
          110,
          53,
          110,
          87,
          109,
          17,
          112,
          52
        ]
      ],
      "transformers/src/transformers/models/florence2/processing_florence2.py": [
        [
          "parse_phrase_grounding_from_text_and_spans",
          539,
          578,
          571,
          34,
          571,
          70,
          571,
          29,
          572,
          32
        ],
        [
          "parse_description_with_bboxes_from_text_and_spans",
          583,
          634,
          623,
          34,
          623,
          70,
          622,
          22,
          624,
          32
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          690,
          55,
          690,
          101,
          690,
          55,
          690,
          30
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          695,
          37,
          695,
          71,
          694,
          17,
          696,
          41
        ],
        [
          "parse_description_with_polygons_from_text_and_spans",
          636,
          720,
          702,
          59,
          702,
          95,
          700,
          21,
          703,
          40
        ]
      ],
      "transformers/src/transformers/models/kosmos2/processing_kosmos2.py": [
        [
          "_insert_patch_index_tokens",
          437,
          480,
          441,
          32,
          441,
          80,
          441,
          27,
          442,
          46
        ],
        [
          "extract_entities_with_patch_indices",
          576,
          631,
          594,
          15,
          594,
          40,
          576,
          41,
          599,
          24
        ]
      ],
      "transformers/src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py": [
        [
          "replace_multimodal_special_tokens",
          214,
          283,
          234,
          77,
          234,
          104,
          230,
          13,
          237,
          45
        ]
      ],
      "transformers/src/transformers/models/qwen3_omni_moe/processing_qwen3_omni_moe.py": [
        [
          "replace_multimodal_special_tokens",
          224,
          300,
          244,
          77,
          244,
          104,
          240,
          13,
          247,
          45
        ]
      ],
      "transformers/tests/models/deepseek_vl/test_modeling_deepseek_vl.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          190,
          229,
          223,
          24,
          223,
          68,
          221,
          17,
          223,
          69
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          190,
          229,
          228,
          24,
          228,
          68,
          226,
          17,
          228,
          69
        ]
      ],
      "transformers/tests/models/deepseek_vl_hybrid/test_modeling_deepseek_vl_hybrid.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          220,
          272,
          259,
          25,
          259,
          69,
          256,
          17,
          259,
          70
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          220,
          272,
          268,
          25,
          268,
          69,
          265,
          17,
          268,
          70
        ]
      ],
      "transformers/tests/models/janus/test_modeling_janus.py": [
        [
          "test_sdpa_can_dispatch_composite_models",
          204,
          243,
          237,
          24,
          237,
          68,
          235,
          17,
          237,
          69
        ],
        [
          "test_sdpa_can_dispatch_composite_models",
          204,
          243,
          242,
          24,
          242,
          68,
          240,
          17,
          242,
          69
        ]
      ]
    },
    "re.fullmatch": {
      "transformers/src/transformers/trainer_utils.py": [
        [
          "check_target_module_exists",
          854,
          890,
          876,
          36,
          876,
          74,
          876,
          31,
          877,
          16
        ],
        [
          "genexpr",
          883,
          883,
          883,
          19,
          883,
          56,
          883,
          63,
          883,
          57
        ]
      ],
      "transformers/src/transformers/models/big_bird/convert_bigbird_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_big_bird",
          50,
          206,
          136,
          16,
          136,
          53,
          135,
          13,
          136,
          53
        ]
      ],
      "transformers/src/transformers/models/canine/convert_canine_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_canine",
          30,
          124,
          93,
          17,
          93,
          54,
          92,
          13,
          93,
          54
        ]
      ],
      "transformers/src/transformers/models/byt5/convert_byt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          74,
          16,
          74,
          53,
          73,
          13,
          74,
          53
        ]
      ],
      "transformers/src/transformers/models/depth_anything/convert_distill_any_depth_to_hf.py": [
        [
          "convert_key_pattern",
          98,
          105,
          100,
          17,
          100,
          42,
          99,
          9,
          101,
          16
        ]
      ],
      "transformers/src/transformers/models/doge/convert_doge_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          69,
          80,
          72,
          16,
          72,
          45,
          72,
          16,
          72,
          45
        ]
      ],
      "transformers/src/transformers/models/electra/convert_electra_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_electra",
          30,
          109,
          77,
          20,
          77,
          57,
          77,
          33,
          77,
          57
        ]
      ],
      "transformers/src/transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_funnel",
          31,
          118,
          88,
          67,
          88,
          100,
          88,
          67,
          88,
          100
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          64,
          75,
          67,
          16,
          67,
          45,
          67,
          16,
          67,
          45
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          69,
          80,
          72,
          16,
          72,
          45,
          72,
          16,
          72,
          45
        ]
      ],
      "transformers/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_gpt2",
          30,
          83,
          59,
          16,
          59,
          52,
          58,
          13,
          59,
          52
        ]
      ],
      "transformers/src/transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": [
        [
          "load_tf_weights_in_gpt_neo",
          32,
          109,
          74,
          16,
          74,
          52,
          73,
          13,
          74,
          52
        ]
      ],
      "transformers/src/transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py": [
        [
          "load_tf_weights_in_imagegpt",
          30,
          138,
          78,
          16,
          78,
          52,
          77,
          13,
          78,
          52
        ]
      ],
      "transformers/src/transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_lxmert",
          30,
          106,
          74,
          16,
          74,
          53,
          73,
          13,
          74,
          53
        ]
      ],
      "transformers/src/transformers/models/mobilebert/convert_mobilebert_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_mobilebert",
          28,
          103,
          69,
          16,
          69,
          53,
          68,
          13,
          69,
          53
        ]
      ],
      "transformers/src/transformers/models/myt5/convert_myt5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          74,
          16,
          74,
          53,
          73,
          13,
          74,
          53
        ]
      ],
      "transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_openai_gpt",
          31,
          106,
          84,
          16,
          84,
          52,
          83,
          13,
          84,
          52
        ]
      ],
      "transformers/src/transformers/models/rembert/convert_rembert_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_rembert",
          30,
          110,
          77,
          16,
          77,
          53,
          76,
          13,
          77,
          53
        ]
      ],
      "transformers/src/transformers/models/roformer/convert_roformer_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_roformer",
          30,
          100,
          67,
          16,
          67,
          53,
          66,
          13,
          67,
          53
        ]
      ],
      "transformers/src/transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_t5",
          30,
          132,
          74,
          16,
          74,
          53,
          73,
          13,
          74,
          53
        ]
      ],
      "transformers/src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py": [
        [
          "load_tf_weights_in_tapas",
          37,
          168,
          107,
          16,
          107,
          53,
          106,
          13,
          107,
          53
        ]
      ]
    },
    "regex.search": {
      "transformers/src/transformers/utils/auto_docstring.py": [
        [
          "parse_docstring",
          1009,
          1083,
          1023,
          13,
          1023,
          68,
          1009,
          21,
          1024,
          12
        ],
        [
          "_process_returns_section",
          1584,
          1616,
          1599,
          29,
          1599,
          85,
          1599,
          29,
          1599,
          98
        ],
        [
          "_process_returns_section",
          1584,
          1616,
          1601,
          21,
          1601,
          78,
          1601,
          21,
          1602,
          20
        ],
        [
          "_process_example_section",
          1619,
          1705,
          1642,
          53,
          1642,
          110,
          1642,
          53,
          1642,
          110
        ],
        [
          "_process_example_section",
          1619,
          1705,
          1648,
          22,
          1648,
          48,
          1647,
          16,
          1652,
          53
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl_hybrid/convert_deepseek_vl_hybrid_weights_to_hf.py": [
        [
          "get_qkv_state_dict",
          157,
          175,
          168,
          19,
          168,
          46,
          157,
          24,
          173,
          85
        ]
      ],
      "transformers/src/transformers/models/deepseek_vl/convert_deepseek_vl_weights_to_hf.py": [
        [
          "get_qkv_state_dict",
          130,
          148,
          141,
          19,
          141,
          46,
          130,
          24,
          146,
          85
        ]
      ],
      "transformers/src/transformers/models/depth_pro/convert_depth_pro_weights_to_hf.py": [
        [
          "get_qkv_state_dict",
          111,
          129,
          122,
          19,
          122,
          46,
          111,
          24,
          127,
          85
        ]
      ],
      "transformers/src/transformers/models/gpt_oss/convert_gpt_oss_weights_to_hf.py": [
        [
          "write_model",
          146,
          284,
          194,
          12,
          194,
          41,
          193,
          9,
          194,
          41
        ],
        [
          "write_model",
          146,
          284,
          208,
          14,
          208,
          57,
          208,
          14,
          208,
          57
        ],
        [
          "write_model",
          146,
          284,
          232,
          20,
          232,
          45,
          231,
          22,
          232,
          45
        ]
      ],
      "transformers/src/transformers/models/mllama/convert_mllama_weights_to_hf.py": [
        [
          "genexpr",
          165,
          165,
          165,
          12,
          165,
          34,
          165,
          40,
          165,
          34
        ],
        [
          "genexpr",
          157,
          157,
          157,
          16,
          157,
          38,
          157,
          44,
          157,
          38
        ],
        [
          "write_model",
          209,
          471,
          378,
          12,
          378,
          52,
          375,
          22,
          378,
          52
        ],
        [
          "write_model",
          209,
          471,
          393,
          44,
          393,
          77,
          393,
          44,
          393,
          77
        ]
      ]
    },
    "fnmatch.fnmatch": {
      "transformers/src/transformers/models/dac/convert_dac_checkpoint.py": [
        [
          "match_pattern",
          43,
          58,
          58,
          12,
          58,
          43,
          58,
          12,
          58,
          43
        ]
      ]
    },
    "re.subn": {
      "transformers/src/transformers/models/doge/convert_doge_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          69,
          80,
          75,
          34,
          75,
          71,
          75,
          34,
          77,
          28
        ]
      ],
      "transformers/src/transformers/models/glm/convert_glm_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          64,
          75,
          70,
          34,
          70,
          71,
          70,
          34,
          72,
          28
        ]
      ],
      "transformers/src/transformers/models/glm4/convert_glm4_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          69,
          80,
          75,
          34,
          75,
          71,
          75,
          34,
          77,
          28
        ]
      ],
      "transformers/src/transformers/models/mistral3/convert_mistral3_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          63,
          71,
          66,
          30,
          66,
          67,
          65,
          9,
          68,
          24
        ]
      ],
      "transformers/src/transformers/models/mistral/convert_mistral_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          51,
          59,
          54,
          30,
          54,
          67,
          53,
          9,
          56,
          24
        ]
      ],
      "transformers/src/transformers/models/phi4_multimodal/convert_phi4_multimodal_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          59,
          75,
          62,
          30,
          62,
          67,
          61,
          9,
          64,
          24
        ]
      ],
      "transformers/src/transformers/models/voxtral/convert_voxtral_weights_to_hf.py": [
        [
          "map_old_key_to_new",
          127,
          135,
          130,
          30,
          130,
          67,
          129,
          9,
          132,
          24
        ]
      ],
      "transformers/src/transformers/modeling_utils.py": [
        [
          "save_pretrained",
          3648,
          4088,
          3871,
          38,
          3871,
          71,
          3868,
          21,
          3873,
          36
        ],
        [
          "_get_key_renaming_mapping",
          5017,
          5090,
          5050,
          42,
          5050,
          79,
          5049,
          21,
          5052,
          36
        ]
      ],
      "transformers/src/transformers/integrations/peft.py": [
        [
          "load_adapter",
          87,
          303,
          254,
          42,
          254,
          79,
          253,
          21,
          256,
          36
        ]
      ]
    }
  }
}