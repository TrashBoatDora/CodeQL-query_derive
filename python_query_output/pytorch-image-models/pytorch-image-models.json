{
  "CWE-022": {
    "os.path.split": {
      "pytorch-image-models/timm/models/_factory.py": [
        [
          "parse_model_name",
          18,
          32,
          31,
          22,
          31,
          47,
          31,
          22,
          32,
          31
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          79,
          48,
          79,
          68,
          79,
          48,
          80,
          32
        ],
        [
          "clean_checkpoint",
          55,
          111,
          83,
          31,
          83,
          55,
          82,
          31,
          84,
          27
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "_extract_tarinfo",
          42,
          60,
          47,
          29,
          47,
          50,
          47,
          29,
          50,
          24
        ],
        [
          "extract_tarinfos",
          63,
          169,
          75,
          27,
          75,
          45,
          73,
          9,
          77,
          19
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_tar.py": [
        [
          "extract_tarinfo",
          18,
          38,
          25,
          29,
          25,
          50,
          25,
          29,
          28,
          36
        ]
      ]
    },
    "pathlib.Path.is_dir": {
      "pytorch-image-models/timm/models/_builder.py": [
        [
          "load_pretrained",
          152,
          288,
          230,
          12,
          230,
          35,
          228,
          9,
          230,
          35
        ]
      ]
    },
    "os.path.isfile": {
      "pytorch-image-models/timm/models/_helpers.py": [
        [
          "load_state_dict",
          44,
          87,
          61,
          28,
          61,
          58,
          61,
          28,
          61,
          58
        ],
        [
          "resume_checkpoint",
          161,
          213,
          181,
          8,
          181,
          38,
          162,
          9,
          181,
          38
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "checkpoint_metric",
          46,
          58,
          47,
          35,
          47,
          65,
          47,
          35,
          47,
          65
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          64,
          23,
          64,
          48,
          64,
          23,
          64,
          48
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_factory.py": [
        [
          "create_reader",
          8,
          48,
          44,
          12,
          44,
          31,
          41,
          9,
          44,
          31
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          72,
          8,
          72,
          27,
          70,
          18,
          72,
          27
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_tar.py": [
        [
          "__init__",
          46,
          58,
          52,
          16,
          52,
          35,
          52,
          16,
          52,
          35
        ]
      ],
      "pytorch-image-models/validate.py": [
        [
          "main",
          504,
          564,
          532,
          31,
          532,
          56,
          532,
          31,
          532,
          56
        ]
      ]
    },
    "os.path.splitext": {
      "pytorch-image-models/timm/models/_helpers.py": [
        [
          "load_checkpoint",
          90,
          129,
          115,
          8,
          115,
          40,
          91,
          9,
          115,
          72
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "main",
          61,
          148,
          72,
          26,
          72,
          54,
          72,
          26,
          73,
          21
        ]
      ],
      "pytorch-image-models/timm/data/readers/class_map.py": [
        [
          "load_class_map",
          5,
          22,
          13,
          21,
          13,
          53,
          13,
          21,
          14,
          30
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          80,
          36,
          80,
          68,
          79,
          48,
          80,
          32
        ],
        [
          "clean_checkpoint",
          55,
          111,
          84,
          31,
          84,
          63,
          82,
          31,
          84,
          27
        ]
      ],
      "pytorch-image-models/convert/convert_from_mxnet.py": [
        [
          "convert",
          15,
          71,
          69,
          22,
          69,
          53,
          64,
          5,
          71,
          90
        ]
      ],
      "pytorch-image-models/inference.py": [
        [
          "main",
          156,
          356,
          337,
          32,
          337,
          65,
          337,
          32,
          338,
          14
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_factory.py": [
        [
          "create_reader",
          8,
          48,
          44,
          37,
          44,
          58,
          44,
          37,
          44,
          71
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_folder.py": [
        [
          "find_images_and_targets",
          18,
          56,
          44,
          25,
          44,
          43,
          43,
          13,
          45,
          35
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "_extract_tarinfo",
          42,
          60,
          48,
          21,
          48,
          46,
          47,
          29,
          50,
          24
        ],
        [
          "extract_tarinfos",
          63,
          169,
          73,
          16,
          73,
          37,
          73,
          16,
          73,
          59
        ],
        [
          "extract_tarinfos",
          63,
          169,
          76,
          21,
          76,
          47,
          73,
          9,
          77,
          19
        ],
        [
          "extract_tarinfos",
          63,
          169,
          100,
          43,
          100,
          80,
          100,
          43,
          100,
          83
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_tar.py": [
        [
          "extract_tarinfo",
          18,
          38,
          27,
          15,
          27,
          40,
          25,
          29,
          28,
          36
        ]
      ]
    },
    "os.path.join": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "get_cache_dir",
          56,
          68,
          66,
          17,
          66,
          64,
          65,
          17,
          68,
          20
        ],
        [
          "download_cached_file",
          71,
          94,
          86,
          19,
          86,
          51,
          86,
          19,
          87,
          38
        ],
        [
          "check_cached_file",
          97,
          120,
          109,
          19,
          109,
          51,
          109,
          19,
          110,
          34
        ]
      ],
      "pytorch-image-models/timm/models/_prune.py": [
        [
          "adapt_model_from_file",
          114,
          116,
          115,
          45,
          115,
          91,
          114,
          27,
          116,
          85
        ]
      ],
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "save_checkpoint",
          120,
          157,
          122,
          25,
          122,
          81,
          121,
          9,
          127,
          71
        ],
        [
          "save_checkpoint",
          120,
          157,
          123,
          26,
          123,
          83,
          121,
          9,
          127,
          71
        ],
        [
          "save_checkpoint",
          120,
          157,
          136,
          25,
          136,
          67,
          135,
          24,
          147,
          42
        ],
        [
          "save_checkpoint",
          120,
          157,
          154,
          34,
          154,
          97,
          152,
          35,
          155,
          63
        ],
        [
          "save_recovery",
          159,
          175,
          161,
          25,
          161,
          88,
          160,
          9,
          168,
          50
        ],
        [
          "save_recovery",
          159,
          175,
          165,
          21,
          165,
          61,
          160,
          9,
          168,
          50
        ],
        [
          "find_recovery",
          177,
          181,
          178,
          25,
          178,
          77,
          177,
          23,
          181,
          37
        ]
      ],
      "pytorch-image-models/timm/data/readers/class_map.py": [
        [
          "load_class_map",
          5,
          22,
          11,
          26,
          11,
          59,
          11,
          26,
          12,
          45
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          106,
          36,
          106,
          80,
          106,
          9,
          108,
          29
        ]
      ],
      "pytorch-image-models/timm/data/dataset_factory.py": [
        [
          "_search_split",
          43,
          60,
          46,
          16,
          46,
          45,
          43,
          19,
          47,
          31
        ],
        [
          "_try",
          50,
          55,
          52,
          24,
          52,
          44,
          51,
          13,
          53,
          39
        ]
      ],
      "pytorch-image-models/timm/data/imagenet_info.py": [
        [
          "__init__",
          50,
          67,
          57,
          50,
          57,
          83,
          53,
          9,
          67,
          25
        ],
        [
          "__init__",
          50,
          67,
          62,
          49,
          62,
          82,
          53,
          9,
          67,
          25
        ],
        [
          "__init__",
          50,
          67,
          65,
          54,
          65,
          92,
          53,
          9,
          67,
          25
        ]
      ],
      "pytorch-image-models/inference.py": [
        [
          "main",
          156,
          356,
          349,
          28,
          349,
          75,
          348,
          9,
          349,
          24
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_folder.py": [
        [
          "find_images_and_targets",
          18,
          56,
          46,
          34,
          46,
          54,
          46,
          17,
          47,
          36
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "_extract_tarinfo",
          42,
          60,
          53,
          40,
          53,
          78,
          51,
          18,
          56,
          58
        ],
        [
          "extract_tarinfos",
          63,
          169,
          80,
          30,
          80,
          56,
          79,
          21,
          80,
          21
        ],
        [
          "extract_tarinfos",
          63,
          169,
          92,
          22,
          92,
          55,
          91,
          26,
          92,
          18
        ],
        [
          "_label_from_paths",
          125,
          127,
          126,
          16,
          126,
          34,
          125,
          28,
          127,
          55
        ],
        [
          "__getitem__",
          200,
          223,
          204,
          22,
          204,
          55,
          204,
          22,
          204,
          55
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "_load_info",
          42,
          63,
          48,
          21,
          48,
          41,
          47,
          9,
          50,
          24
        ],
        [
          "listcomp",
          364,
          364,
          364,
          32,
          364,
          57,
          364,
          63,
          364,
          57
        ]
      ],
      "pytorch-image-models/timm/data/real_labels.py": [
        [
          "__init__",
          15,
          28,
          21,
          44,
          21,
          93,
          20,
          27,
          20,
          23
        ]
      ],
      "pytorch-image-models/timm/utils/summary.py": [
        [
          "get_outdir",
          14,
          27,
          15,
          14,
          15,
          39,
          14,
          16,
          16,
          33
        ]
      ],
      "pytorch-image-models/tests/test_models.py": [
        [
          "test_model_inference",
          129,
          166,
          144,
          52,
          144,
          109,
          129,
          26,
          152,
          88
        ],
        [
          "test_model_inference",
          129,
          166,
          145,
          51,
          145,
          107,
          129,
          26,
          152,
          88
        ],
        [
          "test_model_inference",
          129,
          166,
          146,
          31,
          146,
          76,
          129,
          26,
          152,
          88
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "main",
          436,
          1091,
          936,
          19,
          936,
          55,
          924,
          39,
          939,
          25
        ],
        [
          "main",
          436,
          1091,
          1050,
          30,
          1050,
          68,
          1050,
          43,
          1050,
          68
        ],
        [
          "train_one_epoch",
          1094,
          1303,
          1279,
          25,
          1279,
          82,
          1277,
          21,
          1282,
          21
        ]
      ]
    },
    "os.makedirs": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "get_cache_dir",
          56,
          68,
          67,
          5,
          67,
          41,
          65,
          17,
          68,
          20
        ],
        [
          "download_cached_file",
          71,
          94,
          83,
          9,
          83,
          45,
          83,
          9,
          83,
          45
        ]
      ],
      "pytorch-image-models/inference.py": [
        [
          "main",
          156,
          356,
          348,
          9,
          348,
          52,
          348,
          9,
          349,
          24
        ]
      ],
      "pytorch-image-models/timm/utils/summary.py": [
        [
          "get_outdir",
          14,
          27,
          17,
          9,
          17,
          27,
          17,
          9,
          17,
          27
        ],
        [
          "get_outdir",
          14,
          27,
          26,
          9,
          26,
          27,
          25,
          18,
          26,
          27
        ]
      ]
    },
    "os.path.basename": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "download_cached_file",
          71,
          94,
          81,
          20,
          81,
          47,
          80,
          17,
          81,
          16
        ],
        [
          "check_cached_file",
          97,
          120,
          106,
          20,
          106,
          47,
          105,
          17,
          106,
          16
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_folder.py": [
        [
          "find_images_and_targets",
          18,
          56,
          42,
          17,
          42,
          42,
          42,
          17,
          42,
          42
        ],
        [
          "_filename",
          93,
          99,
          96,
          24,
          96,
          49,
          96,
          24,
          96,
          20
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          100,
          60,
          100,
          79,
          100,
          43,
          100,
          83
        ],
        [
          "_filename",
          225,
          229,
          228,
          24,
          228,
          49,
          228,
          24,
          228,
          20
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_tar.py": [
        [
          "extract_tarinfo",
          18,
          38,
          26,
          17,
          26,
          41,
          25,
          29,
          28,
          36
        ],
        [
          "_filename",
          70,
          74,
          73,
          24,
          73,
          49,
          73,
          24,
          73,
          20
        ]
      ],
      "pytorch-image-models/timm/data/real_labels.py": [
        [
          "add_result",
          30,
          41,
          36,
          24,
          36,
          49,
          34,
          13,
          37,
          41
        ]
      ]
    },
    "os.path.exists": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "download_cached_file",
          71,
          94,
          87,
          12,
          87,
          38,
          86,
          19,
          87,
          38
        ],
        [
          "check_cached_file",
          97,
          120,
          110,
          8,
          110,
          34,
          109,
          19,
          110,
          34
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "main",
          61,
          148,
          83,
          8,
          83,
          29,
          83,
          8,
          83,
          29
        ]
      ],
      "pytorch-image-models/bulk_runner.py": [
        [
          "main",
          141,
          231,
          162,
          27,
          162,
          57,
          162,
          27,
          162,
          57
        ]
      ],
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "_replace",
          66,
          73,
          69,
          20,
          69,
          38,
          69,
          35,
          69,
          38
        ],
        [
          "_duplicate",
          75,
          85,
          78,
          20,
          78,
          38,
          78,
          35,
          78,
          38
        ],
        [
          "save_recovery",
          159,
          175,
          168,
          12,
          168,
          50,
          160,
          9,
          168,
          50
        ]
      ],
      "pytorch-image-models/timm/data/readers/class_map.py": [
        [
          "load_class_map",
          5,
          22,
          10,
          12,
          10,
          41,
          9,
          22,
          10,
          41
        ],
        [
          "load_class_map",
          5,
          22,
          12,
          16,
          12,
          45,
          11,
          26,
          12,
          45
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "main",
          38,
          52,
          41,
          8,
          41,
          34,
          39,
          12,
          41,
          34
        ]
      ],
      "pytorch-image-models/timm/data/dataset_factory.py": [
        [
          "_search_split",
          43,
          60,
          47,
          8,
          47,
          31,
          43,
          19,
          47,
          31
        ],
        [
          "_try",
          50,
          55,
          53,
          16,
          53,
          39,
          51,
          13,
          53,
          39
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_factory.py": [
        [
          "create_reader",
          8,
          48,
          41,
          16,
          41,
          35,
          41,
          16,
          41,
          35
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          93,
          8,
          93,
          33,
          93,
          8,
          93,
          33
        ]
      ],
      "pytorch-image-models/timm/utils/summary.py": [
        [
          "get_outdir",
          14,
          27,
          16,
          12,
          16,
          33,
          14,
          16,
          16,
          33
        ],
        [
          "get_outdir",
          14,
          27,
          21,
          15,
          21,
          40,
          21,
          9,
          21,
          40
        ]
      ]
    },
    "open": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "check_cached_file",
          97,
          120,
          115,
          22,
          115,
          44,
          115,
          22,
          117,
          59
        ],
        [
          "load_cfg_from_json",
          140,
          143,
          141,
          10,
          141,
          47,
          140,
          24,
          143,
          27
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "main",
          61,
          148,
          146,
          10,
          146,
          27,
          146,
          10,
          148,
          67
        ]
      ],
      "pytorch-image-models/benchmark.py": [
        [
          "main",
          627,
          679,
          638,
          14,
          638,
          34,
          637,
          22,
          640,
          18
        ],
        [
          "write_results",
          682,
          695,
          683,
          10,
          683,
          37,
          682,
          19,
          684,
          27
        ]
      ],
      "pytorch-image-models/bulk_runner.py": [
        [
          "main",
          141,
          231,
          163,
          14,
          163,
          34,
          163,
          14,
          165,
          22
        ],
        [
          "write_results",
          234,
          240,
          235,
          10,
          235,
          37,
          234,
          19,
          238,
          24
        ]
      ],
      "pytorch-image-models/timm/data/readers/class_map.py": [
        [
          "load_class_map",
          5,
          22,
          15,
          14,
          15,
          33,
          15,
          14,
          16,
          24
        ],
        [
          "load_class_map",
          5,
          22,
          18,
          14,
          18,
          39,
          18,
          14,
          19,
          24
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          93,
          14,
          93,
          38,
          93,
          14,
          96,
          14
        ]
      ],
      "pytorch-image-models/convert/convert_from_mxnet.py": [
        [
          "convert",
          15,
          71,
          67,
          10,
          67,
          35,
          64,
          5,
          71,
          90
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_hfds.py": [
        [
          "__getitem__",
          77,
          95,
          85,
          21,
          85,
          45,
          84,
          13,
          85,
          17
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_folder.py": [
        [
          "__getitem__",
          86,
          88,
          88,
          16,
          88,
          31,
          86,
          21,
          88,
          39
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          95,
          14,
          95,
          35,
          94,
          9,
          97,
          48
        ],
        [
          "extract_tarinfos",
          63,
          169,
          110,
          18,
          110,
          39,
          109,
          13,
          111,
          37
        ]
      ],
      "pytorch-image-models/timm/data/real_labels.py": [
        [
          "__init__",
          15,
          28,
          17,
          18,
          17,
          32,
          17,
          18,
          18,
          27
        ]
      ],
      "pytorch-image-models/timm/utils/summary.py": [
        [
          "update_summary",
          30,
          51,
          47,
          10,
          47,
          33,
          47,
          10,
          49,
          23
        ]
      ],
      "pytorch-image-models/validate.py": [
        [
          "validate",
          179,
          472,
          307,
          14,
          307,
          41,
          307,
          14,
          312,
          23
        ],
        [
          "main",
          504,
          564,
          533,
          18,
          533,
          33,
          533,
          18,
          535,
          22
        ],
        [
          "write_results",
          567,
          580,
          568,
          10,
          568,
          37,
          567,
          19,
          569,
          27
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "_parse_args",
          419,
          433,
          423,
          14,
          423,
          42,
          423,
          14,
          425,
          38
        ],
        [
          "main",
          436,
          1091,
          936,
          14,
          936,
          61,
          924,
          39,
          939,
          25
        ]
      ]
    },
    "pathlib.Path.glob": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "load_state_dict_from_path",
          269,
          299,
          283,
          24,
          283,
          43,
          282,
          9,
          284,
          16
        ]
      ]
    },
    "pathlib.Path.mkdir": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "save_for_hf",
          368,
          393,
          377,
          5,
          377,
          53,
          375,
          5,
          381,
          33
        ]
      ]
    },
    "tempfile.TemporaryDirectory": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "push_to_hf_hub",
          396,
          458,
          433,
          10,
          433,
          29,
          428,
          22,
          458,
          9
        ],
        [
          "push_to_hf_hub",
          396,
          458,
          433,
          10,
          433,
          29,
          429,
          5,
          445,
          35
        ]
      ],
      "pytorch-image-models/tests/test_models.py": [
        [
          "test_model_inference",
          129,
          166,
          140,
          10,
          140,
          38,
          129,
          26,
          152,
          88
        ]
      ]
    },
    "glob.glob": {
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "main",
          61,
          148,
          91,
          19,
          91,
          52,
          90,
          5,
          93,
          16
        ]
      ],
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "find_recovery",
          177,
          181,
          179,
          17,
          179,
          63,
          177,
          23,
          181,
          37
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          80,
          25,
          80,
          73,
          79,
          21,
          80,
          21
        ]
      ],
      "pytorch-image-models/validate.py": [
        [
          "main",
          504,
          564,
          511,
          23,
          511,
          63,
          511,
          23,
          514,
          18
        ],
        [
          "main",
          504,
          564,
          512,
          24,
          512,
          60,
          511,
          23,
          514,
          18
        ]
      ]
    },
    "os.unlink": {
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "_replace",
          66,
          73,
          70,
          21,
          70,
          34,
          70,
          31,
          70,
          34
        ],
        [
          "_duplicate",
          75,
          85,
          80,
          21,
          80,
          34,
          80,
          31,
          80,
          34
        ]
      ]
    },
    "os.replace": {
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "_replace",
          66,
          73,
          73,
          9,
          73,
          28,
          73,
          9,
          73,
          28
        ]
      ]
    },
    "os.link": {
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "_duplicate",
          75,
          85,
          81,
          17,
          81,
          33,
          81,
          25,
          81,
          33
        ]
      ]
    },
    "shutil.copy2": {
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "_duplicate",
          75,
          85,
          85,
          9,
          85,
          30,
          85,
          9,
          85,
          30
        ]
      ]
    },
    "os.remove": {
      "pytorch-image-models/timm/utils/checkpoint_saver.py": [
        [
          "_cleanup_checkpoints",
          106,
          118,
          115,
          17,
          115,
          31,
          115,
          17,
          115,
          31
        ],
        [
          "save_recovery",
          159,
          175,
          171,
          17,
          171,
          50,
          171,
          17,
          171,
          50
        ]
      ]
    },
    "shutil.move": {
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          106,
          9,
          106,
          81,
          106,
          9,
          108,
          29
        ]
      ]
    },
    "os.rename": {
      "pytorch-image-models/convert/convert_from_mxnet.py": [
        [
          "convert",
          15,
          71,
          70,
          5,
          70,
          45,
          64,
          5,
          71,
          90
        ]
      ]
    },
    "os.path.isdir": {
      "pytorch-image-models/timm/data/dataset_factory.py": [
        [
          "create_dataset",
          63,
          230,
          154,
          33,
          154,
          51,
          154,
          33,
          154,
          51
        ],
        [
          "create_dataset",
          63,
          230,
          219,
          29,
          219,
          47,
          219,
          29,
          219,
          47
        ]
      ],
      "pytorch-image-models/validate.py": [
        [
          "main",
          504,
          564,
          509,
          8,
          509,
          37,
          505,
          5,
          509,
          37
        ]
      ]
    },
    "logging.handlers.RotatingFileHandler": {
      "pytorch-image-models/timm/utils/log.py": [
        [
          "setup_default_logging",
          19,
          28,
          25,
          24,
          25,
          110,
          25,
          24,
          28,
          45
        ]
      ]
    },
    "os.walk": {
      "pytorch-image-models/timm/data/readers/reader_image_folder.py": [
        [
          "find_images_and_targets",
          18,
          56,
          40,
          33,
          40,
          80,
          37,
          13,
          40,
          80
        ]
      ]
    },
    "os.path.relpath": {
      "pytorch-image-models/timm/data/readers/reader_image_folder.py": [
        [
          "find_images_and_targets",
          18,
          56,
          41,
          20,
          41,
          48,
          41,
          20,
          41,
          48
        ],
        [
          "_filename",
          93,
          99,
          98,
          24,
          98,
          59,
          98,
          24,
          98,
          20
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          102,
          41,
          102,
          65,
          100,
          20,
          107,
          48
        ]
      ]
    },
    "tarfile.open": {
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "_extract_tarinfo",
          42,
          60,
          51,
          18,
          51,
          68,
          51,
          18,
          56,
          58
        ],
        [
          "extract_tarinfos",
          63,
          169,
          101,
          18,
          101,
          44,
          100,
          20,
          107,
          48
        ],
        [
          "__getitem__",
          200,
          223,
          212,
          18,
          212,
          41,
          212,
          18,
          213,
          34
        ],
        [
          "__getitem__",
          200,
          223,
          218,
          23,
          218,
          68,
          218,
          23,
          219,
          38
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_tar.py": [
        [
          "__init__",
          46,
          58,
          55,
          14,
          55,
          31,
          52,
          9,
          58,
          20
        ],
        [
          "__getitem__",
          60,
          65,
          62,
          28,
          62,
          50,
          62,
          28,
          62,
          24
        ]
      ]
    },
    "tarfile.TarFile.extractfile": {
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "_extract_tarinfo",
          42,
          60,
          51,
          39,
          51,
          56,
          51,
          18,
          56,
          58
        ]
      ]
    },
    "os.path.dirname": {
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "_add_samples",
          129,
          138,
          132,
          53,
          132,
          75,
          131,
          13,
          133,
          34
        ]
      ]
    }
  },
  "CWE-078": {
    "subprocess.check_output": {
      "pytorch-image-models/bulk_runner.py": [
        [
          "main",
          141,
          231,
          200,
          25,
          200,
          62,
          200,
          54,
          200,
          62
        ]
      ]
    }
  },
  "CWE-079": {},
  "CWE-095": {
    "json.loads": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "load_cfg_from_json",
          140,
          143,
          143,
          12,
          143,
          27,
          140,
          24,
          143,
          27
        ]
      ],
      "pytorch-image-models/bulk_runner.py": [
        [
          "main",
          141,
          231,
          201,
          25,
          201,
          37,
          201,
          36,
          201,
          37
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "_decode",
          135,
          168,
          150,
          16,
          150,
          41,
          150,
          16,
          152,
          26
        ]
      ],
      "pytorch-image-models/timm/data/real_labels.py": [
        [
          "__init__",
          15,
          28,
          20,
          27,
          21,
          111,
          20,
          27,
          20,
          23
        ]
      ]
    },
    "ast.literal_eval": {
      "pytorch-image-models/timm/utils/misc.py": [
        [
          "__call__",
          24,
          32,
          29,
          27,
          29,
          49,
          29,
          44,
          29,
          49
        ]
      ]
    },
    "yaml.safe_load": {
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "_load_info",
          42,
          63,
          55,
          33,
          55,
          49,
          55,
          48,
          55,
          49
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "_parse_args",
          419,
          433,
          424,
          19,
          424,
          35,
          423,
          14,
          425,
          38
        ]
      ]
    }
  },
  "CWE-113": {},
  "CWE-117": {
    "str.replace": {
      "pytorch-image-models/timm/models/_factory.py": [
        [
          "parse_model_name",
          18,
          32,
          22,
          22,
          22,
          59,
          22,
          22,
          22,
          18
        ]
      ],
      "pytorch-image-models/timm/layers/create_norm.py": [
        [
          "get_norm_layer",
          60,
          81,
          74,
          22,
          74,
          48,
          74,
          22,
          75,
          18
        ]
      ],
      "pytorch-image-models/timm/layers/create_norm_act.py": [
        [
          "get_norm_act_layer",
          107,
          145,
          125,
          22,
          125,
          48,
          125,
          22,
          126,
          22
        ]
      ]
    },
    "json.dumps": {
      "pytorch-image-models/timm/optim/_param_groups.py": [
        [
          "param_groups_layer_decay",
          69,
          137,
          135,
          49,
          135,
          87,
          134,
          16,
          135,
          88
        ]
      ],
      "pytorch-image-models/benchmark.py": [
        [
          "main",
          627,
          679,
          679,
          24,
          679,
          52,
          679,
          5,
          679,
          55
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "main",
          436,
          1091,
          1091,
          28,
          1091,
          70,
          1086,
          27,
          1091,
          73
        ]
      ],
      "pytorch-image-models/validate.py": [
        [
          "main",
          504,
          564,
          564,
          24,
          564,
          52,
          564,
          5,
          564,
          55
        ]
      ]
    },
    "logging.info": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "load_state_dict_from_path",
          269,
          299,
          277,
          13,
          277,
          65,
          277,
          13,
          279,
          17
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "main",
          436,
          1091,
          603,
          9,
          605,
          9,
          600,
          20,
          605,
          9
        ]
      ]
    },
    "logging.warning": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "load_state_dict_from_path",
          269,
          299,
          286,
          17,
          289,
          17,
          286,
          17,
          289,
          17
        ]
      ]
    },
    "warnings.warn": {
      "pytorch-image-models/timm/models/_registry.py": [
        [
          "register_model",
          75,
          136,
          90,
          9,
          94,
          9,
          90,
          9,
          94,
          9
        ],
        [
          "_fn",
          140,
          145,
          143,
          9,
          143,
          114,
          142,
          24,
          145,
          78
        ]
      ],
      "pytorch-image-models/timm/layers/config.py": [
        [
          "set_fused_attn",
          146,
          156,
          149,
          9,
          149,
          119,
          149,
          9,
          150,
          14
        ]
      ],
      "pytorch-image-models/timm/optim/kron.py": [
        [
          "__init__",
          109,
          179,
          133,
          13,
          133,
          104,
          133,
          13,
          133,
          104
        ]
      ],
      "pytorch-image-models/timm/data/naflex_dataset.py": [
        [
          "_create_canonical_schedule",
          305,
          388,
          368,
          18,
          368,
          149,
          368,
          18,
          369,
          22
        ],
        [
          "_create_canonical_schedule",
          305,
          388,
          377,
          13,
          382,
          13,
          377,
          13,
          382,
          13
        ],
        [
          "_prepare_epoch_batches",
          391,
          475,
          431,
          14,
          435,
          15,
          431,
          14,
          439,
          30
        ],
        [
          "_prepare_epoch_batches",
          391,
          475,
          461,
          22,
          461,
          179,
          461,
          22,
          461,
          179
        ],
        [
          "_prepare_epoch_batches",
          391,
          475,
          471,
          14,
          475,
          14,
          471,
          14,
          475,
          14
        ],
        [
          "__iter__",
          496,
          556,
          535,
          25,
          535,
          99,
          535,
          25,
          535,
          99
        ],
        [
          "__iter__",
          496,
          556,
          542,
          22,
          542,
          138,
          541,
          17,
          543,
          29
        ],
        [
          "__iter__",
          496,
          556,
          546,
          21,
          546,
          103,
          544,
          17,
          547,
          28
        ]
      ],
      "pytorch-image-models/timm/data/naflex_transforms.py": [
        [
          "_validate_range",
          483,
          493,
          490,
          9,
          490,
          71,
          490,
          9,
          491,
          33
        ],
        [
          "__init__",
          539,
          584,
          584,
          17,
          584,
          96,
          584,
          17,
          584,
          96
        ],
        [
          "get_params",
          587,
          701,
          693,
          18,
          693,
          207,
          692,
          31,
          693,
          207
        ]
      ],
      "pytorch-image-models/timm/data/transforms.py": [
        [
          "__init__",
          181,
          200,
          193,
          13,
          193,
          63,
          193,
          13,
          193,
          63
        ]
      ],
      "pytorch-image-models/timm/layers/weight_init.py": [
        [
          "_trunc_normal_",
          8,
          40,
          16,
          9,
          18,
          35,
          16,
          9,
          18,
          35
        ]
      ]
    },
    "print": {
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "checkpoint_metric",
          46,
          58,
          49,
          5,
          49,
          78,
          49,
          5,
          52,
          29
        ],
        [
          "checkpoint_metric",
          46,
          58,
          56,
          9,
          56,
          22,
          55,
          19,
          57,
          14
        ],
        [
          "main",
          61,
          148,
          78,
          9,
          81,
          9,
          78,
          9,
          81,
          9
        ],
        [
          "main",
          61,
          148,
          84,
          9,
          84,
          75,
          84,
          9,
          85,
          15
        ],
        [
          "main",
          61,
          148,
          102,
          13,
          102,
          42,
          102,
          13,
          103,
          56
        ],
        [
          "listcomp",
          103,
          103,
          103,
          14,
          103,
          24,
          103,
          30,
          103,
          24
        ],
        [
          "main",
          61,
          148,
          108,
          13,
          108,
          42,
          108,
          13,
          109,
          43
        ],
        [
          "listcomp",
          109,
          109,
          109,
          14,
          109,
          21,
          109,
          27,
          109,
          21
        ],
        [
          "main",
          61,
          148,
          112,
          9,
          112,
          56,
          112,
          9,
          113,
          15
        ],
        [
          "main",
          61,
          148,
          120,
          13,
          120,
          59,
          120,
          13,
          121,
          20
        ],
        [
          "main",
          61,
          148,
          148,
          5,
          148,
          67,
          146,
          10,
          148,
          67
        ]
      ],
      "pytorch-image-models/benchmark.py": [
        [
          "profile_fvcore",
          201,
          211,
          210,
          9,
          210,
          18,
          209,
          15,
          210,
          18
        ],
        [
          "main",
          627,
          679,
          679,
          5,
          679,
          55,
          679,
          5,
          679,
          55
        ]
      ],
      "pytorch-image-models/bulk_runner.py": [
        [
          "main",
          141,
          231,
          177,
          9,
          177,
          67,
          173,
          9,
          178,
          28
        ],
        [
          "main",
          141,
          231,
          188,
          9,
          188,
          87,
          188,
          9,
          191,
          35
        ],
        [
          "main",
          141,
          231,
          214,
          13,
          214,
          65,
          214,
          13,
          215,
          27
        ],
        [
          "main",
          141,
          231,
          217,
          21,
          217,
          75,
          217,
          21,
          217,
          75
        ],
        [
          "main",
          141,
          231,
          219,
          21,
          219,
          28,
          219,
          21,
          219,
          28
        ],
        [
          "main",
          141,
          231,
          225,
          13,
          225,
          80,
          225,
          13,
          225,
          80
        ],
        [
          "main",
          141,
          231,
          230,
          13,
          230,
          95,
          230,
          13,
          231,
          48
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "main",
          38,
          52,
          42,
          9,
          42,
          80,
          42,
          9,
          43,
          15
        ],
        [
          "clean_checkpoint",
          55,
          111,
          65,
          9,
          65,
          62,
          65,
          9,
          68,
          38
        ],
        [
          "clean_checkpoint",
          55,
          111,
          75,
          9,
          75,
          66,
          75,
          9,
          78,
          17
        ],
        [
          "clean_checkpoint",
          55,
          111,
          107,
          9,
          107,
          89,
          106,
          9,
          108,
          29
        ],
        [
          "clean_checkpoint",
          55,
          111,
          110,
          9,
          110,
          72,
          110,
          9,
          111,
          17
        ]
      ],
      "pytorch-image-models/convert/convert_from_mxnet.py": [
        [
          "convert",
          15,
          71,
          33,
          9,
          33,
          31,
          30,
          9,
          37,
          33
        ],
        [
          "convert",
          15,
          71,
          34,
          9,
          34,
          33,
          30,
          9,
          37,
          33
        ],
        [
          "convert",
          15,
          71,
          52,
          9,
          52,
          21,
          51,
          9,
          56,
          30
        ],
        [
          "convert",
          15,
          71,
          53,
          9,
          53,
          33,
          51,
          9,
          56,
          30
        ],
        [
          "convert",
          15,
          71,
          71,
          5,
          71,
          90,
          64,
          5,
          71,
          90
        ]
      ],
      "pytorch-image-models/timm/models/eva.py": [
        [
          "checkpoint_filter_fn",
          1068,
          1189,
          1135,
          21,
          1135,
          28,
          1134,
          17,
          1137,
          28
        ]
      ],
      "pytorch-image-models/inference.py": [
        [
          "main",
          156,
          356,
          355,
          9,
          355,
          26,
          355,
          9,
          356,
          80
        ],
        [
          "main",
          156,
          356,
          356,
          9,
          356,
          80,
          355,
          9,
          356,
          80
        ]
      ],
      "pytorch-image-models/timm/layers/ml_decoder.py": [
        [
          "add_ml_decoder_head",
          9,
          32,
          28,
          9,
          28,
          76,
          28,
          9,
          29,
          16
        ]
      ],
      "pytorch-image-models/timm/data/naflex_dataset.py": [
        [
          "_create_canonical_schedule",
          305,
          388,
          321,
          18,
          321,
          142,
          319,
          29,
          321,
          142
        ],
        [
          "_create_canonical_schedule",
          305,
          388,
          388,
          9,
          388,
          154,
          386,
          42,
          388,
          154
        ]
      ],
      "pytorch-image-models/onnx_export.py": [
        [
          "main",
          65,
          108,
          72,
          5,
          72,
          61,
          72,
          5,
          84,
          19
        ]
      ],
      "pytorch-image-models/onnx_validate.py": [
        [
          "main",
          43,
          99,
          91,
          13,
          97,
          13,
          91,
          13,
          97,
          13
        ],
        [
          "main",
          43,
          99,
          99,
          5,
          99,
          103,
          99,
          5,
          99,
          103
        ]
      ],
      "pytorch-image-models/tests/test_models.py": [
        [
          "test_model_forward_intermediates_features",
          485,
          509,
          504,
          9,
          504,
          22,
          503,
          9,
          505,
          38
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "main",
          436,
          1091,
          1091,
          9,
          1091,
          73,
          1086,
          27,
          1091,
          73
        ]
      ],
      "pytorch-image-models/validate.py": [
        [
          "main",
          504,
          564,
          564,
          5,
          564,
          55,
          564,
          5,
          564,
          55
        ]
      ]
    },
    "re.sub": {
      "pytorch-image-models/timm/models/convnext.py": [
        [
          "checkpoint_filter_fn",
          605,
          644,
          628,
          13,
          628,
          74,
          626,
          9,
          632,
          21
        ],
        [
          "checkpoint_filter_fn",
          605,
          644,
          629,
          13,
          629,
          89,
          626,
          9,
          632,
          21
        ]
      ],
      "pytorch-image-models/timm/models/byobnet.py": [
        [
          "_convert_openai_clip",
          2195,
          2235,
          2220,
          13,
          2220,
          67,
          2220,
          13,
          2224,
          44
        ],
        [
          "_convert_openai_clip",
          2195,
          2235,
          2221,
          13,
          2221,
          63,
          2220,
          13,
          2224,
          44
        ],
        [
          "_convert_openai_clip",
          2195,
          2235,
          2222,
          13,
          2222,
          86,
          2220,
          13,
          2224,
          44
        ],
        [
          "_convert_openai_clip",
          2195,
          2235,
          2223,
          13,
          2223,
          89,
          2220,
          13,
          2224,
          44
        ]
      ],
      "pytorch-image-models/timm/models/davit.py": [
        [
          "_convert_florence2",
          727,
          752,
          736,
          13,
          736,
          65,
          733,
          17,
          750,
          19
        ],
        [
          "_convert_florence2",
          727,
          752,
          737,
          13,
          737,
          62,
          733,
          17,
          750,
          19
        ],
        [
          "checkpoint_filter_fn",
          755,
          778,
          769,
          13,
          769,
          72,
          768,
          9,
          777,
          19
        ],
        [
          "checkpoint_filter_fn",
          755,
          778,
          770,
          13,
          770,
          67,
          768,
          9,
          777,
          19
        ]
      ],
      "pytorch-image-models/timm/models/edgenext.py": [
        [
          "checkpoint_filter_fn",
          516,
          544,
          533,
          13,
          533,
          74,
          531,
          9,
          538,
          32
        ],
        [
          "checkpoint_filter_fn",
          516,
          544,
          534,
          13,
          534,
          89,
          531,
          9,
          538,
          32
        ]
      ],
      "pytorch-image-models/timm/models/efficientformer.py": [
        [
          "checkpoint_filter_fn",
          559,
          583,
          576,
          13,
          576,
          79,
          576,
          13,
          582,
          19
        ],
        [
          "checkpoint_filter_fn",
          559,
          583,
          577,
          13,
          577,
          83,
          576,
          13,
          582,
          19
        ],
        [
          "checkpoint_filter_fn",
          559,
          583,
          578,
          13,
          578,
          83,
          576,
          13,
          582,
          19
        ],
        [
          "checkpoint_filter_fn",
          559,
          583,
          580,
          13,
          580,
          60,
          576,
          13,
          582,
          19
        ]
      ],
      "pytorch-image-models/timm/models/focalnet.py": [
        [
          "checkpoint_filter_fn",
          603,
          621,
          611,
          13,
          611,
          54,
          610,
          9,
          614,
          22
        ],
        [
          "checkpoint_filter_fn",
          603,
          621,
          613,
          13,
          613,
          103,
          610,
          9,
          614,
          22
        ],
        [
          "checkpoint_filter_fn",
          603,
          621,
          615,
          17,
          615,
          57,
          615,
          17,
          615,
          13
        ]
      ],
      "pytorch-image-models/timm/models/fastvit.py": [
        [
          "checkpoint_filter_fn",
          1465,
          1538,
          1508,
          13,
          1508,
          70,
          1499,
          13,
          1509,
          36
        ]
      ],
      "pytorch-image-models/timm/data/imagenet_info.py": [
        [
          "__init__",
          50,
          67,
          52,
          18,
          52,
          54,
          50,
          18,
          53,
          33
        ]
      ],
      "pytorch-image-models/timm/models/mambaout.py": [
        [
          "checkpoint_filter_fn",
          497,
          519,
          507,
          13,
          507,
          74,
          505,
          9,
          510,
          32
        ],
        [
          "checkpoint_filter_fn",
          497,
          519,
          508,
          13,
          508,
          77,
          505,
          9,
          510,
          32
        ]
      ],
      "pytorch-image-models/timm/models/metaformer.py": [
        [
          "checkpoint_filter_fn",
          683,
          717,
          693,
          17,
          693,
          74,
          693,
          17,
          700,
          13
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          702,
          13,
          702,
          77,
          702,
          13,
          713,
          41
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          705,
          13,
          705,
          60,
          702,
          13,
          713,
          41
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          710,
          13,
          710,
          42,
          702,
          13,
          713,
          41
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          711,
          13,
          711,
          44,
          702,
          13,
          713,
          41
        ]
      ],
      "pytorch-image-models/timm/models/mvitv2.py": [
        [
          "checkpoint_filter_fn",
          944,
          988,
          975,
          13,
          978,
          14,
          974,
          9,
          980,
          22
        ],
        [
          "checkpoint_filter_fn",
          944,
          988,
          981,
          17,
          981,
          107,
          981,
          17,
          981,
          13
        ],
        [
          "checkpoint_filter_fn",
          944,
          988,
          983,
          17,
          983,
          106,
          983,
          17,
          983,
          13
        ]
      ],
      "pytorch-image-models/timm/models/pvt_v2.py": [
        [
          "checkpoint_filter_fn",
          463,
          480,
          477,
          13,
          477,
          105,
          476,
          13,
          479,
          19
        ],
        [
          "checkpoint_filter_fn",
          463,
          480,
          478,
          13,
          478,
          84,
          476,
          13,
          479,
          19
        ]
      ],
      "pytorch-image-models/timm/models/regnet.py": [
        [
          "_filter_fn",
          851,
          913,
          885,
          17,
          887,
          74,
          882,
          13,
          889,
          32
        ],
        [
          "_filter_fn",
          851,
          913,
          888,
          17,
          888,
          73,
          882,
          13,
          889,
          32
        ],
        [
          "_filter_fn",
          851,
          913,
          905,
          17,
          907,
          74,
          902,
          13,
          908,
          32
        ]
      ],
      "pytorch-image-models/timm/models/sequencer.py": [
        [
          "checkpoint_filter_fn",
          441,
          456,
          451,
          13,
          451,
          114,
          450,
          9,
          454,
          19
        ],
        [
          "checkpoint_filter_fn",
          441,
          456,
          452,
          13,
          452,
          74,
          450,
          9,
          454,
          19
        ]
      ],
      "pytorch-image-models/timm/models/swiftformer.py": [
        [
          "checkpoint_filter_fn",
          525,
          548,
          537,
          13,
          537,
          69,
          531,
          9,
          539,
          12
        ]
      ],
      "pytorch-image-models/timm/models/swin_transformer.py": [
        [
          "checkpoint_filter_fn",
          929,
          975,
          971,
          17,
          971,
          107,
          970,
          12,
          974,
          19
        ]
      ],
      "pytorch-image-models/timm/models/swin_transformer_v2.py": [
        [
          "checkpoint_filter_fn",
          972,
          1011,
          1007,
          17,
          1007,
          107,
          1007,
          17,
          1008,
          13
        ]
      ],
      "pytorch-image-models/timm/models/tresnet.py": [
        [
          "checkpoint_filter_fn",
          317,
          336,
          326,
          13,
          326,
          81,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          327,
          13,
          327,
          79,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          328,
          13,
          328,
          79,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          329,
          13,
          329,
          77,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          330,
          13,
          330,
          94,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          331,
          13,
          331,
          92,
          325,
          9,
          332,
          34
        ]
      ],
      "pytorch-image-models/timm/models/vision_transformer.py": [
        [
          "_convert_beit3",
          1325,
          1382,
          1358,
          17,
          1358,
          35,
          1357,
          13,
          1358,
          13
        ],
        [
          "checkpoint_filter_fn",
          1385,
          1461,
          1456,
          17,
          1456,
          58,
          1456,
          17,
          1456,
          13
        ]
      ]
    },
    "logging.StreamHandler": {
      "pytorch-image-models/timm/utils/log.py": [
        [
          "setup_default_logging",
          19,
          28,
          20,
          23,
          20,
          45,
          19,
          27,
          24,
          15
        ]
      ]
    },
    "logging.handlers.RotatingFileHandler": {
      "pytorch-image-models/timm/utils/log.py": [
        [
          "setup_default_logging",
          19,
          28,
          25,
          24,
          25,
          110,
          25,
          24,
          28,
          45
        ]
      ]
    },
    "logging.Formatter": {
      "pytorch-image-models/timm/utils/log.py": [
        [
          "setup_default_logging",
          19,
          28,
          26,
          26,
          26,
          102,
          25,
          24,
          28,
          45
        ]
      ]
    },
    "repr": {
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "log_and_continue",
          126,
          132,
          128,
          51,
          128,
          59,
          126,
          22,
          130,
          33
        ]
      ]
    }
  },
  "CWE-326": {},
  "CWE-327": {
    "hashlib.sha256": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "check_cached_file",
          97,
          120,
          116,
          26,
          116,
          49,
          115,
          22,
          117,
          59
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "main",
          61,
          148,
          147,
          20,
          147,
          43,
          146,
          10,
          148,
          67
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          94,
          24,
          94,
          47,
          93,
          14,
          96,
          14
        ]
      ],
      "pytorch-image-models/convert/convert_from_mxnet.py": [
        [
          "convert",
          15,
          71,
          68,
          20,
          68,
          43,
          64,
          5,
          71,
          90
        ]
      ]
    }
  },
  "CWE-329": {
    "random.random": {
      "pytorch-image-models/timm/data/auto_augment.py": [
        [
          "_randomly_negate",
          201,
          203,
          203,
          18,
          203,
          32,
          201,
          22,
          203,
          38
        ],
        [
          "__call__",
          380,
          396,
          381,
          32,
          381,
          46,
          381,
          32,
          381,
          58
        ]
      ],
      "pytorch-image-models/timm/data/naflex_mixup.py": [
        [
          "__call__",
          213,
          250,
          231,
          12,
          231,
          26,
          231,
          12,
          231,
          38
        ]
      ],
      "pytorch-image-models/timm/data/naflex_random_erasing.py": [
        [
          "_drop_patches",
          122,
          161,
          142,
          12,
          142,
          26,
          123,
          13,
          142,
          44
        ],
        [
          "_erase_patches",
          163,
          207,
          183,
          12,
          183,
          26,
          164,
          13,
          183,
          44
        ],
        [
          "_erase_region",
          209,
          280,
          229,
          12,
          229,
          26,
          210,
          13,
          229,
          44
        ]
      ],
      "pytorch-image-models/timm/data/naflex_transforms.py": [
        [
          "get_params",
          244,
          329,
          278,
          38,
          278,
          52,
          278,
          38,
          278,
          72
        ],
        [
          "get_params",
          244,
          329,
          288,
          39,
          288,
          53,
          288,
          39,
          288,
          74
        ]
      ],
      "pytorch-image-models/timm/data/random_erasing.py": [
        [
          "_erase",
          78,
          100,
          79,
          12,
          79,
          26,
          78,
          16,
          79,
          45
        ]
      ],
      "pytorch-image-models/timm/data/transforms.py": [
        [
          "get_params",
          491,
          528,
          509,
          38,
          509,
          52,
          509,
          38,
          509,
          72
        ],
        [
          "get_params",
          491,
          528,
          519,
          39,
          519,
          53,
          519,
          39,
          519,
          74
        ]
      ]
    },
    "numpy.random.randint": {
      "pytorch-image-models/timm/data/auto_augment.py": [
        [
          "_apply_blended",
          901,
          915,
          909,
          55,
          909,
          77,
          909,
          55,
          909,
          77
        ],
        [
          "_apply_basic",
          917,
          932,
          924,
          55,
          924,
          77,
          924,
          55,
          924,
          77
        ]
      ],
      "pytorch-image-models/timm/data/mixup.py": [
        [
          "rand_bbox",
          30,
          51,
          45,
          10,
          45,
          70,
          30,
          15,
          51,
          25
        ],
        [
          "rand_bbox",
          30,
          51,
          46,
          10,
          46,
          70,
          30,
          15,
          51,
          25
        ],
        [
          "rand_bbox_minmax",
          54,
          74,
          68,
          13,
          68,
          89,
          66,
          5,
          74,
          25
        ],
        [
          "rand_bbox_minmax",
          54,
          74,
          69,
          13,
          69,
          89,
          66,
          5,
          74,
          25
        ],
        [
          "rand_bbox_minmax",
          54,
          74,
          70,
          10,
          70,
          56,
          66,
          5,
          74,
          25
        ],
        [
          "rand_bbox_minmax",
          54,
          74,
          71,
          10,
          71,
          56,
          66,
          5,
          74,
          25
        ]
      ]
    },
    "random.randint": {
      "pytorch-image-models/timm/data/naflex_mixup.py": [
        [
          "mix_batch_variable_size",
          23,
          129,
          107,
          21,
          107,
          46,
          104,
          25,
          116,
          23
        ],
        [
          "mix_batch_variable_size",
          23,
          129,
          108,
          21,
          108,
          46,
          104,
          25,
          116,
          23
        ]
      ],
      "pytorch-image-models/timm/data/naflex_random_erasing.py": [
        [
          "_erase_patches",
          163,
          207,
          192,
          17,
          192,
          62,
          192,
          17,
          201,
          38
        ],
        [
          "_erase_patches",
          163,
          207,
          196,
          21,
          196,
          56,
          192,
          17,
          201,
          38
        ],
        [
          "_erase_region",
          209,
          280,
          242,
          17,
          242,
          62,
          236,
          17,
          243,
          29
        ],
        [
          "_erase_region",
          209,
          280,
          258,
          23,
          258,
          51,
          258,
          23,
          269,
          35
        ],
        [
          "_erase_region",
          209,
          280,
          259,
          24,
          259,
          52,
          258,
          23,
          269,
          35
        ]
      ],
      "pytorch-image-models/timm/data/naflex_transforms.py": [
        [
          "get_params",
          429,
          446,
          439,
          37,
          439,
          72,
          439,
          19,
          439,
          15
        ],
        [
          "get_params",
          429,
          446,
          444,
          38,
          444,
          72,
          444,
          20,
          444,
          16
        ],
        [
          "get_params",
          587,
          701,
          623,
          23,
          623,
          56,
          623,
          23,
          625,
          21
        ],
        [
          "get_params",
          587,
          701,
          624,
          24,
          624,
          56,
          623,
          23,
          625,
          21
        ]
      ],
      "pytorch-image-models/timm/data/random_erasing.py": [
        [
          "_erase",
          78,
          100,
          83,
          13,
          83,
          58,
          83,
          13,
          83,
          58
        ],
        [
          "_erase",
          78,
          100,
          91,
          27,
          91,
          54,
          91,
          27,
          100,
          25
        ],
        [
          "_erase",
          78,
          100,
          92,
          28,
          92,
          55,
          91,
          27,
          100,
          25
        ]
      ],
      "pytorch-image-models/timm/data/transforms.py": [
        [
          "get_params",
          203,
          243,
          226,
          21,
          226,
          55,
          226,
          21,
          228,
          47
        ],
        [
          "get_params",
          203,
          243,
          227,
          21,
          227,
          55,
          226,
          21,
          228,
          47
        ],
        [
          "get_params",
          395,
          401,
          399,
          33,
          399,
          68,
          395,
          20,
          401,
          24
        ],
        [
          "get_params",
          395,
          401,
          400,
          34,
          400,
          68,
          395,
          20,
          401,
          24
        ],
        [
          "get_params",
          432,
          440,
          436,
          20,
          436,
          49,
          432,
          20,
          440,
          55
        ],
        [
          "get_params",
          432,
          440,
          437,
          19,
          437,
          49,
          432,
          20,
          440,
          55
        ]
      ]
    }
  },
  "CWE-347": {},
  "CWE-377": {
    "open": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "check_cached_file",
          97,
          120,
          115,
          22,
          115,
          44,
          115,
          22,
          117,
          59
        ],
        [
          "load_cfg_from_json",
          140,
          143,
          141,
          10,
          141,
          47,
          140,
          24,
          143,
          27
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "main",
          61,
          148,
          146,
          10,
          146,
          27,
          146,
          10,
          148,
          67
        ]
      ],
      "pytorch-image-models/benchmark.py": [
        [
          "main",
          627,
          679,
          638,
          14,
          638,
          34,
          637,
          22,
          640,
          18
        ],
        [
          "write_results",
          682,
          695,
          683,
          10,
          683,
          37,
          682,
          19,
          684,
          27
        ]
      ],
      "pytorch-image-models/bulk_runner.py": [
        [
          "main",
          141,
          231,
          163,
          14,
          163,
          34,
          163,
          14,
          165,
          22
        ],
        [
          "write_results",
          234,
          240,
          235,
          10,
          235,
          37,
          234,
          19,
          238,
          24
        ]
      ],
      "pytorch-image-models/timm/data/readers/class_map.py": [
        [
          "load_class_map",
          5,
          22,
          15,
          14,
          15,
          33,
          15,
          14,
          16,
          24
        ],
        [
          "load_class_map",
          5,
          22,
          18,
          14,
          18,
          39,
          18,
          14,
          19,
          24
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          93,
          14,
          93,
          38,
          93,
          14,
          96,
          14
        ]
      ],
      "pytorch-image-models/convert/convert_from_mxnet.py": [
        [
          "convert",
          15,
          71,
          67,
          10,
          67,
          35,
          64,
          5,
          71,
          90
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_hfds.py": [
        [
          "__getitem__",
          77,
          95,
          85,
          21,
          85,
          45,
          84,
          13,
          85,
          17
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_folder.py": [
        [
          "__getitem__",
          86,
          88,
          88,
          16,
          88,
          31,
          86,
          21,
          88,
          39
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          95,
          14,
          95,
          35,
          94,
          9,
          97,
          48
        ],
        [
          "extract_tarinfos",
          63,
          169,
          110,
          18,
          110,
          39,
          109,
          13,
          111,
          37
        ]
      ],
      "pytorch-image-models/timm/data/real_labels.py": [
        [
          "__init__",
          15,
          28,
          17,
          18,
          17,
          32,
          17,
          18,
          18,
          27
        ]
      ],
      "pytorch-image-models/timm/utils/summary.py": [
        [
          "update_summary",
          30,
          51,
          47,
          10,
          47,
          33,
          47,
          10,
          49,
          23
        ]
      ],
      "pytorch-image-models/validate.py": [
        [
          "validate",
          179,
          472,
          307,
          14,
          307,
          41,
          307,
          14,
          312,
          23
        ],
        [
          "main",
          504,
          564,
          533,
          18,
          533,
          33,
          533,
          18,
          535,
          22
        ],
        [
          "write_results",
          567,
          580,
          568,
          10,
          568,
          37,
          567,
          19,
          569,
          27
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "_parse_args",
          419,
          433,
          423,
          14,
          423,
          42,
          423,
          14,
          425,
          38
        ],
        [
          "main",
          436,
          1091,
          936,
          14,
          936,
          61,
          924,
          39,
          939,
          25
        ]
      ]
    },
    "tempfile.TemporaryDirectory": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "push_to_hf_hub",
          396,
          458,
          433,
          10,
          433,
          29,
          428,
          22,
          458,
          9
        ],
        [
          "push_to_hf_hub",
          396,
          458,
          433,
          10,
          433,
          29,
          429,
          5,
          445,
          35
        ]
      ],
      "pytorch-image-models/tests/test_models.py": [
        [
          "test_model_inference",
          129,
          166,
          140,
          10,
          140,
          38,
          129,
          26,
          152,
          88
        ]
      ]
    }
  },
  "CWE-502": {
    "torch.load": {
      "pytorch-image-models/timm/models/_helpers.py": [
        [
          "load_state_dict",
          44,
          87,
          68,
          30,
          68,
          104,
          68,
          41,
          68,
          104
        ],
        [
          "load_state_dict",
          44,
          87,
          70,
          30,
          70,
          77,
          69,
          13,
          70,
          26
        ],
        [
          "resume_checkpoint",
          161,
          213,
          182,
          22,
          182,
          88,
          182,
          22,
          183,
          39
        ]
      ],
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "load_state_dict_from_hf",
          216,
          254,
          251,
          22,
          251,
          91,
          251,
          33,
          251,
          91
        ],
        [
          "load_state_dict_from_hf",
          216,
          254,
          253,
          22,
          253,
          64,
          252,
          5,
          253,
          18
        ],
        [
          "load_state_dict_from_path",
          269,
          299,
          296,
          22,
          296,
          90,
          296,
          33,
          296,
          90
        ],
        [
          "load_state_dict_from_path",
          269,
          299,
          298,
          22,
          298,
          63,
          297,
          5,
          298,
          18
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "checkpoint_metric",
          46,
          58,
          50,
          18,
          50,
          64,
          49,
          5,
          52,
          29
        ]
      ],
      "pytorch-image-models/timm/utils/model_ema.py": [
        [
          "_load_checkpoint",
          52,
          67,
          53,
          22,
          53,
          68,
          52,
          26,
          54,
          43
        ]
      ],
      "pytorch-image-models/timm/models/naflexvit.py": [
        [
          "_load_weights_adapter",
          1272,
          1289,
          1274,
          26,
          1274,
          72,
          1272,
          35,
          1275,
          43
        ]
      ]
    },
    "json.loads": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "load_cfg_from_json",
          140,
          143,
          143,
          12,
          143,
          27,
          140,
          24,
          143,
          27
        ]
      ],
      "pytorch-image-models/bulk_runner.py": [
        [
          "main",
          141,
          231,
          201,
          25,
          201,
          37,
          201,
          36,
          201,
          37
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "_decode",
          135,
          168,
          150,
          16,
          150,
          41,
          150,
          16,
          152,
          26
        ]
      ],
      "pytorch-image-models/timm/data/real_labels.py": [
        [
          "__init__",
          15,
          28,
          20,
          27,
          21,
          111,
          20,
          27,
          20,
          23
        ]
      ]
    },
    "pickle.load": {
      "pytorch-image-models/timm/data/readers/class_map.py": [
        [
          "load_class_map",
          5,
          22,
          19,
          28,
          19,
          41,
          18,
          14,
          19,
          24
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_image_in_tar.py": [
        [
          "extract_tarinfos",
          63,
          169,
          96,
          20,
          96,
          34,
          94,
          9,
          97,
          48
        ]
      ]
    },
    "PIL.Image.open": {
      "pytorch-image-models/timm/data/dataset.py": [
        [
          "__getitem__",
          53,
          80,
          57,
          54,
          57,
          68,
          57,
          65,
          57,
          68
        ]
      ],
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "_decode",
          135,
          168,
          161,
          15,
          161,
          27,
          159,
          11,
          163,
          17
        ]
      ],
      "pytorch-image-models/tests/test_models.py": [
        [
          "test_model_inference",
          129,
          166,
          146,
          20,
          146,
          77,
          129,
          26,
          152,
          88
        ]
      ]
    },
    "pandas.read_csv": {
      "pytorch-image-models/results/generate_csv_results.py": [
        [
          "diff",
          20,
          70,
          23,
          15,
          23,
          35,
          20,
          10,
          31,
          45
        ]
      ]
    },
    "ast.literal_eval": {
      "pytorch-image-models/timm/utils/misc.py": [
        [
          "__call__",
          24,
          32,
          29,
          27,
          29,
          49,
          29,
          44,
          29,
          49
        ]
      ]
    },
    "json.load": {
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "_load_info",
          42,
          63,
          53,
          33,
          53,
          44,
          53,
          43,
          53,
          44
        ]
      ],
      "pytorch-image-models/timm/data/real_labels.py": [
        [
          "__init__",
          15,
          28,
          18,
          31,
          18,
          52,
          17,
          18,
          18,
          27
        ]
      ]
    },
    "yaml.safe_load": {
      "pytorch-image-models/timm/data/readers/reader_wds.py": [
        [
          "_load_info",
          42,
          63,
          55,
          33,
          55,
          49,
          55,
          48,
          55,
          49
        ]
      ],
      "pytorch-image-models/train.py": [
        [
          "_parse_args",
          419,
          433,
          424,
          19,
          424,
          35,
          423,
          14,
          425,
          38
        ]
      ]
    },
    "numpy.load": {
      "pytorch-image-models/timm/models/resnetv2.py": [
        [
          "_load_weights",
          792,
          826,
          801,
          15,
          801,
          38,
          792,
          19,
          807,
          61
        ]
      ],
      "pytorch-image-models/timm/models/vision_transformer.py": [
        [
          "_load_weights",
          1092,
          1243,
          1124,
          13,
          1124,
          36,
          1124,
          13,
          1124,
          9
        ]
      ]
    }
  },
  "CWE-643": {},
  "CWE-760": {
    "hashlib.sha256": {
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "check_cached_file",
          97,
          120,
          116,
          26,
          116,
          49,
          115,
          22,
          117,
          59
        ]
      ],
      "pytorch-image-models/avg_checkpoints.py": [
        [
          "main",
          61,
          148,
          147,
          20,
          147,
          43,
          146,
          10,
          148,
          67
        ]
      ],
      "pytorch-image-models/clean_checkpoint.py": [
        [
          "clean_checkpoint",
          55,
          111,
          94,
          24,
          94,
          47,
          93,
          14,
          96,
          14
        ]
      ],
      "pytorch-image-models/convert/convert_from_mxnet.py": [
        [
          "convert",
          15,
          71,
          68,
          20,
          68,
          43,
          64,
          5,
          71,
          90
        ]
      ]
    }
  },
  "CWE-918": {
    "urllib.parse.urlsplit": {
      "pytorch-image-models/timm/models/_factory.py": [
        [
          "parse_model_name",
          18,
          32,
          23,
          14,
          23,
          33,
          23,
          14,
          24,
          55
        ]
      ]
    },
    "pandas.read_csv": {
      "pytorch-image-models/results/generate_csv_results.py": [
        [
          "diff",
          20,
          70,
          23,
          15,
          23,
          35,
          20,
          10,
          31,
          45
        ]
      ]
    }
  },
  "CWE-943": {},
  "CWE-1333": {
    "str.startswith": {
      "pytorch-image-models/timm/models/_factory.py": [
        [
          "parse_model_name",
          18,
          32,
          20,
          8,
          20,
          38,
          18,
          22,
          20,
          38
        ]
      ],
      "pytorch-image-models/timm/models/_helpers.py": [
        [
          "_remove_prefix",
          23,
          27,
          25,
          8,
          25,
          30,
          23,
          20,
          25,
          30
        ]
      ],
      "pytorch-image-models/timm/utils/distributed.py": [
        [
          "init_distributed_device_so",
          100,
          182,
          173,
          8,
          173,
          33,
          173,
          8,
          173,
          33
        ],
        [
          "init_distributed_device_so",
          100,
          182,
          173,
          8,
          173,
          33,
          166,
          8,
          173,
          33
        ]
      ],
      "pytorch-image-models/timm/data/readers/img_extensions.py": [
        [
          "_valid_extension",
          18,
          19,
          19,
          57,
          19,
          73,
          19,
          57,
          19,
          73
        ]
      ],
      "pytorch-image-models/timm/models/mlp_mixer.py": [
        [
          "_init_weights",
          486,
          523,
          496,
          12,
          496,
          34,
          496,
          12,
          496,
          34
        ]
      ],
      "pytorch-image-models/timm/models/nest.py": [
        [
          "_init_nest_weights",
          510,
          525,
          515,
          12,
          515,
          34,
          515,
          12,
          515,
          34
        ]
      ],
      "pytorch-image-models/timm/models/sequencer.py": [
        [
          "_init_weights",
          26,
          56,
          28,
          12,
          28,
          34,
          28,
          12,
          28,
          34
        ]
      ],
      "pytorch-image-models/timm/models/vision_transformer_relpos.py": [
        [
          "__init__",
          223,
          348,
          303,
          12,
          303,
          41,
          300,
          13,
          303,
          41
        ]
      ],
      "pytorch-image-models/timm/models/vision_transformer.py": [
        [
          "init_weights_vit_jax",
          1013,
          1034,
          1022,
          12,
          1022,
          34,
          1022,
          12,
          1022,
          34
        ]
      ],
      "pytorch-image-models/timm/layers/weight_init.py": [
        [
          "init_weight_vit",
          128,
          144,
          136,
          12,
          136,
          43,
          136,
          12,
          136,
          43
        ],
        [
          "init_weight_jax",
          147,
          166,
          154,
          12,
          154,
          43,
          154,
          12,
          154,
          43
        ]
      ]
    },
    "re.split": {
      "pytorch-image-models/timm/models/_efficientnet_builder.py": [
        [
          "_decode_block_str",
          81,
          229,
          137,
          22,
          137,
          44,
          137,
          22,
          138,
          31
        ]
      ],
      "pytorch-image-models/timm/models/_registry.py": [
        [
          "_natural_key",
          171,
          173,
          173,
          51,
          173,
          85,
          171,
          18,
          173,
          86
        ]
      ],
      "pytorch-image-models/timm/data/auto_augment.py": [
        [
          "auto_augment_transform",
          586,
          618,
          608,
          14,
          608,
          35,
          607,
          9,
          609,
          22
        ],
        [
          "rand_augment_transform",
          762,
          843,
          807,
          18,
          807,
          39,
          807,
          18,
          808,
          26
        ],
        [
          "augment_and_mix_transform",
          951,
          1000,
          979,
          14,
          979,
          35,
          978,
          9,
          980,
          22
        ]
      ],
      "pytorch-image-models/timm/utils/misc.py": [
        [
          "natural_key",
          10,
          12,
          12,
          51,
          12,
          85,
          10,
          17,
          12,
          86
        ]
      ]
    },
    "str.endswith": {
      "pytorch-image-models/timm/models/_helpers.py": [
        [
          "load_state_dict",
          44,
          87,
          63,
          12,
          63,
          56,
          63,
          12,
          63,
          56
        ]
      ],
      "pytorch-image-models/timm/models/_hub.py": [
        [
          "_get_safe_alternatives",
          530,
          542,
          541,
          73,
          541,
          97,
          541,
          73,
          541,
          97
        ]
      ],
      "pytorch-image-models/timm/models/_registry.py": [
        [
          "generate_default_cfgs",
          43,
          72,
          54,
          50,
          54,
          66,
          54,
          50,
          54,
          66
        ]
      ]
    },
    "re.compile": {
      "pytorch-image-models/timm/models/_manipulate.py": [
        [
          "group_with_matcher",
          79,
          137,
          95,
          35,
          95,
          54,
          94,
          21,
          95,
          28
        ],
        [
          "group_with_matcher",
          79,
          137,
          97,
          31,
          97,
          47,
          97,
          17,
          97,
          24
        ]
      ],
      "pytorch-image-models/timm/utils/attention_extract.py": [
        [
          "listcomp",
          48,
          48,
          48,
          28,
          48,
          40,
          48,
          46,
          48,
          40
        ],
        [
          "listcomp",
          65,
          65,
          65,
          28,
          65,
          40,
          65,
          46,
          65,
          40
        ]
      ],
      "pytorch-image-models/timm/models/densenet.py": [
        [
          "_filter_torchvision_pretrained",
          417,
          435,
          426,
          15,
          427,
          105,
          417,
          36,
          429,
          38
        ]
      ],
      "pytorch-image-models/timm/models/pit.py": [
        [
          "checkpoint_filter_fn",
          360,
          371,
          363,
          16,
          363,
          43,
          360,
          26,
          364,
          34
        ]
      ],
      "pytorch-image-models/timm/models/vision_transformer.py": [
        [
          "_convert_beit3",
          1325,
          1382,
          1367,
          11,
          1367,
          74,
          1366,
          16,
          1368,
          27
        ]
      ]
    },
    "fnmatch.fnmatch": {
      "pytorch-image-models/timm/optim/_optim_factory.py": [
        [
          "genexpr",
          147,
          147,
          147,
          59,
          147,
          71,
          147,
          45,
          147,
          71
        ],
        [
          "listcomp",
          152,
          152,
          152,
          50,
          152,
          75,
          152,
          32,
          152,
          75
        ]
      ],
      "pytorch-image-models/timm/utils/attention_extract.py": [
        [
          "listcomp",
          51,
          51,
          51,
          58,
          51,
          78,
          51,
          84,
          51,
          78
        ],
        [
          "listcomp",
          68,
          68,
          68,
          60,
          68,
          80,
          68,
          86,
          68,
          80
        ]
      ],
      "pytorch-image-models/timm/utils/model.py": [
        [
          "register_hook",
          86,
          90,
          88,
          20,
          88,
          53,
          87,
          13,
          88,
          53
        ]
      ],
      "pytorch-image-models/tests/test_models.py": [
        [
          "listcomp",
          275,
          275,
          275,
          22,
          275,
          51,
          275,
          57,
          275,
          51
        ]
      ]
    },
    "re.sub": {
      "pytorch-image-models/timm/models/convnext.py": [
        [
          "checkpoint_filter_fn",
          605,
          644,
          628,
          13,
          628,
          74,
          626,
          9,
          632,
          21
        ],
        [
          "checkpoint_filter_fn",
          605,
          644,
          629,
          13,
          629,
          89,
          626,
          9,
          632,
          21
        ]
      ],
      "pytorch-image-models/timm/models/byobnet.py": [
        [
          "_convert_openai_clip",
          2195,
          2235,
          2220,
          13,
          2220,
          67,
          2220,
          13,
          2224,
          44
        ],
        [
          "_convert_openai_clip",
          2195,
          2235,
          2221,
          13,
          2221,
          63,
          2220,
          13,
          2224,
          44
        ],
        [
          "_convert_openai_clip",
          2195,
          2235,
          2222,
          13,
          2222,
          86,
          2220,
          13,
          2224,
          44
        ],
        [
          "_convert_openai_clip",
          2195,
          2235,
          2223,
          13,
          2223,
          89,
          2220,
          13,
          2224,
          44
        ]
      ],
      "pytorch-image-models/timm/models/davit.py": [
        [
          "_convert_florence2",
          727,
          752,
          736,
          13,
          736,
          65,
          733,
          17,
          750,
          19
        ],
        [
          "_convert_florence2",
          727,
          752,
          737,
          13,
          737,
          62,
          733,
          17,
          750,
          19
        ],
        [
          "checkpoint_filter_fn",
          755,
          778,
          769,
          13,
          769,
          72,
          768,
          9,
          777,
          19
        ],
        [
          "checkpoint_filter_fn",
          755,
          778,
          770,
          13,
          770,
          67,
          768,
          9,
          777,
          19
        ]
      ],
      "pytorch-image-models/timm/models/edgenext.py": [
        [
          "checkpoint_filter_fn",
          516,
          544,
          533,
          13,
          533,
          74,
          531,
          9,
          538,
          32
        ],
        [
          "checkpoint_filter_fn",
          516,
          544,
          534,
          13,
          534,
          89,
          531,
          9,
          538,
          32
        ]
      ],
      "pytorch-image-models/timm/models/efficientformer.py": [
        [
          "checkpoint_filter_fn",
          559,
          583,
          576,
          13,
          576,
          79,
          576,
          13,
          582,
          19
        ],
        [
          "checkpoint_filter_fn",
          559,
          583,
          577,
          13,
          577,
          83,
          576,
          13,
          582,
          19
        ],
        [
          "checkpoint_filter_fn",
          559,
          583,
          578,
          13,
          578,
          83,
          576,
          13,
          582,
          19
        ],
        [
          "checkpoint_filter_fn",
          559,
          583,
          580,
          13,
          580,
          60,
          576,
          13,
          582,
          19
        ]
      ],
      "pytorch-image-models/timm/models/focalnet.py": [
        [
          "checkpoint_filter_fn",
          603,
          621,
          611,
          13,
          611,
          54,
          610,
          9,
          614,
          22
        ],
        [
          "checkpoint_filter_fn",
          603,
          621,
          613,
          13,
          613,
          103,
          610,
          9,
          614,
          22
        ],
        [
          "checkpoint_filter_fn",
          603,
          621,
          615,
          17,
          615,
          57,
          615,
          17,
          615,
          13
        ]
      ],
      "pytorch-image-models/timm/models/fastvit.py": [
        [
          "checkpoint_filter_fn",
          1465,
          1538,
          1508,
          13,
          1508,
          70,
          1499,
          13,
          1509,
          36
        ]
      ],
      "pytorch-image-models/timm/data/imagenet_info.py": [
        [
          "__init__",
          50,
          67,
          52,
          18,
          52,
          54,
          50,
          18,
          53,
          33
        ]
      ],
      "pytorch-image-models/timm/models/mambaout.py": [
        [
          "checkpoint_filter_fn",
          497,
          519,
          507,
          13,
          507,
          74,
          505,
          9,
          510,
          32
        ],
        [
          "checkpoint_filter_fn",
          497,
          519,
          508,
          13,
          508,
          77,
          505,
          9,
          510,
          32
        ]
      ],
      "pytorch-image-models/timm/models/metaformer.py": [
        [
          "checkpoint_filter_fn",
          683,
          717,
          693,
          17,
          693,
          74,
          693,
          17,
          700,
          13
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          702,
          13,
          702,
          77,
          702,
          13,
          713,
          41
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          705,
          13,
          705,
          60,
          702,
          13,
          713,
          41
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          710,
          13,
          710,
          42,
          702,
          13,
          713,
          41
        ],
        [
          "checkpoint_filter_fn",
          683,
          717,
          711,
          13,
          711,
          44,
          702,
          13,
          713,
          41
        ]
      ],
      "pytorch-image-models/timm/models/mvitv2.py": [
        [
          "checkpoint_filter_fn",
          944,
          988,
          975,
          13,
          978,
          14,
          974,
          9,
          980,
          22
        ],
        [
          "checkpoint_filter_fn",
          944,
          988,
          981,
          17,
          981,
          107,
          981,
          17,
          981,
          13
        ],
        [
          "checkpoint_filter_fn",
          944,
          988,
          983,
          17,
          983,
          106,
          983,
          17,
          983,
          13
        ]
      ],
      "pytorch-image-models/timm/models/pvt_v2.py": [
        [
          "checkpoint_filter_fn",
          463,
          480,
          477,
          13,
          477,
          105,
          476,
          13,
          479,
          19
        ],
        [
          "checkpoint_filter_fn",
          463,
          480,
          478,
          13,
          478,
          84,
          476,
          13,
          479,
          19
        ]
      ],
      "pytorch-image-models/timm/models/regnet.py": [
        [
          "_filter_fn",
          851,
          913,
          885,
          17,
          887,
          74,
          882,
          13,
          889,
          32
        ],
        [
          "_filter_fn",
          851,
          913,
          888,
          17,
          888,
          73,
          882,
          13,
          889,
          32
        ],
        [
          "_filter_fn",
          851,
          913,
          905,
          17,
          907,
          74,
          902,
          13,
          908,
          32
        ]
      ],
      "pytorch-image-models/timm/models/sequencer.py": [
        [
          "checkpoint_filter_fn",
          441,
          456,
          451,
          13,
          451,
          114,
          450,
          9,
          454,
          19
        ],
        [
          "checkpoint_filter_fn",
          441,
          456,
          452,
          13,
          452,
          74,
          450,
          9,
          454,
          19
        ]
      ],
      "pytorch-image-models/timm/models/swiftformer.py": [
        [
          "checkpoint_filter_fn",
          525,
          548,
          537,
          13,
          537,
          69,
          531,
          9,
          539,
          12
        ]
      ],
      "pytorch-image-models/timm/models/swin_transformer.py": [
        [
          "checkpoint_filter_fn",
          929,
          975,
          971,
          17,
          971,
          107,
          970,
          12,
          974,
          19
        ]
      ],
      "pytorch-image-models/timm/models/swin_transformer_v2.py": [
        [
          "checkpoint_filter_fn",
          972,
          1011,
          1007,
          17,
          1007,
          107,
          1007,
          17,
          1008,
          13
        ]
      ],
      "pytorch-image-models/timm/models/tresnet.py": [
        [
          "checkpoint_filter_fn",
          317,
          336,
          326,
          13,
          326,
          81,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          327,
          13,
          327,
          79,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          328,
          13,
          328,
          79,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          329,
          13,
          329,
          77,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          330,
          13,
          330,
          94,
          325,
          9,
          332,
          34
        ],
        [
          "checkpoint_filter_fn",
          317,
          336,
          331,
          13,
          331,
          92,
          325,
          9,
          332,
          34
        ]
      ],
      "pytorch-image-models/timm/models/vision_transformer.py": [
        [
          "_convert_beit3",
          1325,
          1382,
          1358,
          17,
          1358,
          35,
          1357,
          13,
          1358,
          13
        ],
        [
          "checkpoint_filter_fn",
          1385,
          1461,
          1456,
          17,
          1456,
          58,
          1456,
          17,
          1456,
          13
        ]
      ]
    },
    "re.match": {
      "pytorch-image-models/timm/models/efficientformer.py": [
        [
          "checkpoint_filter_fn",
          559,
          583,
          574,
          12,
          574,
          55,
          574,
          12,
          574,
          55
        ]
      ],
      "pytorch-image-models/timm/models/fastvit.py": [
        [
          "checkpoint_filter_fn",
          1465,
          1538,
          1486,
          17,
          1486,
          60,
          1485,
          9,
          1487,
          16
        ],
        [
          "checkpoint_filter_fn",
          1465,
          1538,
          1522,
          17,
          1522,
          47,
          1522,
          17,
          1524,
          16
        ]
      ],
      "pytorch-image-models/timm/models/swiftformer.py": [
        [
          "checkpoint_filter_fn",
          525,
          548,
          538,
          13,
          538,
          49,
          531,
          9,
          539,
          12
        ]
      ],
      "pytorch-image-models/timm/models/vision_transformer.py": [
        [
          "_convert_dinov2",
          1284,
          1304,
          1297,
          12,
          1297,
          67,
          1296,
          9,
          1297,
          67
        ],
        [
          "_convert_dinov2",
          1284,
          1304,
          1300,
          14,
          1300,
          68,
          1300,
          14,
          1300,
          68
        ]
      ]
    }
  }
}