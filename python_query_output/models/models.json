{
  "CWE-022": {
    "os.path.splitext": {
      "models/research/marco/Automated_Marco.py": [
        [
          "listcomp",
          41,
          41,
          41,
          100,
          41,
          118,
          41,
          82,
          41,
          151
        ]
      ],
      "models/research/object_detection/dataset_tools/create_oid_tf_record.py": [
        [
          "listcomp",
          87,
          87,
          87,
          20,
          87,
          56,
          87,
          65,
          87,
          59
        ]
      ],
      "models/research/efficient-hrl/eval.py": [
        [
          "dictcomp",
          439,
          441,
          441,
          9,
          441,
          27,
          442,
          13,
          441,
          30
        ]
      ],
      "models/research/delf/delf/python/examples/extract_boxes.py": [
        [
          "main",
          130,
          182,
          161,
          30,
          161,
          75,
          161,
          30,
          164,
          45
        ]
      ],
      "models/research/delf/delf/python/examples/extract_features.py": [
        [
          "main",
          65,
          112,
          95,
          25,
          96,
          24,
          95,
          25,
          98,
          44
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/mask_bbox_saver.py": [
        [
          "save_cropped_objects",
          170,
          224,
          219,
          17,
          219,
          48,
          203,
          9,
          222,
          57
        ]
      ],
      "models/official/legacy/bert/run_squad_helper.py": [
        [
          "predict_squad",
          390,
          416,
          412,
          29,
          413,
          51,
          412,
          21,
          412,
          17
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "create_folders_from_video_name",
          75,
          98,
          89,
          25,
          89,
          52,
          75,
          36,
          93,
          31
        ]
      ]
    },
    "os.path.join": {
      "models/research/marco/Automated_Marco.py": [
        [
          "listcomp",
          41,
          41,
          41,
          19,
          41,
          37,
          41,
          19,
          41,
          37
        ]
      ],
      "models/official/core/actions.py": [
        [
          "__init__",
          85,
          113,
          105,
          18,
          105,
          60,
          105,
          18,
          109,
          28
        ]
      ],
      "models/official/projects/videoglue/datasets/action_localization.py": [
        [
          "__init__",
          46,
          58,
          55,
          18,
          55,
          67,
          55,
          18,
          58,
          28
        ]
      ],
      "models/official/core/actions_test.py": [
        [
          "test_ema_checkpointing",
          50,
          85,
          72,
          28,
          72,
          69,
          50,
          30,
          84,
          9
        ],
        [
          "test_ema_checkpointing",
          50,
          85,
          76,
          15,
          76,
          56,
          50,
          30,
          84,
          9
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py": [
        [
          "test_beam_pipeline",
          335,
          363,
          340,
          25,
          340,
          65,
          335,
          26,
          359,
          35
        ],
        [
          "test_beam_pipeline_sequence_example",
          365,
          395,
          370,
          25,
          370,
          65,
          365,
          43,
          390,
          35
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/aggregation_extraction.py": [
        [
          "ExtractAggregatedRepresentationsToFiles",
          74,
          193,
          145,
          35,
          146,
          77,
          141,
          18,
          147,
          54
        ],
        [
          "ExtractAggregatedRepresentationsToFiles",
          74,
          193,
          160,
          25,
          161,
          72,
          159,
          11,
          165,
          39
        ],
        [
          "ExtractAggregatedRepresentationsToFiles",
          74,
          193,
          173,
          29,
          174,
          70,
          173,
          29,
          177,
          33
        ]
      ],
      "models/research/cognitive_planning/envs/active_vision_dataset_env.py": [
        [
          "_get_detection_path",
          152,
          153,
          153,
          10,
          153,
          74,
          152,
          25,
          153,
          74
        ],
        [
          "_get_image_folder",
          156,
          157,
          157,
          10,
          157,
          45,
          156,
          23,
          157,
          45
        ],
        [
          "_get_json_path",
          160,
          161,
          161,
          10,
          161,
          54,
          160,
          20,
          161,
          54
        ],
        [
          "_get_image_path",
          164,
          165,
          165,
          10,
          165,
          72,
          164,
          21,
          165,
          72
        ],
        [
          "read_all_poses",
          186,
          226,
          203,
          10,
          203,
          63,
          186,
          20,
          214,
          25
        ],
        [
          "read_cached_data",
          229,
          302,
          249,
          27,
          250,
          66,
          229,
          22,
          262,
          27
        ],
        [
          "read_cached_data",
          229,
          302,
          256,
          22,
          256,
          70,
          229,
          22,
          262,
          27
        ],
        [
          "read_cached_data",
          229,
          302,
          274,
          15,
          275,
          59,
          272,
          47,
          281,
          26
        ],
        [
          "read_cached_data",
          229,
          302,
          291,
          18,
          291,
          60,
          291,
          18,
          296,
          45
        ],
        [
          "read_cached_data",
          229,
          302,
          298,
          22,
          298,
          73,
          298,
          8,
          302,
          20
        ],
        [
          "__init__",
          315,
          510,
          459,
          26,
          460,
          74,
          458,
          31,
          464,
          31
        ]
      ],
      "models/official/core/base_trainer_test.py": [
        [
          "test_export_best_ckpt",
          329,
          347,
          347,
          28,
          347,
          76,
          329,
          29,
          347,
          78
        ]
      ],
      "models/official/projects/basnet/configs/basnet.py": [
        [
          "basnet_duts",
          100,
          161,
          117,
          26,
          118,
          56,
          101,
          3,
          161,
          15
        ],
        [
          "basnet_duts",
          100,
          161,
          126,
          26,
          127,
          55,
          101,
          3,
          161,
          15
        ]
      ],
      "models/research/delf/delf/python/box_io_test.py": [
        [
          "testWriteAndReadToFile",
          60,
          69,
          63,
          16,
          63,
          60,
          60,
          30,
          69,
          52
        ],
        [
          "testWriteAndReadToFileEmptyFile",
          71,
          78,
          72,
          16,
          72,
          58,
          71,
          39,
          78,
          51
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/boxes_and_features_extraction.py": [
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          130,
          43,
          131,
          58,
          129,
          18,
          139,
          46
        ],
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          132,
          27,
          133,
          67,
          129,
          18,
          139,
          46
        ],
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          170,
          35,
          171,
          74,
          169,
          20,
          175,
          52
        ]
      ],
      "models/research/deeplab/datasets/build_ade20k_data.py": [
        [
          "_convert_dataset",
          58,
          112,
          70,
          29,
          70,
          62,
          58,
          22,
          73,
          20
        ],
        [
          "_convert_dataset",
          58,
          112,
          77,
          11,
          77,
          58,
          73,
          7,
          78,
          25
        ],
        [
          "_convert_dataset",
          58,
          112,
          87,
          23,
          89,
          76,
          86,
          7,
          93,
          40
        ]
      ],
      "models/research/deeplab/datasets/build_cityscapes_data.py": [
        [
          "_get_files",
          111,
          134,
          131,
          18,
          132,
          73,
          130,
          13,
          134,
          26
        ],
        [
          "_convert_dataset",
          137,
          188,
          163,
          23,
          163,
          68,
          160,
          7,
          167,
          40
        ]
      ],
      "models/research/deeplab/datasets/build_voc2012_data.py": [
        [
          "_convert_dataset",
          89,
          136,
          108,
          23,
          110,
          70,
          107,
          7,
          114,
          40
        ],
        [
          "_convert_dataset",
          89,
          136,
          119,
          26,
          120,
          72,
          114,
          11,
          129,
          31
        ],
        [
          "_convert_dataset",
          89,
          136,
          124,
          24,
          126,
          52,
          114,
          11,
          129,
          31
        ],
        [
          "main",
          139,
          142,
          140,
          34,
          140,
          73,
          139,
          10,
          141,
          37
        ]
      ],
      "models/research/delf/delf/python/training/build_image_dataset.py": [
        [
          "_get_all_image_files_and_labels",
          98,
          124,
          113,
          34,
          113,
          65,
          98,
          37,
          115,
          25
        ],
        [
          "_get_clean_train_image_files_and_labels",
          127,
          175,
          156,
          34,
          156,
          65,
          156,
          17,
          157,
          31
        ],
        [
          "_write_tfrecord",
          253,
          286,
          276,
          19,
          278,
          69,
          275,
          7,
          281,
          54
        ],
        [
          "_write_relabeling_rules",
          289,
          302,
          296,
          26,
          297,
          55,
          289,
          29,
          301,
          56
        ]
      ],
      "models/official/legacy/image_classification/callbacks.py": [
        [
          "get_callbacks",
          30,
          80,
          46,
          22,
          46,
          70,
          46,
          22,
          49,
          63
        ],
        [
          "get_callbacks",
          30,
          80,
          51,
          18,
          51,
          47,
          51,
          18,
          53,
          69
        ],
        [
          "get_callbacks",
          30,
          80,
          71,
          22,
          72,
          59,
          71,
          22,
          79,
          45
        ]
      ],
      "models/research/slim/datasets/build_imagenet_data.py": [
        [
          "_process_image_files_batch",
          341,
          410,
          377,
          19,
          377,
          71,
          373,
          7,
          382,
          27
        ]
      ],
      "models/research/object_detection/utils/category_util_test.py": [
        [
          "test_load_categories_from_csv_file",
          31,
          44,
          37,
          16,
          37,
          60,
          31,
          42,
          44,
          60
        ],
        [
          "test_save_categories_to_csv_file",
          46,
          55,
          52,
          16,
          52,
          60,
          46,
          40,
          55,
          50
        ]
      ],
      "models/official/projects/centernet/configs/centernet.py": [
        [
          "centernet_hourglass_coco",
          190,
          246,
          198,
          27,
          199,
          64,
          191,
          3,
          246,
          15
        ],
        [
          "centernet_hourglass_coco",
          190,
          246,
          202,
          26,
          202,
          69,
          191,
          3,
          246,
          15
        ],
        [
          "centernet_hourglass_coco",
          190,
          246,
          208,
          26,
          208,
          67,
          191,
          3,
          246,
          15
        ]
      ],
      "models/research/slim/datasets/cifar10.py": [
        [
          "get_split",
          43,
          97,
          65,
          18,
          65,
          69,
          65,
          18,
          68,
          15
        ]
      ],
      "models/official/nlp/data/classifier_data_lib_test.py": [
        [
          "test_generate_dataset_from_tfds_processor",
          61,
          91,
          63,
          21,
          63,
          59,
          61,
          49,
          91,
          7
        ]
      ],
      "models/official/legacy/image_classification/classifier_trainer_test.py": [
        [
          "test_gpu_train",
          153,
          183,
          170,
          19,
          170,
          51,
          153,
          22,
          183,
          48
        ]
      ],
      "models/official/legacy/image_classification/classifier_trainer_util_test.py": [
        [
          "test_resume_from_checkpoint",
          120,
          152,
          135,
          13,
          135,
          61,
          120,
          35,
          152,
          33
        ],
        [
          "test_serialize_config",
          154,
          161,
          159,
          25,
          159,
          62,
          154,
          29,
          161,
          33
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/cluster_delf_features.py": [
        [
          "main",
          69,
          168,
          102,
          25,
          102,
          78,
          101,
          25,
          104,
          25
        ]
      ],
      "models/official/legacy/image_classification/classifier_trainer.py": [
        [
          "serialize_config",
          279,
          284,
          281,
          22,
          281,
          59,
          279,
          22,
          284,
          64
        ]
      ],
      "models/official/nlp/data/classifier_data_lib.py": [
        [
          "get_train_examples",
          244,
          245,
          245,
          34,
          245,
          64,
          244,
          26,
          245,
          65
        ],
        [
          "get_dev_examples",
          247,
          248,
          248,
          34,
          248,
          63,
          247,
          24,
          248,
          64
        ],
        [
          "_create_examples",
          255,
          273,
          259,
          17,
          259,
          45,
          258,
          9,
          260,
          50
        ],
        [
          "_create_examples",
          255,
          273,
          267,
          16,
          267,
          46,
          267,
          16,
          272,
          73
        ],
        [
          "get_train_examples",
          385,
          405,
          395,
          26,
          395,
          68,
          394,
          7,
          395,
          74
        ],
        [
          "get_dev_examples",
          407,
          422,
          412,
          26,
          412,
          67,
          410,
          9,
          412,
          73
        ],
        [
          "get_test_examples",
          424,
          436,
          428,
          30,
          428,
          72,
          427,
          9,
          429,
          37
        ],
        [
          "get_train_examples",
          798,
          818,
          805,
          15,
          806,
          62,
          801,
          9,
          806,
          68
        ],
        [
          "get_dev_examples",
          820,
          833,
          822,
          28,
          822,
          65,
          820,
          24,
          824,
          35
        ],
        [
          "get_test_examples",
          835,
          849,
          837,
          28,
          837,
          66,
          835,
          25,
          839,
          35
        ],
        [
          "get_train_examples",
          882,
          907,
          886,
          30,
          886,
          67,
          886,
          15,
          887,
          37
        ],
        [
          "get_train_examples",
          882,
          907,
          897,
          13,
          898,
          53,
          895,
          11,
          899,
          39
        ],
        [
          "get_dev_examples",
          909,
          932,
          913,
          30,
          913,
          65,
          913,
          15,
          914,
          37
        ],
        [
          "get_dev_examples",
          909,
          932,
          923,
          32,
          923,
          72,
          922,
          11,
          924,
          39
        ],
        [
          "get_test_examples",
          934,
          963,
          939,
          30,
          939,
          71,
          937,
          9,
          940,
          37
        ],
        [
          "get_test_examples",
          934,
          963,
          953,
          13,
          954,
          58,
          951,
          42,
          955,
          39
        ],
        [
          "get_train_examples",
          999,
          1029,
          1001,
          28,
          1001,
          65,
          999,
          26,
          1004,
          39
        ],
        [
          "get_train_examples",
          999,
          1029,
          1017,
          13,
          1018,
          53,
          1015,
          11,
          1019,
          39
        ],
        [
          "get_dev_examples",
          1031,
          1056,
          1035,
          30,
          1035,
          65,
          1035,
          15,
          1036,
          37
        ],
        [
          "get_dev_examples",
          1031,
          1056,
          1045,
          32,
          1045,
          72,
          1044,
          11,
          1046,
          39
        ],
        [
          "get_test_examples",
          1058,
          1087,
          1063,
          30,
          1063,
          71,
          1061,
          9,
          1064,
          37
        ],
        [
          "get_test_examples",
          1058,
          1087,
          1077,
          13,
          1078,
          58,
          1075,
          42,
          1079,
          39
        ],
        [
          "get_test_examples",
          1206,
          1209,
          1209,
          26,
          1209,
          61,
          1206,
          25,
          1209,
          71
        ]
      ],
      "models/research/object_detection/metrics/coco_tools_test.py": [
        [
          "testExportGroundtruthToCOCO",
          81,
          103,
          89,
          19,
          89,
          74,
          81,
          35,
          103,
          52
        ],
        [
          "testExportDetectionsToCOCO",
          105,
          129,
          114,
          19,
          114,
          73,
          105,
          34,
          129,
          52
        ],
        [
          "testExportSegmentsToCOCO",
          131,
          161,
          148,
          19,
          148,
          71,
          142,
          25,
          161,
          52
        ],
        [
          "testExportKeypointsToCOCO",
          163,
          193,
          181,
          19,
          181,
          72,
          163,
          33,
          193,
          52
        ]
      ],
      "models/official/vision/evaluation/coco_utils_test.py": [
        [
          "test_scan_and_generator_annotation_file",
          28,
          50,
          34,
          17,
          34,
          68,
          28,
          47,
          50,
          5
        ],
        [
          "test_scan_and_generator_annotation_file",
          28,
          50,
          38,
          23,
          38,
          76,
          28,
          47,
          50,
          5
        ]
      ],
      "models/official/legacy/image_classification/resnet/common.py": [
        [
          "get_callbacks",
          119,
          148,
          144,
          24,
          144,
          72,
          144,
          24,
          147,
          54
        ]
      ],
      "models/research/lstm_object_detection/utils/config_util_test.py": [
        [
          "test_get_configs_from_pipeline_file",
          40,
          68,
          42,
          28,
          42,
          79,
          40,
          43,
          68,
          30
        ],
        [
          "test_create_pipeline_proto_from_configs",
          70,
          90,
          72,
          28,
          72,
          79,
          70,
          47,
          90,
          68
        ]
      ],
      "models/research/object_detection/utils/config_util.py": [
        [
          "save_pipeline_config",
          240,
          255,
          250,
          26,
          250,
          67,
          250,
          26,
          255,
          24
        ]
      ],
      "models/research/object_detection/utils/config_util_test.py": [
        [
          "_create_and_load_test_configs",
          86,
          89,
          87,
          28,
          87,
          79,
          86,
          37,
          89,
          75
        ],
        [
          "test_get_configs_from_pipeline_file",
          91,
          113,
          93,
          28,
          93,
          79,
          91,
          43,
          113,
          57
        ],
        [
          "test_create_pipeline_proto_from_configs",
          135,
          150,
          137,
          28,
          137,
          79,
          135,
          47,
          150,
          68
        ],
        [
          "test_save_pipeline_config",
          152,
          167,
          163,
          9,
          163,
          60,
          152,
          33,
          167,
          68
        ],
        [
          "test_get_configs_from_multiple_files",
          169,
          214,
          174,
          25,
          174,
          62,
          169,
          44,
          214,
          79
        ],
        [
          "test_get_configs_from_multiple_files",
          169,
          214,
          180,
          25,
          180,
          62,
          169,
          44,
          214,
          79
        ],
        [
          "test_get_configs_from_multiple_files",
          169,
          214,
          186,
          31,
          186,
          74,
          169,
          44,
          214,
          79
        ],
        [
          "test_get_configs_from_multiple_files",
          169,
          214,
          192,
          24,
          192,
          60,
          169,
          44,
          214,
          79
        ],
        [
          "test_get_configs_from_multiple_files",
          169,
          214,
          198,
          30,
          198,
          72,
          169,
          44,
          214,
          79
        ],
        [
          "_assertOptimizerWithNewLearningRate",
          216,
          284,
          222,
          28,
          222,
          79,
          216,
          43,
          264,
          52
        ],
        [
          "testGenericConfigOverride",
          302,
          335,
          313,
          28,
          313,
          79,
          302,
          33,
          335,
          79
        ],
        [
          "testNewBatchSize",
          338,
          351,
          342,
          28,
          342,
          79,
          338,
          24,
          351,
          40
        ],
        [
          "testNewBatchSizeWithClipping",
          354,
          367,
          358,
          28,
          358,
          79,
          354,
          36,
          367,
          39
        ],
        [
          "testOverwriteSampleFromDatasetWeights",
          381,
          397,
          386,
          28,
          386,
          79,
          381,
          45,
          397,
          73
        ],
        [
          "testOverwriteSampleFromDatasetWeightsWrongLength",
          400,
          417,
          405,
          28,
          405,
          79,
          400,
          56,
          417,
          70
        ],
        [
          "testNewMomentumOptimizerValue",
          440,
          455,
          444,
          28,
          444,
          79,
          440,
          37,
          455,
          51
        ],
        [
          "testNewClassificationLocalizationWeightRatio",
          458,
          478,
          465,
          28,
          465,
          79,
          458,
          52,
          478,
          72
        ],
        [
          "testNewFocalLossParameters",
          481,
          503,
          489,
          28,
          489,
          79,
          481,
          34,
          503,
          76
        ],
        [
          "testMergingKeywordArguments",
          505,
          520,
          509,
          28,
          509,
          79,
          505,
          35,
          520,
          58
        ],
        [
          "testGetNumberOfClasses",
          522,
          531,
          524,
          28,
          524,
          79,
          522,
          30,
          531,
          43
        ],
        [
          "testNewTrainInputPath",
          533,
          550,
          537,
          28,
          537,
          79,
          533,
          29,
          550,
          50
        ],
        [
          "testNewTrainInputPathList",
          552,
          569,
          556,
          28,
          556,
          79,
          552,
          33,
          569,
          48
        ],
        [
          "testNewLabelMapPath",
          571,
          591,
          575,
          28,
          575,
          79,
          571,
          27,
          590,
          58
        ],
        [
          "testDontOverwriteEmptyLabelMapPath",
          593,
          613,
          597,
          28,
          597,
          79,
          593,
          42,
          613,
          69
        ],
        [
          "testNewMaskType",
          615,
          633,
          619,
          28,
          619,
          79,
          615,
          23,
          633,
          79
        ],
        [
          "testUseMovingAverageForEval",
          635,
          647,
          637,
          28,
          637,
          79,
          635,
          35,
          647,
          70
        ],
        [
          "testEvalShuffle",
          700,
          714,
          705,
          28,
          705,
          79,
          700,
          23,
          714,
          79
        ],
        [
          "testTrainShuffle",
          716,
          731,
          721,
          28,
          721,
          79,
          716,
          24,
          731,
          52
        ],
        [
          "testOverWriteRetainOriginalImages",
          733,
          751,
          738,
          28,
          738,
          79,
          733,
          41,
          751,
          76
        ],
        [
          "testOverwriteAllEvalSampling",
          753,
          771,
          757,
          28,
          757,
          79,
          753,
          36,
          769,
          58
        ],
        [
          "testOverwriteAllEvalNumEpochs",
          773,
          788,
          777,
          28,
          777,
          79,
          773,
          37,
          787,
          58
        ],
        [
          "testUpdateMaskTypeForAllInputConfigs",
          790,
          813,
          794,
          28,
          794,
          79,
          790,
          44,
          812,
          58
        ],
        [
          "testErrorOverwritingMultipleInputConfig",
          815,
          832,
          818,
          28,
          818,
          79,
          815,
          47,
          831,
          13
        ],
        [
          "testCheckAndParseInputConfigKey",
          834,
          887,
          835,
          28,
          835,
          79,
          834,
          39,
          887,
          66
        ],
        [
          "testUpdateInputReaderConfigSuccess",
          889,
          912,
          892,
          28,
          892,
          79,
          889,
          42,
          912,
          72
        ],
        [
          "testUpdateInputReaderConfigErrors",
          914,
          947,
          915,
          28,
          915,
          79,
          914,
          41,
          947,
          22
        ],
        [
          "testOverWriteRetainOriginalImageAdditionalChannels",
          949,
          970,
          954,
          28,
          954,
          79,
          949,
          58,
          970,
          63
        ],
        [
          "testUpdateNumClasses",
          972,
          986,
          973,
          28,
          973,
          79,
          972,
          28,
          986,
          76
        ],
        [
          "testUpdateRescoreInstances",
          1021,
          1038,
          1022,
          28,
          1022,
          79,
          1021,
          34,
          1038,
          71
        ],
        [
          "testUpdateRescoreInstancesWithBooleanString",
          1040,
          1057,
          1041,
          28,
          1041,
          79,
          1040,
          51,
          1057,
          71
        ],
        [
          "testUpdateRescoreInstancesWithMultipleTasks",
          1059,
          1080,
          1060,
          28,
          1060,
          79,
          1059,
          51,
          1080,
          70
        ]
      ],
      "models/research/cvt_text/base/configure.py": [
        [
          "__init__",
          30,
          132,
          107,
          28,
          107,
          58,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          108,
          30,
          112,
          50,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          113,
          39,
          115,
          35,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          117,
          37,
          117,
          76,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          118,
          27,
          119,
          76,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          120,
          28,
          120,
          75,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          121,
          28,
          121,
          75,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          123,
          22,
          123,
          67,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          124,
          28,
          124,
          62,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          125,
          23,
          125,
          67,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          126,
          39,
          127,
          49,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          128,
          34,
          129,
          59,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          130,
          21,
          130,
          62,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          131,
          26,
          131,
          58,
          103,
          20,
          132,
          21
        ],
        [
          "__init__",
          30,
          132,
          132,
          25,
          132,
          59,
          103,
          20,
          132,
          21
        ],
        [
          "write",
          134,
          138,
          136,
          15,
          136,
          49,
          134,
          13,
          138,
          49
        ]
      ],
      "models/official/projects/const_cl/tasks/const_cl_test.py": [
        [
          "setUp",
          36,
          49,
          38,
          16,
          38,
          56,
          36,
          13,
          49,
          75
        ],
        [
          "setUp",
          36,
          49,
          40,
          23,
          40,
          61,
          36,
          13,
          49,
          75
        ]
      ],
      "models/official/nlp/continuous_finetune_lib_test.py": [
        [
          "setUp",
          38,
          40,
          40,
          23,
          40,
          68,
          38,
          13,
          40,
          19
        ],
        [
          "testContinuousFinetune",
          42,
          94,
          94,
          30,
          94,
          72,
          42,
          30,
          94,
          74
        ]
      ],
      "models/official/nlp/continuous_finetune_lib.py": [
        [
          "run_continuous_finetune",
          72,
          217,
          127,
          7,
          127,
          37,
          126,
          20,
          145,
          28
        ]
      ],
      "models/orbit/controller_test.py": [
        [
          "summaries_with_matching_keyword",
          39,
          48,
          42,
          34,
          42,
          69,
          39,
          37,
          43,
          67
        ],
        [
          "test_no_checkpoint",
          255,
          284,
          263,
          21,
          263,
          67,
          255,
          26,
          284,
          67
        ],
        [
          "test_no_checkpoint",
          255,
          284,
          264,
          26,
          264,
          71,
          255,
          26,
          284,
          67
        ],
        [
          "test_no_checkpoint",
          255,
          284,
          270,
          29,
          270,
          75,
          255,
          26,
          284,
          67
        ],
        [
          "test_no_checkpoint",
          255,
          284,
          273,
          21,
          273,
          67,
          255,
          26,
          284,
          67
        ],
        [
          "test_no_checkpoint",
          255,
          284,
          275,
          29,
          275,
          74,
          255,
          26,
          284,
          67
        ],
        [
          "test_no_checkpoint",
          255,
          284,
          278,
          26,
          278,
          71,
          255,
          26,
          284,
          67
        ],
        [
          "test_has_checkpoint_no_summaries",
          303,
          326,
          326,
          9,
          326,
          62,
          303,
          40,
          326,
          64
        ],
        [
          "test_has_checkpoint_eval_summary_only",
          332,
          360,
          349,
          26,
          349,
          71,
          333,
          7,
          360,
          65
        ],
        [
          "test_has_checkpoint_eval_summary_only",
          332,
          360,
          357,
          9,
          357,
          62,
          333,
          7,
          360,
          65
        ],
        [
          "test_has_checkpoint_eval_summary_only",
          332,
          360,
          360,
          9,
          360,
          63,
          333,
          7,
          360,
          65
        ],
        [
          "test_restore_from_most_recent_checkpoint",
          366,
          387,
          382,
          26,
          382,
          71,
          367,
          7,
          387,
          71
        ],
        [
          "test_train_and_evaluate",
          395,
          433,
          413,
          21,
          413,
          67,
          396,
          7,
          433,
          73
        ],
        [
          "test_train_and_evaluate",
          395,
          433,
          416,
          26,
          416,
          71,
          396,
          7,
          433,
          73
        ],
        [
          "test_train_and_evaluate",
          395,
          433,
          421,
          42,
          421,
          78,
          396,
          7,
          433,
          73
        ],
        [
          "test_train_and_evaluate",
          395,
          433,
          425,
          29,
          425,
          75,
          396,
          7,
          433,
          73
        ],
        [
          "test_train_and_evaluate",
          395,
          433,
          428,
          21,
          428,
          67,
          396,
          7,
          433,
          73
        ],
        [
          "test_train_and_evaluate",
          395,
          433,
          430,
          29,
          430,
          74,
          396,
          7,
          433,
          73
        ],
        [
          "test_train_and_evaluate",
          395,
          433,
          433,
          26,
          433,
          71,
          396,
          7,
          433,
          73
        ],
        [
          "test_train_only",
          439,
          471,
          454,
          21,
          454,
          67,
          439,
          23,
          471,
          75
        ],
        [
          "test_train_only",
          439,
          471,
          457,
          26,
          457,
          71,
          439,
          23,
          471,
          75
        ],
        [
          "test_train_only",
          439,
          471,
          462,
          42,
          462,
          78,
          439,
          23,
          471,
          75
        ],
        [
          "test_train_only",
          439,
          471,
          466,
          29,
          466,
          75,
          439,
          23,
          471,
          75
        ],
        [
          "test_train_only",
          439,
          471,
          469,
          21,
          469,
          67,
          439,
          23,
          471,
          75
        ],
        [
          "test_train_only",
          439,
          471,
          471,
          28,
          471,
          73,
          439,
          23,
          471,
          75
        ],
        [
          "test_evaluate_only",
          473,
          516,
          477,
          21,
          477,
          56,
          473,
          26,
          516,
          52
        ],
        [
          "test_evaluate_only",
          473,
          516,
          487,
          21,
          487,
          67,
          473,
          26,
          516,
          52
        ],
        [
          "test_evaluate_only",
          473,
          516,
          488,
          26,
          488,
          71,
          473,
          26,
          516,
          52
        ],
        [
          "test_evaluate_only",
          473,
          516,
          493,
          28,
          493,
          74,
          473,
          26,
          516,
          52
        ],
        [
          "test_evaluate_only",
          473,
          516,
          495,
          29,
          495,
          74,
          473,
          26,
          516,
          52
        ],
        [
          "test_evaluate_only",
          473,
          516,
          498,
          26,
          498,
          71,
          473,
          26,
          516,
          52
        ],
        [
          "test_evaluate_only",
          473,
          516,
          502,
          17,
          502,
          67,
          473,
          26,
          516,
          52
        ],
        [
          "test_evaluate_only",
          473,
          516,
          513,
          26,
          513,
          71,
          473,
          26,
          516,
          52
        ],
        [
          "test_no_eval_steps",
          518,
          532,
          522,
          21,
          522,
          56,
          518,
          26,
          532,
          30
        ],
        [
          "test_summaries_inside_train_fn",
          559,
          589,
          573,
          21,
          573,
          67,
          559,
          38,
          589,
          75
        ],
        [
          "test_summaries_inside_train_fn",
          559,
          589,
          580,
          39,
          580,
          75,
          559,
          38,
          589,
          75
        ],
        [
          "test_summaries_inside_train_fn",
          559,
          589,
          584,
          29,
          584,
          75,
          559,
          38,
          589,
          75
        ],
        [
          "test_summaries_inside_train_fn",
          559,
          589,
          587,
          21,
          587,
          67,
          559,
          38,
          589,
          75
        ],
        [
          "test_summaries_inside_train_fn",
          559,
          589,
          589,
          28,
          589,
          73,
          559,
          38,
          589,
          75
        ],
        [
          "test_train_and_evaluate_with_same_summary_dir",
          591,
          620,
          606,
          21,
          606,
          61,
          591,
          53,
          620,
          68
        ],
        [
          "test_train_and_evaluate_with_same_summary_dir",
          591,
          620,
          608,
          26,
          608,
          66,
          591,
          53,
          620,
          68
        ],
        [
          "test_train_and_evaluate_with_same_summary_dir",
          591,
          620,
          614,
          29,
          614,
          69,
          591,
          53,
          620,
          68
        ],
        [
          "test_train_and_evaluate_with_same_summary_dir",
          591,
          620,
          617,
          21,
          617,
          61,
          591,
          53,
          620,
          68
        ],
        [
          "test_train_and_evaluate_with_same_summary_dir",
          591,
          620,
          620,
          26,
          620,
          66,
          591,
          53,
          620,
          68
        ],
        [
          "test_evaluate_with_loss_output",
          664,
          683,
          668,
          21,
          668,
          56,
          664,
          38,
          683,
          73
        ],
        [
          "test_evaluate_with_loss_output",
          664,
          683,
          675,
          26,
          675,
          71,
          664,
          38,
          683,
          73
        ],
        [
          "test_evaluate_with_loss_output",
          664,
          683,
          680,
          29,
          680,
          74,
          664,
          38,
          683,
          73
        ],
        [
          "test_evaluate_with_loss_output",
          664,
          683,
          683,
          26,
          683,
          71,
          664,
          38,
          683,
          73
        ],
        [
          "test_evaluate_with_no_output",
          685,
          691,
          689,
          26,
          689,
          71,
          685,
          36,
          691,
          69
        ],
        [
          "test_eval_and_checkpoint_interval",
          719,
          746,
          743,
          26,
          743,
          69,
          719,
          41,
          746,
          72
        ],
        [
          "test_evaluate_with_nested_summaries",
          750,
          782,
          767,
          29,
          767,
          67,
          759,
          23,
          782,
          66
        ],
        [
          "test_evaluate_with_nested_summaries",
          750,
          782,
          770,
          21,
          770,
          59,
          759,
          23,
          782,
          66
        ],
        [
          "test_evaluate_with_nested_summaries",
          750,
          782,
          773,
          25,
          773,
          63,
          759,
          23,
          782,
          66
        ],
        [
          "test_evaluate_with_nested_summaries",
          750,
          782,
          776,
          29,
          776,
          68,
          759,
          23,
          782,
          66
        ],
        [
          "test_evaluate_with_nested_summaries",
          750,
          782,
          779,
          21,
          779,
          60,
          759,
          23,
          782,
          66
        ],
        [
          "test_evaluate_with_nested_summaries",
          750,
          782,
          782,
          25,
          782,
          64,
          759,
          23,
          782,
          66
        ],
        [
          "test_actions",
          784,
          828,
          814,
          21,
          814,
          67,
          784,
          20,
          821,
          47
        ],
        [
          "test_actions",
          784,
          828,
          816,
          26,
          816,
          71,
          784,
          20,
          821,
          47
        ]
      ],
      "models/official/projects/unified_detector/data_conversion/convert.py": [
        [
          "main",
          44,
          61,
          58,
          25,
          59,
          69,
          57,
          11,
          61,
          36
        ]
      ],
      "models/official/projects/movinet/tools/convert_3d_2plus1d_test.py": [
        [
          "test_convert_model",
          31,
          57,
          33,
          29,
          33,
          72,
          31,
          26,
          57,
          76
        ],
        [
          "test_convert_model",
          31,
          57,
          34,
          30,
          34,
          67,
          31,
          26,
          57,
          76
        ]
      ],
      "models/research/object_detection/models/keras_models/convert_keras_models.py": [
        [
          "main",
          61,
          80,
          65,
          10,
          65,
          53,
          61,
          10,
          71,
          25
        ],
        [
          "main",
          61,
          80,
          67,
          18,
          67,
          46,
          61,
          10,
          71,
          25
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py": [
        [
          "_write_random_images_to_directory",
          46,
          53,
          53,
          22,
          53,
          51,
          47,
          9,
          53,
          60
        ],
        [
          "_create_json_file",
          55,
          85,
          82,
          17,
          82,
          57,
          82,
          17,
          85,
          20
        ]
      ],
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "listcomp",
          162,
          164,
          162,
          22,
          164,
          25,
          164,
          31,
          164,
          25
        ],
        [
          "_download_data",
          451,
          479,
          462,
          16,
          463,
          58,
          457,
          5,
          467,
          41
        ],
        [
          "_download_data",
          451,
          479,
          468,
          18,
          469,
          56,
          467,
          9,
          474,
          18
        ],
        [
          "_download_data",
          451,
          479,
          471,
          27,
          471,
          77,
          467,
          9,
          474,
          18
        ],
        [
          "_download_data",
          451,
          479,
          476,
          36,
          478,
          58,
          476,
          17,
          479,
          27
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record_test.py": [
        [
          "test_create_tf_example",
          51,
          123,
          55,
          17,
          55,
          54,
          51,
          30,
          123,
          23
        ],
        [
          "test_create_tf_example_with_instance_masks",
          125,
          204,
          129,
          17,
          129,
          54,
          125,
          50,
          204,
          77
        ],
        [
          "test_create_tf_example_with_keypoints",
          206,
          311,
          211,
          17,
          211,
          56,
          206,
          45,
          229,
          22
        ],
        [
          "test_create_tf_example_with_dense_pose",
          313,
          437,
          318,
          17,
          318,
          56,
          313,
          46,
          336,
          22
        ],
        [
          "test_create_sharded_tf_record",
          439,
          493,
          444,
          19,
          444,
          51,
          442,
          9,
          446,
          27
        ],
        [
          "test_create_sharded_tf_record",
          439,
          493,
          481,
          23,
          481,
          62,
          449,
          9,
          493,
          68
        ],
        [
          "test_create_sharded_tf_record",
          439,
          493,
          485,
          19,
          485,
          53,
          449,
          9,
          493,
          68
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py": [
        [
          "process",
          80,
          225,
          104,
          17,
          104,
          61,
          80,
          15,
          108,
          13
        ]
      ],
      "models/official/vision/data/create_coco_tf_record.py": [
        [
          "listcomp",
          305,
          305,
          305,
          19,
          305,
          51,
          305,
          57,
          305,
          51
        ],
        [
          "create_tf_example",
          254,
          361,
          319,
          17,
          319,
          49,
          318,
          18,
          319,
          13
        ],
        [
          "create_tf_example",
          254,
          361,
          342,
          30,
          344,
          41,
          341,
          21,
          352,
          29
        ]
      ],
      "models/research/object_detection/dataset_tools/create_kitti_tf_record.py": [
        [
          "convert_kitti_to_tfrecords",
          72,
          135,
          98,
          20,
          100,
          42,
          72,
          32,
          113,
          24
        ],
        [
          "convert_kitti_to_tfrecords",
          72,
          135,
          102,
          15,
          105,
          37,
          72,
          32,
          113,
          24
        ],
        [
          "convert_kitti_to_tfrecords",
          72,
          135,
          116,
          37,
          117,
          78,
          113,
          7,
          127,
          24
        ],
        [
          "convert_kitti_to_tfrecords",
          72,
          135,
          119,
          18,
          119,
          50,
          113,
          7,
          127,
          24
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record.py": [
        [
          "create_tf_example",
          112,
          359,
          171,
          15,
          171,
          47,
          112,
          23,
          206,
          44
        ],
        [
          "main",
          476,
          515,
          486,
          23,
          486,
          73,
          486,
          23,
          515,
          20
        ],
        [
          "main",
          476,
          515,
          487,
          21,
          487,
          69,
          486,
          23,
          515,
          20
        ],
        [
          "main",
          476,
          515,
          488,
          25,
          488,
          77,
          486,
          23,
          515,
          20
        ]
      ],
      "models/research/object_detection/dataset_tools/create_kitti_tf_record_test.py": [
        [
          "test_dict_to_tf_example",
          40,
          128,
          43,
          17,
          43,
          66,
          40,
          31,
          128,
          12
        ]
      ],
      "models/research/object_detection/dataset_tools/create_oid_tf_record.py": [
        [
          "main",
          66,
          113,
          86,
          7,
          86,
          57,
          85,
          16,
          99,
          76
        ],
        [
          "main",
          66,
          113,
          105,
          20,
          105,
          80,
          99,
          9,
          111,
          19
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pascal_tf_record_test.py": [
        [
          "test_dict_to_tf_example",
          40,
          117,
          43,
          17,
          43,
          66,
          40,
          31,
          117,
          20
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pascal_tf_record.py": [
        [
          "dict_to_tf_example",
          59,
          144,
          86,
          15,
          86,
          55,
          59,
          24,
          91,
          27
        ],
        [
          "dict_to_tf_example",
          59,
          144,
          85,
          14,
          85,
          79,
          59,
          24,
          91,
          27
        ],
        [
          "main",
          147,
          181,
          164,
          21,
          165,
          67,
          162,
          7,
          168,
          48
        ],
        [
          "main",
          147,
          181,
          166,
          23,
          166,
          73,
          162,
          7,
          168,
          48
        ],
        [
          "main",
          147,
          181,
          171,
          14,
          171,
          60,
          171,
          14,
          179,
          50
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "dict_to_tf_example",
          76,
          211,
          108,
          14,
          108,
          63,
          76,
          24,
          113,
          27
        ],
        [
          "create_tf_record",
          214,
          265,
          242,
          18,
          242,
          72,
          242,
          18,
          245,
          37
        ],
        [
          "create_tf_record",
          214,
          265,
          243,
          19,
          243,
          76,
          242,
          18,
          245,
          37
        ],
        [
          "main",
          269,
          314,
          274,
          15,
          274,
          46,
          269,
          10,
          292,
          25
        ],
        [
          "main",
          269,
          314,
          275,
          21,
          275,
          57,
          269,
          10,
          292,
          25
        ],
        [
          "main",
          269,
          314,
          276,
          19,
          276,
          63,
          269,
          10,
          292,
          25
        ],
        [
          "main",
          269,
          314,
          290,
          23,
          290,
          78,
          269,
          10,
          292,
          25
        ],
        [
          "main",
          269,
          314,
          291,
          21,
          291,
          74,
          269,
          10,
          292,
          25
        ],
        [
          "main",
          269,
          314,
          293,
          25,
          294,
          77,
          293,
          25,
          295,
          19
        ],
        [
          "main",
          269,
          314,
          295,
          23,
          296,
          73,
          293,
          25,
          295,
          19
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data_test.py": [
        [
          "_create_files",
          32,
          44,
          39,
          19,
          39,
          54,
          38,
          7,
          41,
          30
        ]
      ],
      "models/official/recommendation/ranking/preprocessing/criteo_preprocess.py": [
        [
          "apply_vocab_fn",
          121,
          144,
          140,
          16,
          141,
          73,
          139,
          7,
          142,
          16
        ],
        [
          "transform_data",
          220,
          303,
          244,
          29,
          244,
          71,
          244,
          9,
          252,
          20
        ],
        [
          "transform_data",
          220,
          303,
          245,
          26,
          245,
          57,
          244,
          9,
          252,
          20
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data.py": [
        [
          "create_tfrecords",
          586,
          693,
          660,
          17,
          660,
          48,
          644,
          5,
          661,
          32
        ],
        [
          "create_tfrecords",
          586,
          693,
          689,
          26,
          689,
          61,
          679,
          9,
          693,
          32
        ],
        [
          "create_tfrecords",
          586,
          693,
          689,
          26,
          689,
          61,
          677,
          6,
          693,
          32
        ]
      ],
      "models/research/deeplab/datasets/data_generator.py": [
        [
          "_get_all_files",
          341,
          350,
          348,
          20,
          349,
          63,
          341,
          22,
          350,
          38
        ]
      ],
      "models/official/legacy/transformer/data_pipeline.py": [
        [
          "train_input_fn",
          292,
          306,
          294,
          18,
          294,
          66,
          294,
          57,
          295,
          33
        ],
        [
          "eval_input_fn",
          309,
          323,
          311,
          18,
          311,
          64,
          311,
          57,
          312,
          33
        ]
      ],
      "models/official/recommendation/data_preprocessing.py": [
        [
          "instantiate_pipeline",
          202,
          265,
          226,
          21,
          226,
          75,
          202,
          26,
          233,
          31
        ],
        [
          "instantiate_pipeline",
          202,
          265,
          227,
          16,
          227,
          69,
          202,
          26,
          233,
          31
        ]
      ],
      "models/official/legacy/transformer/data_download.py": [
        [
          "find_file",
          93,
          103,
          97,
          14,
          97,
          41,
          97,
          14,
          97,
          41
        ],
        [
          "download_from_url",
          151,
          175,
          164,
          16,
          164,
          43,
          164,
          16,
          172,
          19
        ],
        [
          "compile_files",
          226,
          256,
          242,
          25,
          243,
          73,
          226,
          19,
          249,
          46
        ],
        [
          "compile_files",
          226,
          256,
          244,
          26,
          245,
          74,
          226,
          19,
          249,
          46
        ],
        [
          "shard_filename",
          321,
          324,
          323,
          10,
          324,
          75,
          321,
          20,
          324,
          75
        ],
        [
          "main",
          376,
          414,
          393,
          16,
          393,
          55,
          376,
          10,
          399,
          36
        ]
      ],
      "models/research/autoaugment/data_utils.py": [
        [
          "__init__",
          37,
          134,
          85,
          22,
          85,
          55,
          84,
          11,
          86,
          22
        ]
      ],
      "models/official/recommendation/data_pipeline.py": [
        [
          "current_data_root",
          105,
          109,
          109,
          12,
          109,
          49,
          107,
          9,
          109,
          49
        ],
        [
          "start_construction",
          232,
          239,
          235,
          18,
          235,
          76,
          234,
          7,
          236,
          19
        ],
        [
          "get_dataset",
          274,
          335,
          295,
          22,
          296,
          68,
          295,
          22,
          307,
          13
        ]
      ],
      "models/official/recommendation/data_test.py": [
        [
          "setUp",
          59,
          95,
          62,
          22,
          62,
          62,
          59,
          13,
          83,
          63
        ],
        [
          "setUp",
          59,
          95,
          78,
          24,
          78,
          75,
          59,
          13,
          83,
          63
        ],
        [
          "test_preprocessing",
          111,
          120,
          115,
          18,
          115,
          70,
          111,
          26,
          119,
          50
        ]
      ],
      "models/research/adversarial_text/data/data_utils.py": [
        [
          "write_vocab_and_frequency",
          325,
          332,
          328,
          13,
          328,
          49,
          325,
          31,
          330,
          43
        ],
        [
          "write_vocab_and_frequency",
          325,
          332,
          329,
          15,
          329,
          56,
          325,
          31,
          330,
          43
        ]
      ],
      "models/official/projects/triviaqa/dataset.py": [
        [
          "_wiki_evidence_dir",
          75,
          76,
          76,
          27,
          76,
          67,
          75,
          24,
          76,
          68
        ],
        [
          "_web_evidence_dir",
          71,
          72,
          72,
          27,
          72,
          66,
          71,
          23,
          72,
          67
        ],
        [
          "_split_generators",
          281,
          331,
          292,
          9,
          292,
          69,
          292,
          9,
          292,
          69
        ],
        [
          "_split_generators",
          281,
          331,
          294,
          9,
          294,
          44,
          294,
          9,
          294,
          44
        ],
        [
          "_split_generators",
          281,
          331,
          295,
          36,
          295,
          75,
          292,
          9,
          300,
          26
        ],
        [
          "_split_generators",
          281,
          331,
          297,
          9,
          297,
          53,
          292,
          9,
          300,
          26
        ],
        [
          "_split_generators",
          281,
          331,
          298,
          35,
          298,
          73,
          292,
          9,
          300,
          26
        ],
        [
          "_split_generators",
          281,
          331,
          304,
          26,
          304,
          74,
          304,
          26,
          305,
          23
        ],
        [
          "_split_generators",
          281,
          331,
          305,
          27,
          305,
          76,
          304,
          26,
          305,
          23
        ],
        [
          "_add_context",
          409,
          426,
          420,
          32,
          420,
          60,
          420,
          45,
          420,
          60
        ]
      ],
      "models/research/object_detection/builders/dataset_builder_test.py": [
        [
          "_get_labelmap_path",
          51,
          55,
          54,
          10,
          55,
          44,
          52,
          3,
          55,
          44
        ],
        [
          "create_tf_record",
          60,
          113,
          80,
          14,
          80,
          55,
          79,
          9,
          83,
          44
        ],
        [
          "create_tf_record",
          60,
          113,
          113,
          12,
          113,
          62,
          113,
          12,
          113,
          62
        ],
        [
          "create_tf_record_sequence_example",
          129,
          164,
          130,
          12,
          130,
          60,
          129,
          41,
          164,
          15
        ],
        [
          "setUp",
          502,
          517,
          503,
          27,
          503,
          78,
          502,
          13,
          505,
          21
        ],
        [
          "setUp",
          502,
          517,
          510,
          35,
          511,
          64,
          510,
          35,
          512,
          21
        ]
      ],
      "models/research/delf/delf/python/datasets/sfm120k/dataset_download.py": [
        [
          "download_train",
          22,
          103,
          38,
          18,
          38,
          48,
          38,
          18,
          39,
          41
        ],
        [
          "download_train",
          22,
          103,
          44,
          13,
          44,
          67,
          43,
          13,
          46,
          36
        ],
        [
          "download_train",
          22,
          103,
          47,
          16,
          47,
          51,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          48,
          16,
          48,
          51,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          59,
          17,
          59,
          71,
          59,
          17,
          61,
          37
        ],
        [
          "download_train",
          22,
          103,
          60,
          13,
          60,
          66,
          59,
          17,
          61,
          37
        ],
        [
          "download_train",
          22,
          103,
          62,
          26,
          62,
          72,
          61,
          6,
          66,
          36
        ],
        [
          "download_train",
          22,
          103,
          72,
          15,
          72,
          49,
          71,
          7,
          73,
          38
        ],
        [
          "download_train",
          22,
          103,
          87,
          18,
          87,
          57,
          86,
          9,
          89,
          37
        ],
        [
          "download_train",
          22,
          103,
          88,
          18,
          88,
          57,
          86,
          9,
          89,
          37
        ],
        [
          "download_train",
          22,
          103,
          95,
          29,
          95,
          68,
          95,
          29,
          96,
          48
        ],
        [
          "download_train",
          22,
          103,
          99,
          31,
          99,
          70,
          98,
          13,
          103,
          62
        ],
        [
          "download_train",
          22,
          103,
          100,
          31,
          101,
          61,
          98,
          13,
          103,
          62
        ]
      ],
      "models/official/legacy/xlnet/data_utils.py": [
        [
          "get_squad_input_data",
          204,
          243,
          225,
          18,
          227,
          80,
          225,
          18,
          229,
          22
        ],
        [
          "get_pretrain_input_data",
          579,
          683,
          632,
          19,
          632,
          60,
          631,
          7,
          640,
          40
        ],
        [
          "get_pretrain_input_data",
          579,
          683,
          650,
          22,
          650,
          55,
          648,
          9,
          651,
          40
        ]
      ],
      "models/research/delf/delf/python/datasets/revisited_op/dataset.py": [
        [
          "_ConfigImname",
          503,
          504,
          504,
          12,
          504,
          73,
          503,
          21,
          504,
          73
        ],
        [
          "_ConfigQimname",
          506,
          507,
          507,
          12,
          507,
          75,
          506,
          22,
          507,
          75
        ],
        [
          "CreateConfigForTestDataset",
          477,
          535,
          513,
          15,
          513,
          66,
          513,
          15,
          517,
          26
        ],
        [
          "CreateConfigForTestDataset",
          477,
          535,
          524,
          21,
          524,
          42,
          522,
          16,
          535,
          12
        ],
        [
          "CreateConfigForTestDataset",
          477,
          535,
          525,
          23,
          525,
          63,
          522,
          16,
          535,
          12
        ]
      ],
      "models/research/delf/delf/python/datasets/google_landmarks_dataset/dataset_file_io_test.py": [
        [
          "testReadRecognitionSolutionWorks",
          33,
          62,
          35,
          17,
          35,
          75,
          33,
          40,
          62,
          55
        ],
        [
          "testReadRetrievalSolutionWorks",
          64,
          93,
          66,
          17,
          66,
          73,
          64,
          38,
          93,
          55
        ],
        [
          "testReadRecognitionPredictionsWorks",
          95,
          130,
          97,
          17,
          97,
          78,
          95,
          43,
          130,
          71
        ],
        [
          "testReadRetrievalPredictionsWorks",
          132,
          162,
          134,
          17,
          134,
          76,
          132,
          41,
          162,
          71
        ]
      ],
      "models/research/object_detection/utils/dataset_util_test.py": [
        [
          "test_read_examples_list",
          30,
          37,
          32,
          25,
          32,
          73,
          30,
          31,
          37,
          60
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "collect_frames",
          55,
          67,
          61,
          28,
          61,
          73,
          60,
          9,
          66,
          80
        ],
        [
          "load_image_raw",
          101,
          123,
          104,
          16,
          104,
          59,
          101,
          22,
          111,
          23
        ],
        [
          "collect_train_frames",
          204,
          229,
          208,
          18,
          208,
          53,
          207,
          9,
          210,
          25
        ],
        [
          "collect_train_frames",
          204,
          229,
          211,
          21,
          211,
          46,
          210,
          11,
          212,
          35
        ],
        [
          "collect_train_frames",
          204,
          229,
          216,
          23,
          216,
          69,
          215,
          15,
          218,
          38
        ],
        [
          "load_pose_raw",
          298,
          306,
          300,
          17,
          301,
          47,
          298,
          21,
          306,
          15
        ],
        [
          "load_image_raw",
          308,
          313,
          310,
          16,
          311,
          54,
          308,
          22,
          313,
          14
        ],
        [
          "load_intrinsics_raw",
          315,
          321,
          317,
          18,
          317,
          77,
          315,
          27,
          321,
          21
        ],
        [
          "collect_test_frames",
          361,
          369,
          364,
          17,
          364,
          73,
          363,
          9,
          367,
          32
        ],
        [
          "collect_test_frames",
          361,
          369,
          365,
          17,
          365,
          48,
          363,
          9,
          367,
          32
        ],
        [
          "collect_test_frames",
          361,
          369,
          366,
          34,
          366,
          63,
          363,
          9,
          367,
          32
        ],
        [
          "collect_train_frames",
          371,
          379,
          374,
          17,
          374,
          73,
          373,
          9,
          377,
          32
        ],
        [
          "collect_train_frames",
          371,
          379,
          375,
          17,
          375,
          48,
          373,
          9,
          377,
          32
        ],
        [
          "load_image",
          430,
          434,
          431,
          16,
          432,
          68,
          430,
          18,
          434,
          14
        ],
        [
          "load_intrinsics",
          436,
          441,
          437,
          18,
          438,
          53,
          436,
          23,
          441,
          21
        ],
        [
          "collect_frames",
          496,
          505,
          497,
          15,
          497,
          75,
          496,
          22,
          500,
          25
        ],
        [
          "collect_frames",
          496,
          505,
          501,
          29,
          501,
          64,
          500,
          9,
          502,
          24
        ],
        [
          "load_intrinsics",
          514,
          533,
          517,
          19,
          518,
          67,
          514,
          23,
          528,
          23
        ],
        [
          "is_valid_example",
          535,
          548,
          543,
          24,
          545,
          65,
          540,
          9,
          546,
          43
        ],
        [
          "load_image_sequence",
          550,
          572,
          559,
          24,
          561,
          65,
          556,
          9,
          563,
          25
        ]
      ],
      "models/research/rebar/datasets.py": [
        [
          "read_MNIST",
          42,
          61,
          54,
          24,
          54,
          76,
          42,
          16,
          57,
          17
        ],
        [
          "read_MNIST",
          42,
          61,
          58,
          26,
          58,
          74,
          58,
          10,
          59,
          13
        ],
        [
          "read_omniglot",
          63,
          99,
          80,
          31,
          80,
          76,
          63,
          19,
          86,
          13
        ]
      ],
      "models/research/delf/delf/python/datasets/revisited_op/dataset_test.py": [
        [
          "testSaveMetricsFileWorks",
          200,
          232,
          212,
          19,
          212,
          64,
          200,
          32,
          232,
          47
        ],
        [
          "testSaveAndReadMetricsWorks",
          234,
          263,
          246,
          19,
          246,
          64,
          234,
          35,
          263,
          76
        ],
        [
          "testReadMetricsWithRepeatedProtocolFails",
          265,
          284,
          267,
          18,
          267,
          63,
          265,
          48,
          284,
          41
        ]
      ],
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "write_label_file",
          165,
          179,
          175,
          21,
          175,
          55,
          165,
          22,
          177,
          38
        ],
        [
          "download_url",
          105,
          127,
          116,
          14,
          116,
          48,
          105,
          18,
          127,
          17
        ],
        [
          "download_and_uncompress_zipfile",
          141,
          162,
          149,
          14,
          149,
          48,
          141,
          37,
          151,
          30
        ],
        [
          "download_and_uncompress_zipfile",
          141,
          162,
          159,
          20,
          159,
          52,
          158,
          9,
          161,
          40
        ],
        [
          "has_labels",
          182,
          192,
          192,
          26,
          192,
          60,
          182,
          16,
          192,
          61
        ],
        [
          "read_label_file",
          195,
          215,
          205,
          21,
          205,
          55,
          195,
          21,
          212,
          19
        ]
      ],
      "models/research/delf/delf/python/datum_io_test.py": [
        [
          "testWriteAndReadToFile",
          72,
          78,
          75,
          16,
          75,
          60,
          72,
          30,
          78,
          40
        ],
        [
          "testWriteAndReadPairToFile",
          83,
          93,
          89,
          16,
          89,
          65,
          83,
          34,
          93,
          44
        ]
      ],
      "models/official/legacy/image_classification/dataset_factory.py": [
        [
          "load_records",
          362,
          375,
          369,
          22,
          370,
          66,
          369,
          22,
          371,
          13
        ]
      ],
      "models/research/object_detection/builders/decoder_builder_test.py": [
        [
          "_get_labelmap_path",
          34,
          38,
          37,
          10,
          38,
          44,
          35,
          3,
          38,
          44
        ]
      ],
      "models/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn.py": [
        [
          "deep_mask_head_rcnn_resnetfpn_coco",
          51,
          114,
          63,
          27,
          64,
          64,
          52,
          3,
          114,
          15
        ],
        [
          "deep_mask_head_rcnn_resnetfpn_coco",
          51,
          114,
          69,
          26,
          70,
          47,
          52,
          3,
          114,
          15
        ],
        [
          "deep_mask_head_rcnn_resnetfpn_coco",
          51,
          114,
          76,
          26,
          77,
          45,
          52,
          3,
          114,
          15
        ],
        [
          "deep_mask_head_rcnn_spinenet_coco",
          118,
          198,
          128,
          27,
          129,
          64,
          119,
          3,
          198,
          15
        ],
        [
          "deep_mask_head_rcnn_spinenet_coco",
          118,
          198,
          149,
          26,
          150,
          47,
          119,
          3,
          198,
          15
        ],
        [
          "deep_mask_head_rcnn_spinenet_coco",
          118,
          198,
          156,
          26,
          157,
          45,
          119,
          3,
          198,
          15
        ]
      ],
      "models/research/attention_ocr/python/demo_inference_test.py": [
        [
          "setUp",
          14,
          24,
          23,
          31,
          24,
          60,
          22,
          24,
          23,
          27
        ]
      ],
      "models/research/object_detection/core/densepose_ops.py": [
        [
          "__init__",
          264,
          304,
          269,
          9,
          270,
          50,
          264,
          16,
          279,
          46
        ]
      ],
      "models/research/object_detection/inference/detection_inference_tf1_test.py": [
        [
          "get_mock_tfrecord_path",
          31,
          32,
          32,
          10,
          32,
          59,
          32,
          10,
          32,
          59
        ],
        [
          "get_mock_graph_path",
          54,
          55,
          55,
          10,
          55,
          62,
          55,
          10,
          55,
          62
        ]
      ],
      "models/official/vision/serving/detection_test.py": [
        [
          "test_export",
          112,
          157,
          126,
          36,
          126,
          74,
          113,
          7,
          148,
          41
        ],
        [
          "test_export",
          112,
          157,
          128,
          24,
          128,
          76,
          113,
          7,
          148,
          41
        ],
        [
          "test_export",
          112,
          157,
          131,
          13,
          132,
          57,
          113,
          7,
          148,
          41
        ]
      ],
      "models/official/projects/deepmac_maskrcnn/serving/detection_test.py": [
        [
          "test_export",
          72,
          109,
          79,
          36,
          79,
          74,
          72,
          19,
          98,
          42
        ],
        [
          "test_export",
          72,
          109,
          81,
          24,
          81,
          76,
          72,
          19,
          98,
          42
        ],
        [
          "test_export",
          72,
          109,
          84,
          13,
          85,
          57,
          72,
          19,
          98,
          42
        ],
        [
          "test_export_image_and_boxes",
          117,
          160,
          123,
          36,
          123,
          74,
          117,
          35,
          145,
          42
        ],
        [
          "test_export_image_and_boxes",
          117,
          160,
          125,
          24,
          125,
          76,
          117,
          35,
          145,
          42
        ],
        [
          "test_export_image_and_boxes",
          117,
          160,
          128,
          13,
          129,
          57,
          117,
          35,
          145,
          42
        ]
      ],
      "models/official/projects/detr/configs/detr.py": [
        [
          "detr_coco_tfrecord",
          153,
          213,
          164,
          27,
          165,
          64,
          154,
          3,
          213,
          15
        ],
        [
          "detr_coco_tfrecord",
          153,
          213,
          171,
          26,
          171,
          69,
          154,
          3,
          213,
          15
        ],
        [
          "detr_coco_tfrecord",
          153,
          213,
          177,
          26,
          177,
          67,
          154,
          3,
          213,
          15
        ]
      ],
      "models/official/projects/mobilebert/distillation_test.py": [
        [
          "prepare_config",
          36,
          138,
          134,
          25,
          134,
          79,
          119,
          17,
          138,
          21
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "convert_audio_and_split_transcript",
          87,
          153,
          117,
          16,
          117,
          51,
          87,
          40,
          120,
          39
        ],
        [
          "convert_audio_and_split_transcript",
          87,
          153,
          118,
          16,
          118,
          51,
          87,
          40,
          120,
          39
        ],
        [
          "convert_audio_and_split_transcript",
          87,
          153,
          129,
          20,
          129,
          47,
          128,
          9,
          131,
          23
        ],
        [
          "convert_audio_and_split_transcript",
          87,
          153,
          139,
          23,
          139,
          57,
          131,
          13,
          141,
          45
        ],
        [
          "convert_audio_and_split_transcript",
          87,
          153,
          140,
          22,
          140,
          61,
          131,
          13,
          141,
          45
        ],
        [
          "convert_audio_and_split_transcript",
          87,
          153,
          149,
          19,
          149,
          55,
          149,
          19,
          153,
          74
        ],
        [
          "download_and_process_datasets",
          156,
          172,
          168,
          19,
          168,
          50,
          166,
          7,
          172,
          55
        ]
      ],
      "models/research/adversarial_text/data/document_generators.py": [
        [
          "imdb_documents",
          158,
          219,
          197,
          32,
          197,
          68,
          196,
          7,
          197,
          69
        ],
        [
          "imdb_documents",
          158,
          219,
          202,
          17,
          202,
          63,
          202,
          12,
          209,
          26
        ],
        [
          "dbpedia_documents",
          222,
          263,
          249,
          13,
          249,
          67,
          247,
          3,
          251,
          21
        ],
        [
          "rcv1_documents",
          266,
          314,
          300,
          15,
          300,
          63,
          299,
          7,
          302,
          23
        ],
        [
          "rt_documents",
          317,
          383,
          350,
          26,
          350,
          68,
          350,
          7,
          350,
          76
        ],
        [
          "rt_documents",
          317,
          383,
          352,
          26,
          352,
          68,
          352,
          7,
          352,
          77
        ]
      ],
      "models/research/slim/datasets/download_and_convert_flowers.py": [
        [
          "_clean_up_temporary_files",
          155,
          166,
          165,
          13,
          165,
          54,
          155,
          31,
          166,
          37
        ],
        [
          "_get_filenames_and_classes",
          74,
          100,
          85,
          17,
          85,
          58,
          74,
          32,
          88,
          41
        ],
        [
          "_get_filenames_and_classes",
          74,
          100,
          89,
          12,
          89,
          46,
          88,
          7,
          90,
          26
        ],
        [
          "_get_filenames_and_classes",
          74,
          100,
          97,
          14,
          97,
          46,
          96,
          9,
          98,
          34
        ],
        [
          "_get_dataset_filename",
          103,
          106,
          106,
          10,
          106,
          51,
          103,
          27,
          106,
          51
        ],
        [
          "_clean_up_temporary_files",
          155,
          166,
          162,
          14,
          162,
          48,
          155,
          31,
          166,
          37
        ]
      ],
      "models/official/legacy/detection/executor/distributed_executor.py": [
        [
          "_save_checkpoint",
          42,
          47,
          45,
          21,
          45,
          62,
          42,
          22,
          47,
          63
        ],
        [
          "__init__",
          107,
          114,
          114,
          49,
          114,
          77,
          107,
          16,
          114,
          15
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_download_and_uncompress_dataset",
          124,
          142,
          131,
          14,
          131,
          48,
          124,
          38,
          133,
          33
        ],
        [
          "_clean_up_temporary_files",
          145,
          156,
          152,
          14,
          152,
          48,
          145,
          31,
          156,
          37
        ],
        [
          "_clean_up_temporary_files",
          145,
          156,
          155,
          13,
          155,
          60,
          145,
          31,
          156,
          37
        ],
        [
          "run",
          159,
          198,
          181,
          18,
          183,
          56,
          180,
          9,
          184,
          12
        ],
        [
          "run",
          159,
          198,
          188,
          16,
          190,
          41,
          187,
          8,
          198,
          53
        ]
      ],
      "models/research/slim/datasets/download_and_convert_mnist.py": [
        [
          "_download_dataset",
          145,
          169,
          155,
          16,
          155,
          50,
          151,
          7,
          157,
          35
        ],
        [
          "_clean_up_temporary_files",
          172,
          183,
          182,
          16,
          182,
          50,
          178,
          7,
          183,
          29
        ],
        [
          "run",
          186,
          221,
          206,
          21,
          206,
          67,
          202,
          3,
          221,
          51
        ],
        [
          "run",
          186,
          221,
          207,
          23,
          207,
          71,
          202,
          3,
          221,
          51
        ],
        [
          "run",
          186,
          221,
          212,
          21,
          212,
          66,
          202,
          3,
          221,
          51
        ],
        [
          "run",
          186,
          221,
          213,
          23,
          213,
          70,
          202,
          3,
          221,
          51
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords.py": [
        [
          "run",
          93,
          158,
          105,
          14,
          105,
          58,
          93,
          9,
          107,
          39
        ],
        [
          "run",
          93,
          158,
          113,
          28,
          114,
          67,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          115,
          26,
          116,
          63,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          117,
          21,
          117,
          55,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          118,
          19,
          118,
          51,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          121,
          39,
          122,
          62,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          123,
          37,
          124,
          60,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          125,
          37,
          125,
          75,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          126,
          23,
          126,
          63,
          110,
          3,
          158,
          20
        ],
        [
          "run",
          93,
          158,
          127,
          21,
          127,
          59,
          110,
          3,
          158,
          20
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords_lib.py": [
        [
          "_create_tf_example",
          217,
          287,
          242,
          15,
          242,
          47,
          217,
          24,
          250,
          35
        ]
      ],
      "models/official/nlp/tasks/dual_encoder_test.py": [
        [
          "_run_task",
          45,
          59,
          59,
          16,
          59,
          63,
          45,
          17,
          59,
          64
        ],
        [
          "_export_bert_tfhub",
          86,
          114,
          95,
          28,
          95,
          74,
          86,
          26,
          114,
          22
        ],
        [
          "_export_bert_tfhub",
          86,
          114,
          98,
          21,
          98,
          62,
          86,
          26,
          114,
          22
        ],
        [
          "_export_bert_tfhub",
          86,
          114,
          101,
          18,
          101,
          71,
          86,
          26,
          114,
          22
        ],
        [
          "_export_bert_tfhub",
          86,
          114,
          105,
          19,
          105,
          58,
          86,
          26,
          114,
          22
        ]
      ],
      "models/official/nlp/data/dual_encoder_dataloader_test.py": [
        [
          "test_load_dataset",
          58,
          88,
          61,
          23,
          61,
          74,
          58,
          25,
          88,
          80
        ],
        [
          "test_load_dataset",
          58,
          88,
          62,
          18,
          62,
          63,
          58,
          25,
          88,
          80
        ],
        [
          "test_load_tfds",
          91,
          127,
          99,
          20,
          99,
          65,
          99,
          20,
          103,
          23
        ]
      ],
      "models/official/nlp/configs/encoders_test.py": [
        [
          "test_encoder_from_yaml",
          28,
          40,
          34,
          24,
          34,
          71,
          28,
          30,
          40,
          28
        ]
      ],
      "models/research/object_detection/legacy/eval.py": [
        [
          "main",
          84,
          138,
          93,
          9,
          93,
          55,
          89,
          15,
          94,
          23
        ],
        [
          "main",
          84,
          138,
          103,
          29,
          103,
          62,
          100,
          9,
          103,
          79
        ]
      ],
      "models/research/lstm_object_detection/eval.py": [
        [
          "main",
          53,
          105,
          68,
          22,
          68,
          68,
          65,
          20,
          77,
          29
        ]
      ],
      "models/research/deeplab/evaluation/eval_coco_format_test.py": [
        [
          "test_compare_pc_with_golden_value_normalize_by_size",
          93,
          113,
          95,
          20,
          95,
          64,
          93,
          59,
          113,
          71
        ],
        [
          "test_compare_pc_with_golden_value",
          64,
          91,
          68,
          22,
          68,
          68,
          64,
          41,
          84,
          47
        ],
        [
          "test_compare_pq_with_reference_eval",
          37,
          62,
          38,
          23,
          38,
          45,
          37,
          43,
          58,
          47
        ],
        [
          "test_compare_pq_with_reference_eval",
          37,
          62,
          39,
          20,
          39,
          64,
          37,
          43,
          58,
          47
        ],
        [
          "test_compare_pq_with_reference_eval",
          37,
          62,
          40,
          17,
          40,
          56,
          37,
          43,
          58,
          47
        ],
        [
          "test_compare_pq_with_reference_eval",
          37,
          62,
          41,
          22,
          41,
          68,
          37,
          43,
          58,
          47
        ],
        [
          "test_compare_pq_with_reference_eval",
          37,
          62,
          42,
          19,
          42,
          60,
          37,
          43,
          58,
          47
        ],
        [
          "test_compare_pc_with_golden_value",
          64,
          91,
          65,
          23,
          65,
          45,
          64,
          41,
          84,
          47
        ],
        [
          "test_compare_pc_with_golden_value",
          64,
          91,
          66,
          20,
          66,
          64,
          64,
          41,
          84,
          47
        ],
        [
          "test_compare_pc_with_golden_value",
          64,
          91,
          67,
          17,
          67,
          56,
          64,
          41,
          84,
          47
        ],
        [
          "test_compare_pc_with_golden_value",
          64,
          91,
          69,
          19,
          69,
          60,
          64,
          41,
          84,
          47
        ],
        [
          "test_compare_pc_with_golden_value_normalize_by_size",
          93,
          113,
          94,
          23,
          94,
          45,
          93,
          59,
          113,
          71
        ],
        [
          "test_compare_pc_with_golden_value_normalize_by_size",
          93,
          113,
          96,
          17,
          96,
          56,
          93,
          59,
          113,
          71
        ],
        [
          "test_compare_pc_with_golden_value_normalize_by_size",
          93,
          113,
          97,
          22,
          97,
          68,
          93,
          59,
          113,
          71
        ],
        [
          "test_compare_pc_with_golden_value_normalize_by_size",
          93,
          113,
          98,
          19,
          98,
          60,
          93,
          59,
          113,
          71
        ],
        [
          "test_pc_with_multiple_workers",
          115,
          136,
          116,
          23,
          116,
          45,
          115,
          37,
          136,
          71
        ],
        [
          "test_pc_with_multiple_workers",
          115,
          136,
          117,
          20,
          117,
          64,
          115,
          37,
          136,
          71
        ],
        [
          "test_pc_with_multiple_workers",
          115,
          136,
          118,
          17,
          118,
          56,
          115,
          37,
          136,
          71
        ],
        [
          "test_pc_with_multiple_workers",
          115,
          136,
          119,
          22,
          119,
          68,
          115,
          37,
          136,
          71
        ],
        [
          "test_pc_with_multiple_workers",
          115,
          136,
          120,
          19,
          120,
          60,
          115,
          37,
          136,
          71
        ]
      ],
      "models/research/efficient-hrl/eval.py": [
        [
          "evaluate_checkpoint",
          80,
          168,
          158,
          26,
          160,
          71,
          158,
          26,
          164,
          66
        ],
        [
          "evaluate",
          289,
          460,
          422,
          22,
          422,
          66,
          422,
          22,
          422,
          18
        ],
        [
          "evaluate",
          289,
          460,
          433,
          23,
          433,
          67,
          433,
          23,
          434,
          43
        ],
        [
          "evaluate",
          289,
          460,
          437,
          9,
          437,
          58,
          436,
          19,
          451,
          57
        ]
      ],
      "models/research/deeplab/evaluation/eval_coco_format.py": [
        [
          "_category_and_instance_from_annotation",
          156,
          162,
          160,
          7,
          160,
          49,
          156,
          44,
          162,
          38
        ]
      ],
      "models/official/projects/nhnet/evaluation.py": [
        [
          "continuous_eval",
          84,
          179,
          104,
          9,
          104,
          49,
          84,
          21,
          144,
          33
        ]
      ],
      "models/research/object_detection/eval_util.py": [
        [
          "visualize_detection_results",
          102,
          243,
          226,
          21,
          227,
          58,
          226,
          21,
          226,
          17
        ],
        [
          "visualize_detection_results",
          102,
          243,
          229,
          21,
          229,
          73,
          229,
          21,
          229,
          17
        ]
      ],
      "models/official/vision/serving/export_base_v2_test.py": [
        [
          "test_preprocessor",
          36,
          60,
          50,
          9,
          50,
          37,
          36,
          25,
          60,
          70
        ],
        [
          "test_postprocessor",
          62,
          85,
          76,
          9,
          76,
          37,
          62,
          26,
          85,
          70
        ]
      ],
      "models/official/core/export_base_test.py": [
        [
          "test_export_module",
          42,
          66,
          49,
          9,
          49,
          37,
          42,
          26,
          66,
          75
        ],
        [
          "test_export_module",
          42,
          66,
          55,
          36,
          55,
          77,
          42,
          26,
          66,
          75
        ],
        [
          "test_export_module",
          42,
          66,
          58,
          13,
          58,
          68,
          42,
          26,
          66,
          75
        ],
        [
          "test_export_module",
          42,
          66,
          61,
          13,
          62,
          57,
          42,
          26,
          66,
          75
        ],
        [
          "test_custom_inference_step",
          68,
          88,
          80,
          9,
          80,
          37,
          68,
          34,
          88,
          75
        ]
      ],
      "models/research/slim/export_inference_graph_test.py": [
        [
          "testExportInferenceGraph",
          33,
          41,
          35,
          19,
          35,
          57,
          33,
          32,
          41,
          46
        ]
      ],
      "models/research/audioset/yamnet/export.py": [
        [
          "make_tflite_export",
          138,
          183,
          153,
          21,
          153,
          59,
          145,
          3,
          183,
          24
        ],
        [
          "make_tflite_export",
          138,
          183,
          171,
          23,
          171,
          63,
          145,
          3,
          183,
          24
        ],
        [
          "main",
          200,
          211,
          204,
          20,
          204,
          50,
          200,
          10,
          211,
          59
        ],
        [
          "main",
          200,
          211,
          207,
          23,
          207,
          56,
          200,
          10,
          211,
          59
        ],
        [
          "main",
          200,
          211,
          210,
          21,
          210,
          52,
          200,
          10,
          211,
          59
        ]
      ],
      "models/official/vision/serving/export_module_factory_test.py": [
        [
          "test_export",
          68,
          113,
          76,
          9,
          76,
          37,
          68,
          19,
          113,
          76
        ],
        [
          "test_export",
          68,
          113,
          83,
          36,
          83,
          74,
          68,
          19,
          113,
          76
        ],
        [
          "test_export",
          68,
          113,
          85,
          9,
          85,
          61,
          68,
          19,
          113,
          76
        ],
        [
          "test_export",
          68,
          113,
          87,
          9,
          87,
          75,
          68,
          19,
          113,
          76
        ]
      ],
      "models/official/projects/detr/serving/export_module_test.py": [
        [
          "test_export",
          72,
          94,
          77,
          36,
          77,
          74,
          72,
          19,
          94,
          50
        ],
        [
          "test_export",
          72,
          94,
          79,
          24,
          79,
          76,
          72,
          19,
          94,
          50
        ],
        [
          "test_export",
          72,
          94,
          82,
          13,
          83,
          57,
          72,
          19,
          94,
          50
        ]
      ],
      "models/orbit/actions/export_saved_model.py": [
        [
          "managed_files",
          103,
          117,
          114,
          28,
          114,
          65,
          112,
          9,
          115,
          33
        ],
        [
          "next_name",
          132,
          135,
          135,
          26,
          135,
          68,
          132,
          17,
          135,
          69
        ]
      ],
      "models/official/vision/serving/export_saved_model_lib_test.py": [
        [
          "_export_model_with_log_model_flops_and_params",
          35,
          43,
          41,
          25,
          41,
          65,
          35,
          53,
          43,
          40
        ],
        [
          "assertModelAnalysisFilesExist",
          45,
          49,
          47,
          28,
          47,
          73,
          45,
          37,
          49,
          74
        ],
        [
          "assertModelAnalysisFilesExist",
          45,
          49,
          49,
          28,
          49,
          72,
          45,
          37,
          49,
          74
        ]
      ],
      "models/official/vision/serving/export_saved_model_lib.py": [
        [
          "export_inference_graph",
          33,
          216,
          85,
          35,
          87,
          5,
          85,
          35,
          91,
          30
        ],
        [
          "export_inference_graph",
          33,
          216,
          92,
          36,
          94,
          5,
          92,
          36,
          92,
          32
        ],
        [
          "export_inference_graph",
          33,
          216,
          179,
          15,
          179,
          63,
          178,
          12,
          179,
          64
        ],
        [
          "export_inference_graph",
          33,
          216,
          212,
          9,
          212,
          51,
          192,
          11,
          216,
          5
        ],
        [
          "export_inference_graph",
          33,
          216,
          215,
          30,
          215,
          73,
          192,
          11,
          216,
          5
        ]
      ],
      "models/official/vision/serving/export_saved_model_lib_v2.py": [
        [
          "export",
          28,
          97,
          68,
          35,
          69,
          45,
          68,
          35,
          73,
          30
        ],
        [
          "export",
          28,
          97,
          74,
          36,
          75,
          46,
          74,
          36,
          74,
          32
        ],
        [
          "export",
          28,
          97,
          96,
          15,
          96,
          63,
          95,
          12,
          96,
          64
        ]
      ],
      "models/research/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py": [
        [
          "testExportAndLoad",
          48,
          67,
          55,
          18,
          55,
          67,
          48,
          25,
          56,
          34
        ],
        [
          "get_path",
          35,
          37,
          36,
          10,
          37,
          34,
          35,
          14,
          37,
          34
        ]
      ],
      "models/orbit/actions/export_saved_model_test.py": [
        [
          "test_export_file_manager_default_ids",
          46,
          70,
          48,
          17,
          48,
          61,
          46,
          44,
          70,
          73
        ],
        [
          "test_export_file_manager_custom_ids",
          72,
          107,
          74,
          17,
          74,
          61,
          72,
          43,
          107,
          42
        ],
        [
          "test_export_file_manager_with_suffix",
          109,
          155,
          111,
          17,
          111,
          61,
          109,
          44,
          155,
          65
        ],
        [
          "test_export_file_manager_with_suffix",
          109,
          155,
          154,
          19,
          154,
          68,
          109,
          44,
          155,
          65
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          159,
          17,
          159,
          61,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          186,
          29,
          186,
          76,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          189,
          29,
          189,
          77,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          192,
          29,
          192,
          78,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          201,
          29,
          201,
          76,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          204,
          29,
          204,
          77,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          207,
          29,
          207,
          78,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_with_suffix_second_cleanup_succeeds",
          157,
          211,
          210,
          29,
          210,
          78,
          157,
          68,
          211,
          5
        ],
        [
          "test_export_file_manager_managed_files",
          213,
          228,
          221,
          17,
          221,
          61,
          213,
          46,
          228,
          68
        ],
        [
          "test_export_file_manager_managed_files_double_slash",
          230,
          248,
          238,
          17,
          238,
          61,
          230,
          59,
          248,
          6
        ],
        [
          "test_export_saved_model",
          250,
          278,
          252,
          17,
          252,
          61,
          250,
          31,
          278,
          41
        ]
      ],
      "models/official/nlp/serving/export_savedmodel.py": [
        [
          "main",
          122,
          162,
          142,
          15,
          142,
          45,
          139,
          10,
          144,
          43
        ]
      ],
      "models/official/legacy/bert/export_tfhub_test.py": [
        [
          "test_export_tfhub",
          31,
          104,
          44,
          21,
          44,
          62,
          31,
          25,
          58,
          44
        ],
        [
          "test_export_tfhub",
          31,
          104,
          42,
          28,
          42,
          74,
          31,
          25,
          58,
          44
        ],
        [
          "test_export_tfhub",
          31,
          104,
          47,
          18,
          47,
          71,
          31,
          25,
          58,
          44
        ],
        [
          "test_export_tfhub",
          31,
          104,
          51,
          23,
          51,
          62,
          31,
          25,
          58,
          44
        ]
      ],
      "models/official/projects/labse/export_tfhub_test.py": [
        [
          "test_export_model",
          28,
          106,
          40,
          28,
          40,
          74,
          28,
          25,
          62,
          44
        ],
        [
          "test_export_model",
          28,
          106,
          42,
          21,
          42,
          62,
          28,
          25,
          62,
          44
        ],
        [
          "test_export_model",
          28,
          106,
          45,
          18,
          45,
          71,
          28,
          25,
          62,
          44
        ],
        [
          "test_export_model",
          28,
          106,
          49,
          23,
          49,
          62,
          28,
          25,
          62,
          44
        ]
      ],
      "models/official/nlp/tools/export_tfhub_lib.py": [
        [
          "_move_to_tmpdir",
          392,
          403,
          399,
          16,
          399,
          55,
          396,
          22,
          403,
          20
        ],
        [
          "_move_to_tmpdir",
          392,
          403,
          400,
          17,
          400,
          50,
          396,
          22,
          403,
          20
        ],
        [
          "_check_no_assert",
          469,
          492,
          471,
          26,
          471,
          73,
          469,
          22,
          482,
          40
        ]
      ],
      "models/official/nlp/tools/export_tfhub_lib_test.py": [
        [
          "_get_vocab_or_sp_model_dummy",
          96,
          105,
          98,
          16,
          98,
          55,
          96,
          34,
          101,
          17
        ],
        [
          "test_export_model",
          143,
          251,
          157,
          28,
          157,
          74,
          143,
          25,
          179,
          15
        ],
        [
          "test_export_model",
          143,
          251,
          159,
          21,
          159,
          62,
          143,
          25,
          179,
          15
        ],
        [
          "test_export_model",
          143,
          251,
          164,
          19,
          164,
          58,
          143,
          25,
          179,
          15
        ],
        [
          "test_copy_pooler_dense_to_encoder",
          268,
          317,
          286,
          28,
          286,
          74,
          268,
          41,
          317,
          68
        ],
        [
          "test_copy_pooler_dense_to_encoder",
          268,
          317,
          287,
          21,
          287,
          62,
          268,
          41,
          317,
          68
        ],
        [
          "test_copy_pooler_dense_to_encoder",
          268,
          317,
          291,
          19,
          291,
          58,
          268,
          41,
          317,
          68
        ],
        [
          "test_export_model_with_mlm",
          323,
          483,
          335,
          28,
          335,
          74,
          323,
          34,
          359,
          15
        ],
        [
          "test_export_model_with_mlm",
          323,
          483,
          339,
          21,
          339,
          62,
          323,
          34,
          359,
          15
        ],
        [
          "test_export_model_with_mlm",
          323,
          483,
          344,
          19,
          344,
          58,
          323,
          34,
          359,
          15
        ],
        [
          "_make_vocab_file",
          491,
          521,
          514,
          12,
          518,
          17,
          491,
          24,
          521,
          15
        ],
        [
          "_make_sp_model_file",
          523,
          571,
          543,
          20,
          545,
          15,
          523,
          27,
          550,
          36
        ],
        [
          "test_no_leaks",
          601,
          608,
          606,
          28,
          606,
          63,
          601,
          21,
          608,
          58
        ],
        [
          "test_preprocessing_for_mlm",
          838,
          977,
          866,
          28,
          866,
          74,
          854,
          45,
          952,
          30
        ],
        [
          "test_preprocessing_for_mlm",
          838,
          977,
          868,
          21,
          868,
          62,
          854,
          45,
          952,
          30
        ],
        [
          "test_preprocessing_for_mlm",
          838,
          977,
          872,
          27,
          872,
          77,
          854,
          45,
          952,
          30
        ]
      ],
      "models/official/projects/edgetpu/vision/serving/export_tflite.py": [
        [
          "run_export",
          125,
          178,
          166,
          17,
          167,
          66,
          151,
          16,
          174,
          29
        ],
        [
          "run_export",
          125,
          178,
          172,
          22,
          173,
          59,
          151,
          16,
          174,
          29
        ]
      ],
      "models/research/object_detection/export_tflite_graph_lib_tf2.py": [
        [
          "export_tflite_model",
          309,
          374,
          337,
          34,
          337,
          78,
          309,
          25,
          341,
          55
        ]
      ],
      "models/research/object_detection/export_tflite_graph_lib_tf2_test.py": [
        [
          "test_unsupported_architecture",
          216,
          239,
          226,
          26,
          226,
          56,
          216,
          37,
          229,
          35
        ],
        [
          "test_export_yields_saved_model",
          241,
          264,
          247,
          26,
          247,
          56,
          241,
          38,
          264,
          61
        ],
        [
          "test_export_yields_saved_model",
          241,
          264,
          256,
          15,
          256,
          77,
          241,
          38,
          264,
          61
        ],
        [
          "test_export_yields_saved_model",
          241,
          264,
          259,
          15,
          260,
          45,
          241,
          38,
          264,
          61
        ],
        [
          "test_export_yields_saved_model",
          241,
          264,
          263,
          15,
          264,
          59,
          241,
          38,
          264,
          61
        ],
        [
          "test_exported_model_inference",
          266,
          288,
          268,
          24,
          268,
          54,
          266,
          37,
          288,
          40
        ],
        [
          "test_exported_model_inference",
          266,
          288,
          280,
          24,
          280,
          68,
          266,
          37,
          288,
          40
        ],
        [
          "test_center_net_inference_object_detection",
          290,
          312,
          292,
          24,
          292,
          54,
          290,
          50,
          312,
          40
        ],
        [
          "test_center_net_inference_object_detection",
          290,
          312,
          304,
          24,
          304,
          68,
          290,
          50,
          312,
          40
        ],
        [
          "test_center_net_inference_keypoint",
          314,
          337,
          316,
          24,
          316,
          54,
          314,
          42,
          337,
          40
        ],
        [
          "test_center_net_inference_keypoint",
          314,
          337,
          329,
          24,
          329,
          68,
          314,
          42,
          337,
          40
        ]
      ],
      "models/official/projects/edgetpu/nlp/serving/export_tflite_squad.py": [
        [
          "main",
          108,
          177,
          174,
          23,
          174,
          69,
          173,
          24,
          177,
          71
        ]
      ],
      "models/research/lstm_object_detection/export_tflite_lstd_graph_lib.py": [
        [
          "export_tflite_graph",
          152,
          327,
          322,
          18,
          322,
          60,
          322,
          18,
          327,
          39
        ],
        [
          "export_tflite_graph",
          152,
          327,
          325,
          15,
          325,
          54,
          322,
          18,
          327,
          39
        ]
      ],
      "models/research/lstm_object_detection/export_tflite_lstd_model.py": [
        [
          "main",
          33,
          61,
          60,
          15,
          60,
          45,
          33,
          10,
          61,
          43
        ]
      ],
      "models/official/projects/edgetpu/vision/serving/export_tflite_test.py": [
        [
          "_dump_tflite",
          59,
          66,
          64,
          17,
          64,
          78,
          59,
          18,
          66,
          20
        ],
        [
          "test_model_build_and_export_saved_model",
          101,
          108,
          106,
          24,
          106,
          73,
          101,
          47,
          108,
          74
        ]
      ],
      "models/research/object_detection/export_tflite_ssd_graph_lib.py": [
        [
          "export_tflite_graph",
          157,
          333,
          328,
          18,
          328,
          60,
          328,
          18,
          333,
          39
        ],
        [
          "export_tflite_graph",
          157,
          333,
          331,
          15,
          331,
          54,
          328,
          18,
          333,
          39
        ]
      ],
      "models/research/seq_flow_lite/export_to_tflite.py": [
        [
          "load_runner_config",
          36,
          39,
          37,
          12,
          37,
          62,
          37,
          12,
          39,
          31
        ],
        [
          "main",
          42,
          79,
          77,
          26,
          77,
          68,
          72,
          7,
          79,
          26
        ]
      ],
      "models/research/object_detection/export_tflite_ssd_graph_lib_tf1_test.py": [
        [
          "_export_graph",
          142,
          172,
          148,
          33,
          148,
          70,
          142,
          21,
          172,
          28
        ],
        [
          "_export_graph",
          142,
          172,
          149,
          25,
          149,
          67,
          142,
          21,
          172,
          28
        ],
        [
          "_export_graph_with_postprocessing_op",
          174,
          204,
          180,
          33,
          180,
          70,
          174,
          44,
          204,
          28
        ],
        [
          "_export_graph_with_postprocessing_op",
          174,
          204,
          181,
          25,
          181,
          67,
          174,
          44,
          204,
          28
        ]
      ],
      "models/research/object_detection/exporter_lib_v2.py": [
        [
          "export_inference_graph",
          211,
          281,
          241,
          33,
          241,
          76,
          211,
          28,
          253,
          43
        ],
        [
          "export_inference_graph",
          211,
          281,
          242,
          34,
          242,
          78,
          211,
          28,
          253,
          43
        ]
      ],
      "models/research/object_detection/exporter_lib_tf2_test.py": [
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          129,
          26,
          129,
          56,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          136,
          38,
          137,
          60,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          138,
          38,
          139,
          74,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          140,
          38,
          142,
          42,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          143,
          38,
          144,
          57,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          145,
          38,
          146,
          71,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          147,
          38,
          148,
          46,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_saved_model_and_run_inference",
          183,
          214,
          191,
          26,
          191,
          56,
          184,
          7,
          214,
          78
        ],
        [
          "test_export_saved_model_and_run_inference",
          183,
          214,
          199,
          26,
          199,
          70,
          184,
          7,
          214,
          78
        ],
        [
          "test_export_saved_model_and_run_inference_with_side_inputs",
          220,
          265,
          228,
          26,
          228,
          56,
          221,
          7,
          246,
          28
        ],
        [
          "test_export_saved_model_and_run_inference_with_side_inputs",
          220,
          265,
          240,
          26,
          240,
          70,
          221,
          7,
          246,
          28
        ],
        [
          "test_export_checkpoint_and_run_inference_with_image",
          267,
          297,
          274,
          26,
          274,
          56,
          267,
          59,
          297,
          75
        ],
        [
          "test_export_checkpoint_and_run_inference_with_image",
          267,
          297,
          285,
          24,
          285,
          68,
          267,
          59,
          297,
          75
        ],
        [
          "test_export_saved_model_and_run_inference_for_segmentation",
          343,
          374,
          352,
          26,
          352,
          56,
          344,
          7,
          374,
          79
        ],
        [
          "test_export_saved_model_and_run_inference_for_segmentation",
          343,
          374,
          360,
          26,
          360,
          70,
          344,
          7,
          374,
          79
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "_export_inference_graph",
          488,
          573,
          505,
          23,
          506,
          63,
          488,
          29,
          523,
          24
        ],
        [
          "_export_inference_graph",
          488,
          573,
          507,
          22,
          507,
          66,
          488,
          29,
          523,
          24
        ],
        [
          "_export_inference_graph",
          488,
          573,
          508,
          16,
          508,
          59,
          488,
          29,
          523,
          24
        ],
        [
          "_export_inference_graph",
          488,
          573,
          548,
          28,
          549,
          64,
          547,
          27,
          550,
          40
        ]
      ],
      "models/research/object_detection/exporter_tf1_test.py": [
        [
          "test_export_graph_with_fixed_size_tf_example_input",
          266,
          287,
          287,
          26,
          287,
          73,
          266,
          58,
          287,
          75
        ],
        [
          "test_export_graph_with_image_tensor_input",
          175,
          192,
          177,
          33,
          177,
          67,
          175,
          49,
          192,
          62
        ],
        [
          "test_export_graph_with_image_tensor_input",
          175,
          192,
          183,
          26,
          183,
          56,
          175,
          49,
          192,
          62
        ],
        [
          "test_export_graph_with_image_tensor_input",
          175,
          192,
          191,
          38,
          192,
          60,
          175,
          49,
          192,
          62
        ],
        [
          "test_write_inference_graph",
          194,
          212,
          196,
          33,
          196,
          67,
          194,
          34,
          212,
          54
        ],
        [
          "test_write_inference_graph",
          194,
          212,
          202,
          26,
          202,
          56,
          194,
          34,
          212,
          54
        ],
        [
          "test_write_inference_graph",
          194,
          212,
          211,
          38,
          212,
          52,
          194,
          34,
          212,
          54
        ],
        [
          "test_export_graph_with_fixed_size_image_tensor_input",
          214,
          245,
          218,
          33,
          218,
          67,
          214,
          60,
          245,
          45
        ],
        [
          "test_export_graph_with_fixed_size_image_tensor_input",
          214,
          245,
          224,
          26,
          224,
          56,
          214,
          60,
          245,
          45
        ],
        [
          "test_export_graph_with_fixed_size_image_tensor_input",
          214,
          245,
          233,
          26,
          233,
          70,
          214,
          60,
          245,
          45
        ],
        [
          "test_export_graph_with_fixed_size_image_tensor_input",
          214,
          245,
          235,
          26,
          235,
          73,
          214,
          60,
          245,
          45
        ],
        [
          "test_export_graph_with_tf_example_input",
          247,
          264,
          249,
          33,
          249,
          67,
          247,
          47,
          264,
          62
        ],
        [
          "test_export_graph_with_tf_example_input",
          247,
          264,
          255,
          26,
          255,
          56,
          247,
          47,
          264,
          62
        ],
        [
          "test_export_graph_with_tf_example_input",
          247,
          264,
          263,
          38,
          264,
          60,
          247,
          47,
          264,
          62
        ],
        [
          "test_export_graph_with_fixed_size_tf_example_input",
          266,
          287,
          270,
          33,
          270,
          67,
          266,
          58,
          287,
          75
        ],
        [
          "test_export_graph_with_fixed_size_tf_example_input",
          266,
          287,
          276,
          26,
          276,
          56,
          266,
          58,
          287,
          75
        ],
        [
          "test_export_graph_with_fixed_size_tf_example_input",
          266,
          287,
          285,
          26,
          285,
          70,
          266,
          58,
          287,
          75
        ],
        [
          "test_export_graph_with_encoded_image_string_input",
          289,
          306,
          291,
          33,
          291,
          67,
          289,
          57,
          306,
          62
        ],
        [
          "test_export_graph_with_encoded_image_string_input",
          289,
          306,
          297,
          26,
          297,
          56,
          289,
          57,
          306,
          62
        ],
        [
          "test_export_graph_with_encoded_image_string_input",
          289,
          306,
          305,
          38,
          306,
          60,
          289,
          57,
          306,
          62
        ],
        [
          "test_export_graph_with_fixed_size_encoded_image_string_input",
          308,
          329,
          312,
          33,
          312,
          67,
          308,
          68,
          329,
          75
        ],
        [
          "test_export_graph_with_fixed_size_encoded_image_string_input",
          308,
          329,
          318,
          26,
          318,
          56,
          308,
          68,
          329,
          75
        ],
        [
          "test_export_graph_with_fixed_size_encoded_image_string_input",
          308,
          329,
          327,
          26,
          327,
          70,
          308,
          68,
          329,
          75
        ],
        [
          "test_export_graph_with_fixed_size_encoded_image_string_input",
          308,
          329,
          329,
          26,
          329,
          73,
          308,
          68,
          329,
          75
        ],
        [
          "test_replace_variable_values_with_moving_averages",
          336,
          365,
          338,
          33,
          338,
          67,
          336,
          57,
          365,
          43
        ],
        [
          "test_replace_variable_values_with_moving_averages",
          336,
          365,
          339,
          29,
          339,
          61,
          336,
          57,
          365,
          43
        ],
        [
          "test_export_graph_with_moving_averages",
          367,
          388,
          369,
          33,
          369,
          67,
          367,
          46,
          388,
          66
        ],
        [
          "test_export_graph_with_moving_averages",
          367,
          388,
          372,
          24,
          372,
          54,
          367,
          46,
          388,
          66
        ],
        [
          "test_export_graph_with_moving_averages",
          367,
          388,
          383,
          38,
          384,
          60,
          367,
          46,
          388,
          66
        ],
        [
          "test_export_model_with_quantization_nodes",
          390,
          424,
          392,
          33,
          392,
          67,
          390,
          49,
          420,
          59
        ],
        [
          "test_export_model_with_quantization_nodes",
          390,
          424,
          397,
          24,
          397,
          54,
          390,
          49,
          420,
          59
        ],
        [
          "test_export_model_with_quantization_nodes",
          390,
          424,
          398,
          28,
          399,
          64,
          390,
          49,
          420,
          59
        ],
        [
          "test_export_model_with_all_output_nodes",
          426,
          455,
          428,
          33,
          428,
          67,
          426,
          47,
          455,
          64
        ],
        [
          "test_export_model_with_all_output_nodes",
          426,
          455,
          431,
          24,
          431,
          54,
          426,
          47,
          455,
          64
        ],
        [
          "test_export_model_with_all_output_nodes",
          426,
          455,
          432,
          28,
          433,
          68,
          426,
          47,
          455,
          64
        ],
        [
          "test_export_model_with_detection_only_nodes",
          457,
          484,
          459,
          33,
          459,
          67,
          457,
          51,
          484,
          63
        ],
        [
          "test_export_model_with_detection_only_nodes",
          457,
          484,
          462,
          24,
          462,
          54,
          457,
          51,
          484,
          63
        ],
        [
          "test_export_model_with_detection_only_nodes",
          457,
          484,
          463,
          28,
          464,
          68,
          457,
          51,
          484,
          63
        ],
        [
          "test_export_model_with_detection_only_nodes_and_detection_features",
          486,
          514,
          488,
          33,
          488,
          67,
          486,
          74,
          514,
          63
        ],
        [
          "test_export_model_with_detection_only_nodes_and_detection_features",
          486,
          514,
          491,
          24,
          491,
          54,
          486,
          74,
          514,
          63
        ],
        [
          "test_export_model_with_detection_only_nodes_and_detection_features",
          486,
          514,
          492,
          28,
          493,
          68,
          486,
          74,
          514,
          63
        ],
        [
          "test_export_and_run_inference_with_image_tensor",
          516,
          559,
          518,
          33,
          518,
          67,
          516,
          55,
          559,
          52
        ],
        [
          "test_export_and_run_inference_with_image_tensor",
          516,
          559,
          521,
          24,
          521,
          54,
          516,
          55,
          559,
          52
        ],
        [
          "test_export_and_run_inference_with_image_tensor",
          516,
          559,
          522,
          28,
          523,
          68,
          516,
          55,
          559,
          52
        ],
        [
          "test_export_and_run_inference_with_encoded_image_string_tensor",
          573,
          630,
          575,
          33,
          575,
          67,
          573,
          70,
          609,
          53
        ],
        [
          "test_export_and_run_inference_with_encoded_image_string_tensor",
          573,
          630,
          578,
          24,
          578,
          54,
          573,
          70,
          609,
          53
        ],
        [
          "test_export_and_run_inference_with_encoded_image_string_tensor",
          573,
          630,
          579,
          28,
          580,
          68,
          573,
          70,
          609,
          53
        ],
        [
          "test_raise_runtime_error_on_images_with_different_sizes",
          632,
          672,
          634,
          33,
          634,
          67,
          632,
          63,
          672,
          61
        ],
        [
          "test_raise_runtime_error_on_images_with_different_sizes",
          632,
          672,
          637,
          24,
          637,
          54,
          632,
          63,
          672,
          61
        ],
        [
          "test_raise_runtime_error_on_images_with_different_sizes",
          632,
          672,
          638,
          28,
          639,
          68,
          632,
          63,
          672,
          61
        ],
        [
          "test_export_and_run_inference_with_tf_example",
          674,
          719,
          676,
          33,
          676,
          67,
          674,
          53,
          719,
          52
        ],
        [
          "test_export_and_run_inference_with_tf_example",
          674,
          719,
          679,
          24,
          679,
          54,
          674,
          53,
          719,
          52
        ],
        [
          "test_export_and_run_inference_with_tf_example",
          674,
          719,
          680,
          28,
          681,
          68,
          674,
          53,
          719,
          52
        ],
        [
          "test_write_frozen_graph",
          721,
          783,
          723,
          33,
          723,
          67,
          721,
          31,
          783,
          52
        ],
        [
          "test_write_frozen_graph",
          721,
          783,
          726,
          24,
          726,
          54,
          721,
          31,
          783,
          52
        ],
        [
          "test_write_frozen_graph",
          721,
          783,
          727,
          28,
          728,
          68,
          721,
          31,
          783,
          52
        ],
        [
          "test_export_graph_saves_pipeline_file",
          785,
          808,
          787,
          33,
          787,
          67,
          785,
          45,
          808,
          72
        ],
        [
          "test_export_graph_saves_pipeline_file",
          785,
          808,
          790,
          24,
          790,
          54,
          785,
          45,
          808,
          72
        ],
        [
          "test_export_graph_saves_pipeline_file",
          785,
          808,
          800,
          32,
          801,
          46,
          785,
          45,
          808,
          72
        ],
        [
          "test_export_saved_model_and_run_inference",
          810,
          873,
          812,
          33,
          812,
          67,
          810,
          49,
          873,
          54
        ],
        [
          "test_export_saved_model_and_run_inference",
          810,
          873,
          815,
          24,
          815,
          54,
          810,
          49,
          873,
          54
        ],
        [
          "test_export_saved_model_and_run_inference",
          810,
          873,
          816,
          24,
          816,
          68,
          810,
          49,
          873,
          54
        ],
        [
          "test_write_saved_model",
          875,
          954,
          877,
          33,
          877,
          67,
          875,
          30,
          954,
          54
        ],
        [
          "test_write_saved_model",
          875,
          954,
          880,
          24,
          880,
          54,
          875,
          30,
          954,
          54
        ],
        [
          "test_write_saved_model",
          875,
          954,
          881,
          24,
          881,
          68,
          875,
          30,
          954,
          54
        ],
        [
          "test_export_checkpoint_and_run_inference",
          956,
          1005,
          958,
          33,
          958,
          67,
          956,
          48,
          1005,
          54
        ],
        [
          "test_export_checkpoint_and_run_inference",
          956,
          1005,
          961,
          24,
          961,
          54,
          956,
          48,
          1005,
          54
        ],
        [
          "test_export_checkpoint_and_run_inference",
          956,
          1005,
          962,
          18,
          962,
          61,
          956,
          48,
          1005,
          54
        ],
        [
          "test_write_graph_and_checkpoint",
          1007,
          1075,
          1009,
          33,
          1009,
          67,
          1007,
          39,
          1075,
          54
        ],
        [
          "test_write_graph_and_checkpoint",
          1007,
          1075,
          1012,
          24,
          1012,
          54,
          1007,
          39,
          1075,
          54
        ],
        [
          "test_write_graph_and_checkpoint",
          1007,
          1075,
          1013,
          18,
          1013,
          61,
          1007,
          39,
          1075,
          54
        ]
      ],
      "models/research/delf/delf/python/delg/extract_features.py": [
        [
          "main",
          78,
          159,
          116,
          28,
          117,
          70,
          115,
          18,
          122,
          33
        ],
        [
          "main",
          78,
          159,
          123,
          40,
          124,
          73,
          123,
          40,
          125,
          63
        ],
        [
          "main",
          78,
          159,
          128,
          39,
          129,
          72,
          128,
          39,
          130,
          62
        ]
      ],
      "models/research/delf/delf/python/examples/extract_boxes.py": [
        [
          "main",
          130,
          182,
          163,
          26,
          163,
          78,
          161,
          30,
          164,
          45
        ],
        [
          "main",
          130,
          182,
          181,
          26,
          181,
          80,
          180,
          26,
          182,
          69
        ]
      ],
      "models/research/delf/delf/python/examples/extract_features.py": [
        [
          "main",
          65,
          112,
          97,
          25,
          97,
          76,
          95,
          25,
          98,
          44
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/extract_index_boxes_and_features.py": [
        [
          "listcomp",
          54,
          55,
          55,
          7,
          55,
          76,
          56,
          11,
          55,
          76
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/extract_query_features.py": [
        [
          "main",
          52,
          100,
          77,
          28,
          78,
          76,
          75,
          7,
          81,
          50
        ],
        [
          "main",
          52,
          100,
          79,
          31,
          80,
          78,
          75,
          7,
          81,
          50
        ]
      ],
      "models/research/delf/delf/python/feature_aggregation_extractor_test.py": [
        [
          "setUp",
          48,
          50,
          49,
          27,
          49,
          74,
          48,
          13,
          50,
          45
        ]
      ],
      "models/research/delf/delf/python/feature_io_test.py": [
        [
          "testWriteAndReadToFile",
          84,
          96,
          87,
          16,
          87,
          59,
          84,
          30,
          96,
          51
        ],
        [
          "testWriteAndReadToFileEmptyFile",
          98,
          108,
          99,
          16,
          99,
          59,
          98,
          39,
          108,
          51
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/ffmpeg_ops.py": [
        [
          "split_video_to_frames",
          33,
          52,
          50,
          15,
          50,
          57,
          48,
          7,
          51,
          52
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/ffmpeg_ops.py": [
        [
          "split_video_to_frames",
          30,
          47,
          45,
          12,
          45,
          53,
          42,
          4,
          46,
          49
        ]
      ],
      "models/official/core/file_writers_test.py": [
        [
          "test_write_small_dataset_success",
          36,
          41,
          38,
          25,
          38,
          65,
          36,
          40,
          41,
          54
        ],
        [
          "test_write_small_dataset_unrecognized_format",
          43,
          49,
          46,
          25,
          46,
          65,
          43,
          52,
          49,
          49
        ]
      ],
      "models/research/slim/datasets/flowers.py": [
        [
          "get_split",
          43,
          97,
          65,
          18,
          65,
          69,
          65,
          18,
          68,
          19
        ]
      ],
      "models/research/attention_ocr/python/datasets/fsns.py": [
        [
          "get_split",
          104,
          185,
          168,
          18,
          168,
          70,
          129,
          3,
          185,
          36
        ],
        [
          "get_split",
          104,
          185,
          170,
          18,
          171,
          70,
          129,
          3,
          185,
          36
        ]
      ],
      "models/research/attention_ocr/python/datasets/fsns_test.py": [
        [
          "dataset_dir",
          36,
          37,
          37,
          10,
          37,
          65,
          37,
          10,
          37,
          65
        ]
      ],
      "models/research/vid2depth/dataset/gen_data.py": [
        [
          "_generate_data",
          69,
          147,
          129,
          19,
          129,
          59,
          129,
          8,
          132,
          55
        ],
        [
          "_generate_data",
          69,
          147,
          130,
          21,
          130,
          59,
          129,
          8,
          132,
          55
        ],
        [
          "_gen_example",
          150,
          173,
          162,
          14,
          162,
          65,
          155,
          21,
          163,
          31
        ],
        [
          "_gen_example",
          150,
          173,
          165,
          18,
          165,
          72,
          165,
          18,
          173,
          19
        ],
        [
          "_gen_example",
          150,
          173,
          167,
          18,
          167,
          76,
          165,
          18,
          173,
          19
        ]
      ],
      "models/research/adversarial_text/gen_data.py": [
        [
          "build_shuffling_tf_record_writer",
          56,
          57,
          57,
          39,
          57,
          75,
          56,
          38,
          57,
          76
        ],
        [
          "build_tf_record_writer",
          60,
          61,
          61,
          38,
          61,
          74,
          60,
          28,
          61,
          75
        ],
        [
          "main",
          200,
          213,
          204,
          27,
          204,
          69,
          204,
          27,
          204,
          69
        ]
      ],
      "models/official/nlp/modeling/layers/gaussian_process_test.py": [
        [
          "test_state_saving_and_loading",
          203,
          222,
          216,
          23,
          216,
          58,
          203,
          37,
          222,
          60
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py": [
        [
          "_export_saved_model",
          126,
          144,
          129,
          24,
          129,
          54,
          126,
          27,
          144,
          27
        ],
        [
          "_export_saved_model",
          126,
          144,
          130,
          24,
          130,
          68,
          126,
          27,
          144,
          27
        ],
        [
          "_export_saved_model",
          126,
          144,
          136,
          26,
          136,
          56,
          126,
          27,
          144,
          27
        ],
        [
          "_export_saved_model",
          126,
          144,
          143,
          26,
          143,
          70,
          126,
          27,
          144,
          27
        ],
        [
          "test_beam_pipeline",
          234,
          256,
          237,
          25,
          237,
          65,
          234,
          26,
          252,
          35
        ]
      ],
      "models/research/delf/delf/python/datasets/generic_dataset_test.py": [
        [
          "testGenericDataset",
          38,
          56,
          48,
          18,
          49,
          60,
          45,
          9,
          51,
          55
        ]
      ],
      "models/research/delf/delf/python/datasets/generic_dataset.py": [
        [
          "listcomp",
          44,
          44,
          44,
          25,
          44,
          54,
          44,
          60,
          44,
          54
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py": [
        [
          "_export_saved_model",
          132,
          150,
          135,
          24,
          135,
          54,
          132,
          27,
          150,
          27
        ],
        [
          "_export_saved_model",
          132,
          150,
          136,
          24,
          136,
          68,
          132,
          27,
          150,
          27
        ],
        [
          "_export_saved_model",
          132,
          150,
          142,
          26,
          142,
          56,
          132,
          27,
          150,
          27
        ],
        [
          "_export_saved_model",
          132,
          150,
          149,
          26,
          149,
          70,
          132,
          27,
          150,
          27
        ],
        [
          "test_beam_pipeline",
          301,
          327,
          304,
          25,
          304,
          65,
          301,
          26,
          323,
          35
        ]
      ],
      "models/research/delf/delf/python/training/global_features_utils.py": [
        [
          "create_model_directory",
          177,
          221,
          216,
          12,
          216,
          42,
          210,
          3,
          219,
          31
        ]
      ],
      "models/research/delf/delf/python/training/model/global_model.py": [
        [
          "__init__",
          82,
          167,
          138,
          22,
          138,
          58,
          133,
          9,
          145,
          19
        ]
      ],
      "models/research/delf/delf/python/training/model/global_model_test.py": [
        [
          "testExtractVectors",
          48,
          70,
          63,
          18,
          63,
          79,
          60,
          9,
          65,
          34
        ]
      ],
      "models/research/adversarial_text/graphs_test.py": [
        [
          "setUpClass",
          80,
          135,
          123,
          11,
          123,
          45,
          121,
          9,
          124,
          27
        ],
        [
          "setUpClass",
          80,
          135,
          131,
          15,
          131,
          55,
          128,
          19,
          133,
          45
        ],
        [
          "setUpClass",
          80,
          135,
          132,
          17,
          132,
          62,
          128,
          19,
          133,
          45
        ]
      ],
      "models/research/adversarial_text/graphs.py": [
        [
          "_get_vocab_freqs",
          642,
          667,
          652,
          35,
          652,
          80,
          652,
          35,
          652,
          80
        ]
      ],
      "models/research/vid2depth/ops/icp_test.py": [
        [
          "_load_lidar_cloud",
          84,
          90,
          85,
          24,
          86,
          62,
          84,
          25,
          90,
          22
        ]
      ],
      "models/research/vid2depth/ops/icp_train_demo.py": [
        [
          "setup",
          60,
          74,
          62,
          24,
          63,
          62,
          60,
          13,
          74,
          44
        ]
      ],
      "models/official/projects/edgetpu/vision/tasks/image_classification.py": [
        [
          "_copy_recursively",
          35,
          45,
          38,
          15,
          38,
          62,
          37,
          7,
          39,
          38
        ],
        [
          "_copy_recursively",
          35,
          45,
          43,
          11,
          43,
          41,
          41,
          9,
          45,
          25
        ],
        [
          "_copy_recursively",
          35,
          45,
          44,
          11,
          44,
          41,
          41,
          9,
          45,
          25
        ]
      ],
      "models/official/vision/configs/image_classification.py": [
        [
          "image_classification_imagenet_revnet",
          299,
          361,
          317,
          26,
          317,
          73,
          300,
          3,
          361,
          15
        ],
        [
          "image_classification_imagenet",
          152,
          218,
          169,
          26,
          169,
          73,
          153,
          3,
          218,
          15
        ],
        [
          "image_classification_imagenet",
          152,
          218,
          173,
          26,
          173,
          73,
          153,
          3,
          218,
          15
        ],
        [
          "image_classification_imagenet_resnetrs",
          222,
          295,
          249,
          26,
          249,
          73,
          223,
          3,
          295,
          15
        ],
        [
          "image_classification_imagenet_resnetrs",
          222,
          295,
          255,
          26,
          255,
          73,
          223,
          3,
          295,
          15
        ],
        [
          "image_classification_imagenet_revnet",
          299,
          361,
          321,
          26,
          321,
          73,
          300,
          3,
          361,
          15
        ],
        [
          "image_classification_imagenet_mobilenet",
          365,
          433,
          384,
          26,
          384,
          73,
          366,
          3,
          433,
          15
        ],
        [
          "image_classification_imagenet_mobilenet",
          365,
          433,
          388,
          26,
          388,
          73,
          366,
          3,
          433,
          15
        ],
        [
          "image_classification_imagenet_deit_pretrain",
          437,
          513,
          464,
          26,
          464,
          73,
          438,
          3,
          513,
          15
        ],
        [
          "image_classification_imagenet_deit_pretrain",
          437,
          513,
          474,
          26,
          474,
          73,
          438,
          3,
          513,
          15
        ],
        [
          "image_classification_imagenet_vit_pretrain",
          517,
          577,
          534,
          26,
          534,
          73,
          518,
          3,
          577,
          15
        ],
        [
          "image_classification_imagenet_vit_pretrain",
          517,
          577,
          538,
          26,
          538,
          73,
          518,
          3,
          577,
          15
        ],
        [
          "image_classification_imagenet_vit_finetune",
          581,
          631,
          596,
          26,
          596,
          73,
          582,
          3,
          631,
          15
        ],
        [
          "image_classification_imagenet_vit_finetune",
          581,
          631,
          600,
          26,
          600,
          73,
          582,
          3,
          631,
          15
        ]
      ],
      "models/official/vision/serving/image_classification_test.py": [
        [
          "test_export",
          83,
          127,
          98,
          13,
          98,
          79,
          83,
          19,
          106,
          29
        ],
        [
          "test_export",
          83,
          127,
          92,
          36,
          92,
          74,
          83,
          19,
          106,
          29
        ],
        [
          "test_export",
          83,
          127,
          94,
          24,
          94,
          76,
          83,
          19,
          106,
          29
        ],
        [
          "test_multi_size_images_inference",
          133,
          176,
          142,
          36,
          142,
          74,
          133,
          40,
          158,
          29
        ],
        [
          "test_multi_size_images_inference",
          133,
          176,
          144,
          24,
          144,
          76,
          133,
          40,
          158,
          29
        ],
        [
          "test_multi_size_images_inference",
          133,
          176,
          148,
          13,
          148,
          79,
          133,
          40,
          158,
          29
        ]
      ],
      "models/official/projects/pruning/tasks/image_classification_test.py": [
        [
          "testTaskWithUnstructuredSparsity",
          104,
          145,
          105,
          26,
          105,
          79,
          104,
          40,
          129,
          18
        ],
        [
          "testTaskWithStructuredSparsity",
          149,
          197,
          150,
          26,
          150,
          79,
          149,
          38,
          178,
          18
        ]
      ],
      "models/official/projects/qat/vision/tasks/image_classification_test.py": [
        [
          "test_task",
          40,
          75,
          42,
          26,
          42,
          79,
          40,
          17,
          65,
          25
        ]
      ],
      "models/research/slim/datasets/imagenet.py": [
        [
          "get_split",
          121,
          197,
          143,
          18,
          143,
          69,
          143,
          18,
          146,
          19
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/image_reranking.py": [
        [
          "RerankByGeometricVerification",
          190,
          303,
          253,
          25,
          254,
          74,
          250,
          19,
          260,
          34
        ],
        [
          "RerankByGeometricVerification",
          190,
          303,
          272,
          33,
          274,
          62,
          269,
          22,
          278,
          52
        ]
      ],
      "models/official/legacy/image_classification/resnet/imagenet_preprocessing.py": [
        [
          "listcomp",
          136,
          137,
          137,
          9,
          137,
          57,
          138,
          13,
          137,
          57
        ],
        [
          "listcomp",
          141,
          142,
          142,
          9,
          142,
          62,
          143,
          13,
          142,
          62
        ]
      ],
      "models/research/vid2depth/inference.py": [
        [
          "listcomp",
          95,
          95,
          95,
          19,
          95,
          50,
          95,
          56,
          95,
          50
        ],
        [
          "_run_inference",
          73,
          128,
          77,
          16,
          79,
          65,
          74,
          3,
          80,
          33
        ],
        [
          "_run_inference",
          73,
          128,
          97,
          20,
          97,
          67,
          97,
          20,
          100,
          14
        ],
        [
          "_run_inference",
          73,
          128,
          98,
          29,
          98,
          78,
          97,
          20,
          100,
          14
        ],
        [
          "_run_inference",
          73,
          128,
          120,
          24,
          120,
          65,
          120,
          24,
          120,
          20
        ],
        [
          "_run_inference",
          73,
          128,
          122,
          24,
          122,
          65,
          122,
          24,
          122,
          20
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/inference_pipeline.py": [
        [
          "main",
          117,
          441,
          138,
          16,
          138,
          48,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          143,
          17,
          143,
          55,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          343,
          32,
          343,
          69,
          343,
          58,
          343,
          69
        ]
      ],
      "models/official/projects/unified_detector/data_loaders/input_reader.py": [
        [
          "listcomp",
          105,
          105,
          105,
          22,
          105,
          51,
          105,
          57,
          105,
          51
        ]
      ],
      "models/research/object_detection/builders/input_reader_builder_tf1_test.py": [
        [
          "create_tf_record_sequence_example",
          80,
          116,
          81,
          12,
          81,
          56,
          80,
          41,
          116,
          15
        ],
        [
          "_get_labelmap_path",
          33,
          37,
          36,
          10,
          37,
          44,
          34,
          3,
          37,
          44
        ],
        [
          "create_tf_record",
          43,
          66,
          44,
          12,
          44,
          56,
          43,
          24,
          66,
          15
        ],
        [
          "create_tf_record_with_context",
          118,
          158,
          119,
          12,
          119,
          56,
          118,
          37,
          158,
          15
        ]
      ],
      "models/research/adversarial_text/inputs.py": [
        [
          "_read_and_batch",
          187,
          246,
          214,
          15,
          214,
          43,
          187,
          21,
          215,
          35
        ]
      ],
      "models/official/projects/triviaqa/inputs.py": [
        [
          "listcomp",
          411,
          412,
          412,
          11,
          412,
          58,
          413,
          15,
          412,
          58
        ]
      ],
      "models/research/object_detection/inputs_test.py": [
        [
          "_get_configs_for_model",
          46,
          61,
          48,
          11,
          49,
          67,
          46,
          28,
          61,
          41
        ],
        [
          "_get_configs_for_model",
          46,
          61,
          50,
          20,
          51,
          59,
          46,
          28,
          61,
          41
        ],
        [
          "_get_configs_for_model",
          46,
          61,
          52,
          15,
          53,
          60,
          46,
          28,
          61,
          41
        ],
        [
          "_get_configs_for_model_sequence_example",
          64,
          81,
          66,
          11,
          67,
          61,
          64,
          45,
          81,
          41
        ],
        [
          "_get_configs_for_model_sequence_example",
          64,
          81,
          68,
          20,
          69,
          74,
          64,
          45,
          81,
          41
        ],
        [
          "_get_configs_for_model_sequence_example",
          64,
          81,
          70,
          15,
          72,
          62,
          64,
          45,
          81,
          41
        ]
      ],
      "models/research/object_detection/utils/json_utils_test.py": [
        [
          "testDumpReasonablePrecision",
          25,
          30,
          26,
          19,
          26,
          67,
          25,
          35,
          30,
          40
        ],
        [
          "testDumpPassExtraParams",
          32,
          37,
          33,
          19,
          33,
          67,
          32,
          31,
          37,
          49
        ],
        [
          "testDumpZeroPrecision",
          39,
          44,
          40,
          19,
          40,
          67,
          39,
          29,
          44,
          37
        ],
        [
          "testDumpUnspecifiedPrecision",
          46,
          51,
          47,
          19,
          47,
          67,
          46,
          36,
          51,
          44
        ]
      ],
      "models/research/object_detection/utils/label_map_util_test.py": [
        [
          "test_get_keypoint_label_map_dict",
          77,
          114,
          106,
          22,
          106,
          73,
          77,
          40,
          114,
          57
        ],
        [
          "test_get_label_map_dict",
          58,
          75,
          69,
          22,
          69,
          73,
          58,
          31,
          75,
          46
        ],
        [
          "test_get_keypoint_label_map_dict_invalid",
          116,
          151,
          145,
          22,
          145,
          73,
          116,
          48,
          150,
          7
        ],
        [
          "test_get_label_map_dict_display",
          170,
          188,
          181,
          22,
          181,
          73,
          170,
          39,
          188,
          46
        ],
        [
          "test_load_bad_label_map",
          190,
          210,
          205,
          22,
          205,
          73,
          190,
          31,
          210,
          50
        ],
        [
          "test_load_label_map_with_background",
          212,
          234,
          227,
          22,
          227,
          73,
          212,
          43,
          234,
          46
        ],
        [
          "test_get_label_map_dict_with_fill_in_gaps_and_background",
          236,
          258,
          247,
          22,
          247,
          73,
          236,
          64,
          258,
          75
        ],
        [
          "test_create_categories_from_labelmap",
          450,
          472,
          461,
          22,
          461,
          73,
          450,
          44,
          472,
          19
        ],
        [
          "test_create_category_index_from_labelmap",
          474,
          500,
          485,
          22,
          485,
          73,
          474,
          48,
          500,
          22
        ],
        [
          "test_create_category_index_from_labelmap_display",
          502,
          540,
          515,
          22,
          515,
          73,
          502,
          56,
          540,
          74
        ]
      ],
      "models/research/lfads/lfads.py": [
        [
          "__init__",
          280,
          1026,
          1025,
          20,
          1025,
          64,
          990,
          18,
          1026,
          15
        ],
        [
          "train_epoch",
          1228,
          1274,
          1268,
          25,
          1269,
          72,
          1267,
          17,
          1271,
          55
        ],
        [
          "summarize_all",
          1324,
          1390,
          1388,
          18,
          1388,
          79,
          1388,
          18,
          1390,
          32
        ],
        [
          "train_model",
          1472,
          1560,
          1530,
          29,
          1531,
          80,
          1529,
          28,
          1534,
          63
        ],
        [
          "write_model_runs",
          1962,
          2007,
          2005,
          22,
          2005,
          60,
          2005,
          22,
          2007,
          22
        ],
        [
          "write_model_samples",
          2009,
          2087,
          2085,
          18,
          2085,
          63,
          2085,
          18,
          2087,
          18
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/mask_bbox_saver.py": [
        [
          "save_bbox_masks_labels",
          37,
          81,
          79,
          7,
          79,
          37,
          38,
          5,
          81,
          3
        ],
        [
          "save_binary_masks",
          84,
          108,
          108,
          15,
          108,
          45,
          108,
          3,
          108,
          52
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/mask_bbox_saver_test.py": [
        [
          "test_visualize_tracking_function_runs",
          68,
          80,
          79,
          28,
          79,
          78,
          68,
          45,
          80,
          64
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/mask_bbox_saver.py": [
        [
          "visualize_tracking_results",
          134,
          167,
          166,
          17,
          166,
          56,
          166,
          5,
          166,
          62
        ],
        [
          "save_bbox_masks_labels",
          61,
          105,
          103,
          7,
          103,
          37,
          63,
          5,
          105,
          3
        ],
        [
          "save_binary_masks",
          108,
          130,
          130,
          15,
          130,
          45,
          130,
          3,
          130,
          52
        ],
        [
          "save_cropped_objects",
          170,
          224,
          200,
          20,
          200,
          68,
          199,
          7,
          203,
          41
        ],
        [
          "save_cropped_objects",
          170,
          224,
          205,
          11,
          205,
          73,
          203,
          9,
          222,
          57
        ],
        [
          "save_cropped_objects",
          170,
          224,
          222,
          19,
          222,
          50,
          203,
          9,
          222,
          57
        ]
      ],
      "models/official/projects/maskconver/configs/maskconver.py": [
        [
          "maskconver_coco",
          230,
          319,
          264,
          26,
          264,
          78,
          253,
          12,
          319,
          15
        ],
        [
          "maskconver_coco",
          230,
          319,
          274,
          26,
          274,
          76,
          253,
          12,
          319,
          15
        ],
        [
          "maskconver_seg_pascal",
          381,
          449,
          398,
          26,
          398,
          76,
          382,
          3,
          449,
          15
        ],
        [
          "maskconver_seg_pascal",
          381,
          449,
          409,
          26,
          409,
          70,
          382,
          3,
          449,
          15
        ],
        [
          "maskconver_seg_cityscapes",
          453,
          523,
          470,
          26,
          471,
          52,
          454,
          3,
          523,
          15
        ],
        [
          "maskconver_seg_cityscapes",
          453,
          523,
          483,
          26,
          483,
          79,
          454,
          3,
          523,
          15
        ]
      ],
      "models/official/vision/tasks/maskrcnn.py": [
        [
          "_build_coco_metrics",
          304,
          337,
          315,
          25,
          315,
          74,
          315,
          25,
          316,
          44
        ]
      ],
      "models/official/vision/configs/maskrcnn.py": [
        [
          "fasterrcnn_resnetfpn_coco",
          270,
          336,
          282,
          27,
          283,
          64,
          271,
          3,
          336,
          15
        ],
        [
          "fasterrcnn_resnetfpn_coco",
          270,
          336,
          293,
          26,
          293,
          69,
          271,
          3,
          336,
          15
        ],
        [
          "fasterrcnn_resnetfpn_coco",
          270,
          336,
          299,
          26,
          299,
          67,
          271,
          3,
          336,
          15
        ],
        [
          "maskrcnn_resnetfpn_coco",
          340,
          402,
          353,
          27,
          354,
          64,
          341,
          3,
          402,
          15
        ],
        [
          "maskrcnn_resnetfpn_coco",
          340,
          402,
          359,
          26,
          359,
          69,
          341,
          3,
          402,
          15
        ],
        [
          "maskrcnn_resnetfpn_coco",
          340,
          402,
          365,
          26,
          365,
          67,
          341,
          3,
          402,
          15
        ],
        [
          "maskrcnn_spinenet_coco",
          406,
          484,
          416,
          27,
          417,
          64,
          407,
          3,
          484,
          15
        ],
        [
          "maskrcnn_spinenet_coco",
          406,
          484,
          437,
          26,
          437,
          69,
          407,
          3,
          484,
          15
        ],
        [
          "maskrcnn_spinenet_coco",
          406,
          484,
          443,
          26,
          443,
          67,
          407,
          3,
          484,
          15
        ],
        [
          "cascadercnn_spinenet_coco",
          488,
          570,
          498,
          27,
          499,
          64,
          489,
          3,
          570,
          15
        ],
        [
          "cascadercnn_spinenet_coco",
          488,
          570,
          523,
          26,
          523,
          69,
          489,
          3,
          570,
          15
        ],
        [
          "cascadercnn_spinenet_coco",
          488,
          570,
          529,
          26,
          529,
          67,
          489,
          3,
          570,
          15
        ],
        [
          "maskrcnn_mobilenet_coco",
          574,
          658,
          584,
          27,
          585,
          64,
          575,
          3,
          658,
          15
        ],
        [
          "maskrcnn_mobilenet_coco",
          574,
          658,
          613,
          26,
          613,
          69,
          575,
          3,
          658,
          15
        ],
        [
          "maskrcnn_mobilenet_coco",
          574,
          658,
          619,
          26,
          619,
          67,
          575,
          3,
          658,
          15
        ]
      ],
      "models/official/vision/modeling/maskrcnn_model_test.py": [
        [
          "test_checkpoint",
          345,
          405,
          395,
          15,
          395,
          44,
          358,
          19,
          405,
          71
        ],
        [
          "test_checkpoint",
          345,
          405,
          395,
          15,
          395,
          44,
          363,
          19,
          401,
          19
        ]
      ],
      "models/research/efficient-hrl/environments/maze_env.py": [
        [
          "__init__",
          37,
          234,
          56,
          16,
          56,
          54,
          56,
          16,
          88,
          20
        ]
      ],
      "models/research/slim/datasets/mnist.py": [
        [
          "get_split",
          43,
          97,
          65,
          18,
          65,
          69,
          65,
          18,
          68,
          19
        ]
      ],
      "models/official/legacy/image_classification/mnist_main.py": [
        [
          "run",
          71,
          146,
          120,
          20,
          120,
          78,
          97,
          3,
          146,
          14
        ],
        [
          "run",
          71,
          146,
          139,
          17,
          139,
          64,
          97,
          3,
          146,
          14
        ]
      ],
      "models/official/projects/edgetpu/nlp/mobilebert_edgetpu_trainer.py": [
        [
          "build_exported_ckpt_manager",
          271,
          287,
          283,
          19,
          283,
          72,
          277,
          18,
          281,
          30
        ]
      ],
      "models/official/projects/edgetpu/vision/configs/mobilenet_edgetpu_config.py": [
        [
          "mobilenet_edgetpu_base_experiment_config",
          72,
          150,
          93,
          26,
          93,
          73,
          73,
          5,
          150,
          15
        ],
        [
          "mobilenet_edgetpu_base_experiment_config",
          72,
          150,
          99,
          26,
          99,
          73,
          73,
          5,
          150,
          15
        ]
      ],
      "models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v2_model_test.py": [
        [
          "test_export_tflite",
          37,
          45,
          42,
          21,
          42,
          63,
          37,
          26,
          45,
          54
        ]
      ],
      "models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v1_model_test.py": [
        [
          "_copy_recursively",
          32,
          42,
          35,
          15,
          35,
          62,
          34,
          7,
          36,
          38
        ],
        [
          "_copy_recursively",
          32,
          42,
          40,
          11,
          40,
          41,
          38,
          9,
          42,
          25
        ],
        [
          "_copy_recursively",
          32,
          42,
          41,
          11,
          41,
          41,
          38,
          9,
          42,
          25
        ],
        [
          "_test_prediction",
          218,
          240,
          229,
          18,
          229,
          48,
          218,
          24,
          240,
          39
        ]
      ],
      "models/research/object_detection/builders/model_builder_tf2_test.py": [
        [
          "get_fake_label_map_file_path",
          54,
          82,
          78,
          31,
          79,
          50,
          54,
          36,
          82,
          34
        ]
      ],
      "models/research/attention_ocr/python/model_export_test.py": [
        [
          "setUp",
          47,
          70,
          57,
          31,
          58,
          60,
          55,
          32,
          63,
          33
        ],
        [
          "setUp",
          47,
          70,
          61,
          23,
          62,
          59,
          55,
          32,
          63,
          33
        ]
      ],
      "models/official/projects/pointpillars/utils/model_exporter.py": [
        [
          "export_inference_graph",
          30,
          76,
          73,
          13,
          73,
          58,
          62,
          18,
          76,
          50
        ]
      ],
      "models/research/object_detection/model_lib_tf2_test.py": [
        [
          "_get_data_path",
          48,
          51,
          50,
          10,
          51,
          45,
          49,
          3,
          51,
          45
        ],
        [
          "get_pipeline_config_path",
          54,
          57,
          56,
          10,
          57,
          56,
          54,
          30,
          57,
          56
        ],
        [
          "_get_labelmap_path",
          60,
          63,
          62,
          10,
          63,
          44,
          61,
          3,
          63,
          44
        ],
        [
          "test_train_loop_then_eval_loop",
          85,
          112,
          89,
          32,
          89,
          77,
          85,
          38,
          112,
          33
        ],
        [
          "test_checkpoint_max_to_keep",
          161,
          183,
          170,
          34,
          170,
          79,
          161,
          35,
          183,
          64
        ],
        [
          "test_checkpoint_max_to_keep",
          161,
          183,
          181,
          37,
          181,
          75,
          161,
          35,
          183,
          64
        ],
        [
          "setUp",
          195,
          213,
          203,
          33,
          203,
          68,
          195,
          13,
          210,
          24
        ],
        [
          "test_export_metrics_json_serializable",
          246,
          272,
          258,
          36,
          259,
          70,
          246,
          45,
          272,
          46
        ]
      ],
      "models/official/legacy/bert/model_saving_utils.py": [
        [
          "export_bert_model",
          23,
          67,
          53,
          27,
          53,
          68,
          53,
          27,
          54,
          50
        ]
      ],
      "models/research/object_detection/model_lib_tf1_test.py": [
        [
          "_get_data_path",
          48,
          55,
          51,
          12,
          52,
          70,
          51,
          12,
          52,
          70
        ],
        [
          "_get_data_path",
          48,
          55,
          54,
          12,
          55,
          47,
          54,
          12,
          55,
          47
        ],
        [
          "get_pipeline_config_path",
          58,
          68,
          61,
          12,
          62,
          47,
          61,
          12,
          62,
          47
        ],
        [
          "get_pipeline_config_path",
          58,
          68,
          64,
          12,
          65,
          47,
          64,
          12,
          65,
          47
        ],
        [
          "get_pipeline_config_path",
          58,
          68,
          67,
          12,
          68,
          58,
          67,
          12,
          68,
          58
        ],
        [
          "_get_labelmap_path",
          71,
          74,
          73,
          10,
          74,
          44,
          72,
          3,
          74,
          44
        ],
        [
          "_get_keypoints_labelmap_path",
          77,
          80,
          79,
          10,
          80,
          67,
          78,
          3,
          80,
          67
        ],
        [
          "_get_sequence_example_labelmap_path",
          83,
          86,
          85,
          10,
          86,
          59,
          84,
          3,
          86,
          59
        ]
      ],
      "models/research/object_detection/model_lib_v2.py": [
        [
          "get_filepath",
          411,
          427,
          427,
          12,
          427,
          71,
          426,
          15,
          427,
          71
        ],
        [
          "train_loop",
          444,
          730,
          591,
          42,
          591,
          73,
          590,
          29,
          601,
          44
        ],
        [
          "eval_continuously",
          1022,
          1169,
          1156,
          9,
          1156,
          63,
          1155,
          22,
          1167,
          63
        ]
      ],
      "models/official/legacy/bert/model_training_utils.py": [
        [
          "_save_checkpoint",
          39,
          54,
          43,
          23,
          43,
          64,
          43,
          23,
          45,
          65
        ],
        [
          "_save_checkpoint",
          39,
          54,
          52,
          21,
          52,
          49,
          51,
          15,
          53,
          31
        ],
        [
          "write_txt_summary",
          93,
          100,
          97,
          18,
          97,
          56,
          97,
          18,
          100,
          51
        ],
        [
          "run_customized_training_loop",
          107,
          590,
          303,
          21,
          303,
          56,
          303,
          21,
          303,
          17
        ],
        [
          "run_customized_training_loop",
          107,
          590,
          310,
          9,
          310,
          41,
          309,
          27,
          312,
          43
        ],
        [
          "run_customized_training_loop",
          107,
          590,
          316,
          11,
          316,
          44,
          315,
          30,
          315,
          26
        ]
      ],
      "models/official/legacy/bert/model_training_utils_test.py": [
        [
          "test_train_check_artifacts",
          205,
          246,
          229,
          13,
          229,
          66,
          205,
          34,
          246,
          79
        ],
        [
          "summaries_with_matching_keyword",
          118,
          126,
          120,
          34,
          120,
          69,
          118,
          37,
          121,
          67
        ],
        [
          "test_train_check_artifacts",
          205,
          246,
          212,
          34,
          212,
          75,
          205,
          34,
          246,
          79
        ],
        [
          "test_train_check_artifacts",
          205,
          246,
          220,
          26,
          220,
          74,
          205,
          34,
          246,
          79
        ],
        [
          "test_train_check_artifacts",
          205,
          246,
          234,
          37,
          234,
          78,
          205,
          34,
          246,
          79
        ],
        [
          "test_train_check_artifacts",
          205,
          246,
          237,
          37,
          237,
          78,
          205,
          34,
          246,
          79
        ],
        [
          "test_train_check_artifacts",
          205,
          246,
          240,
          37,
          240,
          78,
          205,
          34,
          246,
          79
        ],
        [
          "test_train_check_artifacts",
          205,
          246,
          243,
          37,
          243,
          77,
          205,
          34,
          246,
          79
        ],
        [
          "test_train_check_artifacts",
          205,
          246,
          246,
          37,
          246,
          77,
          205,
          34,
          246,
          79
        ]
      ],
      "models/official/projects/nhnet/models_test.py": [
        [
          "test_bert2bert_decoding",
          119,
          175,
          145,
          33,
          145,
          73,
          119,
          31,
          175,
          46
        ],
        [
          "test_checkpoint_restore",
          243,
          256,
          246,
          33,
          246,
          73,
          243,
          31,
          255,
          71
        ]
      ],
      "models/official/projects/mosaic/configs/mosaic_config.py": [
        [
          "mosaic_mnv35_cityscapes",
          116,
          235,
          178,
          26,
          179,
          53,
          117,
          3,
          235,
          15
        ],
        [
          "mosaic_mnv35_cityscapes",
          116,
          235,
          187,
          26,
          187,
          78,
          117,
          3,
          235,
          15
        ],
        [
          "mosaic_mnv4_cityscapes",
          239,
          367,
          304,
          26,
          306,
          15,
          240,
          3,
          367,
          15
        ],
        [
          "mosaic_mnv4_cityscapes",
          239,
          367,
          315,
          26,
          315,
          78,
          240,
          3,
          367,
          15
        ]
      ],
      "models/official/projects/mosaic/qat/tasks/mosaic_tasks_test.py": [
        [
          "test_semantic_segmentation_task",
          42,
          86,
          45,
          26,
          45,
          79,
          42,
          39,
          76,
          55
        ]
      ],
      "models/official/projects/mosaic/mosaic_tasks_test.py": [
        [
          "test_semantic_segmentation_task",
          42,
          88,
          45,
          26,
          45,
          79,
          42,
          39,
          76,
          55
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "_download_and_clean",
          90,
          142,
          102,
          17,
          102,
          47,
          102,
          17,
          108,
          62
        ],
        [
          "_download_and_clean",
          90,
          142,
          116,
          16,
          116,
          63,
          116,
          16,
          116,
          63
        ],
        [
          "_download_and_clean",
          90,
          142,
          134,
          33,
          134,
          64,
          134,
          46,
          134,
          64
        ],
        [
          "_download_and_clean",
          90,
          142,
          135,
          26,
          135,
          54,
          135,
          39,
          135,
          54
        ],
        [
          "_download_and_clean",
          90,
          142,
          136,
          26,
          136,
          57,
          136,
          39,
          136,
          57
        ],
        [
          "_regularize_1m_dataset",
          176,
          205,
          193,
          17,
          193,
          45,
          176,
          28,
          205,
          33
        ],
        [
          "_regularize_1m_dataset",
          176,
          205,
          196,
          18,
          196,
          57,
          176,
          28,
          205,
          33
        ],
        [
          "_regularize_1m_dataset",
          176,
          205,
          197,
          19,
          197,
          54,
          176,
          28,
          205,
          33
        ],
        [
          "_regularize_1m_dataset",
          176,
          205,
          201,
          18,
          201,
          56,
          176,
          28,
          205,
          33
        ],
        [
          "_regularize_1m_dataset",
          176,
          205,
          202,
          19,
          202,
          53,
          176,
          28,
          205,
          33
        ],
        [
          "_regularize_20m_dataset",
          208,
          239,
          227,
          17,
          227,
          46,
          208,
          29,
          239,
          33
        ],
        [
          "_regularize_20m_dataset",
          208,
          239,
          230,
          18,
          230,
          57,
          208,
          29,
          239,
          33
        ],
        [
          "_regularize_20m_dataset",
          208,
          239,
          231,
          19,
          231,
          54,
          208,
          29,
          239,
          33
        ],
        [
          "_regularize_20m_dataset",
          208,
          239,
          235,
          18,
          235,
          56,
          208,
          29,
          239,
          33
        ],
        [
          "_regularize_20m_dataset",
          208,
          239,
          236,
          19,
          236,
          53,
          208,
          29,
          239,
          33
        ],
        [
          "ratings_csv_to_dataframe",
          249,
          251,
          250,
          26,
          250,
          70,
          249,
          30,
          251,
          43
        ],
        [
          "csv_to_joint_dataframe",
          254,
          263,
          257,
          26,
          257,
          69,
          254,
          28,
          263,
          11
        ]
      ],
      "models/official/projects/maskconver/configs/multiscale_maskconver.py": [
        [
          "multiscale_maskconver_coco",
          141,
          214,
          176,
          26,
          176,
          70,
          163,
          12,
          214,
          15
        ],
        [
          "multiscale_maskconver_coco",
          141,
          214,
          190,
          26,
          190,
          68,
          163,
          12,
          214,
          15
        ]
      ],
      "models/official/projects/simclr/modeling/multitask_model_test.py": [
        [
          "test_initialize_model_success",
          28,
          41,
          40,
          15,
          40,
          44,
          28,
          37,
          41,
          22
        ]
      ],
      "models/orbit/actions/new_best_metric_test.py": [
        [
          "test_json_persisted_value_create_dirs",
          83,
          90,
          84,
          16,
          84,
          76,
          83,
          45,
          90,
          49
        ]
      ],
      "models/official/recommendation/ncf_keras_main.py": [
        [
          "run_ncf",
          207,
          346,
          308,
          23,
          308,
          64,
          308,
          23,
          315,
          17
        ],
        [
          "run_ncf",
          207,
          346,
          311,
          27,
          311,
          69,
          308,
          23,
          315,
          17
        ],
        [
          "run_ncf_custom_training",
          349,
          518,
          447,
          19,
          447,
          60,
          447,
          19,
          450,
          24
        ],
        [
          "run_ncf_custom_training",
          349,
          518,
          449,
          9,
          449,
          41,
          447,
          19,
          450,
          24
        ],
        [
          "run_ncf_custom_training",
          349,
          518,
          451,
          9,
          451,
          42,
          447,
          19,
          450,
          24
        ],
        [
          "run_ncf_custom_training",
          349,
          518,
          514,
          23,
          514,
          69,
          513,
          18,
          516,
          70
        ]
      ],
      "models/research/object_detection/metrics/offline_eval_map_corloc.py": [
        [
          "write_metrics",
          135,
          147,
          144,
          13,
          144,
          51,
          135,
          19,
          146,
          52
        ]
      ],
      "models/official/projects/panoptic/configs/panoptic_deeplab.py": [
        [
          "panoptic_deeplab_resnet_coco",
          201,
          364,
          294,
          26,
          294,
          70,
          217,
          17,
          364,
          15
        ],
        [
          "panoptic_deeplab_resnet_coco",
          201,
          364,
          309,
          26,
          309,
          68,
          217,
          17,
          364,
          15
        ],
        [
          "panoptic_deeplab_mobilenetv3_large_coco",
          368,
          526,
          456,
          26,
          456,
          70,
          384,
          17,
          526,
          15
        ],
        [
          "panoptic_deeplab_mobilenetv3_large_coco",
          368,
          526,
          471,
          26,
          471,
          68,
          384,
          17,
          526,
          15
        ],
        [
          "panoptic_deeplab_mobilenetv3_small_coco",
          530,
          688,
          618,
          26,
          618,
          70,
          546,
          17,
          688,
          15
        ],
        [
          "panoptic_deeplab_mobilenetv3_small_coco",
          530,
          688,
          633,
          26,
          633,
          68,
          546,
          17,
          688,
          15
        ]
      ],
      "models/official/projects/panoptic/configs/panoptic_maskrcnn.py": [
        [
          "panoptic_fpn_coco",
          196,
          296,
          241,
          26,
          241,
          70,
          219,
          12,
          296,
          15
        ],
        [
          "panoptic_fpn_coco",
          196,
          296,
          247,
          26,
          247,
          68,
          219,
          12,
          296,
          15
        ],
        [
          "panoptic_fpn_coco",
          196,
          296,
          254,
          27,
          255,
          64,
          219,
          12,
          296,
          15
        ]
      ],
      "models/official/modeling/hyperparams/params_dict_test.py": [
        [
          "write_temp_file",
          209,
          213,
          210,
          17,
          210,
          59,
          209,
          23,
          213,
          20
        ],
        [
          "test_save_params_dict_to_yaml",
          215,
          232,
          224,
          24,
          224,
          71,
          215,
          37,
          232,
          56
        ]
      ],
      "models/research/delf/delf/python/delg/perform_retrieval.py": [
        [
          "_ReadDelgGlobalDescriptors",
          80,
          107,
          104,
          27,
          104,
          70,
          103,
          27,
          105,
          73
        ],
        [
          "main",
          110,
          220,
          220,
          27,
          220,
          75,
          218,
          3,
          220,
          76
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/perform_retrieval.py": [
        [
          "_ReadAggregatedDescriptors",
          60,
          112,
          101,
          28,
          101,
          72,
          100,
          28,
          102,
          39
        ],
        [
          "main",
          115,
          223,
          223,
          27,
          223,
          78,
          221,
          3,
          223,
          79
        ]
      ],
      "models/official/projects/pix2seq/configs/pix2seq.py": [
        [
          "pix2seq_r50_coco",
          192,
          280,
          202,
          27,
          204,
          11,
          193,
          3,
          280,
          15
        ],
        [
          "pix2seq_r50_coco",
          192,
          280,
          222,
          26,
          222,
          69,
          193,
          3,
          280,
          15
        ],
        [
          "pix2seq_r50_coco",
          192,
          280,
          231,
          26,
          231,
          67,
          193,
          3,
          280,
          15
        ]
      ],
      "models/official/projects/triviaqa/preprocess.py": [
        [
          "process",
          232,
          248,
          237,
          25,
          237,
          66,
          237,
          25,
          237,
          21
        ],
        [
          "process",
          232,
          248,
          239,
          25,
          239,
          60,
          239,
          25,
          239,
          21
        ]
      ],
      "models/official/legacy/xlnet/preprocess_classification_data.py": [
        [
          "get_train_examples",
          132,
          135,
          135,
          24,
          135,
          62,
          132,
          26,
          135,
          73
        ],
        [
          "get_dev_examples",
          137,
          140,
          140,
          24,
          140,
          60,
          137,
          24,
          140,
          69
        ],
        [
          "get_test_examples",
          142,
          150,
          150,
          24,
          150,
          61,
          149,
          12,
          150,
          71
        ],
        [
          "get_train_examples",
          200,
          201,
          201,
          34,
          201,
          68,
          200,
          26,
          201,
          69
        ],
        [
          "get_dev_examples",
          203,
          204,
          204,
          34,
          204,
          67,
          203,
          24,
          204,
          68
        ],
        [
          "get_train_examples",
          230,
          231,
          231,
          34,
          231,
          64,
          230,
          26,
          231,
          65
        ],
        [
          "get_dev_examples",
          233,
          234,
          234,
          34,
          234,
          63,
          233,
          24,
          234,
          64
        ],
        [
          "_create_examples",
          236,
          254,
          240,
          17,
          240,
          45,
          239,
          9,
          241,
          50
        ],
        [
          "_create_examples",
          236,
          254,
          248,
          16,
          248,
          46,
          248,
          16,
          253,
          73
        ],
        [
          "main",
          387,
          450,
          416,
          16,
          416,
          62,
          403,
          16,
          426,
          30
        ],
        [
          "main",
          387,
          450,
          446,
          15,
          446,
          60,
          443,
          20,
          450,
          52
        ]
      ],
      "models/official/legacy/xlnet/preprocess_squad_data.py": [
        [
          "preprocess",
          53,
          94,
          59,
          22,
          64,
          79,
          59,
          22,
          87,
          24
        ]
      ],
      "models/research/cvt_text/preprocessing.py": [
        [
          "main",
          34,
          75,
          51,
          21,
          51,
          67,
          46,
          7,
          56,
          70
        ]
      ],
      "models/official/legacy/xlnet/preprocess_pretrain_data.py": [
        [
          "_create_data",
          91,
          185,
          138,
          18,
          138,
          58,
          136,
          3,
          151,
          30
        ],
        [
          "create_data",
          188,
          254,
          199,
          18,
          199,
          58,
          199,
          18,
          200,
          38
        ],
        [
          "create_data",
          188,
          254,
          220,
          24,
          220,
          71,
          206,
          9,
          222,
          32
        ],
        [
          "create_data",
          188,
          254,
          251,
          22,
          251,
          60,
          234,
          3,
          254,
          30
        ],
        [
          "create_tfrecords",
          475,
          606,
          514,
          15,
          514,
          47,
          500,
          3,
          522,
          32
        ],
        [
          "get_input_fn",
          850,
          958,
          887,
          19,
          887,
          60,
          886,
          7,
          895,
          40
        ],
        [
          "get_input_fn",
          850,
          958,
          919,
          22,
          919,
          55,
          917,
          9,
          920,
          40
        ]
      ],
      "models/official/nlp/data/pretrain_dataloader_test.py": [
        [
          "test_load_data",
          108,
          140,
          109,
          23,
          109,
          74,
          108,
          22,
          140,
          65
        ],
        [
          "test_v2_feature_names",
          142,
          170,
          143,
          23,
          143,
          74,
          142,
          29,
          170,
          48
        ],
        [
          "test_load_data",
          180,
          238,
          182,
          23,
          182,
          74,
          181,
          7,
          202,
          38
        ]
      ],
      "models/official/nlp/data/pretrain_dynamic_dataloader_test.py": [
        [
          "test_distribution_strategy",
          80,
          157,
          83,
          18,
          83,
          69,
          80,
          34,
          126,
          25
        ],
        [
          "test_load_dataset",
          159,
          210,
          163,
          20,
          163,
          73,
          159,
          25,
          210,
          77
        ],
        [
          "test_load_dataset",
          159,
          210,
          170,
          20,
          170,
          73,
          159,
          25,
          210,
          77
        ],
        [
          "test_load_dataset_not_same_masks",
          212,
          241,
          215,
          20,
          215,
          73,
          212,
          40,
          241,
          22
        ],
        [
          "test_load_dataset_not_same_masks",
          212,
          241,
          222,
          20,
          222,
          73,
          212,
          40,
          241,
          22
        ]
      ],
      "models/official/projects/video_ssl/tasks/pretrain_test.py": [
        [
          "setUp",
          35,
          48,
          37,
          16,
          37,
          56,
          35,
          13,
          48,
          75
        ],
        [
          "setUp",
          35,
          48,
          39,
          23,
          39,
          61,
          35,
          13,
          48,
          75
        ]
      ],
      "models/official/projects/pointpillars/tools/process_wod.py": [
        [
          "main",
          94,
          115,
          109,
          24,
          109,
          73,
          108,
          7,
          115,
          38
        ],
        [
          "main",
          94,
          115,
          110,
          16,
          110,
          51,
          108,
          7,
          115,
          38
        ]
      ],
      "models/official/vision/data/process_coco_few_shot_json_files.py": [
        [
          "main",
          87,
          139,
          92,
          17,
          92,
          74,
          91,
          7,
          101,
          29
        ],
        [
          "main",
          87,
          139,
          98,
          19,
          99,
          58,
          91,
          7,
          101,
          29
        ],
        [
          "listcomp",
          105,
          105,
          105,
          19,
          105,
          47,
          106,
          23,
          105,
          47
        ],
        [
          "main",
          87,
          139,
          134,
          19,
          135,
          72,
          122,
          14,
          139,
          41
        ]
      ],
      "models/official/nlp/data/question_answering_dataloader_test.py": [
        [
          "test_load_dataset",
          48,
          70,
          51,
          18,
          51,
          69,
          48,
          25,
          70,
          66
        ]
      ],
      "models/official/nlp/tasks/question_answering.py": [
        [
          "_preprocess_eval_data",
          132,
          186,
          144,
          18,
          144,
          63,
          143,
          19,
          166,
          45
        ]
      ],
      "models/official/projects/qat/nlp/tasks/question_answering_test.py": [
        [
          "setUp",
          30,
          69,
          63,
          28,
          63,
          77,
          30,
          13,
          69,
          73
        ],
        [
          "setUp",
          30,
          69,
          67,
          24,
          67,
          69,
          30,
          13,
          69,
          73
        ]
      ],
      "models/official/nlp/tasks/question_answering_test.py": [
        [
          "setUp",
          32,
          71,
          65,
          28,
          65,
          77,
          32,
          13,
          71,
          73
        ],
        [
          "setUp",
          32,
          71,
          69,
          24,
          69,
          69,
          32,
          13,
          71,
          73
        ],
        [
          "_run_task",
          85,
          105,
          104,
          16,
          104,
          69,
          85,
          17,
          105,
          35
        ],
        [
          "_export_bert_tfhub",
          134,
          144,
          142,
          23,
          142,
          62,
          134,
          26,
          144,
          26
        ],
        [
          "setUp",
          179,
          220,
          214,
          28,
          214,
          77,
          179,
          13,
          220,
          73
        ],
        [
          "setUp",
          179,
          220,
          218,
          24,
          218,
          69,
          179,
          13,
          220,
          73
        ]
      ],
      "models/official/projects/nhnet/raw_data_process.py": [
        [
          "transform_as_tfrecords",
          44,
          65,
          52,
          20,
          52,
          70,
          44,
          28,
          56,
          44
        ],
        [
          "transform_as_tfrecords",
          44,
          65,
          53,
          19,
          53,
          62,
          44,
          28,
          56,
          44
        ],
        [
          "transform_as_tfrecords",
          44,
          65,
          58,
          9,
          60,
          54,
          56,
          7,
          60,
          55
        ]
      ],
      "models/official/projects/nhnet/raw_data_processor.py": [
        [
          "read_crawled_articles",
          70,
          84,
          77,
          13,
          77,
          36,
          76,
          24,
          78,
          29
        ]
      ],
      "models/official/projects/maxvit/configs/rcnn.py": [
        [
          "rcnn_maxvit_coco",
          43,
          132,
          53,
          27,
          54,
          64,
          44,
          3,
          132,
          15
        ],
        [
          "rcnn_maxvit_coco",
          43,
          132,
          79,
          26,
          79,
          69,
          44,
          3,
          132,
          15
        ],
        [
          "rcnn_maxvit_coco",
          43,
          132,
          85,
          26,
          85,
          67,
          44,
          3,
          132,
          15
        ]
      ],
      "models/research/rebar/rebar_train.py": [
        [
          "train",
          63,
          181,
          83,
          14,
          83,
          57,
          78,
          21,
          106,
          9
        ],
        [
          "train",
          63,
          181,
          87,
          35,
          88,
          37,
          78,
          21,
          106,
          9
        ],
        [
          "train",
          63,
          181,
          96,
          21,
          98,
          48,
          78,
          21,
          106,
          9
        ]
      ],
      "models/research/vid2depth/reader.py": [
        [
          "compile_file_list",
          177,
          202,
          180,
          21,
          180,
          60,
          177,
          25,
          195,
          16
        ],
        [
          "listcomp",
          184,
          185,
          185,
          9,
          185,
          68,
          186,
          13,
          185,
          68
        ],
        [
          "listcomp",
          188,
          189,
          189,
          9,
          189,
          72,
          190,
          13,
          189,
          72
        ],
        [
          "listcomp",
          196,
          197,
          197,
          11,
          197,
          75,
          198,
          15,
          197,
          75
        ]
      ],
      "models/research/deeplab/datasets/remove_gt_colormap.py": [
        [
          "main",
          66,
          79,
          71,
          27,
          72,
          72,
          71,
          17,
          73,
          31
        ],
        [
          "main",
          66,
          79,
          77,
          22,
          79,
          68,
          73,
          7,
          79,
          69
        ]
      ],
      "models/official/legacy/image_classification/resnet/resnet_ctl_imagenet_main.py": [
        [
          "run",
          87,
          182,
          169,
          24,
          169,
          64,
          163,
          17,
          172,
          28
        ]
      ],
      "models/research/delf/delf/python/training/model/resnet50.py": [
        [
          "restore_weights",
          400,
          446,
          418,
          20,
          418,
          70,
          417,
          22,
          427,
          30
        ]
      ],
      "models/official/vision/configs/retinanet.py": [
        [
          "retinanet_resnetfpn_coco",
          242,
          312,
          253,
          27,
          254,
          64,
          243,
          3,
          312,
          15
        ],
        [
          "retinanet_resnetfpn_coco",
          242,
          312,
          263,
          26,
          263,
          69,
          243,
          3,
          312,
          15
        ],
        [
          "retinanet_resnetfpn_coco",
          242,
          312,
          269,
          26,
          269,
          67,
          243,
          3,
          312,
          15
        ],
        [
          "retinanet_spinenet_coco",
          316,
          398,
          326,
          27,
          327,
          64,
          317,
          3,
          398,
          15
        ],
        [
          "retinanet_spinenet_coco",
          316,
          398,
          347,
          26,
          347,
          69,
          317,
          3,
          398,
          15
        ],
        [
          "retinanet_spinenet_coco",
          316,
          398,
          353,
          26,
          353,
          67,
          317,
          3,
          398,
          15
        ],
        [
          "retinanet_spinenet_mobile_coco",
          402,
          484,
          412,
          27,
          413,
          64,
          403,
          3,
          484,
          15
        ],
        [
          "retinanet_spinenet_mobile_coco",
          402,
          484,
          435,
          26,
          435,
          69,
          403,
          3,
          484,
          15
        ],
        [
          "retinanet_spinenet_mobile_coco",
          402,
          484,
          441,
          26,
          441,
          67,
          403,
          3,
          484,
          15
        ]
      ],
      "models/official/projects/qat/vision/tasks/retinanet_test.py": [
        [
          "test_retinanet_task",
          42,
          83,
          45,
          26,
          45,
          79,
          42,
          27,
          73,
          55
        ]
      ],
      "models/official/legacy/bert/run_classifier.py": [
        [
          "run_keras_compile_fit",
          197,
          260,
          231,
          19,
          231,
          54,
          225,
          5,
          242,
          25
        ],
        [
          "custom_main",
          420,
          503,
          476,
          27,
          476,
          75,
          465,
          7,
          479,
          32
        ]
      ],
      "models/official/legacy/xlnet/run_pretrain.py": [
        [
          "main",
          71,
          141,
          139,
          7,
          139,
          69,
          83,
          27,
          141,
          26
        ]
      ],
      "models/official/projects/edgetpu/nlp/run_mobilebert_edgetpu_train.py": [
        [
          "main",
          35,
          110,
          103,
          19,
          103,
          50,
          73,
          14,
          107,
          26
        ],
        [
          "main",
          35,
          110,
          104,
          24,
          104,
          54,
          73,
          14,
          107,
          26
        ]
      ],
      "models/official/projects/unified_detector/run_inference.py": [
        [
          "main",
          153,
          217,
          161,
          39,
          161,
          64,
          160,
          7,
          161,
          66
        ],
        [
          "main",
          153,
          217,
          213,
          21,
          213,
          62,
          210,
          11,
          214,
          57
        ]
      ],
      "models/official/legacy/bert/run_squad.py": [
        [
          "main",
          90,
          141,
          132,
          19,
          132,
          68,
          129,
          20,
          141,
          18
        ],
        [
          "main",
          90,
          141,
          140,
          23,
          140,
          68,
          129,
          20,
          141,
          18
        ]
      ],
      "models/official/nlp/finetuning/glue/run_glue.py": [
        [
          "_write_submission_file",
          178,
          233,
          184,
          7,
          184,
          66,
          178,
          28,
          233,
          28
        ],
        [
          "main",
          236,
          278,
          275,
          31,
          275,
          74,
          273,
          22,
          276,
          12
        ]
      ],
      "models/official/nlp/finetuning/superglue/run_superglue.py": [
        [
          "_write_submission_file",
          145,
          170,
          151,
          7,
          151,
          66,
          145,
          28,
          170,
          28
        ],
        [
          "main",
          173,
          214,
          211,
          31,
          211,
          74,
          209,
          22,
          212,
          12
        ]
      ],
      "models/official/legacy/xlnet/run_squad.py": [
        [
          "run_evaluation",
          97,
          199,
          177,
          28,
          178,
          59,
          177,
          28,
          192,
          33
        ],
        [
          "run_evaluation",
          97,
          199,
          179,
          23,
          180,
          60,
          177,
          28,
          192,
          33
        ],
        [
          "run_evaluation",
          97,
          199,
          181,
          31,
          182,
          60,
          177,
          28,
          192,
          33
        ]
      ],
      "models/research/lfads/run_lfads.py": [
        [
          "build_model",
          407,
          472,
          468,
          14,
          468,
          52,
          467,
          11,
          472,
          14
        ],
        [
          "write_model_parameters",
          677,
          700,
          693,
          11,
          693,
          56,
          693,
          11,
          700,
          16
        ]
      ],
      "models/official/legacy/bert/run_squad_helper.py": [
        [
          "prediction_output_squad",
          284,
          349,
          298,
          16,
          298,
          62,
          284,
          29,
          322,
          30
        ],
        [
          "dump_to_files",
          352,
          371,
          359,
          28,
          360,
          75,
          352,
          19,
          370,
          28
        ],
        [
          "dump_to_files",
          352,
          371,
          361,
          23,
          362,
          76,
          352,
          19,
          370,
          28
        ],
        [
          "dump_to_files",
          352,
          371,
          363,
          31,
          364,
          76,
          352,
          19,
          370,
          28
        ]
      ],
      "models/official/core/savedmodel_checkpoint_manager_test.py": [
        [
          "_models_exist",
          24,
          31,
          27,
          9,
          29,
          45,
          25,
          7,
          29,
          46
        ]
      ],
      "models/official/core/savedmodel_checkpoint_manager.py": [
        [
          "save",
          58,
          104,
          84,
          24,
          84,
          76,
          82,
          9,
          85,
          34
        ]
      ],
      "models/research/deeplab/deprecated/segmentation_dataset.py": [
        [
          "get_dataset",
          128,
          200,
          155,
          18,
          155,
          69,
          151,
          17,
          200,
          23
        ]
      ],
      "models/official/projects/volumetric_models/dataloaders/segmentation_input_3d_test.py": [
        [
          "setUp",
          28,
          34,
          30,
          16,
          30,
          56,
          28,
          13,
          33,
          17
        ],
        [
          "setUp",
          28,
          34,
          32,
          23,
          32,
          61,
          28,
          13,
          33,
          17
        ]
      ],
      "models/official/projects/maxvit/configs/semantic_segmentation.py": [
        [
          "maxvit_seg_pascal",
          41,
          135,
          73,
          26,
          73,
          75,
          42,
          3,
          135,
          15
        ],
        [
          "maxvit_seg_pascal",
          41,
          135,
          82,
          26,
          82,
          69,
          42,
          3,
          135,
          15
        ],
        [
          "maxvit_seg_coco",
          145,
          242,
          175,
          26,
          178,
          15,
          146,
          3,
          242,
          15
        ],
        [
          "maxvit_seg_coco",
          145,
          242,
          187,
          26,
          189,
          15,
          146,
          3,
          242,
          15
        ]
      ],
      "models/official/projects/volumetric_models/tasks/semantic_segmentation_3d_test.py": [
        [
          "setUp",
          37,
          49,
          39,
          16,
          39,
          56,
          37,
          13,
          49,
          75
        ],
        [
          "setUp",
          37,
          49,
          41,
          23,
          41,
          61,
          37,
          13,
          49,
          75
        ]
      ],
      "models/official/projects/volumetric_models/serving/semantic_segmentation_3d_test.py": [
        [
          "test_export",
          80,
          108,
          90,
          13,
          90,
          65,
          80,
          19,
          108,
          58
        ],
        [
          "test_export",
          80,
          108,
          87,
          40,
          87,
          78,
          80,
          19,
          108,
          58
        ],
        [
          "test_export",
          80,
          108,
          93,
          13,
          94,
          57,
          80,
          19,
          108,
          58
        ]
      ],
      "models/official/projects/edgetpu/vision/configs/semantic_segmentation_config.py": [
        [
          "seg_deeplabv3plus_ade20k_32",
          119,
          215,
          169,
          26,
          169,
          72,
          129,
          32,
          215,
          15
        ],
        [
          "seg_deeplabv3plus_ade20k_32",
          119,
          215,
          174,
          26,
          174,
          70,
          129,
          32,
          215,
          15
        ]
      ],
      "models/official/vision/configs/semantic_segmentation.py": [
        [
          "seg_deeplabv3_pascal",
          226,
          314,
          260,
          26,
          260,
          75,
          227,
          3,
          314,
          15
        ],
        [
          "seg_deeplabv3_pascal",
          226,
          314,
          268,
          26,
          268,
          69,
          227,
          3,
          314,
          15
        ],
        [
          "seg_deeplabv3plus_pascal",
          318,
          410,
          357,
          26,
          357,
          75,
          319,
          3,
          410,
          15
        ],
        [
          "seg_deeplabv3plus_pascal",
          318,
          410,
          364,
          26,
          364,
          69,
          319,
          3,
          410,
          15
        ],
        [
          "seg_resnetfpn_pascal",
          414,
          483,
          434,
          26,
          434,
          75,
          415,
          3,
          483,
          15
        ],
        [
          "seg_resnetfpn_pascal",
          414,
          483,
          440,
          26,
          440,
          69,
          415,
          3,
          483,
          15
        ],
        [
          "mnv2_deeplabv3_pascal",
          487,
          576,
          520,
          26,
          520,
          75,
          488,
          3,
          576,
          15
        ],
        [
          "mnv2_deeplabv3_pascal",
          487,
          576,
          527,
          26,
          527,
          69,
          488,
          3,
          576,
          15
        ],
        [
          "seg_deeplabv3plus_cityscapes",
          586,
          683,
          629,
          26,
          630,
          53,
          587,
          3,
          683,
          15
        ],
        [
          "seg_deeplabv3plus_cityscapes",
          586,
          683,
          638,
          26,
          638,
          78,
          587,
          3,
          683,
          15
        ],
        [
          "mnv2_deeplabv3_cityscapes",
          687,
          779,
          722,
          26,
          723,
          53,
          688,
          3,
          779,
          15
        ],
        [
          "mnv2_deeplabv3_cityscapes",
          687,
          779,
          731,
          26,
          731,
          78,
          688,
          3,
          779,
          15
        ]
      ],
      "models/official/projects/edgetpu/vision/configs/semantic_segmentation_searched_config.py": [
        [
          "autoseg_edgetpu_experiment_config",
          110,
          191,
          138,
          26,
          138,
          72,
          133,
          52,
          191,
          15
        ],
        [
          "autoseg_edgetpu_experiment_config",
          110,
          191,
          145,
          26,
          145,
          70,
          133,
          52,
          191,
          15
        ]
      ],
      "models/official/vision/serving/semantic_segmentation_test.py": [
        [
          "test_export",
          89,
          131,
          99,
          36,
          99,
          74,
          89,
          19,
          111,
          29
        ],
        [
          "test_export",
          89,
          131,
          101,
          24,
          101,
          76,
          89,
          19,
          111,
          29
        ],
        [
          "test_export",
          89,
          131,
          104,
          13,
          105,
          57,
          89,
          19,
          111,
          29
        ],
        [
          "test_export_with_extra_input_channels",
          137,
          193,
          158,
          36,
          158,
          74,
          137,
          45,
          173,
          29
        ],
        [
          "test_export_with_extra_input_channels",
          137,
          193,
          160,
          24,
          160,
          76,
          137,
          45,
          173,
          29
        ],
        [
          "test_export_with_extra_input_channels",
          137,
          193,
          164,
          13,
          164,
          79,
          137,
          45,
          173,
          29
        ]
      ],
      "models/official/nlp/tasks/sentence_prediction_test.py": [
        [
          "_run_task",
          76,
          89,
          88,
          16,
          88,
          63,
          76,
          17,
          89,
          71
        ],
        [
          "test_np_metrics_cola_partial_batch",
          188,
          214,
          189,
          23,
          189,
          74,
          188,
          42,
          214,
          76
        ],
        [
          "_export_bert_tfhub",
          216,
          226,
          224,
          23,
          224,
          62,
          216,
          26,
          226,
          26
        ],
        [
          "test_prediction",
          237,
          267,
          244,
          22,
          244,
          72,
          237,
          23,
          258,
          47
        ]
      ],
      "models/official/nlp/data/sentence_prediction_dataloader_test.py": [
        [
          "test_load_dataset_with_label_mapping",
          145,
          168,
          146,
          18,
          146,
          69,
          145,
          44,
          168,
          70
        ],
        [
          "test_saved_model_preprocessing",
          251,
          286,
          255,
          22,
          255,
          73,
          251,
          38,
          257,
          19
        ],
        [
          "_create_fake_sentencepiece_model",
          89,
          109,
          91,
          18,
          91,
          54,
          89,
          38,
          109,
          32
        ],
        [
          "_create_fake_sentencepiece_model",
          89,
          109,
          92,
          26,
          92,
          68,
          89,
          38,
          109,
          32
        ],
        [
          "test_load_dataset",
          124,
          143,
          125,
          18,
          125,
          69,
          124,
          25,
          143,
          70
        ],
        [
          "test_python_wordpiece_preprocessing",
          175,
          210,
          180,
          22,
          180,
          73,
          175,
          43,
          182,
          19
        ],
        [
          "test_python_wordpiece_preprocessing",
          175,
          210,
          185,
          23,
          185,
          68,
          183,
          7,
          210,
          64
        ],
        [
          "test_python_wordpiece_preprocessing",
          175,
          210,
          185,
          23,
          185,
          68,
          185,
          23,
          210,
          64
        ],
        [
          "test_python_sentencepiece_preprocessing",
          213,
          248,
          218,
          22,
          218,
          73,
          213,
          47,
          220,
          19
        ],
        [
          "test_saved_model_preprocessing",
          251,
          286,
          260,
          23,
          260,
          68,
          258,
          7,
          286,
          64
        ],
        [
          "test_saved_model_preprocessing",
          251,
          286,
          260,
          23,
          260,
          68,
          260,
          23,
          286,
          64
        ]
      ],
      "models/official/projects/perceiver/tasks/sentence_prediction_test.py": [
        [
          "test_np_metrics_cola_partial_batch",
          210,
          236,
          211,
          23,
          211,
          74,
          210,
          42,
          236,
          76
        ],
        [
          "test_prediction",
          246,
          276,
          253,
          22,
          253,
          72,
          246,
          23,
          267,
          47
        ]
      ],
      "models/official/nlp/data/sentence_retrieval_lib.py": [
        [
          "get_test_examples",
          72,
          74,
          74,
          24,
          74,
          56,
          72,
          25,
          74,
          66
        ],
        [
          "get_dev_examples",
          32,
          35,
          34,
          24,
          34,
          73,
          32,
          24,
          35,
          17
        ],
        [
          "get_test_examples",
          37,
          40,
          39,
          24,
          39,
          74,
          37,
          25,
          40,
          15
        ],
        [
          "generate_sentence_retrevial_tf_record",
          93,
          166,
          138,
          23,
          138,
          71,
          137,
          36,
          149,
          62
        ],
        [
          "generate_sentence_retrevial_tf_record",
          93,
          166,
          143,
          23,
          145,
          66,
          137,
          36,
          149,
          62
        ],
        [
          "generate_sentence_retrevial_tf_record",
          93,
          166,
          153,
          23,
          153,
          71,
          152,
          36,
          164,
          62
        ],
        [
          "generate_sentence_retrevial_tf_record",
          93,
          166,
          158,
          23,
          160,
          67,
          152,
          36,
          164,
          62
        ]
      ],
      "models/research/lstm_object_detection/inputs/seq_dataset_builder_test.py": [
        [
          "_create_tf_record",
          36,
          96,
          37,
          12,
          37,
          56,
          36,
          25,
          96,
          15
        ]
      ],
      "models/official/pip_package/setup.py": [
        [
          "_get_requirements",
          41,
          60,
          50,
          7,
          50,
          56,
          49,
          8,
          51,
          17
        ]
      ],
      "models/official/nlp/serving/serving_modules_test.py": [
        [
          "test_translation",
          350,
          387,
          377,
          15,
          377,
          72,
          350,
          24,
          387,
          38
        ],
        [
          "_make_sentencepeice",
          83,
          91,
          86,
          30,
          86,
          67,
          83,
          25,
          91,
          33
        ],
        [
          "_make_sentencepeice",
          83,
          91,
          88,
          32,
          88,
          61,
          83,
          25,
          91,
          33
        ],
        [
          "test_sentence_prediction_text",
          164,
          190,
          165,
          23,
          165,
          68,
          164,
          37,
          190,
          55
        ],
        [
          "test_translation",
          350,
          387,
          378,
          23,
          378,
          53,
          350,
          24,
          387,
          38
        ],
        [
          "test_translation",
          350,
          387,
          379,
          16,
          379,
          44,
          350,
          24,
          387,
          38
        ]
      ],
      "models/research/delf/delf/python/datasets/sfm120k/sfm120k.py": [
        [
          "id2filename",
          30,
          47,
          43,
          12,
          44,
          33,
          43,
          12,
          44,
          33
        ],
        [
          "id2filename",
          30,
          47,
          46,
          12,
          47,
          33,
          46,
          12,
          47,
          33
        ],
        [
          "__init__",
          59,
          104,
          89,
          15,
          89,
          65,
          89,
          15,
          104,
          49
        ],
        [
          "__init__",
          59,
          104,
          90,
          16,
          90,
          44,
          89,
          15,
          104,
          49
        ],
        [
          "__init__",
          59,
          104,
          93,
          19,
          93,
          62,
          89,
          15,
          104,
          49
        ]
      ],
      "models/official/recommendation/ranking/preprocessing/shard_rebalancer.py": [
        [
          "rebalance_data_shards",
          63,
          111,
          97,
          27,
          97,
          74,
          64,
          3,
          108,
          34
        ],
        [
          "rebalance_data_shards",
          63,
          111,
          98,
          24,
          98,
          60,
          64,
          3,
          108,
          34
        ]
      ],
      "models/official/projects/simclr/configs/simclr.py": [
        [
          "simclr_pretraining_imagenet",
          205,
          278,
          228,
          26,
          228,
          73,
          206,
          3,
          278,
          8
        ],
        [
          "simclr_pretraining_imagenet",
          205,
          278,
          234,
          26,
          234,
          73,
          206,
          3,
          278,
          8
        ],
        [
          "simclr_finetuning_imagenet",
          282,
          348,
          305,
          26,
          305,
          73,
          283,
          3,
          348,
          8
        ],
        [
          "simclr_finetuning_imagenet",
          282,
          348,
          310,
          26,
          310,
          73,
          283,
          3,
          348,
          8
        ]
      ],
      "models/official/nlp/data/squad_lib_sp.py": [
        [
          "read_squad_examples",
          112,
          162,
          123,
          9,
          123,
          55,
          122,
          24,
          124,
          32
        ]
      ],
      "models/official/nlp/data/squad_lib.py": [
        [
          "read_squad_examples",
          161,
          249,
          170,
          9,
          170,
          55,
          169,
          24,
          171,
          32
        ]
      ],
      "models/official/legacy/xlnet/squad_utils.py": [
        [
          "create_eval_data",
          928,
          972,
          940,
          21,
          943,
          69,
          940,
          21,
          950,
          15
        ],
        [
          "create_eval_data",
          928,
          972,
          944,
          25,
          948,
          72,
          940,
          21,
          950,
          15
        ]
      ],
      "models/official/vision/utils/summary_manager.py": [
        [
          "_write_summaries",
          48,
          63,
          54,
          34,
          54,
          66,
          53,
          9,
          55,
          9
        ],
        [
          "maybe_build_eval_summary_manager",
          66,
          84,
          75,
          24,
          77,
          5,
          75,
          24,
          83,
          5
        ]
      ],
      "models/orbit/utils/summary_manager.py": [
        [
          "summary_writer",
          47,
          62,
          59,
          11,
          59,
          56,
          58,
          46,
          58,
          42
        ],
        [
          "_write_summaries",
          105,
          112,
          109,
          34,
          109,
          66,
          108,
          9,
          109,
          67
        ]
      ],
      "models/official/nlp/data/tagging_data_lib_test.py": [
        [
          "setUp",
          44,
          53,
          51,
          23,
          51,
          68,
          44,
          13,
          53,
          75
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          61,
          22,
          61,
          65,
          59,
          31,
          76,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          65,
          9,
          65,
          52,
          59,
          31,
          76,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          71,
          9,
          71,
          50,
          59,
          31,
          76,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          78,
          11,
          78,
          60,
          76,
          9,
          80,
          23
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          82,
          19,
          82,
          72,
          82,
          19,
          100,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          90,
          32,
          90,
          74,
          82,
          19,
          100,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          91,
          31,
          91,
          72,
          82,
          19,
          100,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          92,
          31,
          92,
          75,
          82,
          19,
          100,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          98,
          27,
          98,
          69,
          82,
          19,
          100,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          99,
          27,
          99,
          68,
          82,
          19,
          100,
          45
        ],
        [
          "test_generate_tf_record",
          59,
          104,
          102,
          11,
          102,
          62,
          100,
          9,
          102,
          63
        ]
      ],
      "models/official/nlp/data/tagging_data_lib.py": [
        [
          "get_train_examples",
          110,
          121,
          119,
          17,
          119,
          63,
          117,
          9,
          120,
          35
        ],
        [
          "get_train_examples",
          110,
          121,
          112,
          9,
          112,
          46,
          110,
          26,
          113,
          33
        ],
        [
          "get_dev_examples",
          123,
          134,
          125,
          9,
          125,
          44,
          123,
          24,
          126,
          31
        ],
        [
          "get_dev_examples",
          123,
          134,
          132,
          17,
          132,
          61,
          130,
          9,
          133,
          35
        ],
        [
          "get_test_examples",
          136,
          141,
          140,
          11,
          140,
          58,
          138,
          9,
          139,
          29
        ],
        [
          "get_train_examples",
          176,
          188,
          179,
          11,
          179,
          48,
          178,
          18,
          178,
          14
        ],
        [
          "get_train_examples",
          176,
          188,
          183,
          40,
          183,
          76,
          181,
          18,
          183,
          77
        ],
        [
          "get_dev_examples",
          190,
          201,
          193,
          11,
          193,
          46,
          192,
          18,
          192,
          14
        ],
        [
          "get_dev_examples",
          190,
          201,
          196,
          40,
          196,
          74,
          195,
          18,
          196,
          75
        ],
        [
          "get_test_examples",
          203,
          208,
          207,
          11,
          207,
          58,
          205,
          9,
          206,
          29
        ]
      ],
      "models/official/nlp/data/tagging_dataloader_test.py": [
        [
          "test_load_dataset",
          53,
          78,
          56,
          23,
          56,
          74,
          53,
          25,
          68,
          26
        ]
      ],
      "models/official/nlp/tasks/tagging_test.py": [
        [
          "test_predict",
          138,
          164,
          146,
          22,
          146,
          72,
          138,
          20,
          164,
          33
        ],
        [
          "_run_task",
          60,
          73,
          73,
          16,
          73,
          63,
          60,
          17,
          73,
          64
        ],
        [
          "_export_bert_tfhub",
          97,
          107,
          105,
          23,
          105,
          62,
          97,
          26,
          107,
          26
        ]
      ],
      "models/research/deeplab/evaluation/test_utils.py": [
        [
          "read_test_image",
          37,
          50,
          49,
          16,
          49,
          53,
          37,
          21,
          50,
          55
        ]
      ],
      "models/official/nlp/tools/tf2_albert_encoder_checkpoint_converter.py": [
        [
          "convert_checkpoint",
          122,
          155,
          130,
          26,
          130,
          71,
          122,
          24,
          140,
          33
        ],
        [
          "convert_checkpoint",
          122,
          155,
          129,
          30,
          129,
          64,
          122,
          24,
          140,
          33
        ]
      ],
      "models/official/nlp/modeling/layers/text_layers_test.py": [
        [
          "setUp",
          136,
          157,
          142,
          20,
          142,
          53,
          136,
          13,
          157,
          18
        ],
        [
          "_make_vocab_file",
          33,
          39,
          34,
          12,
          36,
          17,
          33,
          24,
          39,
          15
        ],
        [
          "setUp",
          136,
          157,
          143,
          28,
          143,
          67,
          136,
          13,
          157,
          18
        ],
        [
          "_make_vocab_file",
          449,
          455,
          450,
          12,
          452,
          17,
          449,
          24,
          455,
          15
        ]
      ],
      "models/official/nlp/tools/tf2_bert_encoder_checkpoint_converter.py": [
        [
          "convert_checkpoint",
          101,
          139,
          111,
          30,
          111,
          64,
          101,
          24,
          123,
          33
        ],
        [
          "convert_checkpoint",
          101,
          139,
          112,
          26,
          112,
          71,
          101,
          24,
          123,
          33
        ]
      ],
      "models/official/projects/mobilebert/tf2_model_checkpoint_converter.py": [
        [
          "convert",
          90,
          186,
          123,
          30,
          123,
          64,
          90,
          13,
          132,
          34
        ],
        [
          "convert",
          90,
          186,
          124,
          26,
          124,
          71,
          90,
          13,
          132,
          34
        ]
      ],
      "models/research/object_detection/dataset_tools/tf_record_creation_util_test.py": [
        [
          "test_sharded_tfrecord_writes",
          33,
          45,
          37,
          11,
          37,
          60,
          33,
          36,
          38,
          26
        ],
        [
          "test_sharded_tfrecord_writes",
          33,
          45,
          43,
          11,
          43,
          60,
          41,
          9,
          45,
          75
        ]
      ],
      "models/official/vision/dataloaders/tf_example_label_map_decoder_test.py": [
        [
          "test_result_shape",
          39,
          76,
          42,
          22,
          42,
          64,
          39,
          25,
          76,
          74
        ],
        [
          "test_result_content",
          78,
          183,
          81,
          22,
          81,
          64,
          78,
          27,
          183,
          57
        ]
      ],
      "models/research/object_detection/data_decoders/tf_sequence_example_decoder_test.py": [
        [
          "graph_fn",
          85,
          115,
          86,
          30,
          86,
          80,
          86,
          30,
          115,
          50
        ],
        [
          "graph_fn",
          148,
          183,
          149,
          30,
          149,
          80,
          149,
          30,
          183,
          50
        ],
        [
          "graph_fn",
          217,
          252,
          218,
          30,
          218,
          80,
          218,
          30,
          252,
          50
        ],
        [
          "graph_fn",
          275,
          302,
          298,
          30,
          298,
          80,
          276,
          37,
          302,
          50
        ]
      ],
      "models/research/object_detection/data_decoders/tf_example_decoder_test.py": [
        [
          "testDecodeKeypointWithText",
          516,
          621,
          557,
          28,
          557,
          79,
          516,
          34,
          621,
          69
        ],
        [
          "testDecodeKeypointWithKptsLabelsNotInText",
          623,
          731,
          668,
          28,
          668,
          79,
          623,
          49,
          731,
          69
        ],
        [
          "graph_fn",
          944,
          976,
          965,
          24,
          965,
          75,
          945,
          17,
          976,
          19
        ],
        [
          "graph_fn",
          992,
          1033,
          1027,
          24,
          1027,
          75,
          993,
          17,
          1033,
          66
        ],
        [
          "graph_fn",
          1046,
          1077,
          1068,
          24,
          1068,
          75,
          1047,
          17,
          1077,
          19
        ],
        [
          "graph_fn",
          1089,
          1121,
          1111,
          24,
          1111,
          75,
          1090,
          17,
          1121,
          19
        ],
        [
          "graph_fn",
          1134,
          1165,
          1160,
          24,
          1160,
          75,
          1135,
          17,
          1165,
          66
        ],
        [
          "graph_fn",
          1177,
          1209,
          1199,
          24,
          1199,
          75,
          1178,
          17,
          1209,
          19
        ],
        [
          "graph_fn_2",
          1648,
          1675,
          1670,
          24,
          1670,
          75,
          1649,
          17,
          1675,
          66
        ],
        [
          "testExpandLabels",
          1770,
          1868,
          1801,
          22,
          1801,
          73,
          1770,
          24,
          1868,
          74
        ]
      ],
      "models/official/legacy/image_classification/resnet/tfhub_export.py": [
        [
          "export_tfhub",
          39,
          54,
          45,
          7,
          45,
          53,
          39,
          18,
          54,
          79
        ],
        [
          "export_tfhub",
          39,
          54,
          54,
          7,
          54,
          53,
          39,
          18,
          54,
          79
        ]
      ],
      "models/official/legacy/image_classification/efficientnet/tfhub_export.py": [
        [
          "export_tfhub",
          38,
          56,
          51,
          7,
          51,
          53,
          38,
          18,
          56,
          79
        ],
        [
          "export_tfhub",
          38,
          56,
          56,
          7,
          56,
          53,
          38,
          18,
          56,
          79
        ]
      ],
      "models/official/vision/data/tfrecord_lib_test.py": [
        [
          "test_write_tf_record_dataset",
          45,
          60,
          48,
          12,
          48,
          51,
          45,
          36,
          60,
          52
        ],
        [
          "test_obj_annotation_tf_example",
          92,
          173,
          133,
          17,
          133,
          46,
          92,
          38,
          134,
          36
        ],
        [
          "test_obj_annotation_tf_example",
          92,
          173,
          137,
          20,
          137,
          62,
          136,
          9,
          141,
          7
        ],
        [
          "test_obj_annotation_tf_example",
          92,
          173,
          143,
          19,
          143,
          50,
          143,
          19,
          170,
          15
        ]
      ],
      "models/official/nlp/modeling/layers/tn_expand_condense_test.py": [
        [
          "test_model_save",
          141,
          156,
          151,
          17,
          151,
          63,
          141,
          23,
          156,
          72
        ]
      ],
      "models/orbit/utils/tpu_summaries_test.py": [
        [
          "_get_events_from_logdir",
          77,
          82,
          80,
          12,
          80,
          47,
          77,
          31,
          82,
          79
        ]
      ],
      "models/research/lstm_object_detection/train.py": [
        [
          "main",
          88,
          181,
          110,
          21,
          110,
          55,
          106,
          11,
          110,
          72
        ],
        [
          "main",
          88,
          181,
          98,
          11,
          98,
          58,
          96,
          7,
          99,
          25
        ]
      ],
      "models/research/delf/delf/python/training/train.py": [
        [
          "main",
          167,
          554,
          232,
          23,
          232,
          65,
          206,
          14,
          433,
          49
        ],
        [
          "main",
          167,
          554,
          269,
          9,
          269,
          48,
          206,
          14,
          433,
          49
        ]
      ],
      "models/research/object_detection/legacy/train.py": [
        [
          "main",
          90,
          182,
          98,
          21,
          98,
          68,
          97,
          7,
          99,
          35
        ],
        [
          "main",
          90,
          182,
          109,
          31,
          109,
          65,
          106,
          11,
          110,
          37
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/train.py": [
        [
          "save_and_convert",
          80,
          91,
          82,
          22,
          82,
          60,
          80,
          22,
          91,
          17
        ],
        [
          "save_and_convert",
          80,
          91,
          90,
          13,
          90,
          52,
          80,
          22,
          91,
          17
        ]
      ],
      "models/official/projects/pointpillars/train.py": [
        [
          "main",
          58,
          100,
          100,
          18,
          100,
          55,
          81,
          27,
          100,
          56
        ]
      ],
      "models/research/vid2depth/train.py": [
        [
          "train",
          109,
          169,
          164,
          26,
          164,
          62,
          163,
          9,
          165,
          43
        ]
      ],
      "models/research/efficient-hrl/train.py": [
        [
          "train_uvf",
          270,
          670,
          606,
          22,
          606,
          75,
          603,
          15,
          670,
          37
        ]
      ],
      "models/research/delf/delf/python/training/global_features/train.py": [
        [
          "main",
          117,
          358,
          128,
          24,
          129,
          65,
          128,
          24,
          130,
          47
        ],
        [
          "main",
          117,
          358,
          351,
          20,
          352,
          71,
          351,
          20,
          352,
          71
        ]
      ],
      "models/official/projects/triviaqa/train.py": [
        [
          "fit",
          158,
          229,
          210,
          9,
          210,
          38,
          205,
          18,
          212,
          65
        ],
        [
          "fit",
          158,
          229,
          225,
          20,
          225,
          52,
          224,
          28,
          226,
          62
        ]
      ],
      "models/official/modeling/fast_training/progressive/train_lib.py": [
        [
          "run_experiment",
          34,
          125,
          89,
          19,
          89,
          50,
          89,
          19,
          89,
          50
        ],
        [
          "run_experiment",
          34,
          125,
          90,
          24,
          90,
          60,
          90,
          24,
          90,
          60
        ]
      ],
      "models/official/core/train_lib.py": [
        [
          "_build_controller",
          193,
          251,
          221,
          26,
          223,
          7,
          221,
          26,
          221,
          22
        ],
        [
          "_build_controller",
          193,
          251,
          235,
          21,
          235,
          57,
          235,
          21,
          235,
          57
        ]
      ],
      "models/official/modeling/multitask/train_lib.py": [
        [
          "run_experiment",
          39,
          150,
          116,
          19,
          116,
          50,
          101,
          24,
          123,
          22
        ],
        [
          "run_experiment",
          39,
          150,
          117,
          24,
          117,
          60,
          101,
          24,
          123,
          22
        ],
        [
          "run_experiment_with_multitask_eval",
          204,
          367,
          328,
          19,
          328,
          50,
          328,
          19,
          328,
          50
        ],
        [
          "run_experiment_with_multitask_eval",
          204,
          367,
          329,
          24,
          329,
          60,
          329,
          24,
          329,
          60
        ]
      ],
      "models/official/modeling/fast_training/progressive/train_lib_test.py": [
        [
          "test_end_to_end",
          142,
          179,
          170,
          26,
          170,
          62,
          169,
          5,
          179,
          15
        ]
      ],
      "models/official/core/train_lib_test.py": [
        [
          "test_end_to_end_class",
          129,
          173,
          165,
          26,
          165,
          62,
          164,
          5,
          167,
          11
        ],
        [
          "test_end_to_end",
          75,
          118,
          106,
          26,
          106,
          63,
          105,
          5,
          107,
          26
        ],
        [
          "test_end_to_end",
          75,
          118,
          99,
          15,
          100,
          68,
          97,
          7,
          101,
          20
        ],
        [
          "test_end_to_end",
          75,
          118,
          110,
          26,
          110,
          62,
          109,
          5,
          112,
          11
        ],
        [
          "test_end_to_end_class",
          129,
          173,
          154,
          15,
          155,
          68,
          152,
          7,
          156,
          20
        ],
        [
          "test_end_to_end_class",
          129,
          173,
          161,
          26,
          161,
          63,
          160,
          5,
          162,
          26
        ]
      ],
      "models/research/autoaugment/train_cifar.py": [
        [
          "__init__",
          216,
          227,
          220,
          22,
          220,
          64,
          216,
          16,
          227,
          28
        ],
        [
          "__init__",
          216,
          227,
          221,
          20,
          221,
          60,
          216,
          16,
          227,
          28
        ],
        [
          "save_model",
          229,
          240,
          236,
          23,
          236,
          64,
          229,
          18,
          237,
          47
        ]
      ],
      "models/official/projects/volumetric_models/train_test.py": [
        [
          "setUp",
          31,
          46,
          33,
          23,
          33,
          68,
          31,
          13,
          46,
          75
        ],
        [
          "setUp",
          31,
          46,
          36,
          16,
          36,
          56,
          31,
          13,
          46,
          75
        ],
        [
          "setUp",
          31,
          46,
          38,
          23,
          38,
          61,
          31,
          13,
          46,
          75
        ]
      ],
      "models/official/projects/movinet/train_test.py": [
        [
          "setUp",
          34,
          50,
          39,
          16,
          39,
          56,
          34,
          13,
          50,
          75
        ],
        [
          "setUp",
          34,
          50,
          41,
          23,
          41,
          61,
          34,
          13,
          50,
          75
        ],
        [
          "setUp",
          34,
          50,
          36,
          23,
          36,
          68,
          34,
          13,
          50,
          75
        ]
      ],
      "models/official/projects/maxvit/train_test.py": [
        [
          "setUp",
          32,
          49,
          35,
          23,
          35,
          68,
          32,
          13,
          49,
          5
        ],
        [
          "setUp",
          32,
          49,
          37,
          32,
          39,
          5,
          32,
          13,
          49,
          5
        ]
      ],
      "models/official/recommendation/ranking/train_test.py": [
        [
          "setUp",
          81,
          88,
          84,
          23,
          84,
          63,
          81,
          13,
          88,
          13
        ],
        [
          "_get_params_override",
          29,
          76,
          61,
          29,
          61,
          61,
          29,
          26,
          76,
          4
        ],
        [
          "_get_params_override",
          29,
          76,
          65,
          29,
          65,
          60,
          29,
          26,
          76,
          4
        ],
        [
          "testTrainEval",
          184,
          218,
          217,
          26,
          217,
          69,
          185,
          7,
          218,
          5
        ],
        [
          "testTrainThenEval",
          274,
          313,
          307,
          26,
          307,
          69,
          275,
          7,
          313,
          14
        ]
      ],
      "models/official/projects/yt8m/train_test.py": [
        [
          "setUp",
          32,
          41,
          37,
          16,
          37,
          56,
          32,
          13,
          41,
          75
        ],
        [
          "setUp",
          32,
          41,
          39,
          23,
          39,
          61,
          32,
          13,
          41,
          75
        ],
        [
          "setUp",
          32,
          41,
          34,
          23,
          34,
          68,
          32,
          13,
          41,
          75
        ]
      ],
      "models/official/projects/assemblenet/train_test.py": [
        [
          "setUp",
          31,
          47,
          33,
          23,
          33,
          68,
          31,
          13,
          47,
          75
        ],
        [
          "setUp",
          31,
          47,
          36,
          16,
          36,
          56,
          31,
          13,
          47,
          75
        ],
        [
          "setUp",
          31,
          47,
          38,
          23,
          38,
          61,
          31,
          13,
          47,
          75
        ]
      ],
      "models/research/cognitive_planning/train_supervised_active_vision.py": [
        [
          "unroll_policy_for_eval",
          308,
          371,
          367,
          17,
          367,
          63,
          367,
          17,
          371,
          34
        ],
        [
          "test",
          415,
          469,
          445,
          21,
          445,
          77,
          441,
          25,
          446,
          41
        ]
      ],
      "models/official/core/train_utils_test.py": [
        [
          "test_write_model_params_keras_model",
          82,
          99,
          87,
          16,
          87,
          70,
          82,
          43,
          99,
          38
        ],
        [
          "test_write_model_params_module",
          101,
          118,
          106,
          16,
          106,
          70,
          101,
          38,
          118,
          38
        ],
        [
          "test_maybe_export",
          144,
          181,
          146,
          22,
          146,
          59,
          144,
          25,
          181,
          40
        ],
        [
          "test_export_best_eval_metric",
          183,
          194,
          189,
          28,
          189,
          63,
          183,
          36,
          194,
          77
        ],
        [
          "test_export_best_eval_metric_skips_non_scalar_values",
          196,
          211,
          206,
          28,
          206,
          63,
          196,
          60,
          211,
          77
        ]
      ],
      "models/research/delf/delf/python/training/global_features/train_utils.py": [
        [
          "test_retrieval",
          201,
          343,
          232,
          16,
          233,
          79,
          232,
          16,
          239,
          35
        ],
        [
          "test_retrieval",
          201,
          343,
          234,
          22,
          237,
          27,
          232,
          16,
          239,
          35
        ],
        [
          "test_retrieval",
          201,
          343,
          252,
          17,
          252,
          70,
          247,
          15,
          294,
          73
        ],
        [
          "test_retrieval",
          201,
          343,
          253,
          18,
          253,
          45,
          247,
          15,
          294,
          73
        ],
        [
          "test_retrieval",
          201,
          343,
          254,
          21,
          255,
          78,
          247,
          15,
          294,
          73
        ],
        [
          "test_retrieval",
          201,
          343,
          304,
          51,
          304,
          73,
          299,
          7,
          330,
          36
        ],
        [
          "test_retrieval",
          201,
          343,
          304,
          51,
          304,
          73,
          299,
          7,
          343,
          79
        ]
      ],
      "models/official/projects/nhnet/trainer.py": [
        [
          "train",
          131,
          179,
          151,
          19,
          151,
          60,
          142,
          8,
          162,
          49
        ]
      ],
      "models/official/core/train_utils.py": [
        [
          "best_ckpt_logs_path",
          235,
          236,
          236,
          12,
          236,
          54,
          235,
          27,
          236,
          54
        ],
        [
          "maybe_create_best_ckpt_exporter",
          113,
          130,
          120,
          21,
          120,
          57,
          120,
          21,
          126,
          35
        ],
        [
          "serialize_config",
          394,
          402,
          399,
          22,
          399,
          59,
          399,
          22,
          402,
          64
        ],
        [
          "save_gin_config",
          405,
          412,
          407,
          19,
          408,
          67,
          405,
          21,
          412,
          39
        ],
        [
          "write_json_summary",
          436,
          448,
          444,
          17,
          444,
          76,
          444,
          17,
          448,
          64
        ],
        [
          "remove_ckpts",
          462,
          471,
          464,
          11,
          464,
          43,
          462,
          18,
          466,
          47
        ],
        [
          "remove_ckpts",
          462,
          471,
          469,
          20,
          469,
          56,
          469,
          20,
          470,
          39
        ]
      ],
      "models/official/projects/nhnet/trainer_test.py": [
        [
          "test_train",
          88,
          97,
          97,
          26,
          97,
          69,
          88,
          18,
          97,
          74
        ]
      ],
      "models/official/modeling/fast_training/progressive/trainer.py": [
        [
          "__init__",
          72,
          139,
          102,
          29,
          102,
          68,
          73,
          7,
          126,
          12
        ]
      ],
      "models/official/modeling/fast_training/progressive/trainer_test.py": [
        [
          "test_checkpointing",
          129,
          142,
          131,
          17,
          131,
          47,
          129,
          26,
          142,
          50
        ]
      ],
      "models/official/legacy/xlnet/training_utils.py": [
        [
          "_save_checkpoint",
          33,
          39,
          36,
          21,
          36,
          62,
          33,
          22,
          39,
          8
        ],
        [
          "train",
          47,
          305,
          112,
          17,
          112,
          52,
          112,
          17,
          113,
          40
        ],
        [
          "train",
          47,
          305,
          124,
          9,
          124,
          42,
          123,
          28,
          123,
          24
        ],
        [
          "train",
          47,
          305,
          119,
          9,
          119,
          41,
          118,
          27,
          118,
          23
        ]
      ],
      "models/research/pcl_rl/trainer.py": [
        [
          "__init__",
          147,
          230,
          222,
          9,
          223,
          71,
          222,
          9,
          223,
          71
        ]
      ],
      "models/official/legacy/transformer/transformer_main_test.py": [
        [
          "setUp",
          43,
          70,
          52,
          23,
          52,
          61,
          52,
          23,
          69,
          20
        ],
        [
          "setUp",
          43,
          70,
          65,
          23,
          65,
          53,
          52,
          23,
          69,
          20
        ],
        [
          "setUp",
          43,
          70,
          67,
          24,
          67,
          60,
          52,
          23,
          69,
          20
        ],
        [
          "setUp",
          43,
          70,
          68,
          21,
          68,
          54,
          52,
          23,
          69,
          20
        ]
      ],
      "models/official/legacy/transformer/transformer_main.py": [
        [
          "train",
          188,
          365,
          213,
          15,
          213,
          58,
          212,
          28,
          212,
          24
        ],
        [
          "train",
          188,
          365,
          330,
          15,
          331,
          67,
          329,
          29,
          332,
          65
        ],
        [
          "_create_callbacks",
          406,
          414,
          410,
          24,
          410,
          71,
          410,
          24,
          413,
          77
        ]
      ],
      "models/official/nlp/tasks/translation_test.py": [
        [
          "setUp",
          62,
          83,
          75,
          31,
          75,
          75,
          62,
          13,
          82,
          34
        ],
        [
          "setUp",
          62,
          83,
          77,
          38,
          77,
          79,
          62,
          13,
          82,
          34
        ],
        [
          "setUp",
          62,
          83,
          79,
          34,
          79,
          67,
          62,
          13,
          82,
          34
        ],
        [
          "test_sentencepiece_no_eos",
          119,
          138,
          120,
          34,
          120,
          74,
          119,
          33,
          138,
          41
        ]
      ],
      "models/research/delf/delf/python/datasets/tuples_dataset_test.py": [
        [
          "testCreateEpochTuples",
          39,
          85,
          52,
          28,
          52,
          68,
          39,
          29,
          57,
          47
        ],
        [
          "testCreateEpochTuples",
          39,
          85,
          60,
          18,
          60,
          68,
          57,
          9,
          61,
          28
        ]
      ],
      "models/official/nlp/tasks/translation.py": [
        [
          "write_test_record",
          131,
          171,
          138,
          17,
          138,
          57,
          131,
          23,
          140,
          18
        ]
      ],
      "models/research/delf/delf/python/datasets/tuples_dataset.py": [
        [
          "__init__",
          44,
          99,
          72,
          19,
          72,
          64,
          72,
          19,
          77,
          50
        ],
        [
          "_img_names_to_full_path",
          122,
          133,
          132,
          14,
          132,
          53,
          132,
          14,
          132,
          53
        ],
        [
          "listcomp",
          133,
          133,
          133,
          13,
          133,
          50,
          133,
          56,
          133,
          50
        ]
      ],
      "models/research/cvt_text/corpus_processing/unlabeled_data.py": [
        [
          "get_unlabeled_sentences",
          59,
          81,
          69,
          33,
          70,
          51,
          67,
          29,
          71,
          37
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "create_log_file",
          211,
          228,
          221,
          19,
          221,
          63,
          211,
          21,
          228,
          15
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "write_datasets",
          225,
          243,
          241,
          20,
          241,
          59,
          225,
          20,
          242,
          42
        ],
        [
          "read_datasets",
          246,
          277,
          264,
          29,
          264,
          57,
          264,
          19,
          269,
          23
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "create_log_file",
          55,
          72,
          65,
          19,
          65,
          69,
          55,
          21,
          72,
          15
        ]
      ],
      "models/official/projects/edgetpu/nlp/utils/utils.py": [
        [
          "serialize_config",
          27,
          33,
          30,
          22,
          30,
          59,
          27,
          22,
          33,
          75
        ]
      ],
      "models/research/delf/delf/python/datasets/utils_test.py": [
        [
          "testDefaultLoader",
          36,
          52,
          40,
          16,
          40,
          64,
          36,
          25,
          52,
          56
        ],
        [
          "testDefaultLoaderWithBoundingBox",
          54,
          72,
          58,
          16,
          58,
          64,
          54,
          40,
          72,
          73
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_files_paths_with_no_images",
          72,
          80,
          77,
          14,
          77,
          45,
          76,
          11,
          77,
          59
        ],
        [
          "test_files_paths_with_images",
          52,
          70,
          67,
          11,
          67,
          45,
          61,
          16,
          70,
          40
        ],
        [
          "test_files_paths_with_images",
          52,
          70,
          58,
          14,
          58,
          45,
          57,
          11,
          58,
          59
        ],
        [
          "test_files_paths_with_images",
          52,
          70,
          65,
          11,
          65,
          44,
          61,
          16,
          70,
          40
        ],
        [
          "test_files_paths_with_images",
          52,
          70,
          66,
          11,
          66,
          44,
          61,
          16,
          70,
          40
        ]
      ],
      "models/research/object_detection/utils/variables_helper_tf1_test.py": [
        [
          "test_return_all_variables_from_checkpoint",
          142,
          156,
          148,
          25,
          148,
          71,
          142,
          49,
          156,
          51
        ],
        [
          "test_return_all_variables_from_checkpoint_with_partition",
          158,
          174,
          166,
          25,
          166,
          71,
          158,
          64,
          174,
          51
        ],
        [
          "test_return_variables_available_in_checkpoint",
          176,
          195,
          177,
          23,
          177,
          69,
          176,
          53,
          195,
          59
        ],
        [
          "test_return_variables_available_an_checkpoint_with_dict_inputs",
          197,
          219,
          198,
          23,
          198,
          69,
          197,
          70,
          219,
          70
        ],
        [
          "test_return_variables_with_correct_sizes",
          221,
          246,
          222,
          23,
          222,
          69,
          221,
          48,
          246,
          70
        ]
      ],
      "models/official/projects/videoglue/datasets/video_classification.py": [
        [
          "__init__",
          42,
          54,
          51,
          18,
          51,
          67,
          51,
          18,
          54,
          28
        ]
      ],
      "models/official/vision/serving/video_classification_test.py": [
        [
          "test_export",
          76,
          109,
          84,
          24,
          84,
          76,
          76,
          19,
          109,
          68
        ],
        [
          "test_export",
          76,
          109,
          82,
          36,
          82,
          74,
          76,
          19,
          109,
          68
        ],
        [
          "test_export",
          76,
          109,
          87,
          13,
          88,
          57,
          76,
          19,
          109,
          68
        ]
      ],
      "models/research/deeplab/vis.py": [
        [
          "main",
          194,
          321,
          219,
          14,
          219,
          77,
          218,
          3,
          236,
          41
        ],
        [
          "main",
          194,
          321,
          221,
          18,
          222,
          61,
          218,
          3,
          236,
          41
        ]
      ],
      "models/research/slim/datasets/visualwakewords.py": [
        [
          "get_split",
          57,
          127,
          79,
          18,
          79,
          69,
          79,
          18,
          82,
          19
        ],
        [
          "get_split",
          57,
          127,
          116,
          17,
          116,
          58,
          86,
          7,
          117,
          33
        ]
      ],
      "models/research/object_detection/utils/visualization_utils_test.py": [
        [
          "test_draw_bounding_boxes_on_image_tensors",
          164,
          206,
          167,
          13,
          167,
          54,
          164,
          49,
          201,
          49
        ],
        [
          "test_draw_bounding_boxes_on_image_tensors",
          164,
          206,
          203,
          21,
          203,
          63,
          201,
          9,
          206,
          33
        ],
        [
          "test_draw_bounding_boxes_on_image_tensors_with_track_ids",
          208,
          253,
          212,
          13,
          212,
          54,
          208,
          64,
          248,
          49
        ],
        [
          "test_draw_bounding_boxes_on_image_tensors_with_track_ids",
          208,
          253,
          250,
          21,
          250,
          63,
          248,
          9,
          253,
          33
        ]
      ],
      "models/research/cognitive_planning/viz_active_vision_dataset_main.py": [
        [
          "visualize",
          223,
          274,
          237,
          26,
          237,
          67,
          223,
          15,
          239,
          51
        ],
        [
          "visualize",
          223,
          274,
          238,
          24,
          238,
          63,
          223,
          15,
          239,
          51
        ],
        [
          "listcomp",
          243,
          244,
          244,
          7,
          244,
          38,
          244,
          7,
          244,
          38
        ],
        [
          "visualize",
          223,
          274,
          251,
          21,
          251,
          65,
          248,
          7,
          252,
          46
        ],
        [
          "visualize",
          223,
          274,
          266,
          21,
          266,
          77,
          265,
          11,
          267,
          36
        ],
        [
          "visualize",
          223,
          274,
          272,
          15,
          272,
          66,
          268,
          13,
          274,
          7
        ],
        [
          "listcomp",
          292,
          293,
          293,
          9,
          293,
          34,
          293,
          9,
          293,
          34
        ],
        [
          "evaluate_folder",
          276,
          349,
          346,
          27,
          346,
          72,
          334,
          14,
          349,
          60
        ]
      ],
      "models/official/nlp/data/wmt_dataloader_test.py": [
        [
          "setUp",
          64,
          88,
          77,
          37,
          77,
          80,
          64,
          13,
          87,
          34
        ],
        [
          "setUp",
          64,
          88,
          79,
          36,
          79,
          78,
          64,
          13,
          87,
          34
        ],
        [
          "setUp",
          64,
          88,
          82,
          38,
          82,
          79,
          64,
          13,
          87,
          34
        ],
        [
          "setUp",
          64,
          88,
          84,
          34,
          84,
          67,
          64,
          13,
          87,
          34
        ]
      ],
      "models/research/cvt_text/task_specific/word_level/word_level_data.py": [
        [
          "__init__",
          35,
          48,
          38,
          27,
          38,
          68,
          35,
          16,
          42,
          31
        ],
        [
          "__init__",
          35,
          48,
          40,
          31,
          43,
          68,
          42,
          10,
          45,
          25
        ],
        [
          "get_dataset",
          50,
          55,
          52,
          25,
          52,
          77,
          52,
          9,
          52,
          78
        ],
        [
          "get_labeled_sentences",
          57,
          80,
          59,
          12,
          59,
          60,
          57,
          29,
          60,
          32
        ]
      ],
      "models/official/projects/yolo/configs/yolo.py": [
        [
          "yolo_darknet",
          304,
          421,
          340,
          26,
          340,
          69,
          305,
          3,
          421,
          15
        ],
        [
          "yolo_darknet",
          304,
          421,
          360,
          26,
          360,
          67,
          305,
          3,
          421,
          15
        ],
        [
          "scaled_yolo",
          425,
          545,
          467,
          26,
          467,
          69,
          426,
          3,
          545,
          15
        ],
        [
          "scaled_yolo",
          425,
          545,
          488,
          26,
          488,
          67,
          426,
          3,
          545,
          15
        ]
      ],
      "models/official/projects/yolo/configs/yolov7.py": [
        [
          "coco_yolov7",
          188,
          329,
          228,
          26,
          228,
          69,
          189,
          3,
          329,
          15
        ],
        [
          "coco_yolov7",
          188,
          329,
          263,
          26,
          263,
          67,
          189,
          3,
          329,
          15
        ]
      ],
      "models/official/projects/yt8m/dataloaders/yt8m_input_test.py": [
        [
          "setUp",
          31,
          43,
          33,
          23,
          33,
          68,
          31,
          13,
          43,
          74
        ],
        [
          "setUp",
          31,
          43,
          36,
          16,
          36,
          56,
          31,
          13,
          43,
          74
        ],
        [
          "setUp",
          31,
          43,
          38,
          22,
          38,
          60,
          31,
          13,
          43,
          74
        ],
        [
          "test_read_video_level_float_input",
          171,
          244,
          174,
          16,
          174,
          57,
          172,
          7,
          205,
          31
        ],
        [
          "test_read_video_level_float_input",
          171,
          244,
          176,
          17,
          176,
          56,
          172,
          7,
          205,
          31
        ]
      ]
    },
    "open": {
      "models/research/marco/Automated_Marco.py": [
        [
          "load_images",
          44,
          47,
          46,
          17,
          46,
          28,
          45,
          9,
          47,
          46
        ]
      ],
      "models/research/deeplab/datasets/build_voc2012_data.py": [
        [
          "_convert_dataset",
          89,
          136,
          100,
          39,
          100,
          62,
          89,
          22,
          107,
          36
        ]
      ],
      "models/research/cvt_text/base/configure.py": [
        [
          "write",
          134,
          138,
          136,
          10,
          136,
          55,
          134,
          13,
          138,
          49
        ]
      ],
      "models/official/projects/unified_detector/data_conversion/convert.py": [
        [
          "main",
          44,
          61,
          45,
          27,
          45,
          46,
          44,
          10,
          51,
          41
        ]
      ],
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_generate_sequence_examples",
          171,
          294,
          200,
          10,
          200,
          33,
          171,
          35,
          202,
          23
        ],
        [
          "_generate_sequence_examples",
          171,
          294,
          204,
          10,
          204,
          35,
          204,
          10,
          209,
          23
        ],
        [
          "_generate_examples",
          296,
          449,
          324,
          10,
          324,
          33,
          296,
          26,
          326,
          23
        ],
        [
          "_generate_examples",
          296,
          449,
          328,
          10,
          328,
          35,
          328,
          10,
          333,
          23
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record_test.py": [
        [
          "test_create_sharded_tf_record",
          439,
          493,
          482,
          10,
          482,
          35,
          449,
          9,
          493,
          68
        ]
      ],
      "models/research/object_detection/dataset_tools/create_kitti_tf_record.py": [
        [
          "read_annotation_file",
          262,
          298,
          275,
          8,
          275,
          21,
          262,
          26,
          298,
          13
        ]
      ],
      "models/official/projects/fffner/utils/create_data.py": [
        [
          "read_file",
          70,
          79,
          72,
          10,
          72,
          30,
          70,
          17,
          73,
          47
        ],
        [
          "read_file",
          70,
          79,
          72,
          39,
          72,
          60,
          70,
          17,
          73,
          47
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data_test.py": [
        [
          "_create_files",
          32,
          44,
          40,
          10,
          40,
          32,
          38,
          7,
          41,
          30
        ]
      ],
      "models/research/adversarial_text/data/data_utils.py": [
        [
          "write_vocab_and_frequency",
          325,
          332,
          328,
          8,
          328,
          73,
          325,
          31,
          330,
          43
        ],
        [
          "write_vocab_and_frequency",
          325,
          332,
          329,
          10,
          329,
          80,
          325,
          31,
          330,
          43
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "__init__",
          168,
          190,
          177,
          10,
          177,
          54,
          168,
          16,
          190,
          31
        ],
        [
          "collect_static_frames",
          192,
          202,
          193,
          10,
          193,
          57,
          192,
          29,
          196,
          20
        ],
        [
          "load_pose_raw",
          298,
          306,
          302,
          10,
          302,
          29,
          298,
          21,
          306,
          15
        ],
        [
          "read_raw_calib_file",
          324,
          336,
          327,
          10,
          327,
          28,
          324,
          27,
          328,
          19
        ],
        [
          "read_calib_file",
          443,
          457,
          451,
          10,
          451,
          28,
          443,
          23,
          457,
          29
        ],
        [
          "load_intrinsics",
          514,
          533,
          520,
          10,
          520,
          31,
          514,
          23,
          528,
          23
        ]
      ],
      "models/research/adversarial_text/data/document_generators.py": [
        [
          "imdb_documents",
          158,
          219,
          202,
          12,
          202,
          82,
          202,
          12,
          209,
          26
        ],
        [
          "imdb_documents",
          158,
          219,
          212,
          10,
          212,
          66,
          211,
          44,
          213,
          25
        ],
        [
          "dbpedia_documents",
          222,
          263,
          249,
          8,
          249,
          68,
          247,
          3,
          251,
          21
        ],
        [
          "rcv1_documents",
          266,
          314,
          300,
          10,
          300,
          64,
          299,
          7,
          302,
          23
        ],
        [
          "rt_documents",
          317,
          383,
          357,
          10,
          357,
          23,
          356,
          7,
          358,
          25
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords_lib.py": [
        [
          "create_labels_file",
          72,
          84,
          82,
          8,
          82,
          45,
          72,
          24,
          83,
          38
        ],
        [
          "create_visual_wakeword_annotations",
          87,
          141,
          135,
          10,
          135,
          52,
          135,
          10,
          141,
          16
        ]
      ],
      "models/research/rebar/download_data.py": [
        [
          "load_mnist_float",
          38,
          47,
          39,
          8,
          39,
          33,
          38,
          22,
          47,
          15
        ]
      ],
      "models/research/deeplab/evaluation/eval_coco_format.py": [
        [
          "eval_coco_format",
          222,
          321,
          268,
          8,
          268,
          30,
          222,
          22,
          272,
          22
        ],
        [
          "eval_coco_format",
          222,
          321,
          270,
          8,
          270,
          32,
          222,
          22,
          272,
          22
        ]
      ],
      "models/research/audioset/yamnet/export.py": [
        [
          "make_tflite_export",
          138,
          183,
          172,
          8,
          172,
          36,
          145,
          3,
          183,
          24
        ]
      ],
      "models/research/lstm_object_detection/export_tflite_lstd_model.py": [
        [
          "main",
          33,
          61,
          61,
          3,
          61,
          23,
          33,
          10,
          61,
          43
        ]
      ],
      "models/research/vid2depth/dataset/gen_data.py": [
        [
          "_gen_example",
          150,
          173,
          169,
          8,
          169,
          30,
          165,
          18,
          173,
          19
        ]
      ],
      "models/research/adversarial_text/gen_data.py": [
        [
          "make_vocab_ids",
          92,
          99,
          98,
          10,
          98,
          47,
          98,
          10,
          99,
          72
        ]
      ],
      "models/research/adversarial_text/graphs_test.py": [
        [
          "setUpClass",
          80,
          135,
          131,
          10,
          131,
          61,
          128,
          19,
          133,
          45
        ],
        [
          "setUpClass",
          80,
          135,
          132,
          12,
          132,
          68,
          128,
          19,
          133,
          45
        ]
      ],
      "models/research/slim/datasets/imagenet.py": [
        [
          "create_readable_names_for_imagenet_labels",
          65,
          118,
          94,
          37,
          94,
          50,
          66,
          3,
          96,
          38
        ],
        [
          "create_readable_names_for_imagenet_labels",
          65,
          118,
          99,
          26,
          99,
          39,
          96,
          3,
          101,
          45
        ]
      ],
      "models/official/projects/waste_identification_ml/model_inference/labels.py": [
        [
          "read_csv_to_list",
          30,
          49,
          44,
          8,
          44,
          27,
          30,
          22,
          47,
          21
        ]
      ],
      "models/research/lfads/lfads.py": [
        [
          "summarize_all",
          1324,
          1390,
          1389,
          12,
          1389,
          30,
          1388,
          18,
          1390,
          32
        ]
      ],
      "models/research/object_detection/metrics/offline_eval_map_corloc.py": [
        [
          "write_metrics",
          135,
          147,
          144,
          8,
          144,
          57,
          135,
          19,
          146,
          52
        ]
      ],
      "models/research/object_detection/metrics/oid_challenge_evaluation.py": [
        [
          "_load_labelmap",
          73,
          93,
          85,
          8,
          85,
          31,
          73,
          20,
          90,
          28
        ],
        [
          "main",
          96,
          145,
          144,
          8,
          144,
          38,
          142,
          13,
          145,
          36
        ]
      ],
      "models/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py": [
        [
          "main",
          192,
          223,
          196,
          8,
          196,
          38,
          192,
          10,
          200,
          31
        ],
        [
          "main",
          192,
          223,
          207,
          8,
          207,
          41,
          201,
          19,
          215,
          24
        ],
        [
          "main",
          192,
          223,
          207,
          8,
          207,
          41,
          205,
          30,
          215,
          24
        ],
        [
          "main",
          192,
          223,
          208,
          10,
          208,
          44,
          201,
          19,
          215,
          24
        ],
        [
          "main",
          192,
          223,
          208,
          10,
          208,
          44,
          205,
          30,
          215,
          24
        ]
      ],
      "models/research/object_detection/metrics/oid_vrd_challenge_evaluation.py": [
        [
          "_load_labelmap",
          48,
          65,
          59,
          8,
          59,
          31,
          48,
          20,
          63,
          28
        ],
        [
          "main",
          80,
          120,
          118,
          8,
          118,
          44,
          113,
          22,
          120,
          43
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/predictor.py": [
        [
          "send_image_for_prediction",
          40,
          67,
          58,
          10,
          58,
          31,
          41,
          5,
          58,
          31
        ]
      ],
      "models/research/cvt_text/preprocessing.py": [
        [
          "write_sentences",
          78,
          83,
          79,
          8,
          79,
          23,
          78,
          21,
          80,
          32
        ]
      ],
      "models/official/projects/movinet/tools/quantize_movinet.py": [
        [
          "main",
          320,
          326,
          323,
          8,
          323,
          38,
          320,
          10,
          326,
          65
        ]
      ],
      "models/official/projects/centernet/utils/checkpoints/read_checkpoints.py": [
        [
          "write_dict_as_tree",
          80,
          98,
          95,
          12,
          95,
          31,
          94,
          9,
          98,
          63
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/run_tflite.py": [
        [
          "main",
          30,
          50,
          31,
          8,
          31,
          30,
          30,
          10,
          48,
          33
        ]
      ],
      "models/official/pip_package/setup.py": [
        [
          "_get_requirements",
          41,
          60,
          49,
          8,
          50,
          62,
          49,
          8,
          51,
          17
        ]
      ],
      "models/official/vision/dataloaders/tf_example_label_map_decoder_test.py": [
        [
          "test_result_content",
          78,
          183,
          82,
          10,
          82,
          34,
          78,
          27,
          183,
          57
        ],
        [
          "test_result_shape",
          39,
          76,
          43,
          10,
          43,
          34,
          39,
          25,
          76,
          74
        ]
      ],
      "models/research/seq_flow_lite/utils/tflite_utils.py": [
        [
          "_dump_graph_in_text_format",
          19,
          27,
          21,
          7,
          21,
          25,
          19,
          32,
          23,
          28
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/train.py": [
        [
          "save_and_convert",
          80,
          91,
          90,
          8,
          90,
          59,
          80,
          22,
          91,
          17
        ]
      ],
      "models/official/legacy/transformer/transformer_main_test.py": [
        [
          "_generate_file",
          34,
          37,
          35,
          8,
          35,
          26,
          34,
          20,
          36,
          18
        ]
      ],
      "models/research/vid2depth/util.py": [
        [
          "read_text_lines",
          117,
          121,
          118,
          8,
          118,
          26,
          117,
          21,
          121,
          14
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "_read_csv_to_list",
          127,
          145,
          141,
          8,
          141,
          27,
          127,
          23,
          143,
          21
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "write_data",
          170,
          202,
          187,
          16,
          187,
          36,
          187,
          16,
          189,
          20
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_files_paths_with_images",
          52,
          70,
          58,
          9,
          58,
          51,
          57,
          11,
          58,
          59
        ],
        [
          "test_files_paths_with_no_images",
          72,
          80,
          77,
          9,
          77,
          51,
          76,
          11,
          77,
          59
        ]
      ],
      "models/official/projects/waste_identification_ml/pre_processing/config/visualization.py": [
        [
          "data_creation",
          24,
          50,
          34,
          8,
          34,
          17,
          24,
          19,
          50,
          11
        ]
      ],
      "models/research/audioset/yamnet/yamnet.py": [
        [
          "class_names",
          131,
          138,
          135,
          8,
          135,
          26,
          135,
          8,
          138,
          70
        ]
      ],
      "models/official/projects/yolo/tasks/yolo.py": [
        [
          "generate_anchors",
          71,
          107,
          101,
          10,
          101,
          33,
          71,
          24,
          107,
          16
        ]
      ],
      "models/official/projects/yolo/tasks/yolov7.py": [
        [
          "generate_anchors",
          98,
          134,
          128,
          10,
          128,
          33,
          98,
          24,
          134,
          16
        ]
      ]
    },
    "os.path.dirname": {
      "models/official/core/actions.py": [
        [
          "__init__",
          85,
          113,
          106,
          26,
          106,
          52,
          105,
          18,
          109,
          28
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py": [
        [
          "main",
          921,
          963,
          936,
          13,
          936,
          49,
          921,
          10,
          963,
          9
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/boxes_and_features_extraction.py": [
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          111,
          29,
          111,
          59,
          111,
          10,
          111,
          60
        ],
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          112,
          26,
          112,
          56,
          112,
          5,
          112,
          57
        ]
      ],
      "models/official/nlp/data/classifier_data_lib.py": [
        [
          "file_based_convert_examples_to_features",
          1455,
          1505,
          1464,
          24,
          1464,
          51,
          1455,
          45,
          1467,
          46
        ]
      ],
      "models/official/nlp/continuous_finetune_lib.py": [
        [
          "run_continuous_finetune",
          72,
          217,
          198,
          21,
          198,
          46,
          198,
          21,
          198,
          17
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py": [
        [
          "main",
          305,
          330,
          320,
          13,
          320,
          56,
          305,
          10,
          330,
          9
        ]
      ],
      "models/official/vision/data/create_coco_tf_record.py": [
        [
          "main",
          540,
          564,
          552,
          15,
          552,
          55,
          552,
          15,
          553,
          37
        ]
      ],
      "models/official/projects/fffner/utils/create_data.py": [
        [
          "file_based_convert_examples_to_features",
          303,
          342,
          305,
          26,
          305,
          53,
          303,
          47,
          308,
          53
        ]
      ],
      "models/official/nlp/data/create_finetuning_data.py": [
        [
          "main",
          407,
          435,
          433,
          24,
          433,
          65,
          433,
          3,
          435,
          62
        ]
      ],
      "models/research/object_detection/builders/dataset_builder_test.py": [
        [
          "_get_labelmap_path",
          51,
          55,
          53,
          17,
          53,
          73,
          52,
          3,
          55,
          44
        ]
      ],
      "models/research/object_detection/builders/decoder_builder_test.py": [
        [
          "_get_labelmap_path",
          34,
          38,
          36,
          17,
          36,
          73,
          35,
          3,
          38,
          44
        ]
      ],
      "models/research/attention_ocr/python/demo_inference_test.py": [
        [
          "setUp",
          14,
          24,
          24,
          9,
          24,
          33,
          22,
          24,
          23,
          27
        ]
      ],
      "models/research/object_detection/core/densepose_ops.py": [
        [
          "__init__",
          264,
          304,
          267,
          12,
          267,
          53,
          264,
          16,
          279,
          46
        ]
      ],
      "models/research/slim/datasets/download_and_convert_flowers.py": [
        [
          "_convert_dataset",
          109,
          152,
          144,
          43,
          144,
          71,
          135,
          15,
          149,
          62
        ]
      ],
      "models/research/slim/export_inference_graph.py": [
        [
          "main",
          119,
          158,
          153,
          11,
          153,
          44,
          151,
          7,
          155,
          23
        ]
      ],
      "models/research/deeplab/export_model.py": [
        [
          "main",
          116,
          195,
          180,
          15,
          180,
          48,
          178,
          13,
          194,
          33
        ]
      ],
      "models/official/projects/edgetpu/vision/serving/export_tflite.py": [
        [
          "run_export",
          125,
          178,
          165,
          24,
          165,
          64,
          151,
          16,
          174,
          29
        ]
      ],
      "models/official/projects/edgetpu/vision/serving/export_tflite_test.py": [
        [
          "_dump_tflite",
          59,
          66,
          63,
          24,
          63,
          57,
          59,
          18,
          66,
          20
        ]
      ],
      "models/research/attention_ocr/python/datasets/fsns_test.py": [
        [
          "dataset_dir",
          36,
          37,
          37,
          23,
          37,
          47,
          37,
          10,
          37,
          65
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data.py": [
        [
          "main",
          250,
          279,
          266,
          13,
          266,
          59,
          250,
          10,
          279,
          9
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py": [
        [
          "main",
          336,
          366,
          351,
          13,
          351,
          59,
          336,
          10,
          366,
          9
        ]
      ],
      "models/research/vid2depth/inference.py": [
        [
          "_run_inference",
          73,
          128,
          76,
          37,
          76,
          69,
          74,
          3,
          80,
          33
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/inference_pipeline.py": [
        [
          "main",
          117,
          441,
          313,
          50,
          313,
          76,
          313,
          66,
          313,
          76
        ]
      ],
      "models/research/object_detection/builders/input_reader_builder_tf1_test.py": [
        [
          "_get_labelmap_path",
          33,
          37,
          35,
          17,
          35,
          73,
          34,
          3,
          37,
          44
        ]
      ],
      "models/official/projects/longformer/utils/longformer_tokenizer_to_tfrecord.py": [
        [
          "file_based_convert_examples_to_features",
          78,
          102,
          80,
          24,
          80,
          51,
          78,
          45,
          83,
          46
        ]
      ],
      "models/research/slim/nets/mobilenet/mobilenet.py": [
        [
          "mobilenet_base",
          149,
          302,
          290,
          15,
          290,
          39,
          285,
          9,
          292,
          35
        ],
        [
          "mobilenet_base",
          149,
          302,
          298,
          15,
          298,
          37,
          297,
          9,
          300,
          24
        ]
      ],
      "models/research/attention_ocr/python/model_export_test.py": [
        [
          "setUp",
          47,
          70,
          58,
          9,
          58,
          33,
          55,
          32,
          63,
          33
        ]
      ],
      "models/orbit/actions/new_best_metric.py": [
        [
          "__init__",
          175,
          207,
          204,
          30,
          204,
          60,
          204,
          9,
          204,
          61
        ]
      ],
      "models/orbit/actions/new_best_metric_test.py": [
        [
          "test_json_persisted_value_create_dirs",
          83,
          90,
          88,
          41,
          88,
          65,
          83,
          45,
          90,
          49
        ]
      ],
      "models/official/nlp/finetuning/glue/run_glue.py": [
        [
          "_write_submission_file",
          178,
          233,
          180,
          24,
          180,
          62,
          178,
          28,
          233,
          28
        ]
      ],
      "models/official/nlp/finetuning/superglue/run_superglue.py": [
        [
          "_write_submission_file",
          145,
          170,
          147,
          24,
          147,
          62,
          145,
          28,
          170,
          28
        ]
      ],
      "models/official/pip_package/setup.py": [
        [
          "_get_requirements",
          41,
          60,
          50,
          20,
          50,
          44,
          49,
          8,
          51,
          17
        ]
      ],
      "models/research/seq_flow_lite/demo/colab/setup.py": [
        [
          "run",
          38,
          41,
          41,
          13,
          41,
          55,
          38,
          11,
          41,
          56
        ]
      ],
      "models/official/nlp/data/squad_lib_sp.py": [
        [
          "__init__",
          894,
          899,
          898,
          26,
          898,
          50,
          894,
          16,
          899,
          16
        ]
      ],
      "models/official/nlp/data/squad_lib.py": [
        [
          "__init__",
          119,
          124,
          123,
          26,
          123,
          50,
          119,
          16,
          124,
          16
        ]
      ],
      "models/official/nlp/data/tagging_data_lib.py": [
        [
          "write_example_to_file",
          292,
          360,
          343,
          24,
          343,
          51,
          292,
          27,
          346,
          48
        ]
      ],
      "models/official/core/train_utils.py": [
        [
          "__init__",
          140,
          158,
          156,
          26,
          156,
          66,
          156,
          5,
          158,
          28
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "write_data",
          170,
          202,
          182,
          14,
          182,
          40,
          170,
          16,
          183,
          33
        ]
      ],
      "models/research/object_detection/utils/variables_helper.py": [
        [
          "ensure_checkpoint_supported",
          195,
          230,
          223,
          41,
          223,
          72,
          223,
          25,
          226,
          37
        ]
      ],
      "models/official/legacy/xlnet/xlnet_config.py": [
        [
          "to_json",
          107,
          117,
          113,
          16,
          113,
          41,
          113,
          16,
          114,
          39
        ]
      ]
    },
    "tempfile.NamedTemporaryFile": {
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py": [
        [
          "InMemoryTFRecord",
          42,
          51,
          43,
          10,
          43,
          50,
          42,
          22,
          46,
          11
        ]
      ],
      "models/official/nlp/metrics/bleu_test.py": [
        [
          "_create_temp_file",
          26,
          30,
          27,
          17,
          27,
          57,
          26,
          25,
          30,
          25
        ]
      ],
      "models/official/nlp/data/classifier_data_lib_test.py": [
        [
          "setUp",
          35,
          53,
          49,
          10,
          49,
          50,
          35,
          13,
          53,
          18
        ]
      ],
      "models/official/legacy/transformer/compute_bleu_test.py": [
        [
          "_create_temp_file",
          26,
          30,
          27,
          17,
          27,
          57,
          26,
          25,
          30,
          25
        ]
      ],
      "models/research/lstm_object_detection/export_tflite_lstd_graph_lib.py": [
        [
          "export_tflite_graph",
          152,
          327,
          287,
          33,
          287,
          61,
          286,
          37,
          291,
          21
        ]
      ],
      "models/research/object_detection/export_tflite_ssd_graph_lib.py": [
        [
          "export_tflite_graph",
          157,
          333,
          287,
          33,
          287,
          61,
          286,
          37,
          291,
          21
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "_export_inference_graph",
          488,
          573,
          528,
          34,
          528,
          62,
          527,
          41,
          528,
          30
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py": [
        [
          "InMemoryTFRecord",
          95,
          104,
          96,
          10,
          96,
          50,
          95,
          22,
          99,
          11
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py": [
        [
          "InMemoryTFRecord",
          101,
          110,
          102,
          10,
          102,
          50,
          101,
          22,
          105,
          11
        ]
      ],
      "models/official/legacy/transformer/utils/tokenizer_test.py": [
        [
          "_init_subtokenizer",
          27,
          33,
          28,
          17,
          28,
          57,
          27,
          26,
          30,
          32
        ]
      ],
      "models/official/nlp/tools/tokenization_test.py": [
        [
          "test_full_tokenizer",
          31,
          52,
          36,
          10,
          36,
          50,
          31,
          27,
          37,
          16
        ]
      ],
      "models/official/nlp/data/train_sentencepiece.py": [
        [
          "dump_chars_to_textfile",
          60,
          85,
          74,
          8,
          74,
          48,
          60,
          28,
          75,
          14
        ]
      ],
      "models/official/legacy/transformer/transformer_main.py": [
        [
          "translate_and_compute_bleu",
          49,
          88,
          72,
          9,
          72,
          49,
          49,
          32,
          88,
          35
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_load_labels",
          26,
          50,
          28,
          10,
          28,
          61,
          26,
          24,
          34,
          46
        ]
      ]
    },
    "os.unlink": {
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py": [
        [
          "InMemoryTFRecord",
          42,
          51,
          51,
          5,
          51,
          24,
          51,
          5,
          51,
          24
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py": [
        [
          "InMemoryTFRecord",
          95,
          104,
          104,
          5,
          104,
          23,
          104,
          5,
          104,
          23
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py": [
        [
          "InMemoryTFRecord",
          101,
          110,
          110,
          5,
          110,
          24,
          110,
          5,
          110,
          24
        ]
      ],
      "models/official/nlp/tools/tokenization_test.py": [
        [
          "test_full_tokenizer",
          31,
          52,
          46,
          5,
          46,
          25,
          43,
          20,
          52,
          69
        ]
      ]
    },
    "tempfile.mkdtemp": {
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py": [
        [
          "test_beam_pipeline",
          335,
          363,
          339,
          18,
          339,
          68,
          335,
          26,
          359,
          35
        ],
        [
          "test_beam_pipeline_sequence_example",
          365,
          395,
          369,
          18,
          369,
          68,
          365,
          43,
          390,
          35
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py": [
        [
          "test_beam_pipeline",
          165,
          186,
          167,
          16,
          167,
          66,
          165,
          26,
          182,
          33
        ],
        [
          "test_beam_pipeline_bbox",
          188,
          210,
          190,
          16,
          190,
          66,
          188,
          31,
          206,
          33
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data_test.py": [
        [
          "_create_files",
          32,
          44,
          35,
          14,
          35,
          43,
          33,
          5,
          38,
          49
        ],
        [
          "test_end_to_end",
          317,
          349,
          331,
          16,
          331,
          56,
          317,
          23,
          349,
          54
        ]
      ],
      "models/official/recommendation/data_pipeline.py": [
        [
          "__init__",
          372,
          459,
          439,
          39,
          439,
          69,
          439,
          39,
          439,
          69
        ]
      ],
      "models/official/nlp/tools/export_tfhub_lib_test.py": [
        [
          "_make_vocab_file",
          491,
          521,
          515,
          9,
          517,
          39,
          491,
          24,
          521,
          15
        ],
        [
          "_make_sp_model_file",
          523,
          571,
          544,
          9,
          544,
          49,
          523,
          27,
          550,
          36
        ],
        [
          "_do_export",
          573,
          599,
          582,
          19,
          582,
          59,
          573,
          18,
          584,
          19
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "_export_inference_graph",
          488,
          573,
          530,
          34,
          530,
          51,
          530,
          34,
          530,
          30
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py": [
        [
          "test_beam_pipeline",
          234,
          256,
          236,
          18,
          236,
          68,
          234,
          26,
          252,
          35
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py": [
        [
          "test_beam_pipeline",
          301,
          327,
          303,
          18,
          303,
          68,
          301,
          26,
          323,
          35
        ]
      ],
      "models/research/adversarial_text/graphs_test.py": [
        [
          "setUpClass",
          80,
          135,
          92,
          22,
          92,
          39,
          80,
          18,
          121,
          52
        ]
      ],
      "models/official/utils/testing/integration.py": [
        [
          "run_synthetic",
          29,
          70,
          52,
          15,
          52,
          44,
          50,
          17,
          56,
          10
        ]
      ],
      "models/research/object_detection/model_lib_tf2_test.py": [
        [
          "test_checkpoint_max_to_keep",
          161,
          183,
          168,
          19,
          168,
          59,
          161,
          35,
          183,
          64
        ]
      ],
      "models/official/legacy/bert/model_training_utils.py": [
        [
          "_save_checkpoint",
          39,
          54,
          51,
          15,
          51,
          32,
          51,
          15,
          53,
          31
        ],
        [
          "run_customized_training_loop",
          107,
          590,
          308,
          21,
          308,
          38,
          308,
          21,
          308,
          17
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "_download_and_clean",
          90,
          142,
          114,
          14,
          114,
          31,
          112,
          9,
          116,
          17
        ]
      ],
      "models/official/projects/qat/nlp/pretrained_checkpoint_converter.py": [
        [
          "_build_model",
          84,
          96,
          95,
          57,
          95,
          74,
          95,
          10,
          96,
          27
        ]
      ],
      "models/official/nlp/modeling/layers/text_layers_test.py": [
        [
          "_make_vocab_file",
          33,
          39,
          35,
          9,
          35,
          49,
          33,
          24,
          39,
          15
        ],
        [
          "setUp",
          136,
          157,
          140,
          5,
          140,
          33,
          136,
          13,
          157,
          18
        ],
        [
          "test_saving",
          294,
          301,
          300,
          19,
          300,
          59,
          294,
          19,
          301,
          42
        ],
        [
          "_make_vocab_file",
          449,
          455,
          451,
          9,
          451,
          49,
          449,
          24,
          455,
          15
        ]
      ],
      "models/official/core/train_lib.py": [
        [
          "_maybe_build_checkpoint_manager",
          162,
          191,
          179,
          21,
          179,
          38,
          179,
          21,
          180,
          19
        ]
      ]
    },
    "os.path.basename": {
      "models/research/deeplab/datasets/build_ade20k_data.py": [
        [
          "_convert_dataset",
          58,
          112,
          75,
          16,
          75,
          34,
          73,
          7,
          78,
          25
        ]
      ],
      "models/research/deeplab/datasets/build_cityscapes_data.py": [
        [
          "_convert_dataset",
          137,
          188,
          183,
          20,
          183,
          54,
          183,
          20,
          186,
          58
        ]
      ],
      "models/research/deeplab/datasets/build_voc2012_data.py": [
        [
          "_convert_dataset",
          89,
          136,
          98,
          13,
          98,
          43,
          89,
          22,
          107,
          36
        ]
      ],
      "models/research/delf/delf/python/training/build_image_dataset.py": [
        [
          "listcomp",
          114,
          114,
          114,
          15,
          114,
          51,
          114,
          62,
          114,
          56
        ],
        [
          "_get_clean_train_image_files_and_labels",
          127,
          175,
          158,
          15,
          158,
          60,
          157,
          7,
          159,
          24
        ]
      ],
      "models/research/slim/datasets/build_imagenet_data.py": [
        [
          "_convert_to_example",
          178,
          226,
          224,
          40,
          224,
          65,
          206,
          16,
          226,
          16
        ],
        [
          "_find_image_bounding_boxes",
          559,
          582,
          574,
          16,
          574,
          34,
          573,
          7,
          575,
          34
        ]
      ],
      "models/official/nlp/continuous_finetune_lib.py": [
        [
          "run_continuous_finetune",
          72,
          217,
          197,
          12,
          197,
          38,
          194,
          5,
          197,
          38
        ],
        [
          "run_continuous_finetune",
          72,
          217,
          200,
          21,
          200,
          47,
          200,
          21,
          200,
          17
        ]
      ],
      "models/research/object_detection/dataset_tools/create_oid_tf_record.py": [
        [
          "listcomp",
          87,
          87,
          87,
          37,
          87,
          55,
          87,
          65,
          87,
          59
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data.py": [
        [
          "create_tfrecords",
          586,
          693,
          688,
          20,
          688,
          45,
          679,
          9,
          693,
          32
        ],
        [
          "create_tfrecords",
          586,
          693,
          688,
          20,
          688,
          45,
          677,
          6,
          693,
          32
        ]
      ],
      "models/official/projects/triviaqa/dataset.py": [
        [
          "listcomp",
          160,
          160,
          160,
          41,
          160,
          59,
          160,
          27,
          160,
          78
        ],
        [
          "process",
          361,
          367,
          365,
          32,
          365,
          53,
          364,
          9,
          367,
          19
        ]
      ],
      "models/official/legacy/xlnet/data_utils.py": [
        [
          "get_pretrain_input_data",
          579,
          683,
          649,
          18,
          649,
          43,
          648,
          9,
          651,
          40
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "listcomp",
          64,
          64,
          64,
          42,
          64,
          60,
          64,
          66,
          64,
          60
        ],
        [
          "listcomp",
          65,
          65,
          65,
          42,
          65,
          60,
          65,
          66,
          65,
          60
        ],
        [
          "listcomp",
          66,
          66,
          66,
          42,
          66,
          60,
          66,
          66,
          66,
          60
        ],
        [
          "collect_frames",
          496,
          505,
          503,
          20,
          503,
          38,
          502,
          11,
          504,
          31
        ]
      ],
      "models/research/slim/datasets/download_and_convert_flowers.py": [
        [
          "_convert_dataset",
          109,
          152,
          144,
          26,
          144,
          72,
          135,
          15,
          149,
          62
        ]
      ],
      "models/official/projects/waste_identification_ml/model_inference/download_and_unzip_models.py": [
        [
          "main",
          74,
          87,
          84,
          15,
          84,
          49,
          74,
          10,
          87,
          57
        ],
        [
          "main",
          74,
          87,
          85,
          15,
          85,
          54,
          74,
          10,
          87,
          57
        ]
      ],
      "models/research/slim/export_inference_graph.py": [
        [
          "main",
          119,
          158,
          154,
          11,
          154,
          45,
          151,
          7,
          155,
          23
        ]
      ],
      "models/orbit/actions/export_saved_model_test.py": [
        [
          "test_export_file_manager_default_ids",
          46,
          70,
          70,
          22,
          70,
          58,
          46,
          44,
          70,
          73
        ]
      ],
      "models/research/delf/delf/python/examples/extract_boxes.py": [
        [
          "main",
          130,
          182,
          161,
          47,
          161,
          74,
          161,
          30,
          164,
          45
        ]
      ],
      "models/research/delf/delf/python/examples/extract_features.py": [
        [
          "main",
          65,
          112,
          95,
          42,
          96,
          23,
          95,
          25,
          98,
          44
        ]
      ],
      "models/research/delf/delf/python/training/model/global_model.py": [
        [
          "__init__",
          82,
          167,
          136,
          27,
          136,
          75,
          133,
          9,
          145,
          19
        ]
      ],
      "models/research/vid2depth/inference.py": [
        [
          "_run_inference",
          73,
          128,
          75,
          19,
          75,
          52,
          74,
          3,
          80,
          33
        ],
        [
          "_run_inference",
          73,
          128,
          76,
          20,
          76,
          70,
          74,
          3,
          80,
          33
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/inference_pipeline.py": [
        [
          "main",
          117,
          441,
          147,
          29,
          147,
          61,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          133,
          23,
          133,
          55,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          137,
          14,
          137,
          52,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          157,
          31,
          157,
          58,
          155,
          7,
          160,
          33
        ],
        [
          "main",
          117,
          441,
          168,
          45,
          168,
          72,
          168,
          62,
          168,
          72
        ],
        [
          "main",
          117,
          441,
          179,
          46,
          179,
          73,
          179,
          63,
          179,
          73
        ],
        [
          "main",
          117,
          441,
          184,
          43,
          184,
          70,
          182,
          5,
          187,
          14
        ],
        [
          "main",
          117,
          441,
          263,
          23,
          263,
          50,
          263,
          40,
          263,
          50
        ],
        [
          "main",
          117,
          441,
          280,
          23,
          280,
          50,
          280,
          40,
          280,
          50
        ],
        [
          "main",
          117,
          441,
          313,
          33,
          313,
          77,
          313,
          33,
          313,
          77
        ],
        [
          "main",
          117,
          441,
          314,
          32,
          314,
          59,
          314,
          49,
          314,
          59
        ],
        [
          "main",
          117,
          441,
          351,
          25,
          351,
          57,
          351,
          42,
          351,
          57
        ],
        [
          "main",
          117,
          441,
          427,
          19,
          427,
          51,
          427,
          36,
          427,
          51
        ],
        [
          "main",
          117,
          441,
          429,
          20,
          429,
          52,
          429,
          37,
          429,
          52
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/mask_bbox_saver_test.py": [
        [
          "test_save_cropped_objects_success",
          102,
          137,
          133,
          23,
          133,
          55,
          103,
          7,
          137,
          37
        ],
        [
          "test_empty_dataframe_returns_early",
          140,
          159,
          157,
          23,
          157,
          55,
          140,
          42,
          159,
          73
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/mask_bbox_saver.py": [
        [
          "save_cropped_objects",
          170,
          224,
          193,
          24,
          193,
          56,
          171,
          5,
          196,
          23
        ],
        [
          "save_cropped_objects",
          170,
          224,
          205,
          24,
          205,
          56,
          203,
          9,
          222,
          57
        ]
      ],
      "models/research/slim/nets/mobilenet/mobilenet.py": [
        [
          "mobilenet_base",
          149,
          302,
          299,
          12,
          299,
          35,
          297,
          9,
          300,
          24
        ]
      ],
      "models/research/object_detection/model_lib.py": [
        [
          "continuous_eval_generator",
          1020,
          1071,
          1062,
          26,
          1062,
          47,
          1062,
          43,
          1062,
          47
        ]
      ],
      "models/official/legacy/xlnet/preprocess_classification_data.py": [
        [
          "main",
          387,
          450,
          412,
          18,
          412,
          58,
          403,
          16,
          426,
          30
        ]
      ],
      "models/official/legacy/xlnet/preprocess_squad_data.py": [
        [
          "preprocess",
          53,
          94,
          57,
          18,
          57,
          58,
          54,
          3,
          58,
          28
        ]
      ],
      "models/official/legacy/xlnet/preprocess_pretrain_data.py": [
        [
          "get_input_fn",
          850,
          958,
          897,
          28,
          897,
          61,
          897,
          28,
          900,
          27
        ],
        [
          "get_input_fn",
          850,
          958,
          918,
          18,
          918,
          43,
          917,
          9,
          920,
          40
        ]
      ],
      "models/research/deeplab/datasets/remove_gt_colormap.py": [
        [
          "main",
          66,
          79,
          75,
          16,
          75,
          43,
          73,
          7,
          79,
          69
        ]
      ],
      "models/research/delf/delf/python/training/model/resnet50.py": [
        [
          "restore_weights",
          400,
          446,
          417,
          22,
          417,
          47,
          417,
          22,
          427,
          30
        ]
      ],
      "models/official/legacy/xlnet/run_squad.py": [
        [
          "main",
          212,
          290,
          265,
          20,
          265,
          60,
          262,
          16,
          266,
          17
        ]
      ],
      "models/official/legacy/bert/run_squad_helper.py": [
        [
          "predict_squad",
          390,
          416,
          413,
          11,
          413,
          50,
          412,
          21,
          412,
          17
        ]
      ],
      "models/research/vid2depth/util.py": [
        [
          "get_vars_to_restore",
          84,
          108,
          106,
          22,
          106,
          43,
          105,
          9,
          106,
          44
        ]
      ],
      "models/research/deeplab/vis.py": [
        [
          "_process_batch",
          139,
          191,
          183,
          24,
          183,
          55,
          183,
          24,
          185,
          40
        ]
      ],
      "models/research/delf/delf/python/whiten.py": [
        [
          "cholesky",
          97,
          125,
          125,
          38,
          125,
          63,
          124,
          7,
          125,
          72
        ]
      ]
    },
    "glob.glob": {
      "models/research/deeplab/datasets/build_cityscapes_data.py": [
        [
          "_get_files",
          111,
          134,
          133,
          15,
          133,
          37,
          130,
          13,
          134,
          26
        ]
      ],
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_generate_sequence_examples",
          171,
          294,
          220,
          20,
          221,
          60,
          216,
          11,
          225,
          25
        ],
        [
          "_generate_examples",
          296,
          449,
          344,
          20,
          345,
          60,
          340,
          11,
          350,
          26
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "collect_frames",
          55,
          67,
          61,
          18,
          61,
          74,
          60,
          9,
          66,
          80
        ],
        [
          "collect_train_frames",
          204,
          229,
          217,
          30,
          217,
          63,
          215,
          15,
          218,
          38
        ],
        [
          "collect_test_frames",
          361,
          369,
          366,
          24,
          366,
          64,
          363,
          9,
          367,
          32
        ],
        [
          "collect_train_frames",
          371,
          379,
          376,
          24,
          376,
          52,
          373,
          9,
          377,
          32
        ],
        [
          "collect_frames",
          496,
          505,
          501,
          19,
          501,
          65,
          500,
          9,
          502,
          24
        ],
        [
          "load_intrinsics",
          514,
          533,
          519,
          19,
          519,
          40,
          514,
          23,
          528,
          23
        ]
      ],
      "models/research/deeplab/datasets/remove_gt_colormap.py": [
        [
          "main",
          66,
          79,
          71,
          17,
          72,
          73,
          71,
          17,
          73,
          31
        ]
      ]
    },
    "os.path.normpath": {
      "models/research/delf/delf/python/training/build_image_dataset.py": [
        [
          "_get_clean_train_image_files_and_labels",
          127,
          175,
          158,
          32,
          158,
          59,
          157,
          7,
          159,
          24
        ],
        [
          "listcomp",
          114,
          114,
          114,
          32,
          114,
          50,
          114,
          62,
          114,
          56
        ]
      ],
      "models/orbit/actions/export_saved_model.py": [
        [
          "safe_normpath",
          28,
          32,
          31,
          25,
          31,
          64,
          31,
          12,
          31,
          64
        ],
        [
          "safe_normpath",
          28,
          32,
          32,
          10,
          32,
          31,
          32,
          10,
          32,
          31
        ]
      ],
      "models/orbit/actions/export_saved_model_test.py": [
        [
          "test_export_file_manager_managed_files_double_slash",
          230,
          248,
          239,
          26,
          239,
          52,
          230,
          59,
          248,
          6
        ]
      ]
    },
    "os.path.exists": {
      "models/official/legacy/image_classification/classifier_trainer_test.py": [
        [
          "test_gpu_train",
          153,
          183,
          183,
          21,
          183,
          47,
          153,
          22,
          183,
          48
        ]
      ],
      "models/official/legacy/image_classification/classifier_trainer_util_test.py": [
        [
          "test_serialize_config",
          154,
          161,
          160,
          21,
          160,
          53,
          154,
          29,
          161,
          33
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record_test.py": [
        [
          "test_create_sharded_tf_record",
          439,
          493,
          492,
          21,
          492,
          67,
          449,
          9,
          493,
          68
        ],
        [
          "test_create_sharded_tf_record",
          439,
          493,
          493,
          21,
          493,
          67,
          449,
          9,
          493,
          68
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "create_tf_record",
          214,
          265,
          245,
          14,
          245,
          37,
          242,
          18,
          245,
          37
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data.py": [
        [
          "create_tfrecords",
          586,
          693,
          661,
          8,
          661,
          32,
          644,
          5,
          661,
          32
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "is_valid_example",
          535,
          548,
          546,
          14,
          546,
          43,
          540,
          9,
          546,
          43
        ]
      ],
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_and_uncompress_zipfile",
          141,
          162,
          161,
          15,
          161,
          40,
          158,
          9,
          161,
          40
        ]
      ],
      "models/official/vision/serving/detection_test.py": [
        [
          "test_export",
          112,
          157,
          126,
          21,
          126,
          75,
          113,
          7,
          148,
          41
        ],
        [
          "test_export",
          112,
          157,
          128,
          9,
          128,
          77,
          113,
          7,
          148,
          41
        ],
        [
          "test_export",
          112,
          157,
          130,
          9,
          132,
          58,
          113,
          7,
          148,
          41
        ]
      ],
      "models/official/projects/deepmac_maskrcnn/serving/detection_test.py": [
        [
          "test_export",
          72,
          109,
          79,
          21,
          79,
          75,
          72,
          19,
          98,
          42
        ],
        [
          "test_export",
          72,
          109,
          81,
          9,
          81,
          77,
          72,
          19,
          98,
          42
        ],
        [
          "test_export",
          72,
          109,
          83,
          9,
          85,
          58,
          72,
          19,
          98,
          42
        ],
        [
          "test_export_image_and_boxes",
          117,
          160,
          123,
          21,
          123,
          75,
          117,
          35,
          145,
          42
        ],
        [
          "test_export_image_and_boxes",
          117,
          160,
          125,
          9,
          125,
          77,
          117,
          35,
          145,
          42
        ],
        [
          "test_export_image_and_boxes",
          117,
          160,
          127,
          9,
          129,
          58,
          117,
          35,
          145,
          42
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_download_and_uncompress_dataset",
          124,
          142,
          133,
          10,
          133,
          33,
          124,
          38,
          133,
          33
        ]
      ],
      "models/research/slim/datasets/download_and_convert_mnist.py": [
        [
          "_download_dataset",
          145,
          169,
          157,
          12,
          157,
          35,
          151,
          7,
          157,
          35
        ]
      ],
      "models/research/delf/delf/python/training/model/export_CNN_global.py": [
        [
          "main",
          137,
          169,
          142,
          6,
          142,
          32,
          141,
          17,
          142,
          32
        ]
      ],
      "models/official/core/export_base_test.py": [
        [
          "test_export_module",
          42,
          66,
          55,
          21,
          55,
          78,
          42,
          26,
          66,
          75
        ],
        [
          "test_export_module",
          42,
          66,
          57,
          9,
          58,
          69,
          42,
          26,
          66,
          75
        ],
        [
          "test_export_module",
          42,
          66,
          60,
          9,
          62,
          58,
          42,
          26,
          66,
          75
        ]
      ],
      "models/research/delf/delf/python/training/model/export_global_model.py": [
        [
          "main",
          146,
          179,
          151,
          6,
          151,
          32,
          150,
          17,
          151,
          32
        ]
      ],
      "models/research/delf/delf/python/training/model/export_local_model.py": [
        [
          "main",
          107,
          124,
          112,
          6,
          112,
          32,
          111,
          17,
          112,
          32
        ]
      ],
      "models/research/audioset/yamnet/export.py": [
        [
          "make_tf2_export",
          101,
          135,
          102,
          6,
          102,
          31,
          101,
          21,
          102,
          31
        ],
        [
          "make_tflite_export",
          138,
          183,
          139,
          6,
          139,
          31,
          138,
          24,
          139,
          31
        ],
        [
          "make_tfjs_export",
          186,
          197,
          187,
          6,
          187,
          31,
          186,
          22,
          187,
          31
        ]
      ],
      "models/research/delf/delf/python/training/model/export_local_and_global_model.py": [
        [
          "main",
          147,
          166,
          152,
          6,
          152,
          32,
          151,
          17,
          152,
          32
        ]
      ],
      "models/official/vision/serving/export_module_factory_test.py": [
        [
          "test_export",
          68,
          113,
          83,
          21,
          83,
          75,
          68,
          19,
          113,
          76
        ],
        [
          "test_export",
          68,
          113,
          84,
          21,
          85,
          62,
          68,
          19,
          113,
          76
        ],
        [
          "test_export",
          68,
          113,
          86,
          21,
          87,
          76,
          68,
          19,
          113,
          76
        ]
      ],
      "models/official/projects/detr/serving/export_module_test.py": [
        [
          "test_export",
          72,
          94,
          77,
          21,
          77,
          75,
          72,
          19,
          94,
          50
        ],
        [
          "test_export",
          72,
          94,
          79,
          9,
          79,
          77,
          72,
          19,
          94,
          50
        ],
        [
          "test_export",
          72,
          94,
          81,
          9,
          83,
          58,
          72,
          19,
          94,
          50
        ]
      ],
      "models/research/object_detection/export_tflite_graph_lib_tf2_test.py": [
        [
          "test_export_yields_saved_model",
          241,
          264,
          255,
          11,
          256,
          78,
          241,
          38,
          264,
          61
        ],
        [
          "test_export_yields_saved_model",
          241,
          264,
          258,
          11,
          260,
          46,
          241,
          38,
          264,
          61
        ],
        [
          "test_export_yields_saved_model",
          241,
          264,
          262,
          11,
          264,
          60,
          241,
          38,
          264,
          61
        ]
      ],
      "models/research/object_detection/export_tflite_ssd_graph_lib_tf1_test.py": [
        [
          "test_export_tflite_graph_with_moving_averages",
          206,
          223,
          217,
          21,
          217,
          53,
          206,
          53,
          223,
          73
        ],
        [
          "test_export_tflite_graph_without_moving_averages",
          225,
          241,
          236,
          21,
          236,
          53,
          225,
          56,
          241,
          73
        ],
        [
          "test_export_tflite_graph_grayscale",
          243,
          262,
          256,
          21,
          256,
          53,
          243,
          42,
          262,
          73
        ],
        [
          "test_export_tflite_graph_with_quantization",
          264,
          282,
          276,
          21,
          276,
          53,
          264,
          50,
          282,
          73
        ],
        [
          "test_export_tflite_graph_with_softmax_score_conversion",
          284,
          303,
          297,
          21,
          297,
          53,
          284,
          62,
          303,
          70
        ],
        [
          "test_export_tflite_graph_with_sigmoid_score_conversion",
          305,
          324,
          318,
          21,
          318,
          53,
          305,
          62,
          324,
          66
        ],
        [
          "test_export_tflite_graph_with_postprocessing_op",
          326,
          363,
          340,
          21,
          340,
          53,
          326,
          55,
          349,
          32
        ],
        [
          "test_export_tflite_graph_with_additional_tensors",
          365,
          379,
          372,
          21,
          372,
          53,
          365,
          56,
          379,
          53
        ],
        [
          "test_export_tflite_graph_with_postprocess_op_and_additional_tensors",
          381,
          399,
          391,
          21,
          391,
          53,
          381,
          75,
          399,
          53
        ],
        [
          "test_export_with_nn_resize_op_not_called_without_fpn",
          402,
          409,
          408,
          21,
          408,
          53,
          402,
          60,
          409,
          32
        ],
        [
          "test_export_with_nn_resize_op_called_with_fpn",
          412,
          421,
          420,
          21,
          420,
          53,
          412,
          53,
          421,
          44
        ]
      ],
      "models/research/object_detection/exporter_lib_tf2_test.py": [
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          136,
          23,
          137,
          61,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          138,
          23,
          139,
          75,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          140,
          23,
          142,
          43,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          143,
          23,
          144,
          58,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          145,
          23,
          146,
          72,
          122,
          7,
          148,
          48
        ],
        [
          "test_export_yields_correct_directory_structure",
          121,
          148,
          147,
          23,
          148,
          47,
          122,
          7,
          148,
          48
        ]
      ],
      "models/research/object_detection/exporter_tf1_test.py": [
        [
          "test_export_graph_with_image_tensor_input",
          175,
          192,
          191,
          23,
          192,
          61,
          175,
          49,
          192,
          62
        ],
        [
          "test_write_inference_graph",
          194,
          212,
          211,
          23,
          212,
          53,
          194,
          34,
          212,
          54
        ],
        [
          "test_export_graph_with_fixed_size_image_tensor_input",
          214,
          245,
          235,
          11,
          235,
          74,
          214,
          60,
          245,
          45
        ],
        [
          "test_export_graph_with_tf_example_input",
          247,
          264,
          263,
          23,
          264,
          61,
          247,
          47,
          264,
          62
        ],
        [
          "test_export_graph_with_fixed_size_tf_example_input",
          266,
          287,
          287,
          11,
          287,
          74,
          266,
          58,
          287,
          75
        ],
        [
          "test_export_graph_with_encoded_image_string_input",
          289,
          306,
          305,
          23,
          306,
          61,
          289,
          57,
          306,
          62
        ],
        [
          "test_export_graph_with_fixed_size_encoded_image_string_input",
          308,
          329,
          329,
          11,
          329,
          74,
          308,
          68,
          329,
          75
        ],
        [
          "test_export_graph_with_moving_averages",
          367,
          388,
          383,
          23,
          384,
          61,
          367,
          46,
          388,
          66
        ],
        [
          "test_export_graph_saves_pipeline_file",
          785,
          808,
          802,
          23,
          802,
          60,
          785,
          45,
          808,
          72
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/ffmpeg_ops.py": [
        [
          "split_video_to_frames",
          33,
          52,
          44,
          10,
          44,
          36,
          34,
          5,
          44,
          36
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/ffmpeg_ops.py": [
        [
          "split_video_to_frames",
          30,
          47,
          39,
          10,
          39,
          36,
          30,
          27,
          39,
          36
        ]
      ],
      "models/official/core/file_writers_test.py": [
        [
          "test_write_small_dataset_success",
          36,
          41,
          41,
          21,
          41,
          53,
          36,
          40,
          41,
          54
        ]
      ],
      "models/research/delf/delf/python/training/global_features_utils.py": [
        [
          "create_model_directory",
          177,
          221,
          219,
          10,
          219,
          31,
          210,
          3,
          219,
          31
        ]
      ],
      "models/official/vision/serving/image_classification_test.py": [
        [
          "test_export",
          83,
          127,
          92,
          21,
          92,
          75,
          83,
          19,
          106,
          29
        ],
        [
          "test_export",
          83,
          127,
          94,
          9,
          94,
          77,
          83,
          19,
          106,
          29
        ],
        [
          "test_export",
          83,
          127,
          97,
          9,
          99,
          9,
          83,
          19,
          106,
          29
        ],
        [
          "test_multi_size_images_inference",
          133,
          176,
          142,
          21,
          142,
          75,
          133,
          40,
          158,
          29
        ],
        [
          "test_multi_size_images_inference",
          133,
          176,
          144,
          9,
          144,
          77,
          133,
          40,
          158,
          29
        ],
        [
          "test_multi_size_images_inference",
          133,
          176,
          147,
          9,
          149,
          9,
          133,
          40,
          158,
          29
        ]
      ],
      "models/official/utils/testing/integration.py": [
        [
          "run_synthetic",
          29,
          70,
          69,
          8,
          69,
          32,
          69,
          8,
          69,
          32
        ]
      ],
      "models/research/attention_ocr/python/model_export.py": [
        [
          "export_model",
          76,
          184,
          111,
          10,
          111,
          45,
          76,
          18,
          111,
          45
        ],
        [
          "main",
          187,
          192,
          188,
          6,
          188,
          37,
          187,
          10,
          188,
          37
        ]
      ],
      "models/research/lfads/run_lfads.py": [
        [
          "build_model",
          407,
          472,
          426,
          10,
          426,
          43,
          423,
          8,
          426,
          43
        ]
      ],
      "models/official/vision/serving/semantic_segmentation_test.py": [
        [
          "test_export",
          89,
          131,
          99,
          21,
          99,
          75,
          89,
          19,
          111,
          29
        ],
        [
          "test_export",
          89,
          131,
          101,
          9,
          101,
          77,
          89,
          19,
          111,
          29
        ],
        [
          "test_export",
          89,
          131,
          103,
          9,
          105,
          58,
          89,
          19,
          111,
          29
        ],
        [
          "test_export_with_extra_input_channels",
          137,
          193,
          158,
          21,
          158,
          75,
          137,
          45,
          173,
          29
        ],
        [
          "test_export_with_extra_input_channels",
          137,
          193,
          160,
          9,
          160,
          77,
          137,
          45,
          173,
          29
        ],
        [
          "test_export_with_extra_input_channels",
          137,
          193,
          163,
          9,
          165,
          9,
          137,
          45,
          173,
          29
        ]
      ],
      "models/official/vision/data/tfrecord_lib_test.py": [
        [
          "test_obj_annotation_tf_example",
          92,
          173,
          134,
          12,
          134,
          36,
          92,
          38,
          134,
          36
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/train.py": [
        [
          "main",
          113,
          117,
          114,
          10,
          114,
          41,
          113,
          10,
          114,
          41
        ]
      ],
      "models/official/legacy/transformer/transformer_main_test.py": [
        [
          "_assert_exists",
          75,
          76,
          76,
          21,
          76,
          44,
          75,
          22,
          76,
          45
        ],
        [
          "_prepare_files_and_flags",
          141,
          165,
          143,
          12,
          143,
          40,
          141,
          32,
          143,
          40
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "write_data",
          170,
          202,
          183,
          10,
          183,
          33,
          170,
          16,
          183,
          33
        ]
      ],
      "models/official/vision/serving/video_classification_test.py": [
        [
          "test_export",
          76,
          109,
          82,
          21,
          82,
          75,
          76,
          19,
          109,
          68
        ],
        [
          "test_export",
          76,
          109,
          84,
          9,
          84,
          77,
          76,
          19,
          109,
          68
        ],
        [
          "test_export",
          76,
          109,
          86,
          9,
          88,
          58,
          76,
          19,
          109,
          68
        ]
      ]
    },
    "tempfile.mkstemp": {
      "models/official/vision/evaluation/coco_evaluator.py": [
        [
          "__init__",
          43,
          131,
          82,
          29,
          82,
          60,
          82,
          29,
          86,
          59
        ]
      ],
      "models/official/legacy/detection/evaluation/coco_evaluator.py": [
        [
          "__init__",
          311,
          362,
          330,
          29,
          330,
          60,
          330,
          29,
          334,
          59
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "download_and_extract",
          55,
          84,
          66,
          21,
          66,
          54,
          66,
          21,
          69,
          11
        ]
      ],
      "models/research/efficient-hrl/environments/maze_env.py": [
        [
          "__init__",
          37,
          234,
          231,
          20,
          231,
          61,
          231,
          20,
          234,
          20
        ]
      ]
    },
    "os.listdir": {
      "models/official/projects/movinet/tools/convert_3d_2plus1d_test.py": [
        [
          "test_convert_model",
          31,
          57,
          55,
          11,
          55,
          38,
          31,
          26,
          57,
          76
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data_test.py": [
        [
          "test_end_to_end",
          317,
          349,
          347,
          32,
          347,
          51,
          317,
          23,
          349,
          54
        ],
        [
          "test_end_to_end",
          317,
          349,
          349,
          32,
          349,
          51,
          317,
          23,
          349,
          54
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "collect_frames",
          55,
          67,
          57,
          18,
          57,
          45,
          55,
          22,
          60,
          27
        ],
        [
          "collect_train_frames",
          204,
          229,
          209,
          19,
          209,
          38,
          207,
          9,
          210,
          25
        ],
        [
          "collect_frames",
          496,
          505,
          498,
          17,
          498,
          35,
          496,
          22,
          500,
          25
        ]
      ],
      "models/research/adversarial_text/data/document_generators.py": [
        [
          "imdb_documents",
          158,
          219,
          197,
          21,
          197,
          69,
          196,
          7,
          197,
          69
        ],
        [
          "rt_documents",
          317,
          383,
          347,
          21,
          347,
          50,
          344,
          3,
          348,
          34
        ]
      ],
      "models/research/slim/datasets/download_and_convert_flowers.py": [
        [
          "_get_filenames_and_classes",
          74,
          100,
          88,
          19,
          88,
          41,
          74,
          32,
          88,
          41
        ],
        [
          "_get_filenames_and_classes",
          74,
          100,
          96,
          21,
          96,
          41,
          95,
          7,
          96,
          41
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "read_datasets",
          246,
          277,
          259,
          12,
          259,
          32,
          246,
          19,
          262,
          21
        ]
      ]
    },
    "os.path.split": {
      "models/official/projects/fffner/utils/convert_checkpoint_huggingface.py": [
        [
          "convert_checkpoint",
          125,
          152,
          127,
          19,
          127,
          44,
          125,
          24,
          152,
          57
        ]
      ],
      "models/official/projects/fffner/utils/convert_checkpoint_tensorflow.py": [
        [
          "convert_checkpoint",
          141,
          168,
          143,
          19,
          143,
          44,
          141,
          24,
          168,
          57
        ]
      ],
      "models/official/projects/longformer/utils/convert_pretrained_pytorch_checkpoint_to_tf.py": [
        [
          "convert_checkpoint",
          170,
          192,
          172,
          19,
          172,
          44,
          170,
          24,
          192,
          57
        ]
      ],
      "models/official/nlp/tools/export_tfhub_lib.py": [
        [
          "_move_to_tmpdir",
          392,
          403,
          396,
          22,
          396,
          45,
          396,
          22,
          403,
          20
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "replace_matches",
          121,
          142,
          134,
          18,
          134,
          49,
          125,
          11,
          137,
          60
        ]
      ],
      "models/official/nlp/tools/tf2_albert_encoder_checkpoint_converter.py": [
        [
          "convert_checkpoint",
          122,
          155,
          126,
          19,
          126,
          44,
          122,
          24,
          140,
          33
        ]
      ],
      "models/official/nlp/tools/tf2_bert_encoder_checkpoint_converter.py": [
        [
          "convert_checkpoint",
          101,
          139,
          107,
          19,
          107,
          44,
          101,
          24,
          123,
          33
        ]
      ],
      "models/official/projects/mobilebert/tf2_model_checkpoint_converter.py": [
        [
          "convert",
          90,
          186,
          120,
          19,
          120,
          51,
          90,
          13,
          132,
          34
        ]
      ]
    },
    "zipfile.ZipFile.extractall": {
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_download_data",
          451,
          479,
          466,
          7,
          466,
          52,
          457,
          5,
          467,
          41
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "_download_and_clean",
          90,
          142,
          126,
          5,
          126,
          55,
          126,
          47,
          126,
          55
        ]
      ]
    },
    "os.walk": {
      "models/official/legacy/transformer/data_download.py": [
        [
          "find_file",
          93,
          103,
          95,
          28,
          95,
          40,
          93,
          15,
          95,
          40
        ]
      ],
      "models/official/projects/nhnet/raw_data_processor.py": [
        [
          "read_crawled_articles",
          70,
          84,
          72,
          27,
          72,
          46,
          70,
          29,
          72,
          46
        ]
      ]
    },
    "tarfile.open": {
      "models/official/legacy/transformer/data_download.py": [
        [
          "download_and_extract",
          178,
          216,
          205,
          8,
          205,
          44,
          201,
          21,
          212,
          15
        ]
      ],
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_and_uncompress_tarball",
          130,
          138,
          138,
          3,
          138,
          32,
          130,
          37,
          138,
          56
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "download_and_extract",
          55,
          84,
          81,
          10,
          81,
          40,
          81,
          23,
          81,
          40
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_download_and_uncompress_dataset",
          124,
          142,
          142,
          5,
          142,
          34,
          134,
          5,
          142,
          58
        ]
      ]
    },
    "os.path.islink": {
      "models/research/delf/delf/python/datasets/sfm120k/dataset_download.py": [
        [
          "download_train",
          22,
          103,
          61,
          42,
          61,
          64,
          61,
          42,
          61,
          64
        ]
      ]
    },
    "os.path.isfile": {
      "models/research/delf/delf/python/datasets/sfm120k/dataset_download.py": [
        [
          "download_train",
          22,
          103,
          89,
          14,
          89,
          37,
          86,
          9,
          89,
          37
        ],
        [
          "download_train",
          22,
          103,
          96,
          16,
          96,
          48,
          95,
          29,
          96,
          48
        ]
      ],
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_and_uncompress_zipfile",
          141,
          162,
          161,
          45,
          161,
          70,
          161,
          45,
          161,
          70
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "_export_inference_graph",
          488,
          573,
          526,
          10,
          526,
          50,
          526,
          10,
          526,
          50
        ]
      ]
    },
    "os.path.isdir": {
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "collect_train_frames",
          204,
          229,
          212,
          12,
          212,
          35,
          210,
          11,
          212,
          35
        ]
      ],
      "models/research/slim/datasets/download_and_convert_flowers.py": [
        [
          "_get_filenames_and_classes",
          74,
          100,
          90,
          8,
          90,
          26,
          88,
          7,
          90,
          26
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/gsutil_ops.py": [
        [
          "move",
          36,
          56,
          51,
          6,
          51,
          29,
          36,
          10,
          51,
          29
        ]
      ]
    },
    "os.stat": {
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_url",
          105,
          127,
          125,
          14,
          125,
          30,
          105,
          18,
          127,
          17
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "download_and_extract",
          55,
          84,
          78,
          16,
          78,
          36,
          78,
          24,
          78,
          36
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_download_and_uncompress_dataset",
          124,
          142,
          140,
          16,
          140,
          32,
          134,
          5,
          142,
          58
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "_download_and_clean",
          90,
          142,
          118,
          16,
          118,
          32,
          118,
          24,
          118,
          32
        ]
      ]
    },
    "zipfile.ZipFile.namelist": {
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_and_uncompress_zipfile",
          141,
          162,
          158,
          19,
          158,
          37,
          157,
          8,
          158,
          37
        ]
      ]
    },
    "zipfile.ZipFile.extract": {
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_and_uncompress_zipfile",
          141,
          162,
          162,
          9,
          162,
          45,
          161,
          10,
          162,
          45
        ]
      ]
    },
    "os.path.abspath": {
      "models/research/object_detection/core/densepose_ops.py": [
        [
          "__init__",
          264,
          304,
          267,
          28,
          267,
          52,
          264,
          16,
          279,
          46
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "convert_audio_and_split_transcript",
          87,
          153,
          145,
          25,
          145,
          49,
          143,
          26,
          145,
          77
        ]
      ],
      "models/research/object_detection/utils/variables_helper.py": [
        [
          "ensure_checkpoint_supported",
          195,
          230,
          223,
          25,
          223,
          73,
          223,
          25,
          226,
          37
        ],
        [
          "ensure_checkpoint_supported",
          195,
          230,
          224,
          15,
          224,
          40,
          223,
          25,
          226,
          37
        ]
      ]
    },
    "os.makedirs": {
      "models/official/projects/waste_identification_ml/model_inference/download_and_unzip_models.py": [
        [
          "main",
          74,
          87,
          80,
          3,
          80,
          40,
          74,
          10,
          87,
          57
        ],
        [
          "main",
          74,
          87,
          81,
          3,
          81,
          45,
          74,
          10,
          87,
          57
        ]
      ],
      "models/research/audioset/yamnet/export.py": [
        [
          "make_tflite_export",
          138,
          183,
          154,
          3,
          154,
          30,
          145,
          3,
          183,
          24
        ],
        [
          "make_tfjs_export",
          186,
          197,
          194,
          3,
          194,
          25,
          193,
          3,
          197,
          13
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/ffmpeg_ops.py": [
        [
          "split_video_to_frames",
          33,
          52,
          45,
          5,
          45,
          28,
          45,
          5,
          45,
          28
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/ffmpeg_ops.py": [
        [
          "split_video_to_frames",
          30,
          47,
          40,
          5,
          40,
          28,
          40,
          5,
          40,
          28
        ]
      ],
      "models/research/delf/delf/python/training/global_features_utils.py": [
        [
          "create_model_directory",
          177,
          221,
          220,
          5,
          220,
          23,
          220,
          5,
          220,
          23
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/inference_pipeline.py": [
        [
          "main",
          117,
          441,
          134,
          3,
          134,
          47,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          139,
          3,
          139,
          40,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          352,
          7,
          352,
          49,
          352,
          19,
          352,
          49
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/mask_bbox_saver.py": [
        [
          "save_cropped_objects",
          170,
          224,
          194,
          3,
          194,
          48,
          171,
          5,
          196,
          23
        ],
        [
          "save_cropped_objects",
          170,
          224,
          201,
          5,
          201,
          44,
          199,
          7,
          203,
          41
        ]
      ],
      "models/official/projects/nhnet/raw_data_process.py": [
        [
          "transform_as_tfrecords",
          44,
          65,
          54,
          3,
          54,
          43,
          44,
          28,
          56,
          44
        ]
      ],
      "models/research/lfads/run_lfads.py": [
        [
          "build_model",
          407,
          472,
          428,
          5,
          428,
          35,
          427,
          5,
          428,
          35
        ]
      ],
      "models/official/legacy/transformer/transformer_main_test.py": [
        [
          "_prepare_files_and_flags",
          141,
          165,
          144,
          7,
          144,
          32,
          144,
          7,
          144,
          32
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "write_data",
          170,
          202,
          184,
          5,
          184,
          25,
          184,
          5,
          184,
          25
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "create_folders_from_video_name",
          75,
          98,
          95,
          5,
          95,
          43,
          93,
          7,
          96,
          36
        ]
      ]
    },
    "tempfile.TemporaryDirectory": {
      "models/official/nlp/tools/export_tfhub_lib.py": [
        [
          "export_preprocessing",
          406,
          429,
          415,
          8,
          415,
          36,
          406,
          26,
          425,
          34
        ]
      ],
      "models/official/projects/edgetpu/nlp/serving/export_tflite_squad.py": [
        [
          "main",
          108,
          177,
          145,
          13,
          145,
          41,
          138,
          23,
          165,
          60
        ]
      ],
      "models/official/projects/edgetpu/vision/tasks/image_classification.py": [
        [
          "load_searched_model",
          66,
          88,
          78,
          8,
          78,
          36,
          66,
          25,
          79,
          42
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_files_paths_with_no_images",
          72,
          80,
          73,
          10,
          73,
          38,
          72,
          39,
          76,
          31
        ],
        [
          "test_files_paths_with_images",
          52,
          70,
          54,
          10,
          54,
          38,
          52,
          36,
          57,
          31
        ],
        [
          "test_files_paths_empty_folder",
          82,
          85,
          83,
          10,
          83,
          38,
          82,
          37,
          85,
          34
        ]
      ]
    },
    "shutil.rmtree": {
      "models/research/adversarial_text/graphs_test.py": [
        [
          "tearDownClass",
          138,
          139,
          139,
          5,
          139,
          33,
          138,
          21,
          139,
          33
        ]
      ],
      "models/official/utils/testing/integration.py": [
        [
          "run_synthetic",
          29,
          70,
          70,
          7,
          70,
          30,
          70,
          7,
          70,
          30
        ]
      ]
    },
    "os.path.relpath": {
      "models/official/projects/edgetpu/vision/tasks/image_classification.py": [
        [
          "_copy_recursively",
          35,
          45,
          38,
          33,
          38,
          61,
          37,
          7,
          39,
          38
        ]
      ],
      "models/official/projects/edgetpu/vision/modeling/mobilenet_edgetpu_v1_model_test.py": [
        [
          "_copy_recursively",
          32,
          42,
          35,
          33,
          35,
          61,
          34,
          7,
          36,
          38
        ]
      ]
    },
    "tempfile.gettempdir": {
      "models/official/projects/pruning/tasks/image_classification_test.py": [
        [
          "testTaskWithUnstructuredSparsity",
          104,
          145,
          136,
          22,
          136,
          42,
          135,
          7,
          136,
          77
        ],
        [
          "testTaskWithStructuredSparsity",
          149,
          197,
          184,
          20,
          184,
          40,
          183,
          23,
          197,
          35
        ]
      ],
      "models/research/delf/delf/python/training/model/resnet50.py": [
        [
          "restore_weights",
          400,
          446,
          418,
          33,
          418,
          53,
          417,
          22,
          427,
          30
        ]
      ]
    },
    "os.path.realpath": {
      "models/research/seq_flow_lite/demo/colab/setup.py": [
        [
          "run",
          38,
          41,
          41,
          29,
          41,
          54,
          38,
          11,
          41,
          56
        ]
      ]
    },
    "os.mkdir": {
      "models/official/vision/data/tfrecord_lib_test.py": [
        [
          "test_obj_annotation_tf_example",
          92,
          173,
          135,
          7,
          135,
          25,
          135,
          7,
          135,
          25
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/train.py": [
        [
          "main",
          113,
          117,
          115,
          5,
          115,
          30,
          115,
          5,
          115,
          30
        ]
      ]
    },
    "os.remove": {
      "models/official/nlp/data/train_sentencepiece.py": [
        [
          "main",
          117,
          129,
          129,
          3,
          129,
          25,
          117,
          10,
          129,
          25
        ]
      ],
      "models/official/legacy/transformer/transformer_main.py": [
        [
          "translate_and_compute_bleu",
          49,
          88,
          87,
          3,
          87,
          25,
          49,
          32,
          88,
          35
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_load_labels",
          26,
          50,
          50,
          7,
          50,
          30,
          50,
          7,
          50,
          30
        ]
      ]
    },
    "os.scandir": {
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "files_paths",
          188,
          208,
          201,
          16,
          201,
          38,
          188,
          17,
          201,
          38
        ]
      ]
    },
    "logging.FileHandler": {
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "create_log_file",
          211,
          228,
          224,
          18,
          224,
          51,
          211,
          21,
          228,
          15
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "create_log_file",
          55,
          72,
          68,
          18,
          68,
          51,
          55,
          21,
          72,
          15
        ]
      ]
    }
  },
  "CWE-078": {
    "shlex.quote": {
      "models/official/utils/flags/core.py": [
        [
          "genexpr",
          130,
          130,
          130,
          19,
          130,
          39,
          130,
          45,
          130,
          39
        ]
      ]
    },
    "pipes.quote": {
      "models/official/utils/flags/core.py": [
        [
          "genexpr",
          130,
          130,
          130,
          19,
          130,
          39,
          130,
          45,
          130,
          39
        ]
      ]
    },
    "os.system": {
      "models/research/delf/delf/python/datasets/sfm120k/dataset_download.py": [
        [
          "download_train",
          22,
          103,
          52,
          5,
          52,
          57,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          54,
          5,
          54,
          60,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          56,
          5,
          56,
          39,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          63,
          5,
          63,
          57,
          61,
          6,
          66,
          36
        ],
        [
          "download_train",
          22,
          103,
          92,
          9,
          92,
          61,
          90,
          9,
          92,
          61
        ],
        [
          "download_train",
          22,
          103,
          102,
          11,
          103,
          62,
          98,
          13,
          103,
          62
        ]
      ],
      "models/research/cognitive_planning/viz_active_vision_dataset_main.py": [
        [
          "visualize",
          223,
          274,
          269,
          7,
          274,
          7,
          268,
          13,
          274,
          7
        ]
      ]
    },
    "subprocess.run": {
      "models/official/projects/waste_identification_ml/model_inference/download_and_unzip_models.py": [
        [
          "execute_command",
          56,
          71,
          58,
          12,
          64,
          3,
          56,
          21,
          66,
          27
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/gsutil_ops.py": [
        [
          "copy",
          26,
          33,
          33,
          3,
          33,
          56,
          26,
          10,
          33,
          56
        ],
        [
          "move",
          36,
          56,
          56,
          3,
          56,
          56,
          56,
          3,
          56,
          56
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/inference_pipeline.py": [
        [
          "main",
          117,
          441,
          130,
          3,
          130,
          49,
          128,
          22,
          155,
          52
        ],
        [
          "main",
          117,
          441,
          368,
          7,
          368,
          64,
          368,
          22,
          368,
          64
        ],
        [
          "main",
          117,
          441,
          391,
          7,
          391,
          64,
          391,
          22,
          391,
          64
        ],
        [
          "main",
          117,
          441,
          435,
          7,
          435,
          64,
          435,
          22,
          435,
          64
        ]
      ],
      "models/official/projects/waste_identification_ml/llm_applications/milk_pouch_detection/models.py": [
        [
          "stop_model",
          206,
          235,
          216,
          16,
          221,
          7,
          217,
          12,
          221,
          7
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "shutdown_system",
          502,
          510,
          508,
          5,
          508,
          39,
          508,
          20,
          508,
          39
        ]
      ]
    },
    "subprocess.call": {
      "models/research/efficient-hrl/scripts/local_eval.py": [
        [
          "main",
          29,
          72,
          72,
          3,
          72,
          31,
          71,
          3,
          72,
          31
        ]
      ],
      "models/research/efficient-hrl/scripts/local_train.py": [
        [
          "main",
          30,
          72,
          72,
          3,
          72,
          31,
          71,
          3,
          72,
          31
        ]
      ]
    },
    "distutils.spawn.find_executable": {
      "models/research/seq_flow_lite/demo/colab/setup.py": [
        [
          "finalize_options",
          35,
          36,
          36,
          23,
          36,
          52,
          35,
          24,
          36,
          19
        ]
      ]
    },
    "subprocess.check_call": {
      "models/research/seq_flow_lite/demo/colab/setup.py": [
        [
          "run",
          38,
          41,
          39,
          5,
          41,
          56,
          38,
          11,
          41,
          56
        ]
      ]
    }
  },
  "CWE-079": {},
  "CWE-095": {
    "json.loads": {
      "models/official/nlp/finetuning/binary_helper.py": [
        [
          "load_model_config_file",
          81,
          140,
          99,
          14,
          99,
          29,
          93,
          3,
          140,
          3
        ]
      ],
      "models/official/nlp/data/classifier_data_lib.py": [
        [
          "_read_jsonl",
          124,
          130,
          129,
          22,
          129,
          41,
          128,
          11,
          129,
          42
        ]
      ],
      "models/research/object_detection/metrics/coco_tools_test.py": [
        [
          "testExportGroundtruthToCOCO",
          81,
          103,
          102,
          24,
          102,
          49,
          81,
          35,
          103,
          52
        ],
        [
          "testExportDetectionsToCOCO",
          105,
          129,
          128,
          24,
          128,
          49,
          105,
          34,
          129,
          52
        ],
        [
          "testExportSegmentsToCOCO",
          131,
          161,
          158,
          24,
          158,
          49,
          142,
          25,
          161,
          52
        ],
        [
          "testExportKeypointsToCOCO",
          163,
          193,
          192,
          24,
          192,
          49,
          163,
          33,
          193,
          52
        ]
      ],
      "models/official/legacy/bert/configs.py": [
        [
          "from_json_file",
          91,
          95,
          95,
          26,
          95,
          41,
          91,
          22,
          95,
          42
        ]
      ],
      "models/official/common/distribute_utils.py": [
        [
          "configure_cluster",
          207,
          239,
          217,
          15,
          217,
          59,
          207,
          23,
          218,
          14
        ]
      ],
      "models/research/seq_flow_lite/export_to_tflite.py": [
        [
          "load_runner_config",
          36,
          39,
          39,
          12,
          39,
          31,
          37,
          12,
          39,
          31
        ]
      ],
      "models/official/recommendation/uplift/keras_test_case.py": [
        [
          "assertLayerConfigurable",
          150,
          170,
          165,
          41,
          165,
          70,
          165,
          41,
          165,
          70
        ]
      ],
      "models/official/projects/mobilebert/model_utils.py": [
        [
          "from_json_file",
          121,
          125,
          125,
          26,
          125,
          41,
          121,
          22,
          125,
          42
        ]
      ],
      "models/official/recommendation/ncf_keras_main.py": [
        [
          "run_ncf",
          207,
          346,
          250,
          25,
          250,
          65,
          248,
          5,
          252,
          15
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/predictor.py": [
        [
          "send_image_for_prediction",
          40,
          67,
          62,
          16,
          62,
          42,
          62,
          16,
          62,
          42
        ]
      ],
      "models/official/legacy/bert/run_classifier.py": [
        [
          "custom_main",
          420,
          503,
          430,
          23,
          430,
          63,
          420,
          17,
          434,
          24
        ]
      ],
      "models/official/legacy/bert/run_squad.py": [
        [
          "main",
          90,
          141,
          94,
          23,
          94,
          63,
          90,
          10,
          96,
          32
        ]
      ],
      "models/official/nlp/finetuning/glue/run_glue.py": [
        [
          "main",
          236,
          278,
          249,
          23,
          249,
          63,
          240,
          3,
          253,
          34
        ]
      ],
      "models/official/nlp/finetuning/superglue/run_superglue.py": [
        [
          "main",
          173,
          214,
          186,
          23,
          186,
          63,
          177,
          3,
          190,
          33
        ]
      ],
      "models/research/lstm_object_detection/train.py": [
        [
          "main",
          88,
          181,
          140,
          9,
          140,
          53,
          112,
          18,
          142,
          62
        ]
      ],
      "models/research/object_detection/legacy/train.py": [
        [
          "main",
          90,
          182,
          127,
          9,
          127,
          53,
          112,
          18,
          129,
          62
        ]
      ],
      "models/official/core/train_utils_test.py": [
        [
          "test_export_best_eval_metric",
          183,
          194,
          191,
          16,
          191,
          40,
          183,
          36,
          194,
          77
        ],
        [
          "test_export_best_eval_metric_skips_non_scalar_values",
          196,
          211,
          208,
          16,
          208,
          40,
          196,
          60,
          211,
          77
        ]
      ],
      "models/research/seq_flow_lite/trainer.py": [
        [
          "load_runner_config",
          46,
          48,
          48,
          12,
          48,
          31,
          47,
          8,
          48,
          31
        ]
      ],
      "models/official/core/train_utils.py": [
        [
          "_maybe_load_best_eval_metric",
          187,
          191,
          191,
          14,
          191,
          38,
          190,
          10,
          191,
          38
        ]
      ],
      "models/research/seq_flow_lite/trainer_v2.py": [
        [
          "load_runner_config",
          44,
          46,
          46,
          12,
          46,
          31,
          45,
          8,
          46,
          31
        ]
      ]
    },
    "ast.literal_eval": {
      "models/research/object_detection/exporter_lib_v2.py": [
        [
          "listcomp",
          60,
          61,
          61,
          7,
          61,
          37,
          61,
          43,
          61,
          37
        ]
      ]
    },
    "eval": {
      "models/research/object_detection/exporter_lib_v2.py": [
        [
          "_combine_side_inputs",
          46,
          65,
          63,
          22,
          63,
          55,
          46,
          26,
          65,
          67
        ]
      ],
      "models/official/projects/maxvit/modeling/layers.py": [
        [
          "build",
          170,
          241,
          218,
          23,
          218,
          44,
          218,
          23,
          220,
          19
        ]
      ]
    }
  },
  "CWE-113": {},
  "CWE-117": {
    "print": {
      "models/research/delf/delf/python/detect_to_retrieve/aggregation_extraction.py": [
        [
          "ExtractAggregatedRepresentationsToFiles",
          74,
          193,
          133,
          7,
          133,
          61,
          133,
          7,
          133,
          61
        ],
        [
          "ExtractAggregatedRepresentationsToFiles",
          74,
          193,
          136,
          7,
          138,
          63,
          135,
          18,
          139,
          11
        ],
        [
          "ExtractAggregatedRepresentationsToFiles",
          74,
          193,
          148,
          7,
          148,
          39,
          148,
          7,
          149,
          14
        ]
      ],
      "models/official/nlp/modeling/networks/bert_encoder.py": [
        [
          "from_config",
          311,
          321,
          318,
          7,
          318,
          38,
          314,
          11,
          319,
          31
        ],
        [
          "from_config",
          632,
          642,
          639,
          7,
          639,
          38,
          635,
          11,
          640,
          31
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/big_query_ops.py": [
        [
          "create_table",
          46,
          91,
          84,
          7,
          84,
          56,
          84,
          7,
          84,
          56
        ],
        [
          "create_table",
          46,
          91,
          86,
          7,
          86,
          69,
          86,
          7,
          86,
          69
        ],
        [
          "create_table",
          46,
          91,
          91,
          5,
          91,
          54,
          87,
          3,
          91,
          54
        ]
      ],
      "models/official/nlp/modeling/layers/bigbird_attention_test.py": [
        [
          "test_config",
          48,
          63,
          58,
          5,
          58,
          34,
          48,
          19,
          63,
          72
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/boxes_and_features_extraction.py": [
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          121,
          7,
          121,
          52,
          121,
          7,
          121,
          52
        ],
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          124,
          7,
          126,
          63,
          123,
          18,
          127,
          11
        ],
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          140,
          7,
          140,
          59,
          140,
          7,
          142,
          24
        ],
        [
          "ExtractBoxesAndFeaturesToFiles",
          65,
          202,
          176,
          9,
          176,
          60,
          176,
          9,
          177,
          16
        ]
      ],
      "models/research/delf/delf/python/training/build_image_dataset.py": [
        [
          "_write_tfrecord",
          253,
          286,
          280,
          5,
          280,
          72,
          275,
          7,
          281,
          54
        ]
      ],
      "models/research/slim/datasets/build_imagenet_data.py": [
        [
          "_process_image",
          305,
          338,
          326,
          5,
          326,
          53,
          326,
          5,
          327,
          14
        ],
        [
          "_process_image",
          305,
          338,
          322,
          5,
          322,
          53,
          322,
          5,
          323,
          14
        ],
        [
          "_process_image_files_batch",
          341,
          410,
          399,
          9,
          400,
          75,
          399,
          9,
          401,
          26
        ],
        [
          "_process_image_files_batch",
          341,
          410,
          404,
          5,
          405,
          69,
          403,
          5,
          407,
          17
        ],
        [
          "_process_image_files_batch",
          341,
          410,
          408,
          3,
          409,
          69,
          408,
          3,
          410,
          20
        ],
        [
          "_process_image_files",
          413,
          462,
          441,
          3,
          441,
          78,
          441,
          3,
          451,
          41
        ],
        [
          "_process_image_files",
          413,
          462,
          460,
          3,
          461,
          41,
          459,
          3,
          462,
          20
        ],
        [
          "_find_image_files",
          465,
          538,
          499,
          3,
          499,
          73,
          465,
          23,
          512,
          33
        ],
        [
          "_find_image_files",
          465,
          538,
          521,
          7,
          522,
          47,
          521,
          7,
          522,
          47
        ],
        [
          "_find_image_files",
          465,
          538,
          536,
          3,
          537,
          59,
          528,
          20,
          538,
          35
        ],
        [
          "_find_image_bounding_boxes",
          559,
          582,
          580,
          3,
          581,
          38,
          580,
          3,
          582,
          15
        ],
        [
          "_build_bounding_box_lookup",
          637,
          682,
          680,
          3,
          681,
          52,
          680,
          3,
          682,
          25
        ],
        [
          "main",
          685,
          701,
          691,
          3,
          691,
          56,
          688,
          3,
          701,
          52
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/cluster_delf_features.py": [
        [
          "main",
          69,
          168,
          84,
          3,
          84,
          60,
          81,
          5,
          93,
          28
        ],
        [
          "main",
          69,
          168,
          87,
          3,
          87,
          45,
          81,
          5,
          93,
          28
        ],
        [
          "main",
          69,
          168,
          92,
          3,
          92,
          60,
          81,
          5,
          93,
          28
        ],
        [
          "main",
          69,
          168,
          96,
          7,
          98,
          63,
          95,
          18,
          99,
          11
        ],
        [
          "main",
          69,
          168,
          110,
          3,
          112,
          77,
          109,
          29,
          158,
          41
        ],
        [
          "main",
          69,
          168,
          156,
          3,
          156,
          41,
          109,
          29,
          158,
          41
        ],
        [
          "main",
          69,
          168,
          163,
          5,
          165,
          75,
          158,
          7,
          166,
          9
        ],
        [
          "main",
          69,
          168,
          168,
          3,
          168,
          39,
          168,
          3,
          168,
          39
        ]
      ],
      "models/research/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py": [
        [
          "test_mask_object_center_in_postprocess_by_true_image_shape",
          2748,
          2815,
          2783,
          5,
          2783,
          23,
          2748,
          66,
          2815,
          70
        ]
      ],
      "models/official/legacy/detection/evaluation/coco_evaluator.py": [
        [
          "_summarize",
          74,
          109,
          106,
          9,
          108,
          33,
          105,
          18,
          108,
          33
        ]
      ],
      "models/research/delf/delf/python/datasets/google_landmarks_dataset/compute_recognition_metrics.py": [
        [
          "main",
          34,
          76,
          39,
          3,
          39,
          30,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          42,
          3,
          42,
          16,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          45,
          3,
          45,
          33,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          50,
          3,
          50,
          16,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          53,
          3,
          53,
          57,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          54,
          3,
          55,
          76,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          56,
          3,
          57,
          78,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          60,
          3,
          60,
          57,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          61,
          3,
          64,
          79,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          65,
          3,
          69,
          42,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          72,
          3,
          72,
          57,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          73,
          3,
          74,
          76,
          39,
          3,
          76,
          78
        ],
        [
          "main",
          34,
          76,
          75,
          3,
          76,
          78,
          39,
          3,
          76,
          78
        ]
      ],
      "models/research/delf/delf/python/datasets/google_landmarks_dataset/compute_retrieval_metrics.py": [
        [
          "main",
          34,
          83,
          39,
          3,
          39,
          30,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          42,
          3,
          42,
          16,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          45,
          3,
          45,
          33,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          50,
          3,
          50,
          16,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          53,
          3,
          53,
          57,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          60,
          3,
          60,
          57,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          54,
          3,
          55,
          74,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          56,
          3,
          57,
          76,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          65,
          3,
          68,
          55,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          69,
          3,
          72,
          57,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          75,
          3,
          75,
          57,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          80,
          3,
          81,
          55,
          39,
          3,
          83,
          57
        ],
        [
          "main",
          34,
          83,
          82,
          3,
          83,
          57,
          39,
          3,
          83,
          57
        ]
      ],
      "models/official/projects/qat/nlp/quantization/configs_test.py": [
        [
          "_test_quantizer",
          228,
          257,
          245,
          5,
          245,
          30,
          228,
          23,
          252,
          68
        ],
        [
          "_test_quantizer",
          228,
          257,
          246,
          5,
          246,
          41,
          228,
          23,
          252,
          68
        ],
        [
          "_test_quantizer",
          228,
          257,
          247,
          5,
          247,
          41,
          228,
          23,
          252,
          68
        ]
      ],
      "models/orbit/controller.py": [
        [
          "_log",
          38,
          41,
          41,
          3,
          41,
          16,
          38,
          10,
          41,
          16
        ]
      ],
      "models/official/projects/movinet/tools/convert_3d_2plus1d_test.py": [
        [
          "test_convert_model",
          31,
          57,
          55,
          5,
          55,
          39,
          31,
          26,
          57,
          76
        ]
      ],
      "models/research/deeplab/convert_to_tflite.py": [
        [
          "check_tflite_consistency",
          64,
          94,
          93,
          3,
          94,
          52,
          64,
          30,
          94,
          52
        ]
      ],
      "models/official/projects/fffner/utils/create_data.py": [
        [
          "process_word_list_and_spans_to_inputs",
          114,
          162,
          120,
          7,
          120,
          56,
          120,
          7,
          121,
          12
        ],
        [
          "bio_labels_to_spans",
          164,
          185,
          172,
          11,
          172,
          57,
          172,
          11,
          173,
          41
        ],
        [
          "bio_labels_to_spans",
          164,
          185,
          175,
          11,
          175,
          66,
          175,
          11,
          176,
          41
        ],
        [
          "prepare",
          195,
          260,
          259,
          5,
          259,
          80,
          259,
          5,
          260,
          46
        ],
        [
          "prepare",
          195,
          260,
          260,
          5,
          260,
          46,
          259,
          5,
          260,
          46
        ],
        [
          "file_based_convert_examples_to_features",
          303,
          342,
          310,
          9,
          310,
          76,
          310,
          9,
          311,
          46
        ],
        [
          "file_based_convert_examples_to_features",
          303,
          342,
          311,
          9,
          311,
          46,
          310,
          9,
          311,
          46
        ]
      ],
      "models/official/recommendation/ranking/data/data_pipeline_multi_hot_test.py": [
        [
          "testSyntheticDataPipeline",
          32,
          74,
          62,
          5,
          62,
          35,
          61,
          20,
          64,
          22
        ]
      ],
      "models/official/recommendation/data_preprocessing.py": [
        [
          "instantiate_pipeline",
          202,
          265,
          264,
          3,
          264,
          17,
          240,
          14,
          265,
          39
        ]
      ],
      "models/official/legacy/transformer/data_download.py": [
        [
          "download_report_hook",
          139,
          148,
          148,
          3,
          148,
          68,
          139,
          26,
          148,
          68
        ],
        [
          "download_from_url",
          151,
          175,
          170,
          5,
          170,
          11,
          164,
          16,
          172,
          19
        ]
      ],
      "models/research/delf/delf/python/datasets/sfm120k/dataset_download.py": [
        [
          "download_train",
          22,
          103,
          49,
          5,
          49,
          76,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          51,
          5,
          51,
          41,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          53,
          5,
          53,
          49,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          55,
          5,
          55,
          58,
          47,
          16,
          56,
          39
        ],
        [
          "download_train",
          22,
          103,
          64,
          5,
          66,
          36,
          61,
          6,
          66,
          36
        ],
        [
          "download_train",
          22,
          103,
          82,
          7,
          83,
          23,
          82,
          7,
          84,
          32
        ],
        [
          "download_train",
          22,
          103,
          90,
          9,
          91,
          35,
          90,
          9,
          92,
          61
        ]
      ],
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_url",
          105,
          127,
          124,
          3,
          124,
          9,
          105,
          18,
          127,
          17
        ],
        [
          "download_url",
          105,
          127,
          126,
          3,
          126,
          72,
          105,
          18,
          127,
          17
        ],
        [
          "download_and_uncompress_zipfile",
          141,
          162,
          152,
          5,
          153,
          74,
          152,
          5,
          153,
          74
        ]
      ],
      "models/research/attention_ocr/python/demo_inference.py": [
        [
          "load_images",
          45,
          54,
          51,
          5,
          51,
          30,
          49,
          7,
          53,
          30
        ],
        [
          "main",
          88,
          93,
          89,
          3,
          89,
          29,
          88,
          10,
          92,
          25
        ],
        [
          "main",
          88,
          93,
          93,
          5,
          93,
          15,
          92,
          7,
          93,
          15
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "download_and_extract",
          55,
          84,
          77,
          5,
          77,
          11,
          77,
          5,
          77,
          11
        ]
      ],
      "models/research/slim/datasets/download_and_convert_flowers.py": [
        [
          "run",
          179,
          215,
          189,
          5,
          189,
          75,
          189,
          5,
          190,
          10
        ],
        [
          "run",
          179,
          215,
          215,
          3,
          215,
          53,
          192,
          3,
          215,
          53
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_download_and_uncompress_dataset",
          124,
          142,
          139,
          5,
          139,
          11,
          134,
          5,
          142,
          58
        ],
        [
          "_download_and_uncompress_dataset",
          124,
          142,
          141,
          5,
          141,
          74,
          134,
          5,
          142,
          58
        ],
        [
          "run",
          159,
          198,
          172,
          5,
          172,
          75,
          172,
          5,
          173,
          10
        ],
        [
          "run",
          159,
          198,
          198,
          3,
          198,
          53,
          187,
          8,
          198,
          53
        ]
      ],
      "models/research/slim/datasets/download_and_convert_mnist.py": [
        [
          "_extract_images",
          64,
          81,
          74,
          3,
          74,
          45,
          64,
          21,
          81,
          13
        ],
        [
          "_extract_labels",
          84,
          99,
          94,
          3,
          94,
          45,
          84,
          21,
          99,
          15
        ],
        [
          "_download_dataset",
          145,
          169,
          158,
          7,
          158,
          48,
          158,
          7,
          169,
          64
        ],
        [
          "_download_dataset",
          145,
          169,
          166,
          7,
          166,
          13,
          158,
          7,
          169,
          64
        ],
        [
          "_download_dataset",
          145,
          169,
          169,
          7,
          169,
          64,
          158,
          7,
          169,
          64
        ],
        [
          "run",
          186,
          221,
          199,
          5,
          199,
          75,
          199,
          5,
          200,
          10
        ],
        [
          "run",
          186,
          221,
          221,
          3,
          221,
          51,
          202,
          3,
          221,
          51
        ]
      ],
      "models/official/projects/token_dropping/encoder.py": [
        [
          "from_config",
          390,
          400,
          397,
          7,
          397,
          38,
          393,
          11,
          398,
          31
        ]
      ],
      "models/official/projects/triviaqa/evaluation.py": [
        [
          "get_oracle_score",
          98,
          125,
          109,
          9,
          109,
          39,
          108,
          19,
          109,
          39
        ],
        [
          "evaluate_triviaqa",
          128,
          168,
          139,
          9,
          139,
          39,
          138,
          19,
          139,
          39
        ],
        [
          "evaluate_triviaqa",
          128,
          168,
          144,
          9,
          144,
          39,
          143,
          19,
          144,
          39
        ],
        [
          "evaluate_triviaqa",
          128,
          168,
          152,
          7,
          152,
          47,
          152,
          7,
          152,
          47
        ]
      ],
      "models/official/modeling/multitask/evaluator_test.py": [
        [
          "call",
          44,
          50,
          45,
          5,
          45,
          31,
          44,
          12,
          46,
          20
        ]
      ],
      "models/research/audioset/yamnet/export.py": [
        [
          "log",
          42,
          43,
          43,
          3,
          43,
          76,
          42,
          9,
          43,
          76
        ]
      ],
      "models/research/delf/delf/python/training/model/export_CNN_global.py": [
        [
          "main",
          137,
          169,
          160,
          3,
          160,
          51,
          153,
          12,
          163,
          36
        ]
      ],
      "models/official/vision/serving/export_base_v2_test.py": [
        [
          "test_preprocessor",
          36,
          60,
          58,
          5,
          58,
          27,
          36,
          25,
          60,
          70
        ]
      ],
      "models/official/core/export_base_test.py": [
        [
          "_preprocessor",
          98,
          100,
          99,
          7,
          99,
          19,
          98,
          23,
          100,
          25
        ]
      ],
      "models/research/delf/delf/python/training/model/export_global_model.py": [
        [
          "main",
          146,
          179,
          170,
          3,
          170,
          51,
          162,
          12,
          173,
          36
        ]
      ],
      "models/research/delf/delf/python/training/model/export_local_model.py": [
        [
          "main",
          107,
          124,
          121,
          3,
          121,
          51,
          116,
          12,
          124,
          42
        ]
      ],
      "models/research/delf/delf/python/training/model/export_local_and_global_model.py": [
        [
          "main",
          147,
          166,
          163,
          3,
          163,
          51,
          156,
          12,
          166,
          42
        ]
      ],
      "models/official/projects/movinet/tools/export_saved_model.py": [
        [
          "main",
          292,
          311,
          311,
          3,
          311,
          76,
          292,
          10,
          311,
          76
        ]
      ],
      "models/official/nlp/serving/export_savedmodel.py": [
        [
          "create_export_module",
          90,
          119,
          97,
          5,
          97,
          23,
          96,
          7,
          98,
          32
        ]
      ],
      "models/official/legacy/bert/export_tfhub.py": [
        [
          "main",
          116,
          134,
          126,
          5,
          126,
          48,
          120,
          9,
          128,
          79
        ]
      ],
      "models/official/projects/edgetpu/vision/serving/export_tflite.py": [
        [
          "run_export",
          125,
          178,
          169,
          3,
          169,
          58,
          151,
          16,
          174,
          29
        ],
        [
          "run_export",
          125,
          178,
          178,
          3,
          178,
          61,
          178,
          3,
          178,
          61
        ]
      ],
      "models/research/object_detection/export_tflite_ssd_graph_lib_tf1_test.py": [
        [
          "_assert_quant_vars_exists",
          118,
          122,
          121,
          7,
          121,
          25,
          118,
          33,
          122,
          61
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/extract_aggregation.py": [
        [
          "main",
          35,
          55,
          40,
          3,
          40,
          54,
          40,
          3,
          43,
          30
        ],
        [
          "main",
          35,
          55,
          48,
          3,
          48,
          45,
          47,
          16,
          55,
          61
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "build_detection_graph",
          446,
          485,
          471,
          7,
          471,
          23,
          468,
          9,
          473,
          42
        ]
      ],
      "models/research/delf/delf/python/delg/extract_features.py": [
        [
          "main",
          78,
          159,
          83,
          3,
          83,
          54,
          83,
          3,
          86,
          31
        ],
        [
          "main",
          78,
          159,
          91,
          3,
          91,
          45,
          90,
          16,
          99,
          54
        ],
        [
          "main",
          78,
          159,
          107,
          7,
          107,
          46,
          107,
          7,
          107,
          46
        ],
        [
          "main",
          78,
          159,
          110,
          7,
          112,
          63,
          109,
          18,
          113,
          11
        ],
        [
          "main",
          78,
          159,
          133,
          7,
          133,
          39,
          132,
          31,
          134,
          14
        ],
        [
          "main",
          78,
          159,
          133,
          7,
          133,
          39,
          133,
          7,
          134,
          14
        ],
        [
          "main",
          78,
          159,
          133,
          7,
          133,
          39,
          132,
          8,
          134,
          14
        ]
      ],
      "models/research/delf/delf/python/examples/extract_boxes.py": [
        [
          "main",
          130,
          182,
          135,
          3,
          135,
          36,
          135,
          3,
          141,
          48
        ],
        [
          "main",
          130,
          182,
          138,
          3,
          138,
          43,
          135,
          3,
          141,
          48
        ],
        [
          "main",
          130,
          182,
          153,
          7,
          153,
          54,
          153,
          7,
          153,
          54
        ],
        [
          "main",
          130,
          182,
          156,
          7,
          157,
          72,
          155,
          18,
          158,
          11
        ],
        [
          "main",
          130,
          182,
          165,
          7,
          165,
          37,
          165,
          7,
          166,
          14
        ]
      ],
      "models/research/delf/delf/python/examples/extract_features.py": [
        [
          "main",
          65,
          112,
          67,
          3,
          67,
          36,
          65,
          10,
          78,
          48
        ],
        [
          "main",
          65,
          112,
          70,
          3,
          70,
          43,
          65,
          10,
          78,
          48
        ],
        [
          "main",
          65,
          112,
          87,
          7,
          87,
          63,
          87,
          7,
          87,
          63
        ],
        [
          "main",
          65,
          112,
          90,
          7,
          91,
          72,
          89,
          18,
          92,
          11
        ],
        [
          "main",
          65,
          112,
          99,
          7,
          99,
          41,
          99,
          7,
          100,
          14
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/extract_index_boxes_and_features.py": [
        [
          "main",
          43,
          68,
          48,
          3,
          48,
          60,
          48,
          3,
          68,
          51
        ],
        [
          "main",
          43,
          68,
          51,
          3,
          51,
          45,
          48,
          3,
          68,
          51
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/extract_query_features.py": [
        [
          "main",
          52,
          100,
          61,
          3,
          61,
          43,
          57,
          3,
          69,
          57
        ],
        [
          "main",
          52,
          100,
          57,
          3,
          57,
          70,
          57,
          3,
          69,
          57
        ],
        [
          "main",
          52,
          100,
          82,
          7,
          82,
          43,
          82,
          7,
          83,
          14
        ],
        [
          "main",
          52,
          100,
          100,
          3,
          100,
          74,
          99,
          14,
          100,
          74
        ]
      ],
      "models/official/projects/volumetric_models/modeling/decoders/factory_test.py": [
        [
          "test_unet_3d_decoder_creation",
          30,
          61,
          58,
          5,
          58,
          25,
          38,
          15,
          61,
          60
        ],
        [
          "test_unet_3d_decoder_creation",
          30,
          61,
          59,
          5,
          59,
          33,
          38,
          15,
          61,
          60
        ]
      ],
      "models/official/projects/fffner/fffner_encoder.py": [
        [
          "from_config",
          318,
          328,
          325,
          7,
          325,
          38,
          321,
          11,
          326,
          31
        ]
      ],
      "models/official/nlp/modeling/networks/fnet.py": [
        [
          "from_config",
          322,
          332,
          329,
          7,
          329,
          38,
          325,
          11,
          330,
          31
        ]
      ],
      "models/official/nlp/modeling/networks/funnel_transformer.py": [
        [
          "from_config",
          622,
          632,
          629,
          7,
          629,
          38,
          625,
          11,
          630,
          31
        ]
      ],
      "models/research/delf/delf/python/training/global_features_utils.py": [
        [
          "debug_and_log",
          147,
          162,
          157,
          5,
          157,
          22,
          157,
          5,
          158,
          10
        ],
        [
          "debug_and_log",
          147,
          162,
          160,
          5,
          160,
          14,
          160,
          5,
          160,
          14
        ]
      ],
      "models/research/vid2depth/ops/icp_train_demo.py": [
        [
          "run_training",
          127,
          154,
          150,
          9,
          150,
          77,
          144,
          11,
          154,
          30
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/image_reranking.py": [
        [
          "RerankByGeometricVerification",
          190,
          303,
          264,
          3,
          264,
          30,
          264,
          3,
          265,
          31
        ],
        [
          "RerankByGeometricVerification",
          190,
          303,
          267,
          7,
          267,
          64,
          267,
          7,
          267,
          64
        ]
      ],
      "models/research/audioset/yamnet/inference.py": [
        [
          "main",
          30,
          60,
          58,
          5,
          60,
          37,
          52,
          39,
          60,
          37
        ]
      ],
      "models/official/projects/yolo/ops/kmeans_anchors.py": [
        [
          "_avg_iou",
          152,
          168,
          164,
          5,
          164,
          39,
          163,
          16,
          168,
          15
        ],
        [
          "_avg_iou",
          152,
          168,
          167,
          5,
          167,
          43,
          163,
          16,
          168,
          15
        ],
        [
          "_avg_iou",
          152,
          168,
          165,
          5,
          165,
          38,
          163,
          16,
          168,
          15
        ],
        [
          "_avg_iou",
          152,
          168,
          166,
          5,
          166,
          43,
          163,
          16,
          168,
          15
        ]
      ],
      "models/research/efficient-hrl/scripts/local_eval.py": [
        [
          "main",
          29,
          72,
          33,
          5,
          36,
          22,
          33,
          5,
          37,
          15
        ],
        [
          "main",
          29,
          72,
          71,
          3,
          71,
          20,
          71,
          3,
          72,
          31
        ]
      ],
      "models/research/efficient-hrl/scripts/local_train.py": [
        [
          "main",
          30,
          72,
          71,
          3,
          71,
          20,
          71,
          3,
          72,
          31
        ],
        [
          "main",
          30,
          72,
          34,
          5,
          37,
          22,
          34,
          5,
          38,
          15
        ]
      ],
      "models/official/projects/centernet/utils/checkpoints/load_weights.py": [
        [
          "load_weights_backbone",
          52,
          89,
          67,
          3,
          67,
          37,
          52,
          27,
          73,
          38
        ],
        [
          "get_backbone_layer_cfgs",
          32,
          49,
          46,
          3,
          46,
          74,
          32,
          29,
          49,
          13
        ],
        [
          "load_weights_backbone",
          52,
          89,
          80,
          7,
          81,
          26,
          79,
          19,
          84,
          23
        ],
        [
          "load_weights_backbone",
          52,
          89,
          85,
          9,
          86,
          58,
          85,
          9,
          87,
          30
        ],
        [
          "get_head_layer_cfgs",
          92,
          108,
          105,
          3,
          105,
          66,
          92,
          25,
          108,
          13
        ],
        [
          "load_weights_head",
          111,
          145,
          126,
          3,
          126,
          33,
          111,
          23,
          132,
          34
        ],
        [
          "load_weights_head",
          111,
          145,
          136,
          7,
          137,
          26,
          135,
          19,
          140,
          23
        ],
        [
          "load_weights_head",
          111,
          145,
          141,
          9,
          142,
          54,
          141,
          9,
          143,
          30
        ],
        [
          "load_weights_model",
          148,
          173,
          160,
          3,
          160,
          34,
          148,
          24,
          162,
          18
        ],
        [
          "load_weights_model",
          148,
          173,
          172,
          3,
          172,
          68,
          172,
          3,
          173,
          14
        ]
      ],
      "models/official/projects/lra/linformer_encoder.py": [
        [
          "from_config",
          273,
          284,
          281,
          7,
          281,
          38,
          276,
          11,
          282,
          31
        ]
      ],
      "models/research/lfads/lfads.py": [
        [
          "__init__",
          280,
          1026,
          297,
          5,
          297,
          30,
          280,
          16,
          300,
          28
        ],
        [
          "__init__",
          280,
          1026,
          370,
          13,
          371,
          49,
          370,
          13,
          371,
          49
        ],
        [
          "__init__",
          280,
          1026,
          373,
          13,
          374,
          49,
          373,
          13,
          374,
          49
        ],
        [
          "__init__",
          280,
          1026,
          384,
          11,
          385,
          46,
          384,
          11,
          385,
          46
        ],
        [
          "__init__",
          280,
          1026,
          387,
          11,
          388,
          46,
          387,
          11,
          388,
          46
        ],
        [
          "__init__",
          280,
          1026,
          936,
          5,
          936,
          18,
          936,
          5,
          939,
          30
        ],
        [
          "__init__",
          280,
          1026,
          937,
          5,
          937,
          48,
          936,
          5,
          939,
          30
        ],
        [
          "__init__",
          280,
          1026,
          941,
          7,
          941,
          44,
          939,
          9,
          942,
          18
        ],
        [
          "__init__",
          280,
          1026,
          943,
          5,
          943,
          51,
          943,
          5,
          975,
          21
        ],
        [
          "summarize_all",
          1324,
          1390,
          1363,
          7,
          1368,
          44,
          1355,
          20,
          1370,
          16
        ],
        [
          "summarize_all",
          1324,
          1390,
          1378,
          7,
          1381,
          44,
          1378,
          7,
          1382,
          16
        ],
        [
          "train_model",
          1472,
          1560,
          1552,
          9,
          1552,
          58,
          1550,
          13,
          1554,
          34
        ],
        [
          "train_model",
          1472,
          1560,
          1559,
          9,
          1559,
          71,
          1559,
          9,
          1560,
          13
        ],
        [
          "eval_model_runs_avg_epoch",
          1735,
          1836,
          1789,
          7,
          1789,
          59,
          1788,
          9,
          1800,
          28
        ],
        [
          "eval_model_runs_avg_epoch",
          1735,
          1836,
          1816,
          7,
          1817,
          64,
          1809,
          32,
          1817,
          64
        ],
        [
          "eval_model_runs_push_mean",
          1838,
          1960,
          1871,
          7,
          1871,
          70,
          1871,
          7,
          1872,
          18
        ],
        [
          "eval_model_runs_push_mean",
          1838,
          1960,
          1907,
          7,
          1908,
          68,
          1905,
          9,
          1918,
          28
        ],
        [
          "write_model_runs",
          1962,
          2007,
          1998,
          9,
          1998,
          79,
          1998,
          9,
          1999,
          20
        ],
        [
          "write_model_runs",
          1962,
          2007,
          2007,
          9,
          2007,
          22,
          2005,
          22,
          2007,
          22
        ],
        [
          "write_model_samples",
          2009,
          2087,
          2031,
          5,
          2031,
          49,
          2009,
          27,
          2034,
          21
        ],
        [
          "write_model_samples",
          2009,
          2087,
          2087,
          5,
          2087,
          18,
          2085,
          18,
          2087,
          18
        ],
        [
          "eval_model_parameters",
          2090,
          2144,
          2116,
          11,
          2117,
          58,
          2116,
          11,
          2119,
          27
        ],
        [
          "eval_model_parameters",
          2090,
          2144,
          2119,
          11,
          2119,
          27,
          2116,
          11,
          2119,
          27
        ]
      ],
      "models/official/projects/longformer/longformer_encoder.py": [
        [
          "from_config",
          300,
          310,
          307,
          7,
          307,
          38,
          303,
          11,
          308,
          31
        ]
      ],
      "models/official/projects/longformer/utils/longformer_tokenizer_to_tfrecord.py": [
        [
          "file_based_convert_examples_to_features",
          78,
          102,
          85,
          7,
          85,
          61,
          85,
          7,
          85,
          61
        ]
      ],
      "models/research/delf/delf/python/examples/match_images.py": [
        [
          "main",
          50,
          102,
          55,
          3,
          55,
          54,
          50,
          10,
          102,
          36
        ],
        [
          "main",
          50,
          102,
          59,
          3,
          59,
          54,
          50,
          10,
          102,
          36
        ],
        [
          "main",
          50,
          102,
          85,
          3,
          85,
          40,
          50,
          10,
          102,
          36
        ]
      ],
      "models/research/delf/delf/python/delg/measure_latency.py": [
        [
          "main",
          70,
          115,
          75,
          3,
          75,
          36,
          75,
          3,
          83,
          29
        ],
        [
          "main",
          70,
          115,
          78,
          3,
          78,
          43,
          75,
          3,
          83,
          29
        ],
        [
          "main",
          70,
          115,
          81,
          3,
          81,
          73,
          75,
          3,
          83,
          29
        ],
        [
          "main",
          70,
          115,
          88,
          3,
          88,
          16,
          87,
          3,
          98,
          34
        ],
        [
          "main",
          70,
          115,
          100,
          7,
          100,
          63,
          100,
          7,
          100,
          63
        ],
        [
          "main",
          70,
          115,
          103,
          7,
          105,
          65,
          102,
          18,
          106,
          11
        ]
      ],
      "models/official/projects/lra/mega_encoder.py": [
        [
          "from_config",
          270,
          281,
          278,
          7,
          278,
          38,
          273,
          11,
          279,
          31
        ]
      ],
      "models/research/slim/nets/mobilenet/mobilenet.py": [
        [
          "mobilenet_base",
          149,
          302,
          287,
          9,
          287,
          75,
          286,
          7,
          288,
          13
        ]
      ],
      "models/official/projects/waste_identification_ml/llm_applications/milk_pouch_detection/models.py": [
        [
          "process_image",
          151,
          178,
          168,
          7,
          168,
          35,
          168,
          7,
          169,
          17
        ],
        [
          "stop_model",
          206,
          235,
          214,
          5,
          214,
          62,
          206,
          18,
          216,
          25
        ],
        [
          "__init__",
          50,
          79,
          69,
          5,
          69,
          44,
          51,
          7,
          79,
          42
        ],
        [
          "__init__",
          50,
          79,
          72,
          5,
          72,
          43,
          51,
          7,
          79,
          42
        ],
        [
          "__init__",
          50,
          79,
          74,
          5,
          74,
          34,
          51,
          7,
          79,
          42
        ],
        [
          "__init__",
          50,
          79,
          79,
          5,
          79,
          42,
          51,
          7,
          79,
          42
        ],
        [
          "process_image",
          151,
          178,
          164,
          5,
          164,
          41,
          152,
          7,
          167,
          26
        ],
        [
          "process_image",
          151,
          178,
          172,
          5,
          172,
          35,
          171,
          28,
          178,
          5
        ],
        [
          "stop_model",
          206,
          235,
          223,
          9,
          223,
          74,
          223,
          9,
          223,
          74
        ],
        [
          "stop_model",
          206,
          235,
          226,
          9,
          229,
          9,
          226,
          9,
          229,
          9
        ],
        [
          "stop_model",
          206,
          235,
          231,
          7,
          233,
          7,
          230,
          5,
          233,
          7
        ],
        [
          "stop_model",
          206,
          235,
          235,
          7,
          235,
          52,
          234,
          5,
          235,
          52
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "_download_and_clean",
          90,
          142,
          121,
          5,
          121,
          11,
          118,
          5,
          121,
          11
        ]
      ],
      "models/official/recommendation/ncf_keras_main.py": [
        [
          "on_train_end",
          141,
          143,
          143,
          7,
          143,
          68,
          143,
          7,
          143,
          68
        ],
        [
          "run_ncf",
          207,
          346,
          213,
          5,
          213,
          28,
          213,
          5,
          214,
          34
        ]
      ],
      "models/official/projects/yolo/modeling/layers/nn_blocks_test.py": [
        [
          "test_pass_through",
          113,
          133,
          126,
          5,
          126,
          31,
          118,
          9,
          133,
          51
        ],
        [
          "test_pass_through",
          26,
          37,
          32,
          5,
          32,
          15,
          26,
          25,
          37,
          42
        ],
        [
          "test_pass_through",
          26,
          37,
          33,
          5,
          33,
          31,
          26,
          25,
          37,
          42
        ],
        [
          "test_pass_through",
          70,
          79,
          74,
          5,
          74,
          15,
          70,
          25,
          79,
          48
        ],
        [
          "test_pass_through",
          70,
          79,
          75,
          5,
          75,
          31,
          70,
          25,
          79,
          48
        ],
        [
          "test_pass_through",
          113,
          133,
          132,
          5,
          132,
          15,
          118,
          9,
          133,
          51
        ],
        [
          "test_pass_through",
          161,
          173,
          168,
          5,
          168,
          15,
          165,
          9,
          173,
          41
        ],
        [
          "test_pass_through",
          161,
          173,
          169,
          5,
          169,
          31,
          165,
          9,
          173,
          41
        ]
      ],
      "models/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py": [
        [
          "main",
          192,
          223,
          203,
          5,
          203,
          56,
          203,
          5,
          204,
          13
        ]
      ],
      "models/research/deeplab/evaluation/panoptic_quality.py": [
        [
          "print_detailed_results",
          219,
          237,
          237,
          5,
          237,
          14,
          237,
          5,
          237,
          14
        ]
      ],
      "models/research/deeplab/evaluation/parsing_covering.py": [
        [
          "print_detailed_results",
          211,
          227,
          227,
          5,
          227,
          14,
          227,
          5,
          227,
          14
        ]
      ],
      "models/official/nlp/modeling/layers/per_dim_scale_attention_test.py": [
        [
          "test_config",
          38,
          48,
          43,
          5,
          43,
          34,
          38,
          19,
          48,
          72
        ]
      ],
      "models/research/delf/delf/python/delg/perform_retrieval.py": [
        [
          "_ReadDelgGlobalDescriptors",
          80,
          107,
          93,
          3,
          93,
          79,
          80,
          32,
          95,
          28
        ],
        [
          "_ReadDelgGlobalDescriptors",
          80,
          107,
          98,
          7,
          100,
          68,
          97,
          18,
          101,
          11
        ],
        [
          "main",
          110,
          220,
          115,
          3,
          115,
          29,
          115,
          3,
          135,
          37
        ],
        [
          "main",
          110,
          220,
          122,
          3,
          123,
          45,
          115,
          3,
          135,
          37
        ],
        [
          "main",
          110,
          220,
          141,
          5,
          141,
          76,
          140,
          7,
          149,
          39
        ],
        [
          "main",
          110,
          220,
          180,
          5,
          180,
          72,
          179,
          16,
          180,
          72
        ]
      ],
      "models/research/delf/delf/python/detect_to_retrieve/perform_retrieval.py": [
        [
          "_ReadAggregatedDescriptors",
          60,
          112,
          90,
          3,
          90,
          72,
          87,
          16,
          92,
          28
        ],
        [
          "_ReadAggregatedDescriptors",
          60,
          112,
          95,
          7,
          97,
          68,
          94,
          18,
          98,
          11
        ],
        [
          "main",
          115,
          223,
          120,
          3,
          120,
          29,
          120,
          3,
          153,
          40
        ],
        [
          "main",
          115,
          223,
          127,
          3,
          128,
          45,
          120,
          3,
          153,
          40
        ],
        [
          "main",
          115,
          223,
          159,
          5,
          159,
          76,
          158,
          7,
          164,
          36
        ],
        [
          "main",
          115,
          223,
          183,
          5,
          183,
          72,
          182,
          16,
          183,
          72
        ]
      ],
      "models/research/lfads/plot_lfads.py": [
        [
          "_plot_item",
          26,
          39,
          29,
          5,
          29,
          24,
          29,
          5,
          29,
          24
        ]
      ],
      "models/research/slim/nets/post_training_quantization.py": [
        [
          "main",
          147,
          173,
          173,
          3,
          173,
          59,
          147,
          10,
          173,
          59
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/predictor.py": [
        [
          "send_image_for_prediction",
          40,
          67,
          66,
          5,
          66,
          36,
          65,
          3,
          67,
          47
        ]
      ],
      "models/official/legacy/xlnet/preprocess_utils.py": [
        [
          "print_",
          47,
          56,
          56,
          3,
          56,
          18,
          56,
          3,
          56,
          18
        ]
      ],
      "models/official/legacy/image_classification/preprocessing.py": [
        [
          "resize_image",
          259,
          278,
          273,
          3,
          273,
          22,
          259,
          18,
          278,
          26
        ]
      ],
      "models/research/slim/datasets/process_bounding_boxes.py": [
        [
          "ProcessXMLAnnotation",
          118,
          167,
          124,
          5,
          124,
          58,
          123,
          3,
          125,
          15
        ]
      ],
      "models/official/projects/nhnet/raw_data_process.py": [
        [
          "transform_as_tfrecords",
          44,
          65,
          51,
          3,
          51,
          61,
          44,
          28,
          56,
          44
        ],
        [
          "transform_as_tfrecords",
          44,
          65,
          64,
          3,
          65,
          63,
          62,
          30,
          65,
          63
        ],
        [
          "main",
          68,
          87,
          81,
          3,
          81,
          38,
          73,
          20,
          87,
          48
        ],
        [
          "main",
          68,
          87,
          83,
          3,
          83,
          61,
          73,
          20,
          87,
          48
        ],
        [
          "main",
          68,
          87,
          84,
          3,
          84,
          9,
          73,
          20,
          87,
          48
        ]
      ],
      "models/official/projects/nhnet/raw_data_processor.py": [
        [
          "read_crawled_articles",
          70,
          84,
          83,
          5,
          83,
          11,
          83,
          5,
          84,
          29
        ],
        [
          "read_crawled_articles",
          70,
          84,
          82,
          11,
          82,
          79,
          82,
          11,
          82,
          79
        ],
        [
          "_write_story_partition",
          139,
          155,
          151,
          11,
          153,
          21,
          153,
          19,
          153,
          21
        ]
      ],
      "models/official/projects/centernet/utils/checkpoints/read_checkpoints.py": [
        [
          "get_ckpt_weights_as_dict",
          49,
          77,
          59,
          3,
          60,
          17,
          49,
          30,
          69,
          26
        ],
        [
          "get_ckpt_weights_as_dict",
          49,
          77,
          76,
          3,
          76,
          67,
          76,
          3,
          77,
          29
        ]
      ],
      "models/research/rebar/rebar_train.py": [
        [
          "train",
          63,
          181,
          125,
          11,
          125,
          24,
          125,
          11,
          126,
          20
        ],
        [
          "train",
          63,
          181,
          151,
          7,
          151,
          89,
          151,
          7,
          155,
          37
        ],
        [
          "train",
          63,
          181,
          159,
          9,
          159,
          56,
          156,
          21,
          164,
          22
        ],
        [
          "train",
          63,
          181,
          160,
          9,
          160,
          54,
          156,
          21,
          164,
          22
        ],
        [
          "main",
          184,
          198,
          188,
          3,
          188,
          25,
          186,
          13,
          197,
          8
        ]
      ],
      "models/research/rebar/rebar.py": [
        [
          "_create_loss",
          992,
          1035,
          1001,
          7,
          1001,
          14,
          1000,
          9,
          1003,
          28
        ]
      ],
      "models/official/vision/modeling/backbones/resnet_deeplab_test.py": [
        [
          "test_network_creation",
          40,
          58,
          49,
          5,
          49,
          20,
          40,
          29,
          58,
          5
        ],
        [
          "test_network_features",
          69,
          99,
          90,
          5,
          90,
          20,
          69,
          29,
          99,
          5
        ]
      ],
      "models/official/vision/modeling/backbones/resnet_unet_test.py": [
        [
          "test_network_creation",
          28,
          55,
          45,
          5,
          45,
          20,
          28,
          29,
          51,
          24
        ]
      ],
      "models/official/projects/roformer/roformer_encoder.py": [
        [
          "from_config",
          263,
          273,
          270,
          7,
          270,
          38,
          266,
          11,
          271,
          31
        ]
      ],
      "models/official/legacy/bert/run_pretraining.py": [
        [
          "main",
          197,
          212,
          210,
          5,
          210,
          73,
          210,
          5,
          210,
          73
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/run_tflite.py": [
        [
          "main",
          30,
          50,
          50,
          7,
          50,
          62,
          49,
          9,
          50,
          62
        ],
        [
          "main",
          30,
          50,
          42,
          3,
          42,
          43,
          30,
          10,
          48,
          33
        ]
      ],
      "models/research/lfads/run_lfads.py": [
        [
          "build_model",
          407,
          472,
          427,
          5,
          427,
          80,
          427,
          5,
          428,
          35
        ],
        [
          "build_model",
          407,
          472,
          433,
          5,
          433,
          72,
          433,
          5,
          434,
          9
        ],
        [
          "build_model",
          407,
          472,
          436,
          5,
          436,
          74,
          436,
          5,
          437,
          9
        ],
        [
          "build_model",
          407,
          472,
          439,
          5,
          439,
          73,
          439,
          5,
          440,
          9
        ],
        [
          "build_model",
          407,
          472,
          446,
          3,
          446,
          23,
          442,
          10,
          447,
          9
        ],
        [
          "build_model",
          407,
          472,
          448,
          5,
          448,
          74,
          448,
          5,
          449,
          54
        ],
        [
          "build_model",
          407,
          472,
          451,
          5,
          451,
          49,
          451,
          5,
          453,
          53
        ],
        [
          "build_model",
          407,
          472,
          454,
          7,
          455,
          26,
          454,
          7,
          458,
          23
        ],
        [
          "build_model",
          407,
          472,
          457,
          7,
          458,
          23,
          454,
          7,
          458,
          23
        ],
        [
          "write_model_parameters",
          677,
          700,
          694,
          3,
          694,
          47,
          693,
          11,
          700,
          16
        ],
        [
          "write_model_parameters",
          677,
          700,
          700,
          3,
          700,
          16,
          693,
          11,
          700,
          16
        ],
        [
          "load_datasets",
          720,
          757,
          740,
          3,
          740,
          39,
          720,
          19,
          742,
          38
        ],
        [
          "load_datasets",
          720,
          757,
          747,
          7,
          747,
          41,
          747,
          7,
          747,
          41
        ],
        [
          "load_datasets",
          720,
          757,
          749,
          7,
          749,
          74,
          749,
          7,
          749,
          74
        ],
        [
          "load_datasets",
          720,
          757,
          753,
          7,
          753,
          43,
          753,
          7,
          753,
          43
        ],
        [
          "load_datasets",
          720,
          757,
          755,
          7,
          755,
          76,
          755,
          7,
          755,
          76
        ]
      ],
      "models/research/slim/nets/s3dg_test.py": [
        [
          "testBuildOnlyUptoFinalEndpointNoGating",
          61,
          78,
          75,
          9,
          75,
          43,
          70,
          9,
          78,
          62
        ]
      ],
      "models/research/object_detection/utils/shape_utils_test.py": [
        [
          "test_pad_tensor_using_integer_input",
          31,
          45,
          33,
          5,
          33,
          53,
          31,
          43,
          45,
          60
        ]
      ],
      "models/official/nlp/modeling/networks/sparse_mixer.py": [
        [
          "from_config",
          377,
          387,
          384,
          7,
          384,
          38,
          380,
          11,
          385,
          31
        ]
      ],
      "models/official/legacy/xlnet/squad_utils.py": [
        [
          "get_raw_scores",
          86,
          107,
          101,
          11,
          101,
          50,
          101,
          11,
          102,
          18
        ],
        [
          "convert_examples_to_features",
          515,
          842,
          621,
          7,
          621,
          33,
          621,
          7,
          622,
          14
        ]
      ],
      "models/research/lstm_object_detection/test_tflite_model.py": [
        [
          "main",
          27,
          49,
          37,
          3,
          37,
          40,
          27,
          10,
          49,
          20
        ],
        [
          "main",
          27,
          49,
          39,
          3,
          39,
          42,
          27,
          10,
          49,
          20
        ],
        [
          "main",
          27,
          49,
          49,
          3,
          49,
          20,
          27,
          10,
          49,
          20
        ]
      ],
      "models/official/projects/edgetpu/vision/serving/tflite_imagenet_evaluator_run.py": [
        [
          "main",
          43,
          66,
          65,
          3,
          66,
          33,
          64,
          14,
          66,
          33
        ]
      ],
      "models/research/seq_flow_lite/utils/tflite_utils.py": [
        [
          "check_op_histogram",
          94,
          109,
          98,
          9,
          98,
          63,
          98,
          9,
          100,
          16
        ],
        [
          "op_details",
          76,
          82,
          81,
          7,
          81,
          42,
          80,
          5,
          81,
          42
        ],
        [
          "check_op_histogram",
          94,
          109,
          102,
          9,
          103,
          31,
          102,
          9,
          104,
          14
        ],
        [
          "check_op_histogram",
          94,
          109,
          107,
          7,
          107,
          61,
          106,
          9,
          108,
          12
        ]
      ],
      "models/research/delf/delf/python/training/train.py": [
        [
          "main",
          167,
          554,
          183,
          5,
          183,
          62,
          183,
          5,
          183,
          62
        ],
        [
          "main",
          167,
          554,
          502,
          15,
          502,
          40,
          502,
          15,
          504,
          52
        ],
        [
          "main",
          167,
          554,
          503,
          15,
          503,
          52,
          502,
          15,
          504,
          52
        ],
        [
          "main",
          167,
          554,
          504,
          15,
          504,
          52,
          502,
          15,
          504,
          52
        ],
        [
          "main",
          167,
          554,
          528,
          15,
          528,
          72,
          528,
          15,
          529,
          72
        ],
        [
          "main",
          167,
          554,
          529,
          15,
          529,
          72,
          528,
          15,
          529,
          72
        ]
      ],
      "models/official/projects/simclr/train.py": [
        [
          "main",
          31,
          61,
          33,
          3,
          33,
          25,
          31,
          10,
          37,
          26
        ]
      ],
      "models/official/modeling/fast_training/progressive/train_lib_test.py": [
        [
          "test_end_to_end",
          142,
          179,
          179,
          5,
          179,
          15,
          169,
          5,
          179,
          15
        ]
      ],
      "models/official/projects/lra/transformer_encoder.py": [
        [
          "from_config",
          277,
          288,
          285,
          7,
          285,
          38,
          280,
          11,
          286,
          31
        ]
      ],
      "models/official/projects/waste_identification_ml/data_generation/utils.py": [
        [
          "generate_coco_json",
          259,
          347,
          304,
          7,
          304,
          26,
          303,
          5,
          305,
          14
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "shutdown_system",
          502,
          510,
          505,
          3,
          505,
          53,
          503,
          3,
          508,
          14
        ],
        [
          "shutdown_system",
          502,
          510,
          510,
          5,
          510,
          38,
          509,
          3,
          510,
          38
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "write_data",
          170,
          202,
          196,
          13,
          196,
          77,
          196,
          13,
          196,
          77
        ],
        [
          "write_data",
          170,
          202,
          198,
          13,
          198,
          57,
          198,
          13,
          198,
          57
        ],
        [
          "write_data",
          170,
          202,
          201,
          7,
          201,
          54,
          200,
          5,
          202,
          11
        ],
        [
          "read_data",
          205,
          222,
          221,
          5,
          221,
          53,
          220,
          3,
          222,
          9
        ],
        [
          "read_datasets",
          246,
          277,
          261,
          3,
          261,
          76,
          246,
          19,
          262,
          21
        ],
        [
          "read_datasets",
          246,
          277,
          276,
          3,
          276,
          53,
          276,
          3,
          277,
          21
        ]
      ],
      "models/research/audioset/vggish/vggish_inference_demo.py": [
        [
          "main",
          81,
          150,
          99,
          3,
          99,
          23,
          98,
          20,
          106,
          49
        ],
        [
          "main",
          81,
          150,
          121,
          5,
          121,
          26,
          105,
          12,
          146,
          13
        ],
        [
          "main",
          81,
          150,
          123,
          5,
          123,
          30,
          105,
          12,
          146,
          13
        ],
        [
          "main",
          81,
          150,
          145,
          5,
          145,
          22,
          105,
          12,
          146,
          13
        ]
      ],
      "models/research/audioset/vggish/vggish_train_demo.py": [
        [
          "main",
          128,
          181,
          181,
          7,
          181,
          57,
          176,
          9,
          181,
          57
        ]
      ],
      "models/official/projects/video_ssl/dataloaders/video_ssl_input_test.py": [
        [
          "test_video_ssl_input_linear_eval",
          90,
          105,
          92,
          5,
          92,
          24,
          90,
          40,
          105,
          44
        ]
      ],
      "models/research/delf/delf/python/whiten.py": [
        [
          "cholesky",
          97,
          125,
          124,
          7,
          125,
          72,
          124,
          7,
          125,
          72
        ]
      ],
      "models/official/nlp/data/wmt_dataloader.py": [
        [
          "_tokenize",
          207,
          217,
          216,
          5,
          216,
          27,
          216,
          5,
          217,
          27
        ]
      ],
      "models/official/projects/yolo/modeling/yolo_model.py": [
        [
          "fuse",
          103,
          112,
          105,
          5,
          105,
          43,
          103,
          12,
          106,
          22
        ]
      ]
    },
    "json.dumps": {
      "models/official/projects/waste_identification_ml/docker_solution/prediction_api/app.py": [
        [
          "predict",
          48,
          90,
          81,
          17,
          83,
          5,
          82,
          38,
          83,
          5
        ]
      ],
      "models/official/nlp/finetuning/binary_helper.py": [
        [
          "write_question_answering",
          392,
          417,
          417,
          18,
          417,
          54,
          392,
          30,
          417,
          62
        ]
      ],
      "models/official/legacy/image_classification/classifier_trainer_test.py": [
        [
          "get_params_override",
          59,
          61,
          61,
          33,
          61,
          59,
          59,
          25,
          61,
          59
        ]
      ],
      "models/research/object_detection/utils/colab_utils.py": [
        [
          "draw_bbox",
          51,
          380,
          374,
          16,
          374,
          37,
          374,
          16,
          380,
          8
        ]
      ],
      "models/official/vision/evaluation/coco_utils.py": [
        [
          "generate_annotation_file",
          413,
          432,
          431,
          13,
          431,
          34,
          427,
          16,
          432,
          46
        ]
      ],
      "models/official/legacy/detection/evaluation/coco_utils.py": [
        [
          "generate_annotation_file",
          356,
          372,
          371,
          13,
          371,
          34,
          367,
          16,
          372,
          46
        ]
      ],
      "models/official/legacy/bert/configs.py": [
        [
          "to_json_string",
          102,
          104,
          104,
          12,
          104,
          63,
          102,
          22,
          104,
          70
        ]
      ],
      "models/research/cvt_text/base/configure.py": [
        [
          "write",
          134,
          138,
          137,
          15,
          138,
          48,
          134,
          13,
          138,
          49
        ]
      ],
      "models/official/nlp/data/create_finetuning_data.py": [
        [
          "main",
          407,
          435,
          435,
          18,
          435,
          54,
          433,
          3,
          435,
          62
        ]
      ],
      "models/official/recommendation/create_ncf_data.py": [
        [
          "generate_data",
          97,
          103,
          103,
          18,
          103,
          53,
          98,
          3,
          103,
          61
        ]
      ],
      "models/official/common/distribute_utils.py": [
        [
          "configure_cluster",
          207,
          239,
          228,
          31,
          236,
          6,
          227,
          23,
          228,
          27
        ],
        [
          "configure_cluster",
          207,
          239,
          228,
          31,
          236,
          6,
          227,
          18,
          228,
          27
        ]
      ],
      "models/research/object_detection/utils/json_utils.py": [
        [
          "Dumps",
          45,
          59,
          56,
          14,
          56,
          38,
          45,
          11,
          57,
          22
        ]
      ],
      "models/official/recommendation/uplift/keras_test_case.py": [
        [
          "assertLayerConfigurable",
          150,
          170,
          165,
          52,
          165,
          69,
          165,
          41,
          165,
          70
        ]
      ],
      "models/research/object_detection/metrics/lvis_evaluation.py": [
        [
          "dump_detections_to_json_file",
          446,
          463,
          459,
          23,
          459,
          60,
          453,
          29,
          463,
          39
        ]
      ],
      "models/research/object_detection/model_lib_tf2_test.py": [
        [
          "export",
          251,
          252,
          252,
          7,
          252,
          22,
          251,
          16,
          252,
          22
        ]
      ],
      "models/official/legacy/bert/model_training_utils.py": [
        [
          "write_txt_summary",
          93,
          100,
          100,
          13,
          100,
          50,
          97,
          18,
          100,
          51
        ]
      ],
      "models/official/projects/mobilebert/model_utils.py": [
        [
          "to_json_string",
          132,
          134,
          134,
          12,
          134,
          63,
          132,
          22,
          134,
          70
        ]
      ],
      "models/official/recommendation/ncf_common.py": [
        [
          "get_v1_distribution_strategy",
          105,
          144,
          135,
          31,
          135,
          55,
          115,
          28,
          137,
          16
        ]
      ],
      "models/official/projects/qat/nlp/tasks/question_answering_test.py": [
        [
          "setUp",
          30,
          69,
          65,
          20,
          65,
          49,
          30,
          13,
          69,
          73
        ]
      ],
      "models/official/nlp/tasks/question_answering_test.py": [
        [
          "setUp",
          32,
          71,
          67,
          20,
          67,
          49,
          32,
          13,
          71,
          73
        ],
        [
          "setUp",
          179,
          220,
          216,
          20,
          216,
          49,
          179,
          13,
          220,
          73
        ]
      ],
      "models/official/projects/unified_detector/run_inference.py": [
        [
          "main",
          153,
          217,
          217,
          13,
          217,
          60,
          216,
          8,
          217,
          61
        ]
      ],
      "models/official/legacy/xlnet/squad_utils.py": [
        [
          "write_predictions",
          282,
          431,
          416,
          18,
          416,
          54,
          415,
          8,
          431,
          17
        ],
        [
          "write_predictions",
          282,
          431,
          419,
          18,
          419,
          53,
          415,
          8,
          431,
          17
        ],
        [
          "write_predictions",
          282,
          431,
          422,
          18,
          422,
          55,
          415,
          8,
          431,
          17
        ]
      ],
      "models/official/nlp/data/squad_lib_sp.py": [
        [
          "write_to_json_files",
          838,
          840,
          840,
          18,
          840,
          51,
          838,
          25,
          840,
          59
        ]
      ],
      "models/official/nlp/data/squad_lib.py": [
        [
          "write_to_json_files",
          788,
          790,
          790,
          18,
          790,
          51,
          788,
          25,
          790,
          59
        ]
      ],
      "models/official/core/train_lib_test.py": [
        [
          "test_end_to_end",
          75,
          118,
          81,
          25,
          81,
          53,
          75,
          23,
          96,
          26
        ],
        [
          "test_end_to_end_class",
          129,
          173,
          136,
          25,
          136,
          53,
          129,
          29,
          151,
          26
        ],
        [
          "test_recovery_nan_error",
          184,
          211,
          190,
          25,
          190,
          53,
          184,
          31,
          211,
          38
        ],
        [
          "test_recovery",
          222,
          260,
          229,
          25,
          229,
          53,
          222,
          21,
          259,
          59
        ],
        [
          "test_parse_configuration",
          262,
          276,
          268,
          25,
          268,
          53,
          262,
          32,
          276,
          58
        ]
      ],
      "models/official/projects/volumetric_models/train_test.py": [
        [
          "test_run",
          48,
          98,
          56,
          23,
          88,
          6,
          48,
          16,
          98,
          52
        ]
      ],
      "models/official/projects/movinet/train_test.py": [
        [
          "test_train_and_evaluation_pipeline_runs",
          52,
          94,
          62,
          23,
          85,
          6,
          52,
          47,
          94,
          52
        ]
      ],
      "models/official/recommendation/ranking/train_test.py": [
        [
          "_get_params_override",
          29,
          76,
          43,
          10,
          76,
          4,
          29,
          26,
          76,
          4
        ]
      ],
      "models/official/projects/maxvit/train_test.py": [
        [
          "test_run",
          51,
          99,
          58,
          23,
          91,
          6,
          51,
          16,
          99,
          52
        ]
      ],
      "models/official/projects/yt8m/train_test.py": [
        [
          "test_train_and_eval",
          81,
          147,
          95,
          23,
          137,
          6,
          94,
          25,
          147,
          52
        ]
      ],
      "models/official/projects/assemblenet/train_test.py": [
        [
          "test_run",
          49,
          98,
          58,
          23,
          88,
          6,
          49,
          16,
          98,
          52
        ]
      ],
      "models/official/core/train_utils.py": [
        [
          "export_best_eval_metric",
          216,
          228,
          228,
          20,
          228,
          54,
          216,
          31,
          228,
          62
        ],
        [
          "write_json_summary",
          436,
          448,
          448,
          18,
          448,
          56,
          444,
          17,
          448,
          64
        ]
      ]
    },
    "logging.info": {
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/big_query_ops.py": [
        [
          "create_table",
          46,
          91,
          78,
          7,
          80,
          7,
          79,
          11,
          80,
          7
        ]
      ],
      "models/official/nlp/modeling/layers/block_sparse_attention.py": [
        [
          "_compute_attention",
          240,
          337,
          248,
          7,
          251,
          7,
          248,
          7,
          259,
          7
        ]
      ],
      "models/official/vision/data/create_coco_tf_record.py": [
        [
          "_load_object_annotations",
          364,
          387,
          374,
          3,
          374,
          46,
          364,
          30,
          375,
          50
        ],
        [
          "_load_object_annotations",
          364,
          387,
          385,
          3,
          385,
          73,
          385,
          3,
          387,
          46
        ],
        [
          "_load_caption_annotations",
          390,
          410,
          396,
          3,
          396,
          41,
          390,
          31,
          397,
          54
        ],
        [
          "_load_caption_annotations",
          390,
          410,
          408,
          3,
          408,
          75,
          408,
          3,
          410,
          34
        ],
        [
          "_load_panoptic_annotations",
          413,
          437,
          419,
          3,
          419,
          42,
          413,
          32,
          420,
          55
        ],
        [
          "_load_panoptic_annotations",
          413,
          437,
          434,
          3,
          435,
          78,
          434,
          3,
          437,
          54
        ],
        [
          "_create_tf_record_from_coco_annotations",
          470,
          537,
          502,
          3,
          502,
          57,
          470,
          45,
          511,
          28
        ],
        [
          "_create_tf_record_from_coco_annotations",
          470,
          537,
          537,
          3,
          537,
          72,
          521,
          27,
          537,
          72
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record.py": [
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          400,
          7,
          400,
          80,
          400,
          7,
          401,
          55
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          412,
          5,
          413,
          42,
          412,
          5,
          416,
          32
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          442,
          9,
          442,
          59,
          442,
          9,
          442,
          59
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          466,
          5,
          467,
          47,
          466,
          5,
          473,
          59
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          466,
          5,
          467,
          47,
          466,
          5,
          471,
          33
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          469,
          7,
          470,
          58,
          466,
          5,
          473,
          59
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          469,
          7,
          470,
          58,
          466,
          5,
          471,
          33
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          472,
          7,
          473,
          59,
          466,
          5,
          473,
          59
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pascal_tf_record.py": [
        [
          "main",
          147,
          181,
          163,
          5,
          163,
          57,
          162,
          7,
          168,
          48
        ],
        [
          "main",
          147,
          181,
          170,
          9,
          170,
          66,
          170,
          9,
          170,
          66
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "create_tf_record",
          214,
          265,
          241,
          9,
          241,
          61,
          241,
          9,
          241,
          61
        ],
        [
          "main",
          269,
          314,
          273,
          3,
          273,
          43,
          269,
          10,
          292,
          25
        ],
        [
          "main",
          269,
          314,
          287,
          3,
          288,
          54,
          269,
          10,
          292,
          25
        ]
      ],
      "models/research/object_detection/legacy/evaluator.py": [
        [
          "_process_batch",
          209,
          260,
          238,
          7,
          238,
          36,
          237,
          5,
          240,
          19
        ]
      ],
      "models/research/attention_ocr/python/datasets/fsns.py": [
        [
          "get_split",
          104,
          185,
          129,
          3,
          130,
          39,
          129,
          3,
          185,
          36
        ]
      ],
      "models/official/projects/yolo/ops/kmeans_anchors.py": [
        [
          "read",
          272,
          317,
          315,
          5,
          315,
          62,
          272,
          12,
          317,
          16
        ],
        [
          "read",
          272,
          317,
          316,
          5,
          316,
          23,
          272,
          12,
          317,
          16
        ]
      ],
      "models/research/cognitive_planning/label_map_util.py": [
        [
          "convert_label_map_to_categories",
          73,
          120,
          110,
          7,
          111,
          43,
          110,
          7,
          112,
          14
        ]
      ],
      "models/research/object_detection/utils/label_map_util.py": [
        [
          "convert_label_map_to_categories",
          82,
          156,
          122,
          7,
          124,
          34,
          122,
          7,
          125,
          14
        ]
      ],
      "models/research/attention_ocr/python/model.py": [
        [
          "assign_from_checkpoint",
          729,
          737,
          730,
          7,
          731,
          30,
          729,
          32,
          732,
          22
        ],
        [
          "create_init_fn_to_restore",
          712,
          757,
          739,
          5,
          740,
          53,
          712,
          33,
          745,
          24
        ],
        [
          "create_init_fn_to_restore",
          712,
          757,
          741,
          5,
          742,
          78,
          712,
          33,
          745,
          24
        ],
        [
          "create_init_fn_to_restore",
          712,
          757,
          743,
          5,
          744,
          73,
          712,
          33,
          745,
          24
        ],
        [
          "init_assign_fn",
          753,
          755,
          754,
          7,
          754,
          45,
          753,
          24,
          755,
          45
        ]
      ],
      "models/research/object_detection/utils/object_detection_evaluation.py": [
        [
          "evaluate",
          1366,
          1441,
          1416,
          7,
          1417,
          75,
          1401,
          27,
          1417,
          75
        ]
      ],
      "models/research/object_detection/metrics/oid_challenge_evaluation.py": [
        [
          "main",
          96,
          145,
          128,
          5,
          128,
          57,
          127,
          7,
          140,
          20
        ]
      ],
      "models/research/attention_ocr/python/train.py": [
        [
          "prepare_training_dir",
          156,
          167,
          158,
          5,
          158,
          75,
          158,
          5,
          159,
          45
        ],
        [
          "prepare_training_dir",
          156,
          167,
          162,
          7,
          162,
          74,
          162,
          7,
          164,
          47
        ],
        [
          "prepare_training_dir",
          156,
          167,
          166,
          7,
          167,
          39,
          166,
          7,
          167,
          39
        ],
        [
          "main",
          177,
          205,
          203,
          7,
          204,
          45,
          203,
          7,
          204,
          45
        ]
      ],
      "models/research/object_detection/utils/variables_helper.py": [
        [
          "freeze_gradients_matching_regex",
          99,
          116,
          115,
          5,
          115,
          55,
          114,
          7,
          115,
          55
        ],
        [
          "multiply_gradients_matching_regex",
          77,
          96,
          92,
          5,
          93,
          41,
          91,
          7,
          93,
          41
        ]
      ],
      "models/research/object_detection/utils/visualization_utils_test.py": [
        [
          "test_draw_bounding_boxes_on_image_tensors",
          164,
          206,
          204,
          7,
          204,
          67,
          201,
          9,
          206,
          33
        ],
        [
          "test_draw_bounding_boxes_on_image_tensors_with_track_ids",
          208,
          253,
          251,
          7,
          251,
          67,
          248,
          9,
          253,
          33
        ]
      ]
    },
    "sys.stdout.write": {
      "models/research/deeplab/datasets/build_ade20k_data.py": [
        [
          "_convert_dataset",
          58,
          112,
          94,
          9,
          95,
          41,
          93,
          11,
          105,
          31
        ],
        [
          "_convert_dataset",
          58,
          112,
          111,
          5,
          111,
          26,
          111,
          5,
          112,
          22
        ]
      ],
      "models/research/deeplab/datasets/build_cityscapes_data.py": [
        [
          "_convert_dataset",
          137,
          188,
          168,
          9,
          169,
          41,
          167,
          11,
          177,
          31
        ],
        [
          "_convert_dataset",
          137,
          188,
          187,
          5,
          187,
          26,
          187,
          5,
          188,
          22
        ]
      ],
      "models/research/deeplab/datasets/build_voc2012_data.py": [
        [
          "_convert_dataset",
          89,
          136,
          99,
          3,
          99,
          43,
          89,
          22,
          107,
          36
        ],
        [
          "_convert_dataset",
          89,
          136,
          115,
          9,
          116,
          45,
          114,
          11,
          129,
          31
        ],
        [
          "_convert_dataset",
          89,
          136,
          135,
          5,
          135,
          26,
          135,
          5,
          136,
          22
        ]
      ],
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "_progress",
          118,
          121,
          119,
          5,
          120,
          73,
          118,
          17,
          121,
          22
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "_progress",
          71,
          74,
          72,
          7,
          73,
          65,
          71,
          19,
          74,
          24
        ]
      ],
      "models/research/slim/datasets/download_and_convert_flowers.py": [
        [
          "_convert_dataset",
          109,
          152,
          136,
          13,
          137,
          47,
          135,
          15,
          149,
          62
        ],
        [
          "_convert_dataset",
          109,
          152,
          151,
          3,
          151,
          24,
          151,
          3,
          152,
          20
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_add_to_tfrecord",
          64,
          108,
          94,
          9,
          95,
          59,
          93,
          11,
          106,
          58
        ],
        [
          "_progress",
          134,
          137,
          135,
          7,
          136,
          75,
          134,
          19,
          137,
          24
        ]
      ],
      "models/research/slim/datasets/download_and_convert_mnist.py": [
        [
          "_add_to_tfrecord",
          102,
          129,
          122,
          9,
          122,
          77,
          121,
          11,
          129,
          58
        ],
        [
          "_progress",
          159,
          162,
          160,
          9,
          161,
          67,
          159,
          21,
          162,
          26
        ]
      ],
      "models/research/cvt_text/base/utils.py": [
        [
          "log",
          58,
          61,
          60,
          3,
          60,
          30,
          58,
          10,
          61,
          20
        ]
      ]
    },
    "re.sub": {
      "models/official/projects/videoglue/tools/checkpoint_loader.py": [
        [
          "_remap_variable_name",
          110,
          116,
          115,
          23,
          115,
          57,
          114,
          9,
          115,
          19
        ]
      ],
      "models/research/cvt_text/base/embeddings.py": [
        [
          "normalize_word",
          166,
          167,
          167,
          10,
          167,
          55,
          166,
          20,
          167,
          55
        ]
      ],
      "models/official/projects/triviaqa/evaluation.py": [
        [
          "remove_articles",
          30,
          31,
          31,
          12,
          31,
          47,
          30,
          23,
          31,
          47
        ]
      ],
      "models/research/object_detection/utils/json_utils.py": [
        [
          "FormatFloat",
          24,
          29,
          29,
          10,
          29,
          42,
          24,
          17,
          29,
          42
        ]
      ],
      "models/research/object_detection/metrics/lvis_evaluation.py": [
        [
          "dump_detections_to_json_file",
          446,
          463,
          460,
          19,
          460,
          54,
          453,
          29,
          463,
          39
        ]
      ],
      "models/research/object_detection/metrics/offline_eval_map_corloc.py": [
        [
          "listcomp",
          61,
          62,
          62,
          9,
          62,
          73,
          63,
          13,
          62,
          73
        ]
      ],
      "models/official/nlp/tools/squad_evaluate_v1_1.py": [
        [
          "remove_articles",
          39,
          40,
          40,
          12,
          40,
          47,
          39,
          23,
          40,
          47
        ]
      ],
      "models/official/nlp/tools/squad_evaluate_v2_0.py": [
        [
          "remove_articles",
          44,
          46,
          46,
          12,
          46,
          35,
          44,
          23,
          46,
          35
        ]
      ],
      "models/official/legacy/xlnet/squad_utils.py": [
        [
          "remove_articles",
          113,
          115,
          115,
          12,
          115,
          35,
          113,
          23,
          115,
          35
        ]
      ]
    },
    "str.replace": {
      "models/research/object_detection/utils/colab_utils.py": [
        [
          "annotate",
          383,
          479,
          409,
          18,
          409,
          51,
          409,
          18,
          409,
          14
        ]
      ],
      "models/official/core/train_utils.py": [
        [
          "_einsum_flops",
          573,
          610,
          586,
          7,
          586,
          32,
          575,
          3,
          597,
          29
        ]
      ]
    },
    "logging.warning": {
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "create_tf_record",
          214,
          265,
          246,
          9,
          246,
          73,
          246,
          9,
          247,
          16
        ],
        [
          "create_tf_record",
          214,
          265,
          265,
          9,
          265,
          67,
          264,
          7,
          265,
          67
        ]
      ],
      "models/official/projects/yt8m/eval_utils/eval_util.py": [
        [
          "calculate_precision_at_equal_recall_rate",
          47,
          74,
          62,
          5,
          62,
          75,
          62,
          5,
          63,
          31
        ]
      ],
      "models/research/object_detection/legacy/evaluator.py": [
        [
          "get_evaluators",
          140,
          171,
          160,
          7,
          163,
          7,
          160,
          7,
          164,
          55
        ],
        [
          "get_evaluators",
          140,
          171,
          165,
          7,
          168,
          7,
          165,
          7,
          168,
          7
        ]
      ],
      "models/research/attention_ocr/python/datasets/fsns.py": [
        [
          "read_charset",
          59,
          86,
          79,
          9,
          79,
          72,
          79,
          9,
          80,
          16
        ]
      ],
      "models/research/attention_ocr/python/model.py": [
        [
          "_create_lstm_inputs",
          348,
          371,
          367,
          7,
          368,
          77,
          367,
          7,
          369,
          9
        ]
      ],
      "models/research/object_detection/utils/object_detection_evaluation.py": [
        [
          "merge_internal_state",
          246,
          260,
          257,
          9,
          257,
          68,
          257,
          9,
          257,
          68
        ],
        [
          "add_single_ground_truth_image_info",
          301,
          359,
          325,
          7,
          325,
          66,
          325,
          7,
          325,
          66
        ],
        [
          "add_single_ground_truth_image_info",
          301,
          359,
          342,
          9,
          344,
          21,
          342,
          9,
          344,
          21
        ],
        [
          "add_single_ground_truth_image_info",
          791,
          844,
          811,
          7,
          811,
          66,
          811,
          7,
          811,
          66
        ],
        [
          "add_single_ground_truth_image_info",
          791,
          844,
          828,
          9,
          830,
          21,
          828,
          9,
          830,
          21
        ],
        [
          "add_single_ground_truth_image_info",
          920,
          957,
          953,
          7,
          954,
          31,
          953,
          7,
          954,
          31
        ],
        [
          "add_single_ground_truth_image_info",
          1199,
          1256,
          1226,
          7,
          1228,
          20,
          1226,
          7,
          1229,
          12
        ],
        [
          "add_single_detected_image_info",
          1258,
          1333,
          1292,
          7,
          1294,
          20,
          1292,
          7,
          1295,
          12
        ],
        [
          "evaluate",
          1366,
          1441,
          1381,
          7,
          1384,
          31,
          1381,
          7,
          1384,
          31
        ]
      ],
      "models/research/object_detection/utils/variables_helper.py": [
        [
          "get_variables_available_in_checkpoint",
          119,
          173,
          162,
          9,
          167,
          49,
          162,
          9,
          167,
          49
        ],
        [
          "get_variables_available_in_checkpoint",
          119,
          173,
          169,
          7,
          170,
          36,
          169,
          7,
          170,
          36
        ]
      ],
      "models/research/object_detection/utils/vrd_evaluation.py": [
        [
          "add_single_detected_image_info",
          169,
          218,
          188,
          7,
          188,
          75,
          188,
          7,
          193,
          40
        ],
        [
          "add_single_ground_truth_image_info",
          453,
          476,
          468,
          7,
          470,
          20,
          468,
          7,
          471,
          12
        ],
        [
          "evaluate",
          531,
          588,
          545,
          7,
          545,
          50,
          545,
          7,
          545,
          50
        ]
      ]
    },
    "logging.getLogger": {
      "models/research/object_detection/metrics/lvis_tools.py": [
        [
          "__init__",
          80,
          99,
          96,
          19,
          96,
          45,
          80,
          16,
          99,
          24
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "create_log_file",
          211,
          228,
          222,
          12,
          222,
          34,
          211,
          21,
          228,
          15
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "create_log_file",
          55,
          72,
          66,
          12,
          66,
          40,
          55,
          21,
          72,
          15
        ]
      ]
    },
    "logging.debug": {
      "models/research/attention_ocr/python/model.py": [
        [
          "conv_tower_fn",
          322,
          346,
          337,
          5,
          337,
          68,
          322,
          21,
          339,
          14
        ],
        [
          "create_base",
          480,
          554,
          499,
          5,
          499,
          39,
          480,
          19,
          528,
          22
        ],
        [
          "create_base",
          480,
          554,
          509,
          7,
          509,
          69,
          480,
          19,
          528,
          22
        ],
        [
          "create_base",
          480,
          554,
          515,
          7,
          515,
          46,
          480,
          19,
          528,
          22
        ],
        [
          "create_base",
          480,
          554,
          518,
          7,
          518,
          69,
          480,
          19,
          528,
          22
        ],
        [
          "create_base",
          480,
          554,
          521,
          7,
          521,
          44,
          480,
          19,
          528,
          22
        ],
        [
          "create_base",
          480,
          554,
          524,
          7,
          524,
          51,
          480,
          19,
          528,
          22
        ]
      ],
      "models/research/attention_ocr/python/sequence_layers.py": [
        [
          "get_image_feature",
          280,
          299,
          298,
          5,
          298,
          47,
          280,
          25,
          299,
          18
        ],
        [
          "get_layer_class",
          400,
          422,
          421,
          3,
          421,
          64,
          421,
          3,
          422,
          20
        ]
      ]
    },
    "logging.error": {
      "models/research/attention_ocr/python/model.py": [
        [
          "assign_from_checkpoint",
          729,
          737,
          733,
          9,
          733,
          62,
          733,
          9,
          734,
          19
        ]
      ]
    },
    "warnings.warn": {
      "models/official/modeling/privacy/ops.py": [
        [
          "clip_l2_norm",
          23,
          43,
          34,
          3,
          35,
          35,
          23,
          18,
          39,
          26
        ],
        [
          "add_noise",
          46,
          63,
          57,
          3,
          57,
          62,
          46,
          15,
          60,
          26
        ]
      ],
      "models/research/object_detection/models/keras_models/base_models/original_mobilenet_v2.py": [
        [
          "_obtain_input_shape",
          112,
          191,
          138,
          9,
          141,
          53,
          138,
          9,
          141,
          53
        ],
        [
          "_obtain_input_shape",
          112,
          191,
          145,
          9,
          148,
          54,
          145,
          9,
          148,
          54
        ],
        [
          "mobilenet_v2",
          228,
          404,
          307,
          5,
          315,
          63,
          307,
          5,
          378,
          16
        ]
      ],
      "models/official/legacy/xlnet/xlnet_modeling.py": [
        [
          "__init__",
          366,
          442,
          419,
          5,
          421,
          41,
          366,
          16,
          442,
          21
        ],
        [
          "__init__",
          836,
          880,
          839,
          5,
          841,
          53,
          836,
          16,
          879,
          22
        ],
        [
          "__init__",
          1090,
          1128,
          1093,
          5,
          1095,
          41,
          1090,
          16,
          1122,
          22
        ]
      ]
    },
    "logging.FileHandler": {
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "create_log_file",
          211,
          228,
          224,
          18,
          224,
          51,
          211,
          21,
          228,
          15
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "create_log_file",
          55,
          72,
          68,
          18,
          68,
          51,
          55,
          21,
          72,
          15
        ]
      ]
    },
    "logging.Formatter": {
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "create_log_file",
          211,
          228,
          225,
          15,
          225,
          76,
          211,
          21,
          228,
          15
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "create_log_file",
          55,
          72,
          69,
          15,
          69,
          76,
          55,
          21,
          72,
          15
        ]
      ]
    }
  },
  "CWE-326": {},
  "CWE-327": {
    "hashlib.sha256": {
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_generate_examples",
          296,
          449,
          400,
          17,
          400,
          41,
          400,
          17,
          447,
          71
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py": [
        [
          "process",
          80,
          225,
          117,
          11,
          117,
          37,
          112,
          7,
          146,
          18
        ]
      ],
      "models/research/object_detection/dataset_tools/create_kitti_tf_record.py": [
        [
          "prepare_example",
          138,
          205,
          156,
          9,
          156,
          35,
          138,
          21,
          205,
          16
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record.py": [
        [
          "create_tf_example",
          112,
          359,
          176,
          9,
          176,
          35,
          112,
          23,
          206,
          44
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pascal_tf_record.py": [
        [
          "dict_to_tf_example",
          59,
          144,
          93,
          9,
          93,
          35,
          93,
          9,
          107,
          21
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "dict_to_tf_example",
          76,
          211,
          115,
          9,
          115,
          35,
          115,
          9,
          121,
          25
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords_lib.py": [
        [
          "_create_tf_example",
          217,
          287,
          247,
          9,
          247,
          35,
          217,
          24,
          250,
          35
        ]
      ],
      "models/official/vision/data/tfrecord_lib.py": [
        [
          "image_info_to_feature_dict",
          89,
          103,
          93,
          9,
          93,
          35,
          89,
          32,
          103,
          3
        ]
      ]
    },
    "hashlib.md5": {
      "models/official/recommendation/data_test.py": [
        [
          "_test_end_to_end",
          135,
          257,
          167,
          11,
          167,
          23,
          146,
          5,
          168,
          39
        ],
        [
          "_test_end_to_end",
          135,
          257,
          218,
          11,
          218,
          23,
          193,
          5,
          219,
          29
        ],
        [
          "_test_fresh_randomness",
          259,
          344,
          283,
          11,
          283,
          23,
          280,
          5,
          284,
          35
        ]
      ]
    },
    "hashlib.sha1": {
      "models/official/nlp/tools/export_tfhub_lib.py": [
        [
          "_move_to_tmpdir",
          392,
          403,
          397,
          12,
          397,
          25,
          396,
          22,
          403,
          20
        ]
      ]
    },
    "hashlib.blake2s": {
      "models/official/vision/data/tf_example_builder.py": [
        [
          "add_encoded_image_feature",
          83,
          154,
          142,
          26,
          142,
          55,
          142,
          22,
          143,
          21
        ]
      ]
    }
  },
  "CWE-329": {
    "numpy.random.randint": {
      "models/official/nlp/modeling/networks/albert_encoder_test.py": [
        [
          "test_network_invocation",
          74,
          140,
          100,
          20,
          101,
          55,
          74,
          31,
          140,
          61
        ],
        [
          "test_network_invocation",
          74,
          140,
          102,
          17,
          102,
          72,
          74,
          31,
          140,
          61
        ],
        [
          "test_network_invocation",
          74,
          140,
          103,
          20,
          104,
          54,
          74,
          31,
          140,
          61
        ]
      ],
      "models/official/nlp/modeling/layers/attention_test.py": [
        [
          "test_masked_attention",
          36,
          63,
          52,
          17,
          53,
          63,
          36,
          29,
          63,
          28
        ],
        [
          "test_padded_decode",
          65,
          90,
          80,
          17,
          81,
          79,
          65,
          26,
          90,
          56
        ]
      ],
      "models/research/autoaugment/augmentation_transforms.py": [
        [
          "zero_pad_and_crop",
          43,
          61,
          58,
          9,
          58,
          49,
          43,
          23,
          61,
          16
        ],
        [
          "zero_pad_and_crop",
          43,
          61,
          59,
          10,
          59,
          50,
          43,
          23,
          61,
          16
        ],
        [
          "create_cutout_mask",
          64,
          99,
          83,
          16,
          83,
          56,
          80,
          3,
          92,
          24
        ],
        [
          "create_cutout_mask",
          64,
          99,
          84,
          15,
          84,
          54,
          80,
          3,
          92,
          24
        ]
      ],
      "models/official/nlp/modeling/networks/bert_dense_encoder_test.py": [
        [
          "test_dict_outputs_network_invocation",
          180,
          310,
          226,
          20,
          227,
          55,
          181,
          7,
          310,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          180,
          310,
          228,
          17,
          228,
          72,
          181,
          7,
          310,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          180,
          310,
          229,
          20,
          230,
          54,
          181,
          7,
          310,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          180,
          310,
          234,
          23,
          235,
          52,
          181,
          7,
          310,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          180,
          310,
          236,
          27,
          237,
          60,
          181,
          7,
          310,
          67
        ]
      ],
      "models/official/nlp/modeling/networks/bert_encoder_test.py": [
        [
          "test_dict_outputs_network_invocation",
          212,
          285,
          242,
          20,
          243,
          55,
          213,
          7,
          285,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          212,
          285,
          244,
          17,
          244,
          72,
          213,
          7,
          285,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          212,
          285,
          245,
          20,
          246,
          54,
          213,
          7,
          285,
          67
        ],
        [
          "test_network_creation",
          377,
          432,
          420,
          20,
          421,
          55,
          377,
          29,
          432,
          71
        ],
        [
          "test_network_creation",
          377,
          432,
          422,
          17,
          422,
          72,
          377,
          29,
          432,
          71
        ],
        [
          "test_network_creation",
          377,
          432,
          423,
          20,
          424,
          54,
          377,
          29,
          432,
          71
        ],
        [
          "test_network_invocation",
          519,
          579,
          544,
          20,
          545,
          55,
          519,
          31,
          579,
          67
        ],
        [
          "test_network_invocation",
          519,
          579,
          546,
          17,
          546,
          72,
          519,
          31,
          579,
          67
        ],
        [
          "test_network_invocation",
          519,
          579,
          547,
          20,
          548,
          54,
          519,
          31,
          579,
          67
        ],
        [
          "test_weights_forward_compatible",
          588,
          645,
          603,
          20,
          604,
          55,
          588,
          39,
          628,
          48
        ],
        [
          "test_weights_forward_compatible",
          588,
          645,
          605,
          17,
          605,
          72,
          588,
          39,
          628,
          48
        ],
        [
          "test_weights_forward_compatible",
          588,
          645,
          606,
          20,
          607,
          54,
          588,
          39,
          628,
          48
        ],
        [
          "test_checkpoint_forward_compatible",
          647,
          687,
          662,
          20,
          663,
          55,
          647,
          42,
          686,
          30
        ],
        [
          "test_checkpoint_forward_compatible",
          647,
          687,
          664,
          17,
          664,
          72,
          647,
          42,
          686,
          30
        ],
        [
          "test_checkpoint_forward_compatible",
          647,
          687,
          665,
          20,
          666,
          54,
          647,
          42,
          686,
          30
        ],
        [
          "test_keras_model_checkpoint_forward_compatible",
          689,
          736,
          705,
          20,
          706,
          55,
          689,
          54,
          735,
          32
        ],
        [
          "test_keras_model_checkpoint_forward_compatible",
          689,
          736,
          707,
          17,
          707,
          72,
          689,
          54,
          735,
          32
        ],
        [
          "test_keras_model_checkpoint_forward_compatible",
          689,
          736,
          708,
          20,
          709,
          54,
          689,
          54,
          735,
          32
        ]
      ],
      "models/official/nlp/modeling/layers/block_sparse_attention_test.py": [
        [
          "test_masked_attention",
          100,
          172,
          138,
          17,
          138,
          61,
          117,
          24,
          167,
          15
        ],
        [
          "test_default_masked_attention",
          178,
          243,
          213,
          17,
          213,
          73,
          188,
          18,
          243,
          67
        ],
        [
          "test_masked_attention_with_scores",
          245,
          295,
          266,
          17,
          266,
          61,
          245,
          41,
          295,
          56
        ]
      ],
      "models/official/projects/detr/dataloaders/coco_test.py": [
        [
          "_gen_fn",
          25,
          40,
          26,
          7,
          26,
          31,
          26,
          7,
          40,
          3
        ],
        [
          "_gen_fn",
          25,
          40,
          27,
          7,
          27,
          31,
          26,
          7,
          40,
          3
        ],
        [
          "_gen_fn",
          25,
          40,
          28,
          15,
          28,
          38,
          26,
          7,
          40,
          3
        ],
        [
          "_gen_fn",
          25,
          40,
          31,
          19,
          31,
          43,
          26,
          7,
          40,
          3
        ]
      ],
      "models/official/vision/evaluation/coco_utils_test.py": [
        [
          "test_convert_keypoint_predictions_to_coco_annotations",
          52,
          91,
          63,
          9,
          63,
          65,
          52,
          61,
          81,
          38
        ]
      ],
      "models/official/projects/fffner/utils/convert_checkpoint_huggingface.py": [
        [
          "convert_checkpoint",
          125,
          152,
          135,
          18,
          136,
          61,
          125,
          24,
          152,
          57
        ],
        [
          "convert_checkpoint",
          125,
          152,
          137,
          15,
          138,
          60,
          125,
          24,
          152,
          57
        ],
        [
          "convert_checkpoint",
          125,
          152,
          139,
          18,
          140,
          60,
          125,
          24,
          152,
          57
        ]
      ],
      "models/official/projects/fffner/utils/convert_checkpoint_tensorflow.py": [
        [
          "convert_checkpoint",
          141,
          168,
          151,
          18,
          152,
          61,
          141,
          24,
          168,
          57
        ],
        [
          "convert_checkpoint",
          141,
          168,
          153,
          15,
          154,
          60,
          141,
          24,
          168,
          57
        ],
        [
          "convert_checkpoint",
          141,
          168,
          155,
          18,
          156,
          60,
          141,
          24,
          168,
          57
        ]
      ],
      "models/official/projects/longformer/utils/convert_pretrained_pytorch_checkpoint_to_tf.py": [
        [
          "convert_checkpoint",
          170,
          192,
          179,
          18,
          180,
          61,
          170,
          24,
          192,
          57
        ],
        [
          "convert_checkpoint",
          170,
          192,
          181,
          15,
          182,
          60,
          170,
          24,
          192,
          57
        ],
        [
          "convert_checkpoint",
          170,
          192,
          183,
          18,
          184,
          60,
          170,
          24,
          192,
          57
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py": [
        [
          "_write_random_images_to_directory",
          46,
          53,
          48,
          13,
          50,
          45,
          47,
          9,
          53,
          60
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record_test.py": [
        [
          "test_create_tf_example_with_keypoints",
          206,
          311,
          209,
          18,
          209,
          71,
          206,
          45,
          229,
          22
        ],
        [
          "test_create_tf_example_with_keypoints",
          206,
          311,
          232,
          13,
          232,
          35,
          229,
          9,
          237,
          27
        ],
        [
          "test_create_tf_example_with_dense_pose",
          313,
          437,
          316,
          18,
          316,
          71,
          313,
          46,
          336,
          22
        ],
        [
          "test_create_tf_example_with_dense_pose",
          313,
          437,
          339,
          13,
          339,
          35,
          336,
          9,
          344,
          27
        ],
        [
          "test_create_tf_example_with_dense_pose",
          313,
          437,
          356,
          12,
          356,
          50,
          347,
          9,
          437,
          22
        ]
      ],
      "models/research/attention_ocr/python/data_provider_test.py": [
        [
          "test_preprocessed_image_values_are_in_range",
          30,
          41,
          32,
          18,
          32,
          69,
          30,
          51,
          40,
          38
        ]
      ],
      "models/official/recommendation/data_test.py": [
        [
          "setUp",
          59,
          95,
          75,
          14,
          75,
          59,
          59,
          13,
          83,
          63
        ],
        [
          "setUp",
          59,
          95,
          76,
          13,
          76,
          76,
          59,
          13,
          83,
          63
        ]
      ],
      "models/research/object_detection/builders/dataset_builder_test.py": [
        [
          "dummy_jpeg_fn",
          63,
          71,
          64,
          22,
          64,
          59,
          64,
          22,
          71,
          59
        ],
        [
          "dummy_jpeg_fn",
          63,
          71,
          65,
          36,
          66,
          30,
          64,
          22,
          71,
          59
        ]
      ],
      "models/research/object_detection/builders/decoder_builder_test.py": [
        [
          "_make_serialized_tf_example",
          43,
          75,
          44,
          23,
          44,
          60,
          43,
          35,
          70,
          30
        ],
        [
          "_make_serialized_tf_example",
          43,
          75,
          45,
          37,
          46,
          28,
          43,
          35,
          70,
          30
        ]
      ],
      "models/official/projects/pointpillars/dataloaders/decoders_test.py": [
        [
          "_mock_serialized_example",
          26,
          58,
          28,
          14,
          28,
          53,
          26,
          30,
          58,
          27
        ],
        [
          "_mock_serialized_example",
          26,
          58,
          31,
          13,
          31,
          75,
          26,
          30,
          58,
          27
        ],
        [
          "_mock_serialized_example",
          26,
          58,
          32,
          13,
          32,
          70,
          26,
          30,
          58,
          27
        ],
        [
          "_mock_serialized_example",
          26,
          58,
          40,
          16,
          40,
          73,
          26,
          30,
          58,
          27
        ]
      ],
      "models/official/projects/detr/tasks/detection_test.py": [
        [
          "_gen_fn",
          31,
          46,
          32,
          7,
          32,
          31,
          32,
          7,
          46,
          3
        ],
        [
          "_gen_fn",
          31,
          46,
          33,
          7,
          33,
          31,
          32,
          7,
          46,
          3
        ],
        [
          "_gen_fn",
          31,
          46,
          34,
          15,
          34,
          38,
          32,
          7,
          46,
          3
        ],
        [
          "_gen_fn",
          31,
          46,
          37,
          19,
          37,
          43,
          32,
          7,
          46,
          3
        ]
      ],
      "models/official/projects/edgetpu/nlp/modeling/edgetpu_layers_test.py": [
        [
          "test_masked_attention",
          75,
          123,
          95,
          17,
          95,
          61,
          75,
          29,
          118,
          15
        ],
        [
          "test_masked_attention_with_scores",
          136,
          179,
          156,
          17,
          156,
          61,
          136,
          41,
          179,
          56
        ],
        [
          "test_high_dim_attention",
          189,
          217,
          203,
          17,
          203,
          53,
          189,
          31,
          217,
          54
        ]
      ],
      "models/official/projects/token_dropping/encoder_test.py": [
        [
          "test_dict_outputs_network_invocation",
          135,
          217,
          168,
          20,
          169,
          55,
          136,
          7,
          217,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          135,
          217,
          170,
          17,
          170,
          72,
          136,
          7,
          217,
          67
        ],
        [
          "test_dict_outputs_network_invocation",
          135,
          217,
          171,
          20,
          172,
          54,
          136,
          7,
          217,
          67
        ],
        [
          "test_network_invocation",
          335,
          413,
          366,
          20,
          367,
          55,
          335,
          31,
          413,
          67
        ],
        [
          "test_network_invocation",
          335,
          413,
          368,
          17,
          368,
          72,
          335,
          31,
          413,
          67
        ],
        [
          "test_network_invocation",
          335,
          413,
          369,
          20,
          370,
          54,
          335,
          31,
          413,
          67
        ],
        [
          "test_checkpoint_forward_compatible",
          422,
          465,
          438,
          20,
          439,
          55,
          422,
          42,
          464,
          30
        ],
        [
          "test_checkpoint_forward_compatible",
          422,
          465,
          440,
          17,
          440,
          72,
          422,
          42,
          464,
          30
        ],
        [
          "test_checkpoint_forward_compatible",
          422,
          465,
          441,
          20,
          442,
          54,
          422,
          42,
          464,
          30
        ],
        [
          "test_keras_model_checkpoint_forward_compatible",
          467,
          515,
          483,
          20,
          484,
          55,
          467,
          54,
          514,
          32
        ],
        [
          "test_keras_model_checkpoint_forward_compatible",
          467,
          515,
          485,
          17,
          485,
          72,
          467,
          54,
          514,
          32
        ],
        [
          "test_keras_model_checkpoint_forward_compatible",
          467,
          515,
          486,
          20,
          487,
          54,
          467,
          54,
          514,
          32
        ]
      ],
      "models/official/projects/bigbird/encoder_test.py": [
        [
          "test_encoder",
          25,
          37,
          31,
          20,
          32,
          55,
          25,
          20,
          37,
          56
        ],
        [
          "test_encoder",
          25,
          37,
          33,
          17,
          33,
          72,
          25,
          20,
          37,
          56
        ],
        [
          "test_encoder",
          25,
          37,
          34,
          20,
          34,
          75,
          25,
          20,
          37,
          56
        ],
        [
          "test_save_restore",
          39,
          59,
          45,
          20,
          46,
          55,
          39,
          25,
          59,
          55
        ],
        [
          "test_save_restore",
          39,
          59,
          47,
          17,
          47,
          72,
          39,
          25,
          59,
          55
        ],
        [
          "test_save_restore",
          39,
          59,
          48,
          20,
          48,
          75,
          39,
          25,
          59,
          55
        ]
      ],
      "models/official/nlp/modeling/networks/encoder_scaffold_test.py": [
        [
          "test_network_invocation",
          219,
          312,
          269,
          20,
          270,
          55,
          219,
          31,
          312,
          5
        ],
        [
          "test_network_invocation",
          219,
          312,
          271,
          17,
          271,
          72,
          219,
          31,
          312,
          5
        ],
        [
          "test_network_invocation",
          219,
          312,
          272,
          20,
          273,
          54,
          219,
          31,
          312,
          5
        ],
        [
          "test_network_invocation",
          385,
          433,
          430,
          20,
          431,
          55,
          385,
          31,
          433,
          5
        ],
        [
          "test_network_invocation",
          385,
          433,
          432,
          17,
          432,
          72,
          385,
          31,
          433,
          5
        ],
        [
          "test_serialize_deserialize",
          435,
          520,
          508,
          20,
          509,
          55,
          435,
          34,
          520,
          39
        ],
        [
          "test_serialize_deserialize",
          435,
          520,
          510,
          17,
          510,
          72,
          435,
          34,
          520,
          39
        ],
        [
          "test_network_invocation",
          526,
          600,
          590,
          20,
          591,
          55,
          526,
          31,
          600,
          80
        ],
        [
          "test_network_invocation",
          526,
          600,
          592,
          17,
          592,
          72,
          526,
          31,
          600,
          80
        ],
        [
          "test_network_invocation",
          526,
          600,
          593,
          20,
          594,
          54,
          526,
          31,
          600,
          80
        ],
        [
          "test_hidden_cls_list",
          602,
          692,
          680,
          20,
          681,
          55,
          602,
          28,
          692,
          46
        ],
        [
          "test_hidden_cls_list",
          602,
          692,
          682,
          17,
          682,
          72,
          602,
          28,
          692,
          46
        ],
        [
          "test_serialize_deserialize",
          695,
          791,
          780,
          20,
          781,
          55,
          755,
          19,
          791,
          37
        ],
        [
          "test_serialize_deserialize",
          695,
          791,
          782,
          17,
          782,
          72,
          755,
          19,
          791,
          37
        ],
        [
          "test_serialize_deserialize",
          695,
          791,
          783,
          20,
          784,
          54,
          755,
          19,
          791,
          37
        ]
      ],
      "models/official/projects/yt8m/eval_utils/eval_util_test.py": [
        [
          "setUp",
          26,
          45,
          34,
          51,
          35,
          37,
          26,
          13,
          40,
          20
        ]
      ],
      "models/official/nlp/modeling/layers/factorized_embedding_test.py": [
        [
          "test_layer_invocation",
          44,
          66,
          63,
          18,
          64,
          55,
          44,
          29,
          66,
          46
        ]
      ],
      "models/official/projects/fffner/fffner_encoder_test.py": [
        [
          "test_encoder",
          30,
          64,
          42,
          20,
          43,
          71,
          30,
          20,
          64,
          51
        ],
        [
          "test_encoder",
          30,
          64,
          44,
          17,
          45,
          62,
          30,
          20,
          64,
          51
        ],
        [
          "test_encoder",
          30,
          64,
          46,
          20,
          47,
          62,
          30,
          20,
          64,
          51
        ],
        [
          "test_encoder",
          30,
          64,
          48,
          27,
          49,
          60,
          30,
          20,
          64,
          51
        ],
        [
          "test_encoder",
          30,
          64,
          50,
          29,
          51,
          60,
          30,
          20,
          64,
          51
        ]
      ],
      "models/official/nlp/modeling/networks/funnel_transformer_test.py": [
        [
          "test_serialize_deserialize",
          376,
          428,
          420,
          20,
          421,
          55,
          376,
          34,
          428,
          5
        ],
        [
          "test_serialize_deserialize",
          376,
          428,
          422,
          17,
          422,
          72,
          376,
          34,
          428,
          5
        ],
        [
          "test_serialize_deserialize",
          376,
          428,
          423,
          20,
          424,
          54,
          376,
          34,
          428,
          5
        ],
        [
          "test_network_invocation",
          256,
          337,
          292,
          20,
          293,
          55,
          257,
          7,
          317,
          30
        ],
        [
          "test_network_invocation",
          256,
          337,
          294,
          17,
          294,
          72,
          257,
          7,
          317,
          30
        ],
        [
          "test_network_invocation",
          256,
          337,
          295,
          20,
          296,
          54,
          257,
          7,
          317,
          30
        ]
      ],
      "models/official/projects/mae/tasks/image_classification_test.py": [
        [
          "_gen_fn",
          29,
          36,
          30,
          7,
          30,
          31,
          30,
          7,
          36,
          3
        ],
        [
          "_gen_fn",
          29,
          36,
          31,
          7,
          31,
          31,
          30,
          7,
          36,
          3
        ],
        [
          "_gen_fn",
          29,
          36,
          34,
          16,
          34,
          40,
          30,
          7,
          36,
          3
        ]
      ],
      "models/research/object_detection/builders/input_reader_builder_tf1_test.py": [
        [
          "create_tf_record",
          43,
          66,
          47,
          20,
          47,
          57,
          43,
          24,
          66,
          15
        ],
        [
          "create_tf_record_with_context",
          118,
          158,
          122,
          20,
          122,
          57,
          118,
          37,
          158,
          15
        ]
      ],
      "models/research/object_detection/inputs_test.py": [
        [
          "test_applies_model_preprocess_fn_to_image_tensor",
          1196,
          1219,
          1197,
          16,
          1197,
          53,
          1196,
          56,
          1219,
          52
        ],
        [
          "test_applies_data_augmentation_fn_to_tensor_dict",
          1221,
          1247,
          1222,
          16,
          1222,
          53,
          1221,
          56,
          1247,
          37
        ],
        [
          "test_applies_data_augmentation_fn_before_model_preprocess_fn",
          1249,
          1275,
          1250,
          16,
          1250,
          53,
          1249,
          68,
          1275,
          50
        ]
      ],
      "models/official/projects/mae/tasks/linear_probe_test.py": [
        [
          "_gen_fn",
          29,
          36,
          30,
          7,
          30,
          31,
          30,
          7,
          36,
          3
        ],
        [
          "_gen_fn",
          29,
          36,
          31,
          7,
          31,
          31,
          30,
          7,
          36,
          3
        ],
        [
          "_gen_fn",
          29,
          36,
          34,
          16,
          34,
          40,
          30,
          7,
          36,
          3
        ]
      ],
      "models/official/projects/longformer/longformer_encoder_test.py": [
        [
          "test_encoder",
          35,
          61,
          48,
          20,
          49,
          71,
          35,
          20,
          61,
          64
        ],
        [
          "test_encoder",
          35,
          61,
          50,
          17,
          51,
          62,
          35,
          20,
          61,
          64
        ],
        [
          "test_encoder",
          35,
          61,
          52,
          20,
          53,
          62,
          35,
          20,
          61,
          64
        ],
        [
          "test_norm_first",
          66,
          93,
          80,
          20,
          81,
          71,
          66,
          23,
          93,
          64
        ],
        [
          "test_norm_first",
          66,
          93,
          82,
          17,
          83,
          62,
          66,
          23,
          93,
          64
        ],
        [
          "test_norm_first",
          66,
          93,
          84,
          20,
          85,
          62,
          66,
          23,
          93,
          64
        ]
      ],
      "models/official/projects/longformer/longformer_attention_test.py": [
        [
          "_create_mock_attention_data",
          24,
          61,
          57,
          17,
          57,
          53,
          56,
          19,
          59,
          26
        ]
      ],
      "models/research/lfads/lfads.py": [
        [
          "shuffle_spikes_in_time",
          1143,
          1189,
          1176,
          32,
          1176,
          68,
          1169,
          9,
          1186,
          53
        ]
      ],
      "models/official/vision/ops/mask_ops_test.py": [
        [
          "testPasteInstanceMasks",
          24,
          33,
          29,
          13,
          29,
          67,
          24,
          30,
          32,
          5
        ],
        [
          "testPasteInstanceMasksV2",
          35,
          49,
          40,
          13,
          40,
          67,
          35,
          32,
          49,
          13
        ]
      ],
      "models/official/projects/mae/tasks/masked_ae_test.py": [
        [
          "_gen_fn",
          30,
          38,
          32,
          7,
          32,
          31,
          31,
          3,
          38,
          3
        ],
        [
          "_gen_fn",
          30,
          38,
          33,
          7,
          33,
          31,
          31,
          3,
          38,
          3
        ],
        [
          "_gen_fn",
          30,
          38,
          36,
          16,
          36,
          40,
          31,
          3,
          38,
          3
        ]
      ],
      "models/official/nlp/modeling/layers/masked_lm_test.py": [
        [
          "test_layer_invocation_with_external_logits",
          62,
          111,
          100,
          28,
          101,
          60,
          62,
          50,
          111,
          45
        ],
        [
          "test_layer_invocation",
          123,
          145,
          141,
          28,
          142,
          46,
          123,
          29,
          145,
          47
        ]
      ],
      "models/official/nlp/modeling/layers/masked_softmax_test.py": [
        [
          "test_masked_softmax",
          36,
          49,
          44,
          17,
          44,
          52,
          36,
          27,
          49,
          49
        ],
        [
          "test_softmax_with_axes_expansion",
          62,
          76,
          70,
          17,
          70,
          49,
          62,
          40,
          76,
          49
        ],
        [
          "test_masked_softmax_high_dims",
          78,
          98,
          89,
          17,
          89,
          59,
          78,
          37,
          98,
          49
        ]
      ],
      "models/official/projects/lra/mega_encoder_test.py": [
        [
          "test_encoder",
          25,
          47,
          34,
          20,
          36,
          5,
          25,
          20,
          47,
          5
        ],
        [
          "test_encoder",
          25,
          47,
          37,
          17,
          37,
          72,
          25,
          20,
          47,
          5
        ],
        [
          "test_encoder",
          25,
          47,
          38,
          20,
          38,
          75,
          25,
          20,
          47,
          5
        ]
      ],
      "models/official/nlp/modeling/networks/mobile_bert_encoder_test.py": [
        [
          "generate_fake_input",
          23,
          32,
          30,
          29,
          30,
          60,
          29,
          9,
          30,
          61
        ]
      ],
      "models/official/nlp/modeling/layers/mobile_bert_layers_test.py": [
        [
          "generate_fake_input",
          24,
          33,
          31,
          29,
          31,
          60,
          30,
          9,
          31,
          61
        ],
        [
          "test_layer_invocation_with_external_logits",
          173,
          225,
          214,
          28,
          215,
          60,
          173,
          50,
          225,
          45
        ],
        [
          "test_layer_invocation",
          227,
          251,
          249,
          28,
          250,
          46,
          227,
          29,
          251,
          5
        ]
      ],
      "models/research/slim/deployment/model_deploy_test.py": [
        [
          "setUp",
          171,
          181,
          176,
          20,
          176,
          56,
          171,
          13,
          179,
          22
        ],
        [
          "setUp",
          171,
          181,
          180,
          37,
          180,
          59,
          179,
          9,
          181,
          24
        ],
        [
          "setUp",
          318,
          328,
          323,
          20,
          323,
          56,
          318,
          13,
          326,
          22
        ],
        [
          "setUp",
          318,
          328,
          327,
          37,
          327,
          59,
          326,
          9,
          328,
          24
        ],
        [
          "setUp",
          467,
          477,
          472,
          20,
          472,
          56,
          467,
          13,
          475,
          22
        ],
        [
          "setUp",
          467,
          477,
          476,
          37,
          476,
          59,
          475,
          9,
          477,
          24
        ]
      ],
      "models/official/legacy/bert/model_training_utils_test.py": [
        [
          "_dataset_fn",
          68,
          88,
          72,
          14,
          72,
          57,
          68,
          19,
          88,
          18
        ]
      ],
      "models/official/nlp/modeling/layers/multi_channel_attention_test.py": [
        [
          "test_multi_channel_attention",
          35,
          51,
          43,
          17,
          43,
          62,
          35,
          36,
          51,
          46
        ],
        [
          "test_multi_channel_attention",
          35,
          51,
          44,
          17,
          45,
          44,
          35,
          36,
          51,
          46
        ]
      ],
      "models/official/nlp/modeling/layers/multi_query_attention_test.py": [
        [
          "test_masked_attention",
          100,
          155,
          121,
          17,
          121,
          61,
          100,
          29,
          150,
          15
        ],
        [
          "test_masked_attention_with_scores",
          161,
          211,
          182,
          17,
          182,
          61,
          161,
          41,
          211,
          56
        ]
      ],
      "models/official/vision/modeling/layers/nn_blocks_test.py": [
        [
          "test_layer_invocation_with_feedforward_cls",
          692,
          741,
          732,
          17,
          733,
          63,
          692,
          50,
          741,
          66
        ],
        [
          "test_layer_invocation_with_mask",
          743,
          782,
          776,
          17,
          777,
          63,
          743,
          39,
          782,
          80
        ],
        [
          "test_layer_invocation_with_float16_dtype",
          784,
          824,
          818,
          17,
          819,
          63,
          784,
          48,
          824,
          80
        ],
        [
          "test_layer_restoration_from_config",
          854,
          911,
          888,
          17,
          889,
          63,
          854,
          42,
          911,
          66
        ],
        [
          "test_layer_with_feedforward_cls_restoration_from_config",
          913,
          979,
          954,
          17,
          955,
          63,
          913,
          63,
          979,
          66
        ]
      ],
      "models/official/nlp/modeling/layers/on_device_embedding_test.py": [
        [
          "test_layer_invocation",
          58,
          77,
          74,
          18,
          75,
          55,
          58,
          29,
          77,
          46
        ],
        [
          "test_layer_invocation_with_mixed_precision",
          79,
          99,
          96,
          18,
          97,
          55,
          79,
          50,
          99,
          46
        ],
        [
          "test_one_hot_layer_invocation",
          138,
          159,
          156,
          18,
          157,
          55,
          138,
          37,
          159,
          46
        ],
        [
          "test_one_hot_layer_invocation_with_mixed_precision",
          161,
          183,
          180,
          18,
          181,
          55,
          161,
          58,
          183,
          46
        ],
        [
          "test_use_scale_layer_invocation",
          185,
          205,
          202,
          18,
          203,
          55,
          185,
          39,
          205,
          46
        ]
      ],
      "models/research/object_detection/utils/ops_test.py": [
        [
          "test_indices_to_dense_vector",
          332,
          347,
          334,
          19,
          334,
          41,
          332,
          36,
          347,
          57
        ]
      ],
      "models/official/nlp/modeling/networks/packed_sequence_embedding_test.py": [
        [
          "test_network_creation",
          36,
          97,
          82,
          17,
          82,
          67,
          70,
          40,
          97,
          76
        ],
        [
          "test_network_creation",
          36,
          97,
          82,
          17,
          82,
          67,
          73,
          23,
          97,
          76
        ],
        [
          "test_network_creation",
          36,
          97,
          81,
          20,
          81,
          79,
          70,
          40,
          97,
          76
        ],
        [
          "test_network_creation",
          36,
          97,
          81,
          20,
          81,
          79,
          73,
          23,
          97,
          76
        ],
        [
          "test_network_creation",
          36,
          97,
          83,
          20,
          84,
          55,
          70,
          40,
          97,
          76
        ],
        [
          "test_network_creation",
          36,
          97,
          83,
          20,
          84,
          55,
          73,
          23,
          97,
          76
        ],
        [
          "test_network_creation",
          36,
          97,
          91,
          36,
          92,
          52,
          70,
          40,
          97,
          76
        ]
      ],
      "models/official/projects/pointpillars/dataloaders/parsers_test.py": [
        [
          "_mock_decoded_example",
          24,
          50,
          26,
          14,
          26,
          53,
          24,
          27,
          50,
          24
        ],
        [
          "_mock_decoded_example",
          24,
          50,
          29,
          13,
          29,
          75,
          24,
          27,
          50,
          24
        ],
        [
          "_mock_decoded_example",
          24,
          50,
          30,
          13,
          30,
          70,
          24,
          27,
          50,
          24
        ],
        [
          "_mock_decoded_example",
          24,
          50,
          35,
          16,
          35,
          73,
          24,
          27,
          50,
          24
        ]
      ],
      "models/official/projects/pix2seq/dataloaders/pix2seq_input_test.py": [
        [
          "fake_seq_example",
          49,
          95,
          51,
          18,
          51,
          78,
          51,
          18,
          95,
          30
        ]
      ],
      "models/official/vision/ops/preprocess_ops_3d_test.py": [
        [
          "test_decode_jpeg",
          84,
          96,
          86,
          20,
          86,
          80,
          84,
          24,
          96,
          62
        ],
        [
          "test_decode_image",
          98,
          123,
          100,
          20,
          100,
          80,
          98,
          25,
          123,
          62
        ],
        [
          "test_decode_image",
          98,
          123,
          113,
          20,
          113,
          80,
          98,
          25,
          123,
          62
        ]
      ],
      "models/official/vision/ops/preprocess_ops_test.py": [
        [
          "test_random_crop",
          332,
          346,
          334,
          20,
          334,
          74,
          332,
          24,
          346,
          5
        ],
        [
          "test_random_crop",
          332,
          346,
          335,
          11,
          335,
          66,
          332,
          24,
          346,
          5
        ],
        [
          "test_random_crop",
          332,
          346,
          337,
          19,
          337,
          72,
          332,
          24,
          346,
          5
        ],
        [
          "test_random_crop",
          332,
          346,
          338,
          12,
          338,
          65,
          332,
          24,
          346,
          5
        ],
        [
          "test_random_crop",
          332,
          346,
          344,
          9,
          344,
          67,
          332,
          24,
          346,
          5
        ],
        [
          "test_random_jpeg_quality",
          484,
          493,
          485,
          19,
          485,
          74,
          484,
          32,
          493,
          46
        ]
      ],
      "models/official/legacy/xlnet/preprocess_pretrain_data.py": [
        [
          "_sample_mask",
          347,
          405,
          397,
          9,
          397,
          34,
          397,
          9,
          398,
          18
        ],
        [
          "_sample_mask_ngram",
          408,
          472,
          464,
          9,
          464,
          34,
          464,
          9,
          465,
          18
        ]
      ],
      "models/research/deeplab/core/preprocess_utils_test.py": [
        [
          "testReturnCorrectCropOfSingleImage",
          125,
          150,
          129,
          13,
          129,
          62,
          125,
          42,
          143,
          45
        ],
        [
          "testRandomCropMaintainsNumberOfChannels",
          152,
          165,
          156,
          13,
          156,
          57,
          152,
          47,
          165,
          78
        ],
        [
          "testReturnDifferentCropAreasOnTwoEvals",
          167,
          179,
          171,
          13,
          171,
          57,
          167,
          46,
          179,
          54
        ]
      ],
      "models/official/nlp/data/pretrain_dataloader_test.py": [
        [
          "_create_fake_bert_dataset",
          31,
          71,
          47,
          17,
          47,
          57,
          45,
          7,
          49,
          27
        ],
        [
          "_create_fake_bert_dataset",
          31,
          71,
          57,
          9,
          57,
          62,
          56,
          39,
          63,
          30
        ],
        [
          "_create_fake_bert_dataset",
          31,
          71,
          59,
          9,
          59,
          62,
          56,
          39,
          63,
          30
        ],
        [
          "_create_fake_xlnet_dataset",
          74,
          99,
          80,
          17,
          80,
          57,
          78,
          7,
          83,
          42
        ],
        [
          "_create_fake_xlnet_dataset",
          74,
          99,
          81,
          28,
          81,
          59,
          78,
          7,
          83,
          42
        ],
        [
          "_create_fake_xlnet_dataset",
          74,
          99,
          94,
          16,
          94,
          73,
          90,
          30,
          98,
          48
        ]
      ],
      "models/official/projects/movinet/tools/quantize_movinet.py": [
        [
          "stateful_representative_dataset_generator",
          174,
          233,
          210,
          22,
          211,
          60,
          204,
          36,
          216,
          47
        ]
      ],
      "models/official/nlp/data/question_answering_dataloader_test.py": [
        [
          "_create_fake_dataset",
          24,
          43,
          34,
          17,
          34,
          57,
          32,
          7,
          42,
          48
        ]
      ],
      "models/official/projects/bigbird/recomputing_dropout.py": [
        [
          "__init__",
          63,
          93,
          92,
          9,
          92,
          56,
          92,
          9,
          92,
          56
        ]
      ],
      "models/official/nlp/modeling/layers/relative_attention_test.py": [
        [
          "_create_mock_attention_data",
          25,
          111,
          91,
          17,
          91,
          53,
          90,
          19,
          98,
          26
        ],
        [
          "_create_mock_attention_data",
          25,
          111,
          102,
          22,
          103,
          59,
          101,
          31,
          109,
          29
        ]
      ],
      "models/official/nlp/modeling/layers/reuse_attention_test.py": [
        [
          "test_masked_attention",
          79,
          148,
          102,
          17,
          102,
          61,
          79,
          29,
          113,
          28
        ],
        [
          "test_masked_attention_with_scores",
          161,
          204,
          181,
          17,
          181,
          61,
          161,
          41,
          204,
          56
        ],
        [
          "test_high_dim_attention",
          214,
          242,
          228,
          17,
          228,
          53,
          214,
          31,
          242,
          54
        ]
      ],
      "models/official/nlp/modeling/layers/reuse_transformer_test.py": [
        [
          "test_layer_invocation_with_mask",
          75,
          98,
          96,
          17,
          97,
          63,
          75,
          39,
          98,
          5
        ],
        [
          "test_layer_output_range",
          100,
          124,
          109,
          17,
          110,
          63,
          100,
          31,
          124,
          75
        ],
        [
          "test_layer_output_range_with_relative_pe",
          126,
          152,
          136,
          17,
          137,
          63,
          126,
          48,
          152,
          75
        ],
        [
          "test_layer_output_range_with_pre_norm",
          180,
          206,
          190,
          17,
          191,
          63,
          180,
          45,
          206,
          75
        ],
        [
          "test_layer_invocation_with_float16_dtype",
          208,
          232,
          230,
          17,
          231,
          63,
          208,
          48,
          232,
          5
        ],
        [
          "test_layer_invocation_with_mask",
          341,
          380,
          376,
          17,
          377,
          63,
          341,
          39,
          380,
          5
        ],
        [
          "test_layer_invocation_with_float16_with_relative_pe",
          387,
          413,
          411,
          17,
          412,
          63,
          388,
          7,
          413,
          5
        ]
      ],
      "models/official/nlp/modeling/layers/rezero_transformer_test.py": [
        [
          "test_rezero_with_kv_heads",
          146,
          174,
          172,
          17,
          173,
          63,
          146,
          33,
          174,
          5
        ],
        [
          "test_layer_invocation_with_float16_dtype",
          32,
          59,
          57,
          17,
          58,
          63,
          32,
          48,
          59,
          5
        ],
        [
          "test_layer_output_range",
          100,
          128,
          111,
          17,
          112,
          63,
          100,
          31,
          128,
          80
        ],
        [
          "test_rezero_with_block_sparse_attention",
          176,
          205,
          203,
          17,
          204,
          63,
          176,
          47,
          205,
          5
        ]
      ],
      "models/official/projects/roformer/roformer_attention_test.py": [
        [
          "_create_mock_attention_data",
          25,
          62,
          58,
          17,
          58,
          53,
          57,
          19,
          60,
          26
        ]
      ],
      "models/official/projects/roformer/roformer_encoder_test.py": [
        [
          "test_network_invocation",
          120,
          186,
          147,
          20,
          148,
          55,
          120,
          31,
          186,
          67
        ],
        [
          "test_network_invocation",
          120,
          186,
          149,
          17,
          149,
          72,
          120,
          31,
          186,
          67
        ],
        [
          "test_network_invocation",
          120,
          186,
          150,
          20,
          151,
          54,
          120,
          31,
          186,
          67
        ]
      ],
      "models/official/projects/roformer/roformer_encoder_block_test.py": [
        [
          "test_layer_invocation_with_mask",
          75,
          98,
          96,
          17,
          97,
          63,
          75,
          39,
          98,
          5
        ],
        [
          "test_layer_output_range",
          100,
          124,
          109,
          17,
          110,
          63,
          100,
          31,
          124,
          75
        ],
        [
          "test_layer_output_range_with_pre_norm",
          154,
          182,
          166,
          17,
          167,
          63,
          154,
          45,
          182,
          75
        ],
        [
          "test_layer_invocation_with_float16_dtype",
          184,
          208,
          206,
          17,
          207,
          63,
          184,
          48,
          208,
          5
        ]
      ],
      "models/official/nlp/tasks/sentence_prediction_test.py": [
        [
          "_create_fake_dataset",
          30,
          59,
          44,
          17,
          44,
          57,
          42,
          7,
          51,
          23
        ]
      ],
      "models/official/nlp/data/sentence_prediction_dataloader_test.py": [
        [
          "_create_fake_preprocessed_dataset",
          26,
          54,
          40,
          17,
          40,
          57,
          38,
          7,
          45,
          26
        ]
      ],
      "models/official/projects/perceiver/tasks/sentence_prediction_test.py": [
        [
          "_create_fake_dataset",
          30,
          72,
          57,
          19,
          57,
          59,
          55,
          9,
          64,
          25
        ]
      ],
      "models/research/lstm_object_detection/inputs/seq_dataset_builder_test.py": [
        [
          "_create_tf_record",
          36,
          96,
          40,
          20,
          40,
          59,
          36,
          25,
          96,
          15
        ]
      ],
      "models/official/projects/perceiver/modeling/networks/sequence_encoder_test.py": [
        [
          "test_dict_outputs_network_invocation",
          70,
          101,
          95,
          20,
          96,
          55,
          70,
          44,
          101,
          52
        ],
        [
          "test_dict_outputs_network_invocation",
          70,
          101,
          97,
          17,
          97,
          72,
          70,
          44,
          101,
          52
        ],
        [
          "test_dict_outputs_network_invocation",
          70,
          101,
          98,
          20,
          99,
          54,
          70,
          44,
          101,
          52
        ]
      ],
      "models/research/attention_ocr/python/sequence_layers_test.py": [
        [
          "fake_labels",
          36,
          40,
          38,
          13,
          39,
          70,
          36,
          17,
          40,
          71
        ]
      ],
      "models/research/object_detection/utils/spatial_transform_ops_test.py": [
        [
          "test_large_input",
          362,
          395,
          384,
          16,
          385,
          48,
          380,
          15,
          395,
          53
        ]
      ],
      "models/official/recommendation/stat_utils.py": [
        [
          "random_int32",
          24,
          25,
          25,
          10,
          25,
          78,
          25,
          10,
          25,
          78
        ],
        [
          "very_slightly_biased_randint",
          50,
          58,
          53,
          13,
          57,
          25,
          50,
          34,
          58,
          79
        ]
      ],
      "models/official/nlp/data/tagging_dataloader_test.py": [
        [
          "_create_fake_dataset",
          25,
          47,
          35,
          17,
          35,
          57,
          33,
          7,
          41,
          26
        ],
        [
          "_create_fake_dataset",
          25,
          47,
          40,
          9,
          40,
          48,
          33,
          7,
          41,
          26
        ]
      ],
      "models/official/nlp/tasks/tagging_test.py": [
        [
          "_create_fake_dataset",
          27,
          48,
          37,
          17,
          37,
          57,
          35,
          7,
          47,
          48
        ]
      ],
      "models/official/nlp/modeling/layers/talking_heads_attention_test.py": [
        [
          "test_masked_attention",
          65,
          114,
          85,
          17,
          85,
          61,
          65,
          29,
          109,
          15
        ],
        [
          "test_high_dim_attention",
          131,
          154,
          145,
          17,
          145,
          53,
          131,
          31,
          154,
          51
        ]
      ],
      "models/research/object_detection/data_decoders/tf_example_decoder_test.py": [
        [
          "testDecodeImageKeyAndFilename",
          115,
          137,
          116,
          13,
          116,
          50,
          115,
          37,
          137,
          72
        ],
        [
          "testDecodeKeypoint",
          396,
          460,
          397,
          20,
          397,
          57,
          396,
          26,
          460,
          78
        ],
        [
          "testDecodeEmptyPngInstanceMasks",
          207,
          236,
          208,
          20,
          208,
          59,
          207,
          39,
          236,
          20
        ],
        [
          "testDecodeAdditionalChannels",
          48,
          79,
          52,
          26,
          52,
          63,
          48,
          36,
          79,
          70
        ],
        [
          "testDecodeJpegImage",
          81,
          113,
          82,
          13,
          82,
          50,
          81,
          27,
          113,
          73
        ],
        [
          "testDecodeAdditionalChannels",
          48,
          79,
          49,
          13,
          49,
          50,
          48,
          36,
          79,
          70
        ],
        [
          "testDecodePngImage",
          139,
          171,
          140,
          13,
          140,
          50,
          139,
          26,
          171,
          73
        ],
        [
          "testDecodePngInstanceMasks",
          173,
          205,
          174,
          13,
          174,
          50,
          173,
          34,
          205,
          71
        ],
        [
          "testDecodePngInstanceMasks",
          173,
          205,
          176,
          14,
          176,
          54,
          173,
          34,
          205,
          71
        ],
        [
          "testDecodePngInstanceMasks",
          173,
          205,
          177,
          14,
          177,
          54,
          173,
          34,
          205,
          71
        ],
        [
          "testDecodeBoundingBox",
          238,
          276,
          239,
          20,
          239,
          57,
          238,
          29,
          276,
          78
        ],
        [
          "testDecodeKeypointDepth",
          278,
          342,
          279,
          20,
          279,
          57,
          278,
          31,
          342,
          79
        ],
        [
          "testDecodeKeypointDepthNoDepth",
          344,
          394,
          345,
          20,
          345,
          57,
          344,
          38,
          394,
          79
        ],
        [
          "testDecodeKeypointNoInstance",
          462,
          514,
          463,
          20,
          463,
          57,
          462,
          36,
          514,
          72
        ],
        [
          "testDecodeKeypointWithText",
          516,
          621,
          517,
          20,
          517,
          57,
          516,
          34,
          621,
          69
        ],
        [
          "testDecodeKeypointWithKptsLabelsNotInText",
          623,
          731,
          624,
          20,
          624,
          57,
          623,
          49,
          731,
          69
        ],
        [
          "testDecodeKeypointNoVisibilities",
          733,
          792,
          734,
          20,
          734,
          57,
          733,
          40,
          792,
          78
        ],
        [
          "testDecodeDefaultGroundtruthWeights",
          794,
          831,
          795,
          20,
          795,
          57,
          794,
          43,
          831,
          53
        ],
        [
          "testDecodeObjectLabel",
          833,
          862,
          834,
          20,
          834,
          57,
          833,
          29,
          862,
          80
        ],
        [
          "testDecodeMultiClassScores",
          864,
          901,
          865,
          20,
          865,
          57,
          864,
          34,
          901,
          78
        ],
        [
          "testDecodeEmptyMultiClassScores",
          903,
          936,
          904,
          20,
          904,
          57,
          903,
          39,
          936,
          74
        ],
        [
          "testDecodeObjectLabelNoText",
          938,
          981,
          939,
          20,
          939,
          57,
          938,
          35,
          981,
          80
        ],
        [
          "testDecodeObjectLabelWithText",
          983,
          1038,
          984,
          20,
          984,
          57,
          983,
          37,
          1038,
          80
        ],
        [
          "testDecodeObjectLabelUnrecognizedName",
          1040,
          1081,
          1041,
          20,
          1041,
          57,
          1040,
          45,
          1081,
          80
        ],
        [
          "testDecodeObjectLabelWithMappingWithDisplayName",
          1083,
          1125,
          1084,
          20,
          1084,
          57,
          1083,
          55,
          1125,
          80
        ],
        [
          "testDecodeObjectLabelUnrecognizedNameWithMappingWithDisplayName",
          1127,
          1169,
          1128,
          20,
          1128,
          57,
          1127,
          71,
          1169,
          80
        ],
        [
          "testDecodeObjectLabelWithMappingWithName",
          1171,
          1213,
          1172,
          20,
          1172,
          57,
          1171,
          48,
          1213,
          80
        ],
        [
          "testDecodeObjectArea",
          1215,
          1243,
          1216,
          20,
          1216,
          57,
          1215,
          28,
          1243,
          77
        ],
        [
          "testDecodeVerifiedNegClasses",
          1245,
          1270,
          1246,
          20,
          1246,
          57,
          1245,
          36,
          1270,
          77
        ],
        [
          "testDecodeNotExhaustiveClasses",
          1272,
          1298,
          1273,
          20,
          1273,
          57,
          1272,
          38,
          1298,
          79
        ],
        [
          "testDecodeObjectIsCrowd",
          1300,
          1329,
          1301,
          20,
          1301,
          57,
          1300,
          31,
          1329,
          65
        ],
        [
          "testDecodeObjectDifficult",
          1331,
          1360,
          1332,
          20,
          1332,
          57,
          1331,
          33,
          1360,
          66
        ],
        [
          "testDecodeObjectGroupOf",
          1362,
          1391,
          1363,
          20,
          1363,
          57,
          1362,
          31,
          1391,
          65
        ],
        [
          "testDecodeObjectWeight",
          1393,
          1422,
          1394,
          20,
          1394,
          57,
          1393,
          30,
          1422,
          80
        ],
        [
          "testDecodeClassConfidence",
          1424,
          1453,
          1425,
          20,
          1425,
          57,
          1424,
          33,
          1453,
          74
        ],
        [
          "testDecodeInstanceSegmentation",
          1455,
          1515,
          1461,
          20,
          1462,
          49,
          1455,
          38,
          1515,
          80
        ],
        [
          "testDecodeInstanceSegmentation",
          1455,
          1515,
          1468,
          9,
          1469,
          48,
          1455,
          38,
          1515,
          80
        ],
        [
          "testDecodeInstanceSegmentation",
          1455,
          1515,
          1473,
          22,
          1474,
          34,
          1455,
          38,
          1515,
          80
        ],
        [
          "testInstancesNotAvailableByDefault",
          1517,
          1559,
          1522,
          20,
          1523,
          49,
          1517,
          42,
          1559,
          33
        ],
        [
          "testInstancesNotAvailableByDefault",
          1517,
          1559,
          1529,
          9,
          1530,
          48,
          1517,
          42,
          1559,
          33
        ],
        [
          "testInstancesNotAvailableByDefault",
          1517,
          1559,
          1534,
          22,
          1535,
          34,
          1517,
          42,
          1559,
          33
        ],
        [
          "testDecodeInstanceSegmentationWithWeights",
          1561,
          1624,
          1567,
          20,
          1568,
          49,
          1561,
          49,
          1624,
          80
        ],
        [
          "testDecodeInstanceSegmentationWithWeights",
          1561,
          1624,
          1574,
          9,
          1575,
          48,
          1561,
          49,
          1624,
          80
        ],
        [
          "testDecodeInstanceSegmentationWithWeights",
          1561,
          1624,
          1580,
          22,
          1581,
          34,
          1561,
          49,
          1624,
          80
        ],
        [
          "testDecodeImageLabels",
          1626,
          1681,
          1627,
          20,
          1627,
          57,
          1626,
          29,
          1681,
          25
        ],
        [
          "testDecodeContextFeatures",
          1683,
          1727,
          1684,
          20,
          1684,
          57,
          1683,
          33,
          1727,
          67
        ],
        [
          "testContextFeaturesNotAvailableByDefault",
          1729,
          1768,
          1730,
          20,
          1730,
          57,
          1729,
          48,
          1768,
          33
        ],
        [
          "testExpandLabels",
          1770,
          1868,
          1804,
          20,
          1804,
          57,
          1770,
          24,
          1868,
          74
        ],
        [
          "testDecodeDensePose",
          1870,
          1955,
          1871,
          20,
          1871,
          57,
          1870,
          27,
          1955,
          70
        ],
        [
          "testDecodeTrack",
          1957,
          1997,
          1958,
          20,
          1958,
          57,
          1957,
          23,
          1997,
          57
        ]
      ],
      "models/research/lstm_object_detection/inputs/tf_sequence_example_decoder_test.py": [
        [
          "testDecodeJpegImageAndBoundingBox",
          47,
          109,
          56,
          20,
          56,
          61,
          47,
          41,
          109,
          78
        ]
      ],
      "models/official/nlp/modeling/layers/tn_expand_condense_test.py": [
        [
          "test_config",
          122,
          138,
          123,
          12,
          123,
          55,
          122,
          19,
          138,
          71
        ],
        [
          "test_train",
          45,
          59,
          47,
          12,
          47,
          55,
          45,
          18,
          59,
          72
        ],
        [
          "test_weights_change",
          62,
          76,
          64,
          12,
          64,
          55,
          62,
          27,
          75,
          33
        ],
        [
          "test_output_shape",
          79,
          87,
          80,
          12,
          80,
          55,
          79,
          25,
          87,
          64
        ],
        [
          "test_expandcondense_num_parameters",
          90,
          111,
          91,
          12,
          91,
          55,
          90,
          42,
          111,
          67
        ],
        [
          "test_incorrect_sizes",
          114,
          119,
          115,
          12,
          115,
          55,
          114,
          28,
          119,
          65
        ],
        [
          "test_model_save",
          141,
          156,
          142,
          12,
          142,
          55,
          141,
          23,
          156,
          72
        ]
      ],
      "models/official/nlp/modeling/layers/tn_transformer_test.py": [
        [
          "test_layer_invocation_with_mask",
          94,
          119,
          117,
          17,
          118,
          63,
          94,
          39,
          119,
          5
        ],
        [
          "test_layer_output_range",
          121,
          147,
          132,
          17,
          133,
          63,
          121,
          31,
          147,
          75
        ],
        [
          "test_layer_invocation_with_float16_dtype",
          149,
          175,
          173,
          17,
          174,
          63,
          149,
          48,
          175,
          5
        ]
      ],
      "models/official/projects/qat/nlp/modeling/layers/transformer_encoder_block_test.py": [
        [
          "test_layer_invocation_with_mask",
          76,
          99,
          97,
          17,
          98,
          63,
          76,
          39,
          99,
          5
        ],
        [
          "test_layer_output_range",
          101,
          124,
          110,
          17,
          111,
          63,
          101,
          31,
          124,
          75
        ],
        [
          "test_layer_output_range_with_pre_norm",
          151,
          176,
          161,
          17,
          162,
          63,
          151,
          45,
          176,
          75
        ]
      ],
      "models/official/nlp/modeling/layers/transformer_encoder_block_test.py": [
        [
          "test_layer_invocation_with_mask",
          96,
          121,
          118,
          17,
          120,
          5,
          96,
          39,
          121,
          5
        ],
        [
          "test_layer_invocation_with_dict_inputs",
          123,
          153,
          151,
          17,
          152,
          63,
          123,
          46,
          153,
          5
        ],
        [
          "test_layer_output_range",
          155,
          181,
          164,
          17,
          165,
          63,
          155,
          31,
          181,
          80
        ],
        [
          "test_layer_output_range_with_pre_norm",
          210,
          240,
          222,
          17,
          223,
          63,
          210,
          45,
          240,
          80
        ],
        [
          "test_layer_invocation_with_float16_dtype",
          242,
          266,
          264,
          17,
          265,
          63,
          242,
          48,
          266,
          5
        ]
      ],
      "models/official/nlp/modeling/layers/transformer_scaffold_test.py": [
        [
          "test_layer_invocation_with_feedforward_cls",
          214,
          263,
          254,
          17,
          255,
          63,
          214,
          50,
          263,
          66
        ],
        [
          "test_layer_invocation_with_mask",
          265,
          304,
          298,
          17,
          299,
          63,
          265,
          39,
          304,
          80
        ],
        [
          "test_layer_invocation_with_float16_dtype",
          306,
          346,
          340,
          17,
          341,
          63,
          306,
          48,
          346,
          80
        ],
        [
          "test_layer_restoration_from_config",
          376,
          433,
          410,
          17,
          411,
          63,
          376,
          42,
          433,
          66
        ],
        [
          "test_layer_with_feedforward_cls_restoration_from_config",
          435,
          501,
          476,
          17,
          477,
          63,
          435,
          63,
          501,
          66
        ]
      ],
      "models/official/nlp/modeling/layers/transformer_xl_test.py": [
        [
          "create_mock_transformer_xl_data",
          26,
          115,
          95,
          17,
          95,
          53,
          94,
          19,
          98,
          34
        ],
        [
          "create_mock_transformer_xl_data",
          26,
          115,
          95,
          17,
          95,
          53,
          94,
          19,
          97,
          17
        ],
        [
          "create_mock_transformer_xl_data",
          26,
          115,
          110,
          22,
          111,
          59,
          110,
          22,
          113,
          31
        ]
      ],
      "models/research/attention_ocr/python/datasets/unittest_utils.py": [
        [
          "create_random_image",
          23,
          37,
          33,
          11,
          33,
          71,
          23,
          25,
          37,
          29
        ]
      ],
      "models/official/projects/mobilebert/utils.py": [
        [
          "generate_fake_input",
          20,
          29,
          27,
          29,
          27,
          60,
          26,
          9,
          27,
          61
        ]
      ],
      "models/official/projects/yt8m/dataloaders/utils.py": [
        [
          "make_yt8m_example",
          167,
          189,
          171,
          9,
          171,
          61,
          168,
          5,
          189,
          20
        ],
        [
          "make_yt8m_example",
          167,
          189,
          172,
          11,
          172,
          62,
          168,
          5,
          189,
          20
        ]
      ],
      "models/official/vision/serving/video_classification_test.py": [
        [
          "_get_dummy_input",
          46,
          70,
          50,
          16,
          51,
          66,
          50,
          16,
          53,
          27
        ]
      ],
      "models/official/vision/dataloaders/video_input_test.py": [
        [
          "fake_seq_example",
          31,
          57,
          33,
          18,
          33,
          78,
          33,
          18,
          54,
          23
        ]
      ],
      "models/official/projects/video_ssl/dataloaders/video_ssl_input_test.py": [
        [
          "fake_seq_example",
          28,
          54,
          30,
          18,
          30,
          78,
          30,
          18,
          51,
          23
        ]
      ],
      "models/official/projects/const_cl/datasets/video_ssl_inputs_test.py": [
        [
          "fake_seq_example",
          30,
          55,
          32,
          18,
          32,
          78,
          31,
          3,
          52,
          23
        ]
      ],
      "models/research/object_detection/utils/visualization_utils_test.py": [
        [
          "test_eval_metric_ops",
          486,
          592,
          556,
          21,
          560,
          39,
          550,
          11,
          565,
          14
        ],
        [
          "test_eval_metric_ops",
          486,
          592,
          579,
          21,
          583,
          39,
          573,
          11,
          588,
          14
        ]
      ],
      "models/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py": [
        [
          "test_loss_3d_input",
          58,
          89,
          79,
          14,
          79,
          78,
          58,
          26,
          89,
          68
        ],
        [
          "test_loss_3d_input",
          58,
          89,
          74,
          28,
          75,
          46,
          58,
          26,
          89,
          68
        ],
        [
          "test_loss_3d_input",
          58,
          89,
          80,
          15,
          80,
          70,
          58,
          26,
          89,
          68
        ],
        [
          "test_loss_weights_3d_input",
          91,
          118,
          107,
          28,
          108,
          46,
          91,
          34,
          118,
          46
        ],
        [
          "test_loss_weights_3d_input",
          91,
          118,
          112,
          14,
          112,
          78,
          91,
          34,
          118,
          46
        ],
        [
          "test_mismatched_predictions_and_labels_ranks_squeezes",
          120,
          128,
          124,
          14,
          124,
          56,
          120,
          61,
          127,
          5
        ],
        [
          "test_mismatched_weights_and_labels_ranks_fail",
          130,
          139,
          134,
          14,
          134,
          57,
          130,
          53,
          138,
          7
        ],
        [
          "test_mismatched_weights_and_labels_ranks_fail",
          130,
          139,
          135,
          15,
          135,
          53,
          130,
          53,
          138,
          7
        ],
        [
          "test_tf_tensor_inputs",
          141,
          153,
          146,
          35,
          146,
          78,
          141,
          29,
          152,
          5
        ],
        [
          "test_tf_tensor_inputs",
          141,
          153,
          147,
          36,
          147,
          78,
          141,
          29,
          152,
          5
        ]
      ],
      "models/official/nlp/modeling/networks/xlnet_base_test.py": [
        [
          "_generate_data",
          375,
          396,
          386,
          22,
          386,
          78,
          386,
          9,
          396,
          5
        ],
        [
          "_generate_data",
          375,
          396,
          388,
          13,
          388,
          68,
          386,
          9,
          396,
          5
        ],
        [
          "_generate_data",
          375,
          396,
          390,
          13,
          390,
          53,
          386,
          9,
          396,
          5
        ],
        [
          "_generate_data",
          375,
          396,
          392,
          13,
          393,
          61,
          386,
          9,
          396,
          5
        ]
      ],
      "models/official/nlp/modeling/models/xlnet_test.py": [
        [
          "test_xlnet_tensor_call",
          93,
          116,
          109,
          20,
          109,
          60,
          93,
          30,
          116,
          31
        ],
        [
          "test_xlnet_tensor_call",
          93,
          116,
          106,
          24,
          107,
          51,
          93,
          30,
          116,
          31
        ],
        [
          "test_xlnet_tensor_call",
          93,
          116,
          108,
          24,
          108,
          79,
          93,
          30,
          116,
          31
        ],
        [
          "test_xlnet_tensor_call",
          93,
          116,
          110,
          26,
          111,
          57,
          93,
          30,
          116,
          31
        ],
        [
          "test_xlnet_tensor_call",
          93,
          116,
          112,
          24,
          113,
          66,
          93,
          30,
          116,
          31
        ],
        [
          "test_xlnet_tensor_call",
          93,
          116,
          114,
          23,
          115,
          51,
          93,
          30,
          116,
          31
        ],
        [
          "test_xlnet_tensor_call",
          176,
          201,
          193,
          24,
          194,
          51,
          176,
          30,
          201,
          31
        ],
        [
          "test_xlnet_tensor_call",
          176,
          201,
          195,
          24,
          195,
          79,
          176,
          30,
          201,
          31
        ],
        [
          "test_xlnet_tensor_call",
          176,
          201,
          196,
          20,
          196,
          60,
          176,
          30,
          201,
          31
        ],
        [
          "test_xlnet_tensor_call",
          176,
          201,
          197,
          26,
          198,
          57,
          176,
          30,
          201,
          31
        ],
        [
          "test_xlnet_tensor_call",
          176,
          201,
          199,
          23,
          200,
          51,
          176,
          30,
          201,
          31
        ],
        [
          "test_xlnet_trainer",
          231,
          291,
          266,
          24,
          267,
          51,
          231,
          26,
          291,
          40
        ],
        [
          "test_xlnet_trainer",
          231,
          291,
          268,
          24,
          268,
          79,
          231,
          26,
          291,
          40
        ],
        [
          "test_xlnet_trainer",
          231,
          291,
          269,
          20,
          269,
          60,
          231,
          26,
          291,
          40
        ],
        [
          "test_xlnet_trainer",
          231,
          291,
          270,
          24,
          271,
          37,
          231,
          26,
          291,
          40
        ],
        [
          "test_xlnet_trainer",
          231,
          291,
          272,
          21,
          272,
          59,
          231,
          26,
          291,
          40
        ]
      ],
      "models/official/projects/yolo/losses/yolov7_loss_test.py": [
        [
          "build_labels",
          32,
          51,
          46,
          20,
          46,
          66,
          33,
          16,
          48,
          29
        ]
      ]
    },
    "random.random": {
      "models/research/autoaugment/augmentation_transforms.py": [
        [
          "return_function",
          211,
          214,
          212,
          10,
          212,
          24,
          211,
          25,
          212,
          38
        ],
        [
          "_rotate_impl",
          253,
          258,
          256,
          6,
          256,
          20,
          253,
          18,
          256,
          26
        ],
        [
          "_shear_x_impl",
          273,
          290,
          288,
          6,
          288,
          20,
          273,
          19,
          288,
          26
        ],
        [
          "_shear_y_impl",
          296,
          313,
          311,
          6,
          311,
          20,
          296,
          19,
          311,
          26
        ],
        [
          "_translate_x_impl",
          319,
          336,
          334,
          6,
          334,
          20,
          319,
          23,
          334,
          26
        ],
        [
          "_translate_y_impl",
          342,
          359,
          357,
          6,
          357,
          20,
          342,
          23,
          357,
          26
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data.py": [
        [
          "_create_a_and_b_segments",
          261,
          338,
          302,
          25,
          302,
          39,
          302,
          25,
          302,
          60
        ]
      ],
      "models/research/pcl_rl/expert_paths.py": [
        [
          "listcomp",
          56,
          56,
          56,
          24,
          56,
          38,
          56,
          52,
          56,
          46
        ],
        [
          "listcomp",
          66,
          66,
          66,
          24,
          66,
          38,
          66,
          52,
          66,
          46
        ],
        [
          "listcomp",
          81,
          81,
          81,
          24,
          81,
          38,
          81,
          52,
          81,
          46
        ],
        [
          "listcomp",
          93,
          93,
          93,
          24,
          93,
          38,
          93,
          52,
          93,
          46
        ],
        [
          "listcomp",
          118,
          118,
          118,
          24,
          118,
          38,
          118,
          52,
          118,
          46
        ]
      ],
      "models/official/legacy/xlnet/preprocess_pretrain_data.py": [
        [
          "_split_a_and_b",
          271,
          335,
          290,
          30,
          290,
          44,
          290,
          30,
          290,
          50
        ]
      ],
      "models/research/pcl_rl/trainer.py": [
        [
          "run",
          356,
          463,
          439,
          11,
          439,
          25,
          429,
          7,
          439,
          31
        ]
      ]
    },
    "random.randint": {
      "models/official/projects/const_cl/tasks/const_cl_test.py": [
        [
          "listcomp",
          42,
          46,
          46,
          19,
          46,
          40,
          46,
          47,
          46,
          41
        ]
      ],
      "models/official/projects/maskconver/modeling/layers/copypaste.py": [
        [
          "__init__",
          61,
          105,
          105,
          48,
          105,
          71,
          105,
          48,
          105,
          71
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data.py": [
        [
          "_create_a_and_b_segments",
          261,
          338,
          310,
          15,
          310,
          59,
          309,
          16,
          311,
          9
        ]
      ],
      "models/research/adversarial_text/data/document_generators.py": [
        [
          "dbpedia_documents",
          222,
          263,
          253,
          23,
          253,
          43,
          251,
          9,
          254,
          22
        ],
        [
          "rcv1_documents",
          266,
          314,
          304,
          25,
          304,
          45,
          302,
          11,
          305,
          24
        ],
        [
          "rt_documents",
          317,
          383,
          371,
          24,
          371,
          44,
          371,
          24,
          374,
          21
        ]
      ],
      "models/research/pcl_rl/expert_paths.py": [
        [
          "sample_expert_path",
          47,
          153,
          49,
          7,
          49,
          27,
          47,
          24,
          54,
          49
        ]
      ],
      "models/research/pcl_rl/gym_wrapper.py": [
        [
          "listcomp",
          39,
          39,
          39,
          28,
          39,
          50,
          40,
          32,
          39,
          50
        ],
        [
          "listcomp",
          66,
          66,
          66,
          19,
          66,
          41,
          66,
          47,
          66,
          41
        ]
      ],
      "models/research/adversarial_text/graphs_test.py": [
        [
          "_build_random_vocabulary",
          42,
          53,
          48,
          24,
          48,
          44,
          46,
          17,
          49,
          24
        ],
        [
          "_build_random_sequence",
          56,
          62,
          57,
          13,
          57,
          35,
          56,
          28,
          60,
          62
        ]
      ],
      "models/official/core/input_reader.py": [
        [
          "_get_random_integer",
          27,
          28,
          28,
          10,
          28,
          41,
          28,
          10,
          28,
          41
        ]
      ],
      "models/research/efficient-hrl/scripts/local_train.py": [
        [
          "main",
          30,
          72,
          51,
          10,
          51,
          35,
          43,
          3,
          68,
          43
        ]
      ],
      "models/official/projects/yolo/ops/mosaic.py": [
        [
          "__init__",
          29,
          116,
          116,
          48,
          116,
          71,
          116,
          48,
          116,
          71
        ]
      ],
      "models/official/legacy/xlnet/preprocess_pretrain_data.py": [
        [
          "_split_a_and_b",
          271,
          335,
          299,
          15,
          299,
          53,
          297,
          13,
          300,
          9
        ]
      ],
      "models/official/projects/video_ssl/tasks/pretrain_test.py": [
        [
          "listcomp",
          41,
          45,
          45,
          19,
          45,
          40,
          45,
          47,
          45,
          41
        ]
      ],
      "models/research/vid2depth/reader.py": [
        [
          "read_data",
          46,
          97,
          50,
          16,
          50,
          43,
          46,
          17,
          64,
          25
        ]
      ],
      "models/official/nlp/data/tagging_data_lib_test.py": [
        [
          "write_one_sentence",
          28,
          33,
          32,
          34,
          32,
          67,
          32,
          9,
          32,
          12
        ]
      ],
      "models/official/projects/movinet/train_test.py": [
        [
          "listcomp",
          43,
          47,
          47,
          19,
          47,
          40,
          47,
          47,
          47,
          41
        ]
      ],
      "models/official/projects/assemblenet/train_test.py": [
        [
          "listcomp",
          40,
          44,
          44,
          19,
          44,
          40,
          44,
          47,
          44,
          41
        ]
      ],
      "models/official/vision/serving/video_classification_test.py": [
        [
          "_get_dummy_input",
          46,
          70,
          58,
          17,
          58,
          38,
          55,
          17,
          68,
          30
        ]
      ]
    },
    "uuid.uuid4": {
      "models/orbit/actions/new_best_metric.py": [
        [
          "write",
          213,
          222,
          219,
          46,
          219,
          57,
          219,
          22,
          222,
          70
        ]
      ]
    }
  },
  "CWE-347": {},
  "CWE-377": {
    "open": {
      "models/research/marco/Automated_Marco.py": [
        [
          "load_images",
          44,
          47,
          46,
          17,
          46,
          28,
          45,
          9,
          47,
          46
        ]
      ],
      "models/research/deeplab/datasets/build_voc2012_data.py": [
        [
          "_convert_dataset",
          89,
          136,
          100,
          39,
          100,
          62,
          89,
          22,
          107,
          36
        ]
      ],
      "models/research/cvt_text/base/configure.py": [
        [
          "write",
          134,
          138,
          136,
          10,
          136,
          55,
          134,
          13,
          138,
          49
        ]
      ],
      "models/official/projects/unified_detector/data_conversion/convert.py": [
        [
          "main",
          44,
          61,
          45,
          27,
          45,
          46,
          44,
          10,
          51,
          41
        ]
      ],
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_generate_sequence_examples",
          171,
          294,
          200,
          10,
          200,
          33,
          171,
          35,
          202,
          23
        ],
        [
          "_generate_sequence_examples",
          171,
          294,
          204,
          10,
          204,
          35,
          204,
          10,
          209,
          23
        ],
        [
          "_generate_examples",
          296,
          449,
          324,
          10,
          324,
          33,
          296,
          26,
          326,
          23
        ],
        [
          "_generate_examples",
          296,
          449,
          328,
          10,
          328,
          35,
          328,
          10,
          333,
          23
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record_test.py": [
        [
          "test_create_sharded_tf_record",
          439,
          493,
          482,
          10,
          482,
          35,
          449,
          9,
          493,
          68
        ]
      ],
      "models/research/object_detection/dataset_tools/create_kitti_tf_record.py": [
        [
          "read_annotation_file",
          262,
          298,
          275,
          8,
          275,
          21,
          262,
          26,
          298,
          13
        ]
      ],
      "models/official/projects/fffner/utils/create_data.py": [
        [
          "read_file",
          70,
          79,
          72,
          10,
          72,
          30,
          70,
          17,
          73,
          47
        ],
        [
          "read_file",
          70,
          79,
          72,
          39,
          72,
          60,
          70,
          17,
          73,
          47
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data_test.py": [
        [
          "_create_files",
          32,
          44,
          40,
          10,
          40,
          32,
          38,
          7,
          41,
          30
        ]
      ],
      "models/research/adversarial_text/data/data_utils.py": [
        [
          "write_vocab_and_frequency",
          325,
          332,
          328,
          8,
          328,
          73,
          325,
          31,
          330,
          43
        ],
        [
          "write_vocab_and_frequency",
          325,
          332,
          329,
          10,
          329,
          80,
          325,
          31,
          330,
          43
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "__init__",
          168,
          190,
          177,
          10,
          177,
          54,
          168,
          16,
          190,
          31
        ],
        [
          "collect_static_frames",
          192,
          202,
          193,
          10,
          193,
          57,
          192,
          29,
          196,
          20
        ],
        [
          "load_pose_raw",
          298,
          306,
          302,
          10,
          302,
          29,
          298,
          21,
          306,
          15
        ],
        [
          "read_raw_calib_file",
          324,
          336,
          327,
          10,
          327,
          28,
          324,
          27,
          328,
          19
        ],
        [
          "read_calib_file",
          443,
          457,
          451,
          10,
          451,
          28,
          443,
          23,
          457,
          29
        ],
        [
          "load_intrinsics",
          514,
          533,
          520,
          10,
          520,
          31,
          514,
          23,
          528,
          23
        ]
      ],
      "models/research/adversarial_text/data/document_generators.py": [
        [
          "imdb_documents",
          158,
          219,
          202,
          12,
          202,
          82,
          202,
          12,
          209,
          26
        ],
        [
          "imdb_documents",
          158,
          219,
          212,
          10,
          212,
          66,
          211,
          44,
          213,
          25
        ],
        [
          "dbpedia_documents",
          222,
          263,
          249,
          8,
          249,
          68,
          247,
          3,
          251,
          21
        ],
        [
          "rcv1_documents",
          266,
          314,
          300,
          10,
          300,
          64,
          299,
          7,
          302,
          23
        ],
        [
          "rt_documents",
          317,
          383,
          357,
          10,
          357,
          23,
          356,
          7,
          358,
          25
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords_lib.py": [
        [
          "create_labels_file",
          72,
          84,
          82,
          8,
          82,
          45,
          72,
          24,
          83,
          38
        ],
        [
          "create_visual_wakeword_annotations",
          87,
          141,
          135,
          10,
          135,
          52,
          135,
          10,
          141,
          16
        ]
      ],
      "models/research/rebar/download_data.py": [
        [
          "load_mnist_float",
          38,
          47,
          39,
          8,
          39,
          33,
          38,
          22,
          47,
          15
        ]
      ],
      "models/research/deeplab/evaluation/eval_coco_format.py": [
        [
          "eval_coco_format",
          222,
          321,
          268,
          8,
          268,
          30,
          222,
          22,
          272,
          22
        ],
        [
          "eval_coco_format",
          222,
          321,
          270,
          8,
          270,
          32,
          222,
          22,
          272,
          22
        ]
      ],
      "models/research/audioset/yamnet/export.py": [
        [
          "make_tflite_export",
          138,
          183,
          172,
          8,
          172,
          36,
          145,
          3,
          183,
          24
        ]
      ],
      "models/research/lstm_object_detection/export_tflite_lstd_model.py": [
        [
          "main",
          33,
          61,
          61,
          3,
          61,
          23,
          33,
          10,
          61,
          43
        ]
      ],
      "models/research/vid2depth/dataset/gen_data.py": [
        [
          "_gen_example",
          150,
          173,
          169,
          8,
          169,
          30,
          165,
          18,
          173,
          19
        ]
      ],
      "models/research/adversarial_text/gen_data.py": [
        [
          "make_vocab_ids",
          92,
          99,
          98,
          10,
          98,
          47,
          98,
          10,
          99,
          72
        ]
      ],
      "models/research/adversarial_text/graphs_test.py": [
        [
          "setUpClass",
          80,
          135,
          131,
          10,
          131,
          61,
          128,
          19,
          133,
          45
        ],
        [
          "setUpClass",
          80,
          135,
          132,
          12,
          132,
          68,
          128,
          19,
          133,
          45
        ]
      ],
      "models/research/slim/datasets/imagenet.py": [
        [
          "create_readable_names_for_imagenet_labels",
          65,
          118,
          94,
          37,
          94,
          50,
          66,
          3,
          96,
          38
        ],
        [
          "create_readable_names_for_imagenet_labels",
          65,
          118,
          99,
          26,
          99,
          39,
          96,
          3,
          101,
          45
        ]
      ],
      "models/official/projects/waste_identification_ml/model_inference/labels.py": [
        [
          "read_csv_to_list",
          30,
          49,
          44,
          8,
          44,
          27,
          30,
          22,
          47,
          21
        ]
      ],
      "models/research/lfads/lfads.py": [
        [
          "summarize_all",
          1324,
          1390,
          1389,
          12,
          1389,
          30,
          1388,
          18,
          1390,
          32
        ]
      ],
      "models/research/object_detection/metrics/offline_eval_map_corloc.py": [
        [
          "write_metrics",
          135,
          147,
          144,
          8,
          144,
          57,
          135,
          19,
          146,
          52
        ]
      ],
      "models/research/object_detection/metrics/oid_challenge_evaluation.py": [
        [
          "_load_labelmap",
          73,
          93,
          85,
          8,
          85,
          31,
          73,
          20,
          90,
          28
        ],
        [
          "main",
          96,
          145,
          144,
          8,
          144,
          38,
          142,
          13,
          145,
          36
        ]
      ],
      "models/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py": [
        [
          "main",
          192,
          223,
          196,
          8,
          196,
          38,
          192,
          10,
          200,
          31
        ],
        [
          "main",
          192,
          223,
          207,
          8,
          207,
          41,
          201,
          19,
          215,
          24
        ],
        [
          "main",
          192,
          223,
          207,
          8,
          207,
          41,
          205,
          30,
          215,
          24
        ],
        [
          "main",
          192,
          223,
          208,
          10,
          208,
          44,
          201,
          19,
          215,
          24
        ],
        [
          "main",
          192,
          223,
          208,
          10,
          208,
          44,
          205,
          30,
          215,
          24
        ]
      ],
      "models/research/object_detection/metrics/oid_vrd_challenge_evaluation.py": [
        [
          "_load_labelmap",
          48,
          65,
          59,
          8,
          59,
          31,
          48,
          20,
          63,
          28
        ],
        [
          "main",
          80,
          120,
          118,
          8,
          118,
          44,
          113,
          22,
          120,
          43
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/predictor.py": [
        [
          "send_image_for_prediction",
          40,
          67,
          58,
          10,
          58,
          31,
          41,
          5,
          58,
          31
        ]
      ],
      "models/research/cvt_text/preprocessing.py": [
        [
          "write_sentences",
          78,
          83,
          79,
          8,
          79,
          23,
          78,
          21,
          80,
          32
        ]
      ],
      "models/official/projects/movinet/tools/quantize_movinet.py": [
        [
          "main",
          320,
          326,
          323,
          8,
          323,
          38,
          320,
          10,
          326,
          65
        ]
      ],
      "models/official/projects/centernet/utils/checkpoints/read_checkpoints.py": [
        [
          "write_dict_as_tree",
          80,
          98,
          95,
          12,
          95,
          31,
          94,
          9,
          98,
          63
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/run_tflite.py": [
        [
          "main",
          30,
          50,
          31,
          8,
          31,
          30,
          30,
          10,
          48,
          33
        ]
      ],
      "models/official/pip_package/setup.py": [
        [
          "_get_requirements",
          41,
          60,
          49,
          8,
          50,
          62,
          49,
          8,
          51,
          17
        ]
      ],
      "models/official/vision/dataloaders/tf_example_label_map_decoder_test.py": [
        [
          "test_result_content",
          78,
          183,
          82,
          10,
          82,
          34,
          78,
          27,
          183,
          57
        ],
        [
          "test_result_shape",
          39,
          76,
          43,
          10,
          43,
          34,
          39,
          25,
          76,
          74
        ]
      ],
      "models/research/seq_flow_lite/utils/tflite_utils.py": [
        [
          "_dump_graph_in_text_format",
          19,
          27,
          21,
          7,
          21,
          25,
          19,
          32,
          23,
          28
        ]
      ],
      "models/research/seq_flow_lite/models/sgnn/train.py": [
        [
          "save_and_convert",
          80,
          91,
          90,
          8,
          90,
          59,
          80,
          22,
          91,
          17
        ]
      ],
      "models/official/legacy/transformer/transformer_main_test.py": [
        [
          "_generate_file",
          34,
          37,
          35,
          8,
          35,
          26,
          34,
          20,
          36,
          18
        ]
      ],
      "models/research/vid2depth/util.py": [
        [
          "read_text_lines",
          117,
          121,
          118,
          8,
          118,
          26,
          117,
          21,
          121,
          14
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils.py": [
        [
          "_read_csv_to_list",
          127,
          145,
          141,
          8,
          141,
          27,
          127,
          23,
          143,
          21
        ]
      ],
      "models/research/lfads/utils.py": [
        [
          "write_data",
          170,
          202,
          187,
          16,
          187,
          36,
          187,
          16,
          189,
          20
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_files_paths_with_images",
          52,
          70,
          58,
          9,
          58,
          51,
          57,
          11,
          58,
          59
        ],
        [
          "test_files_paths_with_no_images",
          72,
          80,
          77,
          9,
          77,
          51,
          76,
          11,
          77,
          59
        ]
      ],
      "models/official/projects/waste_identification_ml/pre_processing/config/visualization.py": [
        [
          "data_creation",
          24,
          50,
          34,
          8,
          34,
          17,
          24,
          19,
          50,
          11
        ]
      ],
      "models/research/audioset/yamnet/yamnet.py": [
        [
          "class_names",
          131,
          138,
          135,
          8,
          135,
          26,
          135,
          8,
          138,
          70
        ]
      ],
      "models/official/projects/yolo/tasks/yolo.py": [
        [
          "generate_anchors",
          71,
          107,
          101,
          10,
          101,
          33,
          71,
          24,
          107,
          16
        ]
      ],
      "models/official/projects/yolo/tasks/yolov7.py": [
        [
          "generate_anchors",
          98,
          134,
          128,
          10,
          128,
          33,
          98,
          24,
          134,
          16
        ]
      ]
    },
    "tempfile.NamedTemporaryFile": {
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py": [
        [
          "InMemoryTFRecord",
          42,
          51,
          43,
          10,
          43,
          50,
          42,
          22,
          46,
          11
        ]
      ],
      "models/official/nlp/metrics/bleu_test.py": [
        [
          "_create_temp_file",
          26,
          30,
          27,
          17,
          27,
          57,
          26,
          25,
          30,
          25
        ]
      ],
      "models/official/nlp/data/classifier_data_lib_test.py": [
        [
          "setUp",
          35,
          53,
          49,
          10,
          49,
          50,
          35,
          13,
          53,
          18
        ]
      ],
      "models/official/legacy/transformer/compute_bleu_test.py": [
        [
          "_create_temp_file",
          26,
          30,
          27,
          17,
          27,
          57,
          26,
          25,
          30,
          25
        ]
      ],
      "models/research/lstm_object_detection/export_tflite_lstd_graph_lib.py": [
        [
          "export_tflite_graph",
          152,
          327,
          287,
          33,
          287,
          61,
          286,
          37,
          291,
          21
        ]
      ],
      "models/research/object_detection/export_tflite_ssd_graph_lib.py": [
        [
          "export_tflite_graph",
          157,
          333,
          287,
          33,
          287,
          61,
          286,
          37,
          291,
          21
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "_export_inference_graph",
          488,
          573,
          528,
          34,
          528,
          62,
          527,
          41,
          528,
          30
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py": [
        [
          "InMemoryTFRecord",
          95,
          104,
          96,
          10,
          96,
          50,
          95,
          22,
          99,
          11
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py": [
        [
          "InMemoryTFRecord",
          101,
          110,
          102,
          10,
          102,
          50,
          101,
          22,
          105,
          11
        ]
      ],
      "models/official/legacy/transformer/utils/tokenizer_test.py": [
        [
          "_init_subtokenizer",
          27,
          33,
          28,
          17,
          28,
          57,
          27,
          26,
          30,
          32
        ]
      ],
      "models/official/nlp/tools/tokenization_test.py": [
        [
          "test_full_tokenizer",
          31,
          52,
          36,
          10,
          36,
          50,
          31,
          27,
          37,
          16
        ]
      ],
      "models/official/nlp/data/train_sentencepiece.py": [
        [
          "dump_chars_to_textfile",
          60,
          85,
          74,
          8,
          74,
          48,
          60,
          28,
          75,
          14
        ]
      ],
      "models/official/legacy/transformer/transformer_main.py": [
        [
          "translate_and_compute_bleu",
          49,
          88,
          72,
          9,
          72,
          49,
          49,
          32,
          88,
          35
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_load_labels",
          26,
          50,
          28,
          10,
          28,
          61,
          26,
          24,
          34,
          46
        ]
      ]
    },
    "tempfile.mkdtemp": {
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py": [
        [
          "test_beam_pipeline",
          335,
          363,
          339,
          18,
          339,
          68,
          335,
          26,
          359,
          35
        ],
        [
          "test_beam_pipeline_sequence_example",
          365,
          395,
          369,
          18,
          369,
          68,
          365,
          43,
          390,
          35
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py": [
        [
          "test_beam_pipeline",
          165,
          186,
          167,
          16,
          167,
          66,
          165,
          26,
          182,
          33
        ],
        [
          "test_beam_pipeline_bbox",
          188,
          210,
          190,
          16,
          190,
          66,
          188,
          31,
          206,
          33
        ]
      ],
      "models/official/nlp/data/create_xlnet_pretraining_data_test.py": [
        [
          "_create_files",
          32,
          44,
          35,
          14,
          35,
          43,
          33,
          5,
          38,
          49
        ],
        [
          "test_end_to_end",
          317,
          349,
          331,
          16,
          331,
          56,
          317,
          23,
          349,
          54
        ]
      ],
      "models/official/recommendation/data_pipeline.py": [
        [
          "__init__",
          372,
          459,
          439,
          39,
          439,
          69,
          439,
          39,
          439,
          69
        ]
      ],
      "models/official/nlp/tools/export_tfhub_lib_test.py": [
        [
          "_make_vocab_file",
          491,
          521,
          515,
          9,
          517,
          39,
          491,
          24,
          521,
          15
        ],
        [
          "_make_sp_model_file",
          523,
          571,
          544,
          9,
          544,
          49,
          523,
          27,
          550,
          36
        ],
        [
          "_do_export",
          573,
          599,
          582,
          19,
          582,
          59,
          573,
          18,
          584,
          19
        ]
      ],
      "models/research/object_detection/exporter.py": [
        [
          "_export_inference_graph",
          488,
          573,
          530,
          34,
          530,
          51,
          530,
          34,
          530,
          30
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py": [
        [
          "test_beam_pipeline",
          234,
          256,
          236,
          18,
          236,
          68,
          234,
          26,
          252,
          35
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py": [
        [
          "test_beam_pipeline",
          301,
          327,
          303,
          18,
          303,
          68,
          301,
          26,
          323,
          35
        ]
      ],
      "models/research/adversarial_text/graphs_test.py": [
        [
          "setUpClass",
          80,
          135,
          92,
          22,
          92,
          39,
          80,
          18,
          121,
          52
        ]
      ],
      "models/official/utils/testing/integration.py": [
        [
          "run_synthetic",
          29,
          70,
          52,
          15,
          52,
          44,
          50,
          17,
          56,
          10
        ]
      ],
      "models/research/object_detection/model_lib_tf2_test.py": [
        [
          "test_checkpoint_max_to_keep",
          161,
          183,
          168,
          19,
          168,
          59,
          161,
          35,
          183,
          64
        ]
      ],
      "models/official/legacy/bert/model_training_utils.py": [
        [
          "_save_checkpoint",
          39,
          54,
          51,
          15,
          51,
          32,
          51,
          15,
          53,
          31
        ],
        [
          "run_customized_training_loop",
          107,
          590,
          308,
          21,
          308,
          38,
          308,
          21,
          308,
          17
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "_download_and_clean",
          90,
          142,
          114,
          14,
          114,
          31,
          112,
          9,
          116,
          17
        ]
      ],
      "models/official/projects/qat/nlp/pretrained_checkpoint_converter.py": [
        [
          "_build_model",
          84,
          96,
          95,
          57,
          95,
          74,
          95,
          10,
          96,
          27
        ]
      ],
      "models/official/nlp/modeling/layers/text_layers_test.py": [
        [
          "_make_vocab_file",
          33,
          39,
          35,
          9,
          35,
          49,
          33,
          24,
          39,
          15
        ],
        [
          "setUp",
          136,
          157,
          140,
          5,
          140,
          33,
          136,
          13,
          157,
          18
        ],
        [
          "test_saving",
          294,
          301,
          300,
          19,
          300,
          59,
          294,
          19,
          301,
          42
        ],
        [
          "_make_vocab_file",
          449,
          455,
          451,
          9,
          451,
          49,
          449,
          24,
          455,
          15
        ]
      ],
      "models/official/core/train_lib.py": [
        [
          "_maybe_build_checkpoint_manager",
          162,
          191,
          179,
          21,
          179,
          38,
          179,
          21,
          180,
          19
        ]
      ]
    },
    "tempfile.mkstemp": {
      "models/official/vision/evaluation/coco_evaluator.py": [
        [
          "__init__",
          43,
          131,
          82,
          29,
          82,
          60,
          82,
          29,
          86,
          59
        ]
      ],
      "models/official/legacy/detection/evaluation/coco_evaluator.py": [
        [
          "__init__",
          311,
          362,
          330,
          29,
          330,
          60,
          330,
          29,
          334,
          59
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "download_and_extract",
          55,
          84,
          66,
          21,
          66,
          54,
          66,
          21,
          69,
          11
        ]
      ],
      "models/research/efficient-hrl/environments/maze_env.py": [
        [
          "__init__",
          37,
          234,
          231,
          20,
          231,
          61,
          231,
          20,
          234,
          20
        ]
      ]
    },
    "tempfile.TemporaryDirectory": {
      "models/official/nlp/tools/export_tfhub_lib.py": [
        [
          "export_preprocessing",
          406,
          429,
          415,
          8,
          415,
          36,
          406,
          26,
          425,
          34
        ]
      ],
      "models/official/projects/edgetpu/nlp/serving/export_tflite_squad.py": [
        [
          "main",
          108,
          177,
          145,
          13,
          145,
          41,
          138,
          23,
          165,
          60
        ]
      ],
      "models/official/projects/edgetpu/vision/tasks/image_classification.py": [
        [
          "load_searched_model",
          66,
          88,
          78,
          8,
          78,
          36,
          66,
          25,
          79,
          42
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/utils_test.py": [
        [
          "test_files_paths_with_no_images",
          72,
          80,
          73,
          10,
          73,
          38,
          72,
          39,
          76,
          31
        ],
        [
          "test_files_paths_with_images",
          52,
          70,
          54,
          10,
          54,
          38,
          52,
          36,
          57,
          31
        ],
        [
          "test_files_paths_empty_folder",
          82,
          85,
          83,
          10,
          83,
          38,
          82,
          37,
          85,
          34
        ]
      ]
    },
    "tempfile.gettempdir": {
      "models/official/projects/pruning/tasks/image_classification_test.py": [
        [
          "testTaskWithUnstructuredSparsity",
          104,
          145,
          136,
          22,
          136,
          42,
          135,
          7,
          136,
          77
        ],
        [
          "testTaskWithStructuredSparsity",
          149,
          197,
          184,
          20,
          184,
          40,
          183,
          23,
          197,
          35
        ]
      ],
      "models/research/delf/delf/python/training/model/resnet50.py": [
        [
          "restore_weights",
          400,
          446,
          418,
          33,
          418,
          53,
          417,
          22,
          427,
          30
        ]
      ]
    }
  },
  "CWE-502": {
    "PIL.Image.open": {
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py": [
        [
          "_resize_image",
          134,
          185,
          162,
          13,
          162,
          42,
          134,
          21,
          185,
          24
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_api/app.py": [
        [
          "predict",
          48,
          90,
          61,
          15,
          61,
          52,
          61,
          15,
          61,
          52
        ]
      ],
      "models/official/vision/evaluation/coco_utils.py": [
        [
          "convert_groundtruths_to_coco_dataset",
          190,
          316,
          266,
          20,
          267,
          68,
          266,
          20,
          266,
          16
        ],
        [
          "convert_groundtruths_to_coco_dataset",
          190,
          316,
          269,
          20,
          270,
          60,
          269,
          20,
          269,
          16
        ]
      ],
      "models/official/legacy/detection/evaluation/coco_utils.py": [
        [
          "convert_groundtruths_to_coco_dataset",
          175,
          263,
          240,
          18,
          240,
          72,
          240,
          18,
          245,
          40
        ]
      ],
      "models/research/deeplab/convert_to_tflite.py": [
        [
          "check_tflite_consistency",
          64,
          94,
          75,
          13,
          75,
          25,
          64,
          30,
          94,
          52
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record_test.py": [
        [
          "listcomp",
          195,
          196,
          196,
          18,
          196,
          49,
          197,
          13,
          196,
          50
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py": [
        [
          "process",
          80,
          225,
          111,
          15,
          111,
          44,
          111,
          30,
          111,
          44
        ]
      ],
      "models/research/object_detection/dataset_tools/create_kitti_tf_record.py": [
        [
          "prepare_example",
          138,
          205,
          153,
          11,
          153,
          34,
          138,
          21,
          205,
          16
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record.py": [
        [
          "create_tf_example",
          112,
          359,
          175,
          11,
          175,
          40,
          112,
          23,
          206,
          44
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pascal_tf_record.py": [
        [
          "dict_to_tf_example",
          59,
          144,
          90,
          11,
          90,
          40,
          59,
          24,
          91,
          27
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "dict_to_tf_example",
          76,
          211,
          112,
          11,
          112,
          40,
          76,
          24,
          113,
          27
        ],
        [
          "dict_to_tf_example",
          76,
          211,
          120,
          10,
          120,
          39,
          115,
          9,
          121,
          25
        ]
      ],
      "models/research/attention_ocr/python/demo_inference.py": [
        [
          "load_images",
          45,
          54,
          52,
          17,
          52,
          61,
          49,
          7,
          53,
          30
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords_lib.py": [
        [
          "_create_tf_example",
          217,
          287,
          246,
          11,
          246,
          40,
          217,
          24,
          250,
          35
        ]
      ],
      "models/research/deeplab/evaluation/eval_coco_format.py": [
        [
          "_open_panoptic_id_image",
          131,
          134,
          134,
          16,
          134,
          37,
          131,
          29,
          134,
          56
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/ffmpeg_ops.py": [
        [
          "get_image_creation_time",
          72,
          106,
          85,
          13,
          85,
          34,
          85,
          24,
          85,
          34
        ]
      ],
      "models/official/vision/data/image_utils.py": [
        [
          "decode_image",
          84,
          94,
          90,
          15,
          90,
          49,
          90,
          15,
          92,
          28
        ]
      ],
      "models/research/deeplab/datasets/remove_gt_colormap.py": [
        [
          "_remove_colormap",
          42,
          51,
          51,
          19,
          51,
          38,
          42,
          22,
          51,
          39
        ]
      ],
      "models/official/vision/data/tfrecord_lib.py": [
        [
          "read_image",
          106,
          108,
          107,
          15,
          107,
          36,
          106,
          16,
          108,
          30
        ]
      ],
      "models/research/attention_ocr/python/datasets/unittest_utils_test.py": [
        [
          "test_encoded_image_corresponds_to_numpy_array",
          31,
          34,
          33,
          17,
          33,
          50,
          31,
          53,
          34,
          51
        ]
      ],
      "models/research/delf/delf/python/utils.py": [
        [
          "RgbLoader",
          30,
          41,
          40,
          11,
          40,
          23,
          30,
          15,
          41,
          29
        ]
      ],
      "models/research/object_detection/utils/visualization_utils_test.py": [
        [
          "test_draw_bounding_boxes_on_image_tensors",
          164,
          206,
          168,
          25,
          168,
          41,
          164,
          49,
          201,
          49
        ],
        [
          "test_draw_bounding_boxes_on_image_tensors_with_track_ids",
          208,
          253,
          213,
          25,
          213,
          41,
          208,
          64,
          248,
          49
        ]
      ]
    },
    "json.load": {
      "models/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py": [
        [
          "__init__",
          379,
          445,
          431,
          35,
          431,
          46,
          430,
          12,
          431,
          31
        ]
      ],
      "models/research/cognitive_planning/envs/active_vision_dataset_env.py": [
        [
          "__init__",
          315,
          510,
          423,
          34,
          423,
          46,
          418,
          9,
          423,
          30
        ]
      ],
      "models/research/deeplab/common.py": [
        [
          "__new__",
          213,
          288,
          236,
          40,
          236,
          51,
          235,
          12,
          236,
          36
        ]
      ],
      "models/official/projects/unified_detector/data_conversion/convert.py": [
        [
          "main",
          44,
          61,
          45,
          17,
          45,
          47,
          44,
          10,
          51,
          41
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py": [
        [
          "load_json_data",
          228,
          231,
          230,
          17,
          230,
          30,
          228,
          20,
          231,
          18
        ]
      ],
      "models/official/vision/data/create_coco_tf_record.py": [
        [
          "_load_object_annotations",
          364,
          387,
          367,
          23,
          367,
          36,
          364,
          30,
          375,
          50
        ],
        [
          "_load_caption_annotations",
          390,
          410,
          393,
          27,
          393,
          40,
          390,
          31,
          397,
          54
        ],
        [
          "_load_panoptic_annotations",
          413,
          437,
          416,
          28,
          416,
          41,
          413,
          32,
          420,
          55
        ],
        [
          "_load_images_info",
          440,
          443,
          442,
          17,
          442,
          30,
          440,
          23,
          443,
          28
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record.py": [
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          393,
          24,
          393,
          37,
          362,
          45,
          399,
          40
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          418,
          37,
          418,
          50,
          417,
          12,
          419,
          51
        ],
        [
          "_create_tf_record_from_coco_annotations",
          362,
          473,
          429,
          38,
          429,
          51,
          428,
          12,
          430,
          52
        ]
      ],
      "models/official/projects/triviaqa/dataset.py": [
        [
          "process",
          361,
          367,
          363,
          14,
          363,
          25,
          361,
          15,
          364,
          32
        ]
      ],
      "models/official/legacy/xlnet/data_utils.py": [
        [
          "get_pretrain_input_data",
          579,
          683,
          642,
          16,
          642,
          28,
          640,
          9,
          644,
          36
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "load_intrinsics",
          514,
          533,
          521,
          16,
          521,
          27,
          514,
          23,
          528,
          23
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords_lib.py": [
        [
          "create_visual_wakeword_annotations",
          87,
          141,
          106,
          24,
          106,
          37,
          87,
          40,
          110,
          50
        ],
        [
          "create_tf_record_for_visualwakewords_dataset",
          188,
          214,
          202,
          24,
          202,
          37,
          188,
          50,
          208,
          39
        ]
      ],
      "models/research/deeplab/evaluation/eval_coco_format.py": [
        [
          "eval_coco_format",
          222,
          321,
          269,
          15,
          269,
          35,
          222,
          22,
          272,
          22
        ],
        [
          "eval_coco_format",
          222,
          321,
          271,
          17,
          271,
          39,
          222,
          22,
          272,
          22
        ]
      ],
      "models/official/projects/triviaqa/evaluate.py": [
        [
          "main",
          34,
          43,
          39,
          59,
          39,
          70,
          37,
          8,
          43,
          71
        ],
        [
          "main",
          34,
          43,
          42,
          19,
          42,
          30,
          37,
          8,
          43,
          71
        ]
      ],
      "models/orbit/actions/new_best_metric.py": [
        [
          "__init__",
          175,
          207,
          202,
          27,
          202,
          38,
          201,
          16,
          202,
          23
        ]
      ],
      "models/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py": [
        [
          "main",
          192,
          223,
          197,
          17,
          197,
          28,
          192,
          10,
          200,
          31
        ]
      ],
      "models/official/projects/triviaqa/preprocess.py": [
        [
          "read_question_answers",
          125,
          148,
          128,
          12,
          128,
          23,
          125,
          27,
          130,
          19
        ]
      ],
      "models/official/legacy/xlnet/preprocess_pretrain_data.py": [
        [
          "get_input_fn",
          850,
          958,
          905,
          16,
          905,
          28,
          904,
          12,
          906,
          33
        ]
      ],
      "models/official/vision/data/process_coco_few_shot_json_files.py": [
        [
          "main",
          87,
          139,
          94,
          19,
          94,
          30,
          91,
          7,
          101,
          29
        ],
        [
          "main",
          87,
          139,
          110,
          27,
          110,
          38,
          108,
          9,
          110,
          39
        ]
      ],
      "models/official/nlp/tasks/question_answering.py": [
        [
          "reduce_aggregated_logs",
          283,
          320,
          301,
          22,
          301,
          38,
          283,
          30,
          303,
          63
        ]
      ],
      "models/official/projects/nhnet/raw_data_processor.py": [
        [
          "_get_article_content_from_json",
          125,
          137,
          128,
          17,
          128,
          44,
          125,
          38,
          129,
          46
        ],
        [
          "generate_examples",
          86,
          110,
          94,
          17,
          94,
          42,
          93,
          10,
          96,
          26
        ]
      ],
      "models/official/legacy/xlnet/run_squad.py": [
        [
          "main",
          212,
          290,
          271,
          21,
          271,
          32,
          270,
          8,
          290,
          34
        ]
      ],
      "models/official/legacy/bert/run_squad_helper.py": [
        [
          "eval_squad",
          419,
          450,
          443,
          20,
          443,
          36,
          434,
          17,
          445,
          58
        ]
      ],
      "models/official/nlp/data/squad_lib_sp.py": [
        [
          "read_squad_examples",
          112,
          162,
          119,
          18,
          119,
          34,
          112,
          25,
          121,
          40
        ],
        [
          "read_squad_examples",
          112,
          162,
          126,
          27,
          126,
          43,
          124,
          9,
          126,
          52
        ]
      ],
      "models/official/nlp/data/squad_lib.py": [
        [
          "read_squad_examples",
          161,
          249,
          166,
          18,
          166,
          34,
          161,
          25,
          168,
          40
        ],
        [
          "read_squad_examples",
          161,
          249,
          173,
          27,
          173,
          43,
          171,
          9,
          173,
          52
        ]
      ],
      "models/official/legacy/xlnet/squad_utils.py": [
        [
          "read_squad_examples",
          434,
          473,
          437,
          18,
          437,
          34,
          434,
          25,
          440,
          25
        ]
      ],
      "models/official/projects/triviaqa/train.py": [
        [
          "read_model_config",
          125,
          147,
          130,
          20,
          130,
          31,
          125,
          23,
          131,
          54
        ],
        [
          "main",
          278,
          376,
          351,
          59,
          351,
          70,
          317,
          8,
          376,
          46
        ]
      ],
      "models/official/projects/waste_identification_ml/pre_processing/config/visualization.py": [
        [
          "data_creation",
          24,
          50,
          35,
          12,
          35,
          31,
          24,
          19,
          50,
          11
        ]
      ],
      "models/official/legacy/xlnet/xlnet_config.py": [
        [
          "init_from_json",
          102,
          105,
          104,
          19,
          104,
          30,
          102,
          22,
          105,
          36
        ]
      ]
    },
    "numpy.load": {
      "models/research/cognitive_planning/envs/active_vision_dataset_env.py": [
        [
          "read_cached_data",
          229,
          302,
          254,
          30,
          254,
          39,
          229,
          22,
          262,
          27
        ],
        [
          "read_cached_data",
          229,
          302,
          259,
          18,
          259,
          27,
          229,
          22,
          262,
          27
        ],
        [
          "read_cached_data",
          229,
          302,
          278,
          17,
          278,
          26,
          272,
          47,
          281,
          26
        ],
        [
          "read_cached_data",
          229,
          302,
          294,
          20,
          294,
          29,
          291,
          18,
          296,
          45
        ],
        [
          "read_cached_data",
          229,
          302,
          299,
          36,
          299,
          45,
          298,
          8,
          302,
          20
        ],
        [
          "__init__",
          315,
          510,
          462,
          16,
          462,
          35,
          458,
          31,
          464,
          31
        ],
        [
          "_reset_env",
          829,
          913,
          891,
          50,
          891,
          59,
          886,
          12,
          891,
          46
        ]
      ],
      "models/official/projects/videoglue/tools/checkpoint_loader.py": [
        [
          "_customized_vmae_initialize",
          135,
          195,
          140,
          17,
          140,
          48,
          135,
          35,
          147,
          30
        ]
      ],
      "models/research/rebar/datasets.py": [
        [
          "read_MNIST",
          42,
          61,
          59,
          17,
          59,
          26,
          58,
          10,
          59,
          13
        ]
      ],
      "models/official/legacy/detection/modeling/architecture/heads.py": [
        [
          "_get_priors",
          946,
          962,
          951,
          16,
          951,
          71,
          951,
          16,
          953,
          24
        ]
      ],
      "models/research/vid2depth/ops/icp_test.py": [
        [
          "_load_lidar_cloud",
          84,
          90,
          87,
          19,
          87,
          43,
          84,
          25,
          90,
          22
        ]
      ],
      "models/research/vid2depth/ops/icp_train_demo.py": [
        [
          "setup",
          60,
          74,
          64,
          24,
          64,
          48,
          60,
          13,
          74,
          44
        ]
      ],
      "models/research/audioset/vggish/vggish_postprocess.py": [
        [
          "__init__",
          35,
          50,
          42,
          14,
          42,
          41,
          35,
          16,
          47,
          67
        ]
      ],
      "models/research/cognitive_planning/viz_active_vision_dataset_main.py": [
        [
          "compute_acc",
          280,
          287,
          282,
          14,
          282,
          23,
          280,
          19,
          283,
          41
        ],
        [
          "visualize",
          223,
          274,
          261,
          16,
          261,
          25,
          254,
          11,
          265,
          37
        ]
      ]
    },
    "tensorflow.saved_model.load": {
      "models/official/projects/waste_identification_ml/docker_solution/prediction_api/app_utils.py": [
        [
          "load_model",
          72,
          89,
          86,
          15,
          86,
          47,
          73,
          7,
          89,
          25
        ]
      ],
      "models/official/vision/serving/detection_test.py": [
        [
          "test_export",
          112,
          157,
          134,
          16,
          134,
          43,
          113,
          7,
          148,
          41
        ],
        [
          "test_export_retinanet_with_intermediate_features",
          166,
          193,
          175,
          16,
          175,
          43,
          166,
          56,
          193,
          5
        ],
        [
          "test_export_normalized_coordinates_no_nms",
          205,
          236,
          221,
          16,
          221,
          43,
          206,
          7,
          236,
          5
        ],
        [
          "test_export_without_decoding_boxes",
          242,
          271,
          257,
          16,
          257,
          43,
          243,
          7,
          271,
          5
        ]
      ],
      "models/research/delf/delf/python/examples/detector.py": [
        [
          "MakeDetector",
          24,
          55,
          33,
          11,
          33,
          40,
          24,
          18,
          55,
          19
        ]
      ],
      "models/official/projects/deepmac_maskrcnn/serving/detection_test.py": [
        [
          "test_export",
          72,
          109,
          87,
          16,
          87,
          43,
          72,
          19,
          98,
          42
        ],
        [
          "test_export_image_and_boxes",
          117,
          160,
          131,
          16,
          131,
          43,
          117,
          35,
          145,
          42
        ]
      ],
      "models/official/vision/serving/export_base_v2_test.py": [
        [
          "test_preprocessor",
          36,
          60,
          56,
          16,
          56,
          46,
          36,
          25,
          60,
          70
        ],
        [
          "test_postprocessor",
          62,
          85,
          82,
          16,
          82,
          46,
          62,
          26,
          85,
          70
        ]
      ],
      "models/official/core/export_base_test.py": [
        [
          "test_export_module",
          42,
          66,
          64,
          16,
          64,
          46,
          42,
          26,
          66,
          75
        ],
        [
          "test_custom_inference_step",
          68,
          88,
          86,
          16,
          86,
          46,
          68,
          34,
          88,
          75
        ]
      ],
      "models/research/audioset/yamnet/export.py": [
        [
          "make_tflite_export",
          138,
          183,
          162,
          11,
          162,
          46,
          145,
          3,
          183,
          24
        ]
      ],
      "models/official/vision/serving/export_module_factory_test.py": [
        [
          "test_export",
          68,
          113,
          89,
          16,
          89,
          46,
          68,
          19,
          113,
          76
        ]
      ],
      "models/official/projects/detr/serving/export_module_test.py": [
        [
          "test_export",
          72,
          94,
          85,
          16,
          85,
          43,
          72,
          19,
          94,
          50
        ]
      ],
      "models/official/nlp/serving/export_savedmodel_test.py": [
        [
          "test_sentence_prediction",
          43,
          74,
          63,
          16,
          63,
          46,
          43,
          32,
          74,
          54
        ],
        [
          "test_masked_lm",
          76,
          116,
          105,
          16,
          105,
          46,
          76,
          22,
          116,
          61
        ],
        [
          "test_tagging",
          119,
          160,
          147,
          16,
          147,
          46,
          119,
          20,
          159,
          29
        ]
      ],
      "models/orbit/actions/export_saved_model_test.py": [
        [
          "test_export_saved_model",
          250,
          278,
          263,
          22,
          263,
          72,
          250,
          31,
          278,
          41
        ],
        [
          "test_export_saved_model",
          250,
          278,
          270,
          22,
          270,
          72,
          250,
          31,
          278,
          41
        ],
        [
          "test_export_saved_model",
          250,
          278,
          277,
          22,
          277,
          72,
          250,
          31,
          278,
          41
        ]
      ],
      "models/official/nlp/tools/export_tfhub_lib_test.py": [
        [
          "test_exported_callables",
          611,
          699,
          612,
          18,
          620,
          39,
          611,
          31,
          642,
          44
        ],
        [
          "test_cased_length10",
          704,
          748,
          705,
          18,
          711,
          59,
          704,
          27,
          748,
          54
        ],
        [
          "test_shapes",
          756,
          801,
          757,
          18,
          765,
          39,
          756,
          19,
          773,
          31
        ],
        [
          "test_reexport",
          804,
          835,
          814,
          14,
          814,
          39,
          804,
          21,
          835,
          54
        ],
        [
          "test_reexport",
          804,
          835,
          820,
          14,
          820,
          39,
          804,
          21,
          835,
          54
        ],
        [
          "test_preprocessing_for_mlm",
          838,
          977,
          846,
          18,
          853,
          39,
          838,
          34,
          854,
          57
        ],
        [
          "test_preprocessing_for_mlm",
          838,
          977,
          882,
          15,
          882,
          54,
          854,
          45,
          952,
          30
        ],
        [
          "input_fn",
          1006,
          1024,
          1010,
          20,
          1010,
          62,
          1007,
          7,
          1013,
          45
        ]
      ],
      "models/research/delf/delf/python/examples/extractor.py": [
        [
          "MakeExtractor",
          34,
          262,
          52,
          11,
          52,
          48,
          52,
          11,
          63,
          30
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_detection_data.py": [
        [
          "_load_inference_model",
          84,
          89,
          89,
          25,
          89,
          60,
          84,
          29,
          89,
          21
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py": [
        [
          "_load_inference_model",
          165,
          170,
          170,
          25,
          170,
          60,
          165,
          29,
          170,
          21
        ]
      ],
      "models/official/vision/serving/image_classification_test.py": [
        [
          "test_multi_size_images_inference",
          133,
          176,
          152,
          16,
          152,
          43,
          133,
          40,
          158,
          29
        ],
        [
          "test_export",
          83,
          127,
          102,
          16,
          102,
          43,
          83,
          19,
          106,
          29
        ]
      ],
      "models/official/projects/pointpillars/utils/model_exporter.py": [
        [
          "load_model_predict_fn",
          79,
          91,
          88,
          11,
          88,
          41,
          79,
          27,
          91,
          19
        ]
      ],
      "models/official/projects/volumetric_models/serving/semantic_segmentation_3d_test.py": [
        [
          "test_export",
          80,
          108,
          97,
          16,
          97,
          43,
          80,
          19,
          108,
          58
        ]
      ],
      "models/official/vision/serving/semantic_segmentation_test.py": [
        [
          "test_export_with_extra_input_channels",
          137,
          193,
          168,
          16,
          168,
          43,
          137,
          45,
          173,
          29
        ],
        [
          "test_export",
          89,
          131,
          107,
          16,
          107,
          43,
          89,
          19,
          111,
          29
        ]
      ],
      "models/official/nlp/serving/serving_modules_test.py": [
        [
          "test_translation",
          350,
          387,
          384,
          14,
          384,
          44,
          350,
          24,
          387,
          38
        ]
      ],
      "models/official/legacy/transformer/transformer_test.py": [
        [
          "test_export",
          63,
          94,
          87,
          16,
          87,
          46,
          63,
          19,
          94,
          70
        ]
      ],
      "models/official/vision/serving/video_classification_test.py": [
        [
          "test_export",
          76,
          109,
          90,
          16,
          90,
          43,
          76,
          19,
          109,
          68
        ]
      ]
    },
    "yaml.load": {
      "models/official/modeling/hyperparams/base_config.py": [
        [
          "from_yaml",
          336,
          342,
          339,
          16,
          339,
          51,
          336,
          17,
          342,
          19
        ]
      ],
      "models/official/nlp/serving/export_savedmodel.py": [
        [
          "main",
          122,
          162,
          123,
          20,
          125,
          29,
          122,
          10,
          137,
          22
        ]
      ],
      "models/official/modeling/hyperparams/params_dict_test.py": [
        [
          "test_save_params_dict_to_yaml",
          215,
          232,
          228,
          18,
          228,
          49,
          215,
          37,
          232,
          56
        ],
        [
          "test_basic_csv_str_load",
          368,
          373,
          372,
          22,
          372,
          69,
          368,
          31,
          373,
          57
        ],
        [
          "test_basic_nested_csv_str_load",
          381,
          386,
          385,
          22,
          385,
          69,
          381,
          38,
          386,
          57
        ],
        [
          "test_complex_nested_csv_str_load",
          394,
          399,
          398,
          22,
          398,
          69,
          394,
          40,
          399,
          57
        ],
        [
          "test_csv_str_load_supported_datatypes",
          418,
          426,
          421,
          22,
          421,
          69,
          418,
          45,
          426,
          48
        ]
      ],
      "models/official/modeling/hyperparams/params_dict.py": [
        [
          "read_yaml_to_params_dict",
          332,
          336,
          335,
          19,
          335,
          46,
          332,
          30,
          336,
          34
        ],
        [
          "override_params_dict",
          455,
          497,
          489,
          19,
          489,
          72,
          489,
          19,
          490,
          36
        ],
        [
          "override_params_dict",
          455,
          497,
          494,
          25,
          494,
          52,
          493,
          12,
          494,
          64
        ]
      ]
    },
    "json.loads": {
      "models/official/nlp/finetuning/binary_helper.py": [
        [
          "load_model_config_file",
          81,
          140,
          99,
          14,
          99,
          29,
          93,
          3,
          140,
          3
        ]
      ],
      "models/official/nlp/data/classifier_data_lib.py": [
        [
          "_read_jsonl",
          124,
          130,
          129,
          22,
          129,
          41,
          128,
          11,
          129,
          42
        ]
      ],
      "models/research/object_detection/metrics/coco_tools_test.py": [
        [
          "testExportGroundtruthToCOCO",
          81,
          103,
          102,
          24,
          102,
          49,
          81,
          35,
          103,
          52
        ],
        [
          "testExportDetectionsToCOCO",
          105,
          129,
          128,
          24,
          128,
          49,
          105,
          34,
          129,
          52
        ],
        [
          "testExportSegmentsToCOCO",
          131,
          161,
          158,
          24,
          158,
          49,
          142,
          25,
          161,
          52
        ],
        [
          "testExportKeypointsToCOCO",
          163,
          193,
          192,
          24,
          192,
          49,
          163,
          33,
          193,
          52
        ]
      ],
      "models/official/legacy/bert/configs.py": [
        [
          "from_json_file",
          91,
          95,
          95,
          26,
          95,
          41,
          91,
          22,
          95,
          42
        ]
      ],
      "models/official/common/distribute_utils.py": [
        [
          "configure_cluster",
          207,
          239,
          217,
          15,
          217,
          59,
          207,
          23,
          218,
          14
        ]
      ],
      "models/research/seq_flow_lite/export_to_tflite.py": [
        [
          "load_runner_config",
          36,
          39,
          39,
          12,
          39,
          31,
          37,
          12,
          39,
          31
        ]
      ],
      "models/official/recommendation/uplift/keras_test_case.py": [
        [
          "assertLayerConfigurable",
          150,
          170,
          165,
          41,
          165,
          70,
          165,
          41,
          165,
          70
        ]
      ],
      "models/official/projects/mobilebert/model_utils.py": [
        [
          "from_json_file",
          121,
          125,
          125,
          26,
          125,
          41,
          121,
          22,
          125,
          42
        ]
      ],
      "models/official/recommendation/ncf_keras_main.py": [
        [
          "run_ncf",
          207,
          346,
          250,
          25,
          250,
          65,
          248,
          5,
          252,
          15
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/predictor.py": [
        [
          "send_image_for_prediction",
          40,
          67,
          62,
          16,
          62,
          42,
          62,
          16,
          62,
          42
        ]
      ],
      "models/official/legacy/bert/run_classifier.py": [
        [
          "custom_main",
          420,
          503,
          430,
          23,
          430,
          63,
          420,
          17,
          434,
          24
        ]
      ],
      "models/official/legacy/bert/run_squad.py": [
        [
          "main",
          90,
          141,
          94,
          23,
          94,
          63,
          90,
          10,
          96,
          32
        ]
      ],
      "models/official/nlp/finetuning/glue/run_glue.py": [
        [
          "main",
          236,
          278,
          249,
          23,
          249,
          63,
          240,
          3,
          253,
          34
        ]
      ],
      "models/official/nlp/finetuning/superglue/run_superglue.py": [
        [
          "main",
          173,
          214,
          186,
          23,
          186,
          63,
          177,
          3,
          190,
          33
        ]
      ],
      "models/research/lstm_object_detection/train.py": [
        [
          "main",
          88,
          181,
          140,
          9,
          140,
          53,
          112,
          18,
          142,
          62
        ]
      ],
      "models/research/object_detection/legacy/train.py": [
        [
          "main",
          90,
          182,
          127,
          9,
          127,
          53,
          112,
          18,
          129,
          62
        ]
      ],
      "models/official/core/train_utils_test.py": [
        [
          "test_export_best_eval_metric",
          183,
          194,
          191,
          16,
          191,
          40,
          183,
          36,
          194,
          77
        ],
        [
          "test_export_best_eval_metric_skips_non_scalar_values",
          196,
          211,
          208,
          16,
          208,
          40,
          196,
          60,
          211,
          77
        ]
      ],
      "models/research/seq_flow_lite/trainer.py": [
        [
          "load_runner_config",
          46,
          48,
          48,
          12,
          48,
          31,
          47,
          8,
          48,
          31
        ]
      ],
      "models/official/core/train_utils.py": [
        [
          "_maybe_load_best_eval_metric",
          187,
          191,
          191,
          14,
          191,
          38,
          190,
          10,
          191,
          38
        ]
      ],
      "models/research/seq_flow_lite/trainer_v2.py": [
        [
          "load_runner_config",
          44,
          46,
          46,
          12,
          46,
          31,
          45,
          8,
          46,
          31
        ]
      ]
    },
    "pandas.read_csv": {
      "models/research/delf/delf/python/training/build_image_dataset.py": [
        [
          "_get_all_image_files_and_labels",
          98,
          124,
          117,
          12,
          117,
          32,
          116,
          10,
          119,
          10
        ],
        [
          "_get_clean_train_image_files_and_labels",
          127,
          175,
          144,
          10,
          144,
          30,
          127,
          45,
          148,
          29
        ]
      ],
      "models/research/object_detection/dataset_tools/create_oid_tf_record.py": [
        [
          "main",
          66,
          113,
          78,
          25,
          78,
          68,
          77,
          15,
          79,
          44
        ],
        [
          "main",
          66,
          113,
          80,
          29,
          80,
          80,
          80,
          29,
          82,
          69
        ]
      ],
      "models/official/recommendation/data_preprocessing.py": [
        [
          "read_dataframe",
          43,
          115,
          70,
          10,
          70,
          23,
          44,
          5,
          93,
          53
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "csv_to_joint_dataframe",
          254,
          263,
          258,
          14,
          258,
          45,
          254,
          28,
          263,
          11
        ],
        [
          "ratings_csv_to_dataframe",
          249,
          251,
          251,
          12,
          251,
          43,
          249,
          30,
          251,
          43
        ]
      ],
      "models/research/object_detection/metrics/oid_challenge_evaluation.py": [
        [
          "main",
          96,
          145,
          103,
          30,
          103,
          71,
          96,
          10,
          109,
          33
        ],
        [
          "main",
          96,
          145,
          104,
          27,
          104,
          69,
          96,
          10,
          109,
          33
        ],
        [
          "main",
          96,
          145,
          111,
          28,
          111,
          68,
          110,
          37,
          116,
          28
        ],
        [
          "main",
          96,
          145,
          125,
          21,
          125,
          56,
          118,
          21,
          127,
          69
        ]
      ],
      "models/research/object_detection/metrics/oid_vrd_challenge_evaluation.py": [
        [
          "main",
          80,
          120,
          102,
          21,
          102,
          62,
          102,
          21,
          103,
          73
        ],
        [
          "main",
          80,
          120,
          81,
          25,
          81,
          72,
          80,
          10,
          92,
          69
        ],
        [
          "main",
          80,
          120,
          82,
          27,
          82,
          75,
          80,
          10,
          92,
          69
        ]
      ]
    },
    "lxml.etree.fromstring": {
      "models/research/object_detection/dataset_tools/create_pascal_tf_record.py": [
        [
          "main",
          147,
          181,
          174,
          13,
          174,
          37,
          171,
          14,
          179,
          50
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "create_tf_record",
          214,
          265,
          250,
          13,
          250,
          37,
          248,
          12,
          254,
          39
        ]
      ]
    },
    "pickle.load": {
      "models/official/recommendation/data_preprocessing.py": [
        [
          "_filter_index_sort",
          118,
          199,
          154,
          21,
          154,
          34,
          153,
          10,
          161,
          35
        ]
      ],
      "models/research/delf/delf/python/datasets/revisited_op/dataset.py": [
        [
          "CreateConfigForTestDataset",
          477,
          535,
          515,
          11,
          515,
          24,
          513,
          15,
          517,
          26
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_add_to_tfrecord",
          64,
          108,
          77,
          14,
          77,
          28,
          77,
          14,
          77,
          10
        ],
        [
          "_add_to_tfrecord",
          64,
          108,
          79,
          14,
          79,
          46,
          79,
          14,
          79,
          10
        ]
      ],
      "models/research/pcl_rl/expert_paths.py": [
        [
          "sample_expert_paths",
          31,
          44,
          39,
          18,
          39,
          31,
          38,
          10,
          41,
          40
        ]
      ],
      "models/research/delf/delf/python/training/model/global_model.py": [
        [
          "__init__",
          82,
          167,
          143,
          30,
          143,
          64,
          133,
          9,
          145,
          19
        ]
      ],
      "models/official/legacy/xlnet/run_squad.py": [
        [
          "main",
          212,
          290,
          259,
          23,
          259,
          36,
          257,
          5,
          260,
          52
        ]
      ],
      "models/research/delf/delf/python/datasets/sfm120k/sfm120k.py": [
        [
          "__init__",
          59,
          104,
          96,
          12,
          96,
          25,
          89,
          15,
          104,
          49
        ]
      ],
      "models/research/delf/delf/python/training/global_features/train_utils.py": [
        [
          "test_retrieval",
          201,
          343,
          244,
          29,
          244,
          63,
          240,
          7,
          244,
          25
        ],
        [
          "test_retrieval",
          201,
          343,
          257,
          14,
          257,
          27,
          247,
          15,
          294,
          73
        ]
      ],
      "models/research/delf/delf/python/datasets/tuples_dataset.py": [
        [
          "__init__",
          44,
          99,
          74,
          12,
          74,
          25,
          72,
          19,
          77,
          50
        ]
      ]
    },
    "ast.literal_eval": {
      "models/research/object_detection/exporter_lib_v2.py": [
        [
          "listcomp",
          60,
          61,
          61,
          7,
          61,
          37,
          61,
          43,
          61,
          37
        ]
      ]
    },
    "cv2.imread": {
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/mask_bbox_saver.py": [
        [
          "save_cropped_objects",
          170,
          224,
          204,
          15,
          206,
          7,
          203,
          9,
          222,
          57
        ]
      ],
      "models/official/projects/unified_detector/run_inference.py": [
        [
          "main",
          153,
          217,
          179,
          26,
          179,
          45,
          177,
          13,
          183,
          33
        ],
        [
          "inference",
          94,
          150,
          96,
          22,
          96,
          41,
          94,
          15,
          111,
          55
        ]
      ],
      "models/official/projects/waste_identification_ml/Triton_TF_Cloud_Deployment/client/triton_server_inference.py": [
        [
          "prepare_image",
          34,
          58,
          48,
          15,
          48,
          30,
          35,
          5,
          58,
          37
        ]
      ],
      "models/official/projects/unified_detector/data_conversion/utils.py": [
        [
          "convert_to_tfe",
          123,
          182,
          127,
          9,
          127,
          33,
          123,
          20,
          143,
          24
        ]
      ],
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/utils.py": [
        [
          "read_image",
          35,
          52,
          50,
          11,
          50,
          26,
          35,
          16,
          52,
          14
        ]
      ]
    },
    "xml.etree.ElementTree.parse": {
      "models/research/efficient-hrl/environments/maze_env.py": [
        [
          "__init__",
          37,
          234,
          57,
          12,
          57,
          29,
          56,
          16,
          88,
          20
        ]
      ],
      "models/research/slim/datasets/process_bounding_boxes.py": [
        [
          "ProcessXMLAnnotation",
          118,
          167,
          122,
          12,
          122,
          29,
          122,
          21,
          122,
          29
        ]
      ]
    }
  },
  "CWE-643": {},
  "CWE-760": {
    "hashlib.sha256": {
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_generate_examples",
          296,
          449,
          400,
          17,
          400,
          41,
          400,
          17,
          447,
          71
        ]
      ],
      "models/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py": [
        [
          "process",
          80,
          225,
          117,
          11,
          117,
          37,
          112,
          7,
          146,
          18
        ]
      ],
      "models/research/object_detection/dataset_tools/create_kitti_tf_record.py": [
        [
          "prepare_example",
          138,
          205,
          156,
          9,
          156,
          35,
          138,
          21,
          205,
          16
        ]
      ],
      "models/research/object_detection/dataset_tools/create_coco_tf_record.py": [
        [
          "create_tf_example",
          112,
          359,
          176,
          9,
          176,
          35,
          112,
          23,
          206,
          44
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pascal_tf_record.py": [
        [
          "dict_to_tf_example",
          59,
          144,
          93,
          9,
          93,
          35,
          93,
          9,
          107,
          21
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "dict_to_tf_example",
          76,
          211,
          115,
          9,
          115,
          35,
          115,
          9,
          121,
          25
        ]
      ],
      "models/research/slim/datasets/download_and_convert_visualwakewords_lib.py": [
        [
          "_create_tf_example",
          217,
          287,
          247,
          9,
          247,
          35,
          217,
          24,
          250,
          35
        ]
      ],
      "models/official/vision/data/tfrecord_lib.py": [
        [
          "image_info_to_feature_dict",
          89,
          103,
          93,
          9,
          93,
          35,
          89,
          32,
          103,
          3
        ]
      ]
    },
    "hashlib.md5": {
      "models/official/recommendation/data_test.py": [
        [
          "_test_end_to_end",
          135,
          257,
          167,
          11,
          167,
          23,
          146,
          5,
          168,
          39
        ],
        [
          "_test_end_to_end",
          135,
          257,
          218,
          11,
          218,
          23,
          193,
          5,
          219,
          29
        ],
        [
          "_test_fresh_randomness",
          259,
          344,
          283,
          11,
          283,
          23,
          280,
          5,
          284,
          35
        ]
      ]
    },
    "hashlib.sha1": {
      "models/official/nlp/tools/export_tfhub_lib.py": [
        [
          "_move_to_tmpdir",
          392,
          403,
          397,
          12,
          397,
          25,
          396,
          22,
          403,
          20
        ]
      ]
    },
    "uuid.uuid4": {
      "models/orbit/actions/new_best_metric.py": [
        [
          "write",
          213,
          222,
          219,
          46,
          219,
          57,
          219,
          22,
          222,
          70
        ]
      ]
    },
    "hashlib.blake2s": {
      "models/official/vision/data/tf_example_builder.py": [
        [
          "add_encoded_image_feature",
          83,
          154,
          142,
          26,
          142,
          55,
          142,
          22,
          143,
          21
        ]
      ]
    }
  },
  "CWE-918": {
    "pandas.read_csv": {
      "models/research/delf/delf/python/training/build_image_dataset.py": [
        [
          "_get_all_image_files_and_labels",
          98,
          124,
          117,
          12,
          117,
          32,
          116,
          10,
          119,
          10
        ],
        [
          "_get_clean_train_image_files_and_labels",
          127,
          175,
          144,
          10,
          144,
          30,
          127,
          45,
          148,
          29
        ]
      ],
      "models/research/object_detection/dataset_tools/create_oid_tf_record.py": [
        [
          "main",
          66,
          113,
          78,
          25,
          78,
          68,
          77,
          15,
          79,
          44
        ],
        [
          "main",
          66,
          113,
          80,
          29,
          80,
          80,
          80,
          29,
          82,
          69
        ]
      ],
      "models/official/recommendation/data_preprocessing.py": [
        [
          "read_dataframe",
          43,
          115,
          70,
          10,
          70,
          23,
          44,
          5,
          93,
          53
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "csv_to_joint_dataframe",
          254,
          263,
          258,
          14,
          258,
          45,
          254,
          28,
          263,
          11
        ],
        [
          "ratings_csv_to_dataframe",
          249,
          251,
          251,
          12,
          251,
          43,
          249,
          30,
          251,
          43
        ]
      ],
      "models/research/object_detection/metrics/oid_challenge_evaluation.py": [
        [
          "main",
          96,
          145,
          103,
          30,
          103,
          71,
          96,
          10,
          109,
          33
        ],
        [
          "main",
          96,
          145,
          104,
          27,
          104,
          69,
          96,
          10,
          109,
          33
        ],
        [
          "main",
          96,
          145,
          111,
          28,
          111,
          68,
          110,
          37,
          116,
          28
        ],
        [
          "main",
          96,
          145,
          125,
          21,
          125,
          56,
          118,
          21,
          127,
          69
        ]
      ],
      "models/research/object_detection/metrics/oid_vrd_challenge_evaluation.py": [
        [
          "main",
          80,
          120,
          102,
          21,
          102,
          62,
          102,
          21,
          103,
          73
        ],
        [
          "main",
          80,
          120,
          81,
          25,
          81,
          72,
          80,
          10,
          92,
          69
        ],
        [
          "main",
          80,
          120,
          82,
          27,
          82,
          75,
          80,
          10,
          92,
          69
        ]
      ]
    },
    "cv2.VideoCapture": {
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_generate_sequence_examples",
          171,
          294,
          222,
          19,
          222,
          44,
          216,
          11,
          225,
          25
        ],
        [
          "_generate_examples",
          296,
          449,
          346,
          19,
          346,
          44,
          340,
          11,
          350,
          26
        ]
      ]
    },
    "urllib.request.urlretrieve": {
      "models/research/object_detection/dataset_tools/create_ava_actions_tf_record.py": [
        [
          "_download_data",
          451,
          479,
          464,
          5,
          464,
          41,
          457,
          5,
          467,
          41
        ]
      ],
      "models/official/legacy/transformer/data_download.py": [
        [
          "download_from_url",
          151,
          175,
          167,
          30,
          168,
          66,
          164,
          16,
          172,
          19
        ]
      ],
      "models/research/slim/datasets/dataset_utils.py": [
        [
          "download_url",
          105,
          127,
          123,
          17,
          123,
          68,
          105,
          18,
          127,
          17
        ]
      ],
      "models/research/deep_speech/data/download.py": [
        [
          "download_and_extract",
          55,
          84,
          76,
          5,
          76,
          60,
          76,
          32,
          76,
          60
        ]
      ],
      "models/research/slim/datasets/download_and_convert_cifar10.py": [
        [
          "_download_and_uncompress_dataset",
          124,
          142,
          138,
          19,
          138,
          76,
          134,
          5,
          142,
          58
        ]
      ],
      "models/research/slim/datasets/download_and_convert_mnist.py": [
        [
          "_download_dataset",
          145,
          169,
          163,
          21,
          165,
          57,
          158,
          7,
          169,
          64
        ]
      ],
      "models/research/slim/datasets/imagenet.py": [
        [
          "create_readable_names_for_imagenet_labels",
          65,
          118,
          93,
          17,
          93,
          54,
          66,
          3,
          96,
          38
        ],
        [
          "create_readable_names_for_imagenet_labels",
          65,
          118,
          98,
          17,
          98,
          63,
          96,
          3,
          101,
          45
        ]
      ],
      "models/official/recommendation/movielens.py": [
        [
          "_download_and_clean",
          90,
          142,
          117,
          19,
          117,
          59,
          117,
          46,
          117,
          59
        ]
      ]
    },
    "requests.post": {
      "models/official/projects/waste_identification_ml/docker_solution/prediction_pipeline/predictor.py": [
        [
          "send_image_for_prediction",
          40,
          67,
          60,
          18,
          60,
          48,
          60,
          32,
          60,
          48
        ]
      ]
    },
    "urllib.parse.urlsplit": {
      "models/official/projects/nhnet/raw_data_processor.py": [
        [
          "normalize_url",
          113,
          123,
          116,
          9,
          116,
          34,
          113,
          21,
          118,
          31
        ]
      ]
    }
  },
  "CWE-943": {},
  "CWE-1333": {
    "re.match": {
      "models/official/legacy/detection/modeling/base_model.py": [
        [
          "listcomp",
          44,
          45,
          46,
          13,
          46,
          52,
          46,
          13,
          46,
          52
        ],
        [
          "listcomp",
          113,
          114,
          116,
          9,
          116,
          56,
          116,
          9,
          116,
          56
        ]
      ],
      "models/official/legacy/detection/modeling/checkpoint_utils.py": [
        [
          "_build_assignment_map",
          32,
          99,
          70,
          33,
          70,
          72,
          70,
          33,
          70,
          72
        ]
      ],
      "models/research/object_detection/dataset_tools/create_pet_tf_record.py": [
        [
          "get_class_name_from_filename",
          62,
          73,
          72,
          11,
          72,
          66,
          62,
          34,
          73,
          26
        ]
      ],
      "models/official/modeling/optimization/lamb.py": [
        [
          "_get_variable_name",
          247,
          252,
          249,
          9,
          249,
          43,
          247,
          26,
          250,
          20
        ]
      ],
      "models/official/modeling/hyperparams/params_dict.py": [
        [
          "nested_csv_str_to_json_str",
          352,
          452,
          427,
          8,
          427,
          45,
          427,
          8,
          427,
          45
        ]
      ],
      "models/official/nlp/tools/tokenization.py": [
        [
          "validate_case_matches_checkpoint",
          34,
          81,
          45,
          7,
          45,
          71,
          45,
          7,
          46,
          14
        ]
      ],
      "models/research/object_detection/utils/variables_helper.py": [
        [
          "filter_variables",
          48,
          74,
          69,
          10,
          69,
          39,
          68,
          9,
          69,
          39
        ]
      ]
    },
    "re.compile": {
      "models/official/nlp/metrics/bleu.py": [
        [
          "__init__",
          34,
          38,
          36,
          30,
          36,
          75,
          34,
          16,
          38,
          18
        ],
        [
          "__init__",
          34,
          38,
          37,
          30,
          37,
          75,
          34,
          16,
          38,
          18
        ],
        [
          "__init__",
          34,
          38,
          38,
          22,
          38,
          71,
          34,
          16,
          38,
          18
        ]
      ],
      "models/research/object_detection/metrics/coco_tools_test.py": [
        [
          "testExportGroundtruthToCOCO",
          81,
          103,
          100,
          17,
          100,
          75,
          81,
          35,
          103,
          52
        ],
        [
          "testExportDetectionsToCOCO",
          105,
          129,
          126,
          17,
          126,
          75,
          105,
          34,
          129,
          52
        ]
      ],
      "models/official/legacy/transformer/compute_bleu.py": [
        [
          "__init__",
          40,
          44,
          42,
          30,
          42,
          75,
          40,
          16,
          44,
          18
        ],
        [
          "__init__",
          40,
          44,
          43,
          30,
          43,
          75,
          40,
          16,
          44,
          18
        ],
        [
          "__init__",
          40,
          44,
          44,
          22,
          44,
          71,
          40,
          16,
          44,
          18
        ]
      ],
      "models/orbit/actions/export_saved_model.py": [
        [
          "_find_managed_files",
          40,
          45,
          42,
          24,
          42,
          66,
          40,
          25,
          45,
          39
        ]
      ],
      "models/research/attention_ocr/python/datasets/fsns.py": [
        [
          "read_charset",
          59,
          86,
          73,
          13,
          73,
          38,
          59,
          18,
          76,
          31
        ]
      ],
      "models/research/object_detection/utils/json_utils.py": [
        [
          "FormatFloat",
          24,
          29,
          25,
          13,
          25,
          35,
          24,
          17,
          29,
          42
        ]
      ],
      "models/research/object_detection/metrics/lvis_evaluation.py": [
        [
          "dump_detections_to_json_file",
          446,
          463,
          454,
          17,
          454,
          42,
          453,
          29,
          463,
          39
        ]
      ],
      "models/official/projects/triviaqa/preprocess.py": [
        [
          "find_answer_spans",
          171,
          184,
          175,
          20,
          177,
          28,
          174,
          7,
          178,
          48
        ]
      ],
      "models/official/nlp/tools/squad_evaluate_v2_0.py": [
        [
          "remove_articles",
          44,
          46,
          45,
          13,
          45,
          53,
          44,
          23,
          46,
          35
        ]
      ],
      "models/official/legacy/xlnet/squad_utils.py": [
        [
          "remove_articles",
          113,
          115,
          114,
          13,
          114,
          53,
          113,
          23,
          115,
          35
        ]
      ]
    },
    "re.sub": {
      "models/official/projects/videoglue/tools/checkpoint_loader.py": [
        [
          "_remap_variable_name",
          110,
          116,
          115,
          23,
          115,
          57,
          114,
          9,
          115,
          19
        ]
      ],
      "models/research/cvt_text/base/embeddings.py": [
        [
          "normalize_word",
          166,
          167,
          167,
          10,
          167,
          55,
          166,
          20,
          167,
          55
        ]
      ],
      "models/official/projects/triviaqa/evaluation.py": [
        [
          "remove_articles",
          30,
          31,
          31,
          12,
          31,
          47,
          30,
          23,
          31,
          47
        ]
      ],
      "models/research/object_detection/utils/json_utils.py": [
        [
          "FormatFloat",
          24,
          29,
          29,
          10,
          29,
          42,
          24,
          17,
          29,
          42
        ]
      ],
      "models/research/object_detection/metrics/lvis_evaluation.py": [
        [
          "dump_detections_to_json_file",
          446,
          463,
          460,
          19,
          460,
          54,
          453,
          29,
          463,
          39
        ]
      ],
      "models/research/object_detection/metrics/offline_eval_map_corloc.py": [
        [
          "listcomp",
          61,
          62,
          62,
          9,
          62,
          73,
          63,
          13,
          62,
          73
        ]
      ],
      "models/official/nlp/tools/squad_evaluate_v1_1.py": [
        [
          "remove_articles",
          39,
          40,
          40,
          12,
          40,
          47,
          39,
          23,
          40,
          47
        ]
      ],
      "models/official/nlp/tools/squad_evaluate_v2_0.py": [
        [
          "remove_articles",
          44,
          46,
          46,
          12,
          46,
          35,
          44,
          23,
          46,
          35
        ]
      ],
      "models/official/legacy/xlnet/squad_utils.py": [
        [
          "remove_articles",
          113,
          115,
          115,
          12,
          115,
          35,
          113,
          23,
          115,
          35
        ]
      ]
    },
    "str.startswith": {
      "models/official/nlp/data/create_xlnet_pretraining_data.py": [
        [
          "_is_functional_piece",
          341,
          342,
          342,
          31,
          342,
          51,
          342,
          31,
          342,
          51
        ],
        [
          "_is_start_piece",
          345,
          350,
          347,
          7,
          347,
          27,
          345,
          21,
          347,
          27
        ]
      ],
      "models/orbit/actions/export_saved_model.py": [
        [
          "safe_normpath",
          28,
          32,
          30,
          6,
          30,
          32,
          28,
          19,
          30,
          32
        ]
      ]
    },
    "str.endswith": {
      "models/official/nlp/data/create_xlnet_pretraining_data.py": [
        [
          "_is_functional_piece",
          341,
          342,
          342,
          57,
          342,
          75,
          342,
          57,
          342,
          75
        ]
      ]
    },
    "re.split": {
      "models/research/adversarial_text/data/data_utils.py": [
        [
          "split_by_punct",
          307,
          309,
          309,
          22,
          309,
          46,
          307,
          20,
          309,
          72
        ]
      ],
      "models/research/vid2depth/dataset/dataset_loader.py": [
        [
          "natural_keys",
          611,
          612,
          612,
          28,
          612,
          51,
          611,
          18,
          612,
          52
        ]
      ],
      "models/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch.py": [
        [
          "restore_map",
          219,
          296,
          267,
          13,
          267,
          72,
          267,
          13,
          266,
          16
        ],
        [
          "restore_map",
          219,
          296,
          267,
          13,
          267,
          72,
          267,
          13,
          271,
          35
        ]
      ]
    },
    "re.search": {
      "models/research/object_detection/eval_util.py": [
        [
          "_run_checkpoint_once",
          246,
          412,
          403,
          13,
          403,
          60,
          403,
          13,
          404,
          16
        ]
      ],
      "models/research/lstm_object_detection/builders/graph_rewriter_builder.py": [
        [
          "_get_context_from_op",
          92,
          97,
          94,
          16,
          94,
          51,
          92,
          26,
          95,
          15
        ]
      ],
      "models/official/modeling/optimization/lamb.py": [
        [
          "_do_use_weight_decay",
          231,
          237,
          235,
          12,
          235,
          35,
          234,
          11,
          235,
          47
        ],
        [
          "_do_layer_adaptation",
          239,
          245,
          243,
          12,
          243,
          35,
          242,
          11,
          243,
          47
        ]
      ],
      "models/official/modeling/optimization/lars.py": [
        [
          "_do_layer_adaptation",
          163,
          169,
          167,
          12,
          167,
          35,
          166,
          11,
          167,
          47
        ],
        [
          "_use_weight_decay",
          153,
          161,
          159,
          12,
          159,
          35,
          158,
          11,
          159,
          47
        ]
      ],
      "models/official/modeling/optimization/legacy_adamw.py": [
        [
          "_do_use_weight_decay",
          125,
          139,
          132,
          12,
          132,
          35,
          131,
          11,
          132,
          47
        ],
        [
          "_do_use_weight_decay",
          125,
          139,
          137,
          12,
          137,
          35,
          136,
          11,
          137,
          47
        ]
      ],
      "models/research/object_detection/metrics/offline_eval_map_corloc.py": [
        [
          "_generate_sharded_filenames",
          57,
          66,
          58,
          7,
          58,
          39,
          57,
          33,
          59,
          6
        ]
      ],
      "models/research/lfads/run_lfads.py": [
        [
          "build_model",
          407,
          472,
          463,
          22,
          463,
          70,
          463,
          22,
          463,
          18
        ]
      ],
      "models/official/core/savedmodel_checkpoint_manager.py": [
        [
          "get_savedmodel_number_from_path",
          147,
          164,
          160,
          25,
          160,
          59,
          147,
          39,
          161,
          24
        ]
      ],
      "models/official/projects/yolo/optimization/sgd_torch.py": [
        [
          "_search",
          132,
          139,
          137,
          12,
          137,
          33,
          136,
          11,
          137,
          45
        ]
      ],
      "models/official/legacy/xlnet/training_utils.py": [
        [
          "_replicated_step",
          148,
          185,
          168,
          15,
          168,
          74,
          167,
          13,
          169,
          18
        ]
      ]
    },
    "re.escape": {
      "models/orbit/actions/export_saved_model.py": [
        [
          "_find_managed_files",
          40,
          45,
          42,
          39,
          42,
          58,
          40,
          25,
          45,
          39
        ]
      ],
      "models/official/projects/triviaqa/preprocess.py": [
        [
          "find_answer_spans",
          171,
          184,
          176,
          9,
          176,
          25,
          174,
          7,
          178,
          48
        ]
      ]
    },
    "re.finditer": {
      "models/official/projects/triviaqa/preprocess.py": [
        [
          "find_answer_spans",
          171,
          184,
          178,
          18,
          178,
          48,
          174,
          7,
          178,
          48
        ]
      ]
    }
  }
}